Calculators\STDA_calculator.py:1:1: N999 Invalid module name: 'STDA_calculator'
Calculators\STDA_calculator.py:42:7: N801 Class name `sTDA_XTB` should use CapWords convention
   |
42 | class sTDA_XTB:
   |       ^^^^^^^^ N801
43 |     """A class to calculate the excited state properties using sTDA method from xtb output.
   |

Calculators\STDA_calculator.py:65:9: D417 Missing argument descriptions in the docstring for `__init__`: `maxev_excitedenergy`, `num_threads`, `stda_bin_path`
   |
63 |     """
64 | 
65 |     def __init__(
   |         ^^^^^^^^ D417
66 |         self,
67 |         stda_bin_path,
   |

Calculators\STDA_calculator.py:126:9: S603 `subprocess` call: check for execution of untrusted input
    |
124 |         env["PATH"] = env["PATH"] + ":" + Path(self.stda_bin_path) / "exe"
125 | 
126 |         sp.call(
    |         ^^^^^^^ S603
127 |             ["xtb4stda", xyz, ">", "gen_wfn.out"],
128 |             stdout=sp.DEVNULL,
    |

Calculators\STDA_calculator.py:127:13: S607 Starting a process with a partial executable path
    |
126 |         sp.call(
127 |             ["xtb4stda", xyz, ">", "gen_wfn.out"],
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ S607
128 |             stdout=sp.DEVNULL,
129 |             stderr=sp.STDOUT,
    |

Calculators\STDA_calculator.py:132:9: S603 `subprocess` call: check for execution of untrusted input
    |
130 |             env=env,
131 |         )
132 |         sp.call(
    |         ^^^^^^^ S603
133 |             ["stda_v1.6.2", "-xtb", "-e", str(self.maxev_excitedenergy), ">", "out_stda.out"],
134 |             stdout=sp.DEVNULL,
    |

Calculators\STDA_calculator.py:133:13: S607 Starting a process with a partial executable path
    |
131 |         )
132 |         sp.call(
133 |             ["stda_v1.6.2", "-xtb", "-e", str(self.maxev_excitedenergy), ">", "out_stda.out"],
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ S607
134 |             stdout=sp.DEVNULL,
135 |             stderr=sp.STDOUT,
    |

Calculators\XTBcalculator.py:1:1: N999 Invalid module name: 'XTBcalculator'
Calculators\XTBcalculator.py:1:1: D100 Missing docstring in public module
Calculators\XTBcalculator.py:9:7: D101 Missing docstring in public class
   |
 9 | class XTBEnergy2(stko.XTBEnergy):
   |       ^^^^^^^^^^ D101
10 |     def _run_xtb(self, xyz, out_file, init_dir, output_dir) -> None:
11 |         """Runs GFN-xTB.
   |

Calculators\XTBcalculator.py:11:9: D401 First line of docstring should be in imperative mood: "Runs GFN-xTB."
   |
 9 |   class XTBEnergy2(stko.XTBEnergy):
10 |       def _run_xtb(self, xyz, out_file, init_dir, output_dir) -> None:
11 |           """Runs GFN-xTB.
   |  _________^
12 | | 
13 | |         Parameters
14 | |         ----------
15 | |         xyz : :class:`str`
16 | |             The name of the input structure ``.xyz`` file.
17 | | 
18 | |         out_file : :class:`str`
19 | |             The name of output file with xTB results.
20 | | 
21 | |         init_dir : :class:`str`
22 | |             The name of the current working directory.
23 | | 
24 | |         output_dir : :class:`str`
25 | |             The name of the directory into which files generated during
26 | |             the calculation are written.
27 | | 
28 | |         Returns
29 | |         -------
30 | |         None : :class:`NoneType`
31 | | 
32 | |         """
   | |___________^ D401
33 |           # Modify the memory limit.
34 |           memory = "ulimit -s unlimited ;" if self._unlimited_memory else ""
   |

Calculators\XTBcalculator.py:53:9: ERA001 Found commented-out code
   |
51 |             f"--uhf {self._num_unpaired_electrons} -I det_control.in"
52 |         )
53 |         # print(cmd)
   |         ^^^^^^^^^^^^ ERA001
54 |         try:
55 |             os.chdir(output_dir)
   |
   = help: Remove commented-out code

Calculators\XTBcalculator.py:57:18: PTH123 `open()` should be replaced by `Path.open()`
   |
55 |             os.chdir(output_dir)
56 |             self._write_detailed_control()
57 |             with open(out_file, "w") as f:
   |                  ^^^^ PTH123
58 |                 # Note that sp.call will hold the program until
59 |                 # completion of the calculation.
   |

Calculators\XTBcalculator.py:60:17: S602 `subprocess` call with `shell=True` identified, security issue
   |
58 |                 # Note that sp.call will hold the program until
59 |                 # completion of the calculation.
60 |                 sp.call(
   |                 ^^^^^^^ S602
61 |                     cmd,
62 |                     stdin=sp.PIPE,
   |

Calculators\XTBcalculator.py:71:9: D102 Missing docstring in public method
   |
69 |             os.chdir(init_dir)
70 | 
71 |     def calculate(self, mol):
   |         ^^^^^^^^^ D102
72 |         if self._output_dir is None:
73 |             output_dir = str(uuid.uuid4().int)
   |

Calculators\XTBcalculator.py:76:9: ERA001 Found commented-out code
   |
74 |         else:
75 |             output_dir = self._output_dir
76 |         # output_dir = os.path.abspath(output_dir)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
77 | 
78 |         if os.path.exists(output_dir):
   |
   = help: Remove commented-out code

Calculators\XTBcalculator.py:78:12: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   |
76 |         # output_dir = os.path.abspath(output_dir)
77 | 
78 |         if os.path.exists(output_dir):
   |            ^^^^^^^^^^^^^^ PTH110
79 |             shutil.rmtree(output_dir)
80 |         os.mkdir(output_dir)
   |

Calculators\XTBcalculator.py:80:9: PTH102 `os.mkdir()` should be replaced by `Path.mkdir()`
   |
78 |         if os.path.exists(output_dir):
79 |             shutil.rmtree(output_dir)
80 |         os.mkdir(output_dir)
   |         ^^^^^^^^ PTH102
81 | 
82 |         init_dir = os.getcwd()
   |

Calculators\XTBcalculator.py:82:20: PTH109 `os.getcwd()` should be replaced by `Path.cwd()`
   |
80 |         os.mkdir(output_dir)
81 | 
82 |         init_dir = os.getcwd()
   |                    ^^^^^^^^^ PTH109
83 |         xyz = os.path.join(output_dir, "input_structure.xyz")
84 |         out_file = os.path.join("energy.output")
   |

Calculators\XTBcalculator.py:83:15: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   |
82 |         init_dir = os.getcwd()
83 |         xyz = os.path.join(output_dir, "input_structure.xyz")
   |               ^^^^^^^^^^^^ PTH118
84 |         out_file = os.path.join("energy.output")
85 |         mol.write(xyz)
   |

Calculators\XTBcalculator.py:84:20: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   |
82 |         init_dir = os.getcwd()
83 |         xyz = os.path.join(output_dir, "input_structure.xyz")
84 |         out_file = os.path.join("energy.output")
   |                    ^^^^^^^^^^^^ PTH118
85 |         mol.write(xyz)
86 |         xyz = os.path.join("input_structure.xyz")
   |

Calculators\XTBcalculator.py:86:15: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   |
84 |         out_file = os.path.join("energy.output")
85 |         mol.write(xyz)
86 |         xyz = os.path.join("input_structure.xyz")
   |               ^^^^^^^^^^^^ PTH118
87 | 
88 |         yield self._run_xtb(
   |

Calculators\XTBcalculator.py:113:22: PTH100 `os.path.abspath()` should be replaced by `Path.resolve()`
    |
111 |         else:
112 |             output_dir = self._output_dir
113 |         output_dir = os.path.abspath(output_dir)
    |                      ^^^^^^^^^^^^^^^ PTH100
114 | 
115 |         out_file = os.path.join(output_dir, "energy.output")
    |

Calculators\XTBcalculator.py:115:20: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
113 |         output_dir = os.path.abspath(output_dir)
114 | 
115 |         out_file = os.path.join(output_dir, "energy.output")
    |                    ^^^^^^^^^^^^ PTH118
116 | 
117 |         return stko.XTBResults(
    |

Calculators\__init__.py:1:1: D104 Missing docstring in public package
Objective_function.py:1:1: N999 Invalid module name: 'Objective_function'
Objective_function.py:1:1: D100 Missing docstring in public module
Objective_function.py:14:5: D103 Missing docstring in public function
   |
14 | def get_inchi_key(molecule):
   |     ^^^^^^^^^^^^^ D103
15 |     return stk.InchiKey().get_key(molecule)
   |

Objective_function.py:18:7: N801 Class name `Objective_Function` should use CapWords convention
   |
18 | class Objective_Function:
   |       ^^^^^^^^^^^^^^^^^^ N801
19 |     """Base class for objective functions
20 |     The objective function is the function that will be used to evaluate the fitness of the molecules in the search.
   |

Objective_function.py:19:5: D205 1 blank line required between summary line and description
   |
18 |   class Objective_Function:
19 |       """Base class for objective functions
   |  _____^
20 | |     The objective function is the function that will be used to evaluate the fitness of the molecules in the search.
21 | | 
22 | |     Functions
23 | |     ---------
24 | |     evaluate_element(element, multiFidelity=False)
25 | |         Evaluates the fitness of the element
26 | |         takes as an input a list of building blocks and returns the fitness of the element
27 | | 
28 | |     """
   | |_______^ D205
29 |   
30 |       def __init__(self):
   |
   = help: Insert single blank line

Objective_function.py:31:9: D401 First line of docstring should be in imperative mood: "Initialises the objective function."
   |
30 |     def __init__(self):
31 |         """Initialises the objective function."""
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
32 | 
33 |     def evaluate_element(self, element, multiFidelity=False):
   |

Objective_function.py:33:9: D417 Missing argument descriptions in the docstring for `evaluate_element`: `element`, `multiFidelity`
   |
31 |         """Initialises the objective function."""
32 | 
33 |     def evaluate_element(self, element, multiFidelity=False):
   |         ^^^^^^^^^^^^^^^^ D417
34 |         """Evaluates the fitness of the element
35 |         takes as an input a list of building blocks and returns the fitness of the element.
   |

Objective_function.py:33:41: FBT002 Boolean default positional argument in function definition
   |
31 |         """Initialises the objective function."""
32 | 
33 |     def evaluate_element(self, element, multiFidelity=False):
   |                                         ^^^^^^^^^^^^^ FBT002
34 |         """Evaluates the fitness of the element
35 |         takes as an input a list of building blocks and returns the fitness of the element.
   |

Objective_function.py:33:41: N803 Argument name `multiFidelity` should be lowercase
   |
31 |         """Initialises the objective function."""
32 | 
33 |     def evaluate_element(self, element, multiFidelity=False):
   |                                         ^^^^^^^^^^^^^ N803
34 |         """Evaluates the fitness of the element
35 |         takes as an input a list of building blocks and returns the fitness of the element.
   |

Objective_function.py:33:41: ARG002 Unused method argument: `multiFidelity`
   |
31 |         """Initialises the objective function."""
32 | 
33 |     def evaluate_element(self, element, multiFidelity=False):
   |                                         ^^^^^^^^^^^^^ ARG002
34 |         """Evaluates the fitness of the element
35 |         takes as an input a list of building blocks and returns the fitness of the element.
   |

Objective_function.py:34:9: D205 1 blank line required between summary line and description
   |
33 |       def evaluate_element(self, element, multiFidelity=False):
34 |           """Evaluates the fitness of the element
   |  _________^
35 | |         takes as an input a list of building blocks and returns the fitness of the element.
36 | | 
37 | |         Parameters
38 | |         ----------
39 | |             element: list
40 | |             list of building blocks
41 | |             multiFidelity: bool
42 | |             if True, the function will return the fitness and the fidelity of the element
43 | | 
44 | |         Returns
45 | |         -------
46 | |             float
47 | |             the fitness of the element
48 | |             str
49 | |             the identifier of the element
50 | | 
51 | |         """
   | |___________^ D205
52 |           for x in element:
53 |               if type(x) == int or type(x) == np.float64:
   |
   = help: Insert single blank line

Objective_function.py:34:9: D401 First line of docstring should be in imperative mood: "Evaluates the fitness of the element"
   |
33 |       def evaluate_element(self, element, multiFidelity=False):
34 |           """Evaluates the fitness of the element
   |  _________^
35 | |         takes as an input a list of building blocks and returns the fitness of the element.
36 | | 
37 | |         Parameters
38 | |         ----------
39 | |             element: list
40 | |             list of building blocks
41 | |             multiFidelity: bool
42 | |             if True, the function will return the fitness and the fidelity of the element
43 | | 
44 | |         Returns
45 | |         -------
46 | |             float
47 | |             the fitness of the element
48 | |             str
49 | |             the identifier of the element
50 | | 
51 | |         """
   | |___________^ D401
52 |           for x in element:
53 |               if type(x) == int or type(x) == np.float64:
   |

Objective_function.py:53:16: E721 Use `is` and `is not` for type comparisons, or `isinstance()` for isinstance checks
   |
51 |         """
52 |         for x in element:
53 |             if type(x) == int or type(x) == np.float64:
   |                ^^^^^^^^^^^^^^ E721
54 |                 return float(x), "test"
55 |         return None
   |

Objective_function.py:53:34: E721 Use `is` and `is not` for type comparisons, or `isinstance()` for isinstance checks
   |
51 |         """
52 |         for x in element:
53 |             if type(x) == int or type(x) == np.float64:
   |                                  ^^^^^^^^^^^^^^^^^^^^^ E721
54 |                 return float(x), "test"
55 |         return None
   |

Objective_function.py:58:7: N801 Class name `Look_up_table` should use CapWords convention
   |
58 | class Look_up_table:
   |       ^^^^^^^^^^^^^ N801
59 |     """Class for look up table objective functions
60 |     The look up table objective function is used to evaluate the fitness of the elements by looking up the fitness in a database.
   |

Objective_function.py:59:5: D205 1 blank line required between summary line and description
   |
58 |   class Look_up_table:
59 |       """Class for look up table objective functions
   |  _____^
60 | |     The look up table objective function is used to evaluate the fitness of the elements by looking up the fitness in a database.
61 | | 
62 | |     """
   | |_______^ D205
63 |   
64 |       def __init__(self, df_look_up, fragment_size, target_name="target", aim=0):
   |
   = help: Insert single blank line

Objective_function.py:64:9: D417 Missing argument descriptions in the docstring for `__init__`: `aim`, `df_look_up`, `fragment_size`, `target_name`
   |
62 |     """
63 | 
64 |     def __init__(self, df_look_up, fragment_size, target_name="target", aim=0):
   |         ^^^^^^^^ D417
65 |         """Initialises the look up table objective function.
   |

Objective_function.py:65:9: D401 First line of docstring should be in imperative mood: "Initialises the look up table objective function."
   |
64 |       def __init__(self, df_look_up, fragment_size, target_name="target", aim=0):
65 |           """Initialises the look up table objective function.
   |  _________^
66 | | 
67 | |         Parameters
68 | |         ----------
69 | |             df_look_up: pd.DataFrame
70 | |             the dataframe containing the look up table
71 | |             the dataframe should contain the InChIKeys of the fragments in the form of 'InChIKey_0', 'InChIKey_1', etc.
72 | |             and the target column
73 | |             and the InChIKeys of the molecule
74 | | 
75 | |             fragment_size: int
76 | |             the size of the fragments
77 | | 
78 | |             target_name: str
79 | |             the name of the target column
80 | | 
81 | |             aim: int or float
82 | |             the aim of the fitness function
83 | |             if the aim is an int, the fitness function will be the negative absolute difference between the target and the aim
84 | | 
85 | |         """
   | |___________^ D401
86 |           self.df_look_up = df_look_up
87 |           self.fragment_size = fragment_size
   |

Objective_function.py:93:9: D401 First line of docstring should be in imperative mood: "Checks the database."
   |
92 |     def check_database(self):
93 |         """Checks the database."""
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
94 |         if self.df_look_up is None:
95 |             msg = "No database found"
   |

Objective_function.py:109:9: D417 Missing argument descriptions in the docstring for `evaluate_element`: `element`, `multiFidelity`
    |
107 |             )
108 | 
109 |     def evaluate_element(self, element, multiFidelity=False):
    |         ^^^^^^^^^^^^^^^^ D417
110 |         """Evaluates the fitness of the element
111 |         takes as an input a list of building blocks and returns the fitness of the element.
    |

Objective_function.py:109:41: FBT002 Boolean default positional argument in function definition
    |
107 |             )
108 | 
109 |     def evaluate_element(self, element, multiFidelity=False):
    |                                         ^^^^^^^^^^^^^ FBT002
110 |         """Evaluates the fitness of the element
111 |         takes as an input a list of building blocks and returns the fitness of the element.
    |

Objective_function.py:109:41: N803 Argument name `multiFidelity` should be lowercase
    |
107 |             )
108 | 
109 |     def evaluate_element(self, element, multiFidelity=False):
    |                                         ^^^^^^^^^^^^^ N803
110 |         """Evaluates the fitness of the element
111 |         takes as an input a list of building blocks and returns the fitness of the element.
    |

Objective_function.py:110:9: D205 1 blank line required between summary line and description
    |
109 |       def evaluate_element(self, element, multiFidelity=False):
110 |           """Evaluates the fitness of the element
    |  _________^
111 | |         takes as an input a list of building blocks and returns the fitness of the element.
112 | | 
113 | |         Parameters
114 | |         ----------
115 | |             element: list
116 | |             list of building blocks
117 | |             multiFidelity: bool
118 | |             if True, the function will return the fitness and the fidelity of the element
119 | | 
120 | |         Returns
121 | |         -------
122 | |             float
123 | |             the fitness of the element
124 | |             str
125 | |             the identifier of the element in the form of an InChIKey
126 | | 
127 | |         """
    | |___________^ D205
128 |           columns = [f"InChIKey_{i}" for i in range(self.fragment_size)]
129 |           if multiFidelity:
    |
    = help: Insert single blank line

Objective_function.py:110:9: D401 First line of docstring should be in imperative mood: "Evaluates the fitness of the element"
    |
109 |       def evaluate_element(self, element, multiFidelity=False):
110 |           """Evaluates the fitness of the element
    |  _________^
111 | |         takes as an input a list of building blocks and returns the fitness of the element.
112 | | 
113 | |         Parameters
114 | |         ----------
115 | |             element: list
116 | |             list of building blocks
117 | |             multiFidelity: bool
118 | |             if True, the function will return the fitness and the fidelity of the element
119 | | 
120 | |         Returns
121 | |         -------
122 | |             float
123 | |             the fitness of the element
124 | |             str
125 | |             the identifier of the element in the form of an InChIKey
126 | | 
127 | |         """
    | |___________^ D401
128 |           columns = [f"InChIKey_{i}" for i in range(self.fragment_size)]
129 |           if multiFidelity:
    |

Objective_function.py:150:7: N801 Class name `IP_ES1_fosc` should use CapWords convention
    |
150 | class IP_ES1_fosc(Objective_Function):
    |       ^^^^^^^^^^^ N801
151 |     """Class for the IP_ES1_fosc objective function
152 |     The IP_ES1_fosc objective function is used to evaluate the fitness of the molecules by calculating the ionisation potential,
    |

Objective_function.py:151:5: D205 1 blank line required between summary line and description
    |
150 |   class IP_ES1_fosc(Objective_Function):
151 |       """Class for the IP_ES1_fosc objective function
    |  _____^
152 | |     The IP_ES1_fosc objective function is used to evaluate the fitness of the molecules by calculating the ionisation potential,
153 | |     the first excited state energy and the first excited state oscillator strength.
154 | |     The fitness function is defined as:
155 | |     -np.abs(IP - 5.5) - 0.5 * np.abs(Es1 - 3) + np.log10
156 | |     where IP is the ionisation potential, Es1 is the first excited state energy and fosc_1 is the first excited state oscillator strength
157 | |     Here the quantum chemical calculation are done using xtb and stda.
158 | | 
159 | |     Functions
160 | |     ---------
161 | |     evaluate_element(element, multiFidelity=False)
162 | |         Evaluates the fitness of the element
163 | |         takes as an input a list of building blocks and returns the fitness of the element
164 | | 
165 | |     Build_polymer(element, db)
166 | |         Builds the polymer from the building blocks
167 | |         takes as an input a list of building blocks and a database containing the building blocks
168 | |         returns the polymer
169 | |     run_xtb_opt(polymer, xtb_path, xtb_opt_output_dir, database, collection, client)
170 | |         Runs the xtb optimisation of the polymer
171 | |         takes as an input the polymer, the path to xtb, the output directory, the database and collection name and the client
172 | |         returns the optimised polymer
173 | |     run_xtb_ipea(polymer, xtb_path, xtb_opt_output_dir, database, collection, target, client)
174 | |         Runs the xtb calculation of the ionisation potential
175 | |         takes as an input the polymer, the path to xtb, the output directory, the database and collection name, the target and the client
176 | |         returns the ionisation potential
177 | |     run_stda(polymer, STDA_bin_path, output_dir, property, state, database, collection, client)
178 | |         Runs the stda calculation of the excited state energy and oscillator strength
179 | |         takes as an input the polymer, the path to stda, the output directory, the property, the state, the database and collection name and the client
180 | |         returns the excited state energy or oscillator strength
181 | | 
182 | | 
183 | | 
184 | |     """
    | |_______^ D205
185 |   
186 |       def __init__(
    |
    = help: Insert single blank line

Objective_function.py:186:9: PLR0913 Too many arguments in function definition (9 > 5)
    |
184 |     """
185 | 
186 |     def __init__(
    |         ^^^^^^^^ PLR0913
187 |         self,
188 |         oligomer_size,
    |

Objective_function.py:186:9: D417 Missing argument descriptions in the docstring for `__init__`: `Db_folder`, `STDA_bin_path`, `client`, `collection_name`, `database_new_calc`, `db_mol`, `host_IP`, `oligomer_size`, `xtb_path`
    |
184 |     """
185 | 
186 |     def __init__(
    |         ^^^^^^^^ D417
187 |         self,
188 |         oligomer_size,
    |

Objective_function.py:192:9: N803 Argument name `STDA_bin_path` should be lowercase
    |
190 |         db_mol="stk_mohammed",
191 |         xtb_path="/rds/general/user/ma11115/home/anaconda3/envs/ML/bin/xtb",
192 |         STDA_bin_path="/rds/general/user/ma11115/home/bin/stda_files/xtb4stda/",
    |         ^^^^^^^^^^^^^ N803
193 |         Db_folder="/rds/general/ephemeral/user/ma11115/ephemeral/BO_polymers",
194 |         database_new_calc="stk_mohammed_BO",
    |

Objective_function.py:193:9: N803 Argument name `Db_folder` should be lowercase
    |
191 |         xtb_path="/rds/general/user/ma11115/home/anaconda3/envs/ML/bin/xtb",
192 |         STDA_bin_path="/rds/general/user/ma11115/home/bin/stda_files/xtb4stda/",
193 |         Db_folder="/rds/general/ephemeral/user/ma11115/ephemeral/BO_polymers",
    |         ^^^^^^^^^ N803
194 |         database_new_calc="stk_mohammed_BO",
195 |         collection_name=None,
    |

Objective_function.py:196:9: N803 Argument name `host_IP` should be lowercase
    |
194 |         database_new_calc="stk_mohammed_BO",
195 |         collection_name=None,
196 |         host_IP="cx1",
    |         ^^^^^^^ N803
197 |     ):
198 |         """Initialises the IP_ES1_fosc objective function.
    |

Objective_function.py:198:9: D401 First line of docstring should be in imperative mood: "Initialises the IP_ES1_fosc objective function."
    |
196 |           host_IP="cx1",
197 |       ):
198 |           """Initialises the IP_ES1_fosc objective function.
    |  _________^
199 | | 
200 | |         Parameters
201 | |         ----------
202 | |             oligomer_size: int
203 | |             the size of the oligomer
204 | |             client: str
205 | |             the path to the mongodb client
206 | |             db_mol: str
207 | |             the name of the database containing the building blocks
208 | |             the database should contain the building blocks position matrix and the InChIKey
209 | |             It is normally generated using stk and the stk.MoleculeMongoDb class
210 | |             xtb_path: str
211 | |             the path to the xtb executable
212 | |             STDA_bin_path: str
213 | |             the path to the stda executable
214 | |             Db_folder: str
215 | |             the path to the output directory
216 | |             database_new_calc: str
217 | |             the name of the database containing the new calculations
218 | |             collection_name: str
219 | |             the name of the collection
220 | |             host_IP: str
221 | |             the host IP
222 | | 
223 | |         """
    | |___________^ D401
224 |           self.client = client
225 |           self.db_mol = db_mol
    |

Objective_function.py:229:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
    |
227 |         self.STDA_bin_path = STDA_bin_path
228 |         self.Db_folder = Db_folder
229 |         os.makedirs(self.Db_folder, exist_ok=True)
    |         ^^^^^^^^^^^ PTH103
230 |         self.database_new_calc = database_new_calc
231 |         self.collection_name = collection_name
    |

Objective_function.py:247:9: S110 `try`-`except`-`pass` detected, consider logging the exception
    |
245 |                   database=self.db_mol,
246 |               )
247 |           except Exception:
    |  _________^
248 | |             pass
    | |________________^ S110
249 |   
250 |       def test_xtb_stda_connection(self):
    |

Objective_function.py:247:16: BLE001 Do not catch blind exception: `Exception`
    |
245 |                 database=self.db_mol,
246 |             )
247 |         except Exception:
    |                ^^^^^^^^^ BLE001
248 |             pass
    |

Objective_function.py:253:13: S605 Starting a process with a shell, possible injection detected
    |
251 |         """Tests the connection to xtb and stda."""
252 |         try:
253 |             os.system(self.xtb_path + " --version")
    |             ^^^^^^^^^ S605
254 |             os.system(self.STDA_bin_path + " --version")
255 |         except Exception:
    |

Objective_function.py:254:13: S605 Starting a process with a shell, possible injection detected
    |
252 |         try:
253 |             os.system(self.xtb_path + " --version")
254 |             os.system(self.STDA_bin_path + " --version")
    |             ^^^^^^^^^ S605
255 |         except Exception:
256 |             pass
    |

Objective_function.py:255:9: S110 `try`-`except`-`pass` detected, consider logging the exception
    |
253 |               os.system(self.xtb_path + " --version")
254 |               os.system(self.STDA_bin_path + " --version")
255 |           except Exception:
    |  _________^
256 | |             pass
    | |________________^ S110
257 |   
258 |       def evaluate_element(self, element, multiFidelity=False):
    |

Objective_function.py:255:16: BLE001 Do not catch blind exception: `Exception`
    |
253 |             os.system(self.xtb_path + " --version")
254 |             os.system(self.STDA_bin_path + " --version")
255 |         except Exception:
    |                ^^^^^^^^^ BLE001
256 |             pass
    |

Objective_function.py:258:9: D417 Missing argument descriptions in the docstring for `evaluate_element`: `element`, `multiFidelity`
    |
256 |             pass
257 | 
258 |     def evaluate_element(self, element, multiFidelity=False):
    |         ^^^^^^^^^^^^^^^^ D417
259 |         """Evaluates the fitness of the element
260 |         takes as an input a list of building blocks and returns the fitness of the element
    |

Objective_function.py:258:41: FBT002 Boolean default positional argument in function definition
    |
256 |             pass
257 | 
258 |     def evaluate_element(self, element, multiFidelity=False):
    |                                         ^^^^^^^^^^^^^ FBT002
259 |         """Evaluates the fitness of the element
260 |         takes as an input a list of building blocks and returns the fitness of the element
    |

Objective_function.py:258:41: N803 Argument name `multiFidelity` should be lowercase
    |
256 |             pass
257 | 
258 |     def evaluate_element(self, element, multiFidelity=False):
    |                                         ^^^^^^^^^^^^^ N803
259 |         """Evaluates the fitness of the element
260 |         takes as an input a list of building blocks and returns the fitness of the element
    |

Objective_function.py:258:41: ARG002 Unused method argument: `multiFidelity`
    |
256 |             pass
257 | 
258 |     def evaluate_element(self, element, multiFidelity=False):
    |                                         ^^^^^^^^^^^^^ ARG002
259 |         """Evaluates the fitness of the element
260 |         takes as an input a list of building blocks and returns the fitness of the element
    |

Objective_function.py:259:9: D205 1 blank line required between summary line and description
    |
258 |       def evaluate_element(self, element, multiFidelity=False):
259 |           """Evaluates the fitness of the element
    |  _________^
260 | |         takes as an input a list of building blocks and returns the fitness of the element
261 | |         The evaluation here is done by first building the polymer from the building blocks
262 | |         then running the xtb optimisation, the xtb calculation of the ionisation potential and the stda calculation of the excited state energy and oscillator strength
263 | |         The fitness function is defined as:
264 | |         -np.abs(IP - 5.5) - 0.5 * np.abs(Es1 - 3) + np.log10(fosc_1 + 1e-10)
265 | |         where IP is the ionisation potential, Es1 is the first excited state energy and fosc_1 is the first excited state oscillator strength.
266 | | 
267 | |         Parameters
268 | |         ----------
269 | |             element: list
270 | |             list of building blocks
271 | |             multiFidelity: bool
272 | |             if True, the function will return the fitness and the fidelity of the element
273 | | 
274 | |         Returns
275 | |         -------
276 | |             float
277 | |             the fitness of the element
278 | |             str
279 | |             the identifier of the element in the form of an InChIKey
280 | | 
281 | |         """
    | |___________^ D205
282 |           # initialise the database
283 |           client = pymongo.MongoClient(self.client)
    |
    = help: Insert single blank line

Objective_function.py:259:9: D401 First line of docstring should be in imperative mood: "Evaluates the fitness of the element"
    |
258 |       def evaluate_element(self, element, multiFidelity=False):
259 |           """Evaluates the fitness of the element
    |  _________^
260 | |         takes as an input a list of building blocks and returns the fitness of the element
261 | |         The evaluation here is done by first building the polymer from the building blocks
262 | |         then running the xtb optimisation, the xtb calculation of the ionisation potential and the stda calculation of the excited state energy and oscillator strength
263 | |         The fitness function is defined as:
264 | |         -np.abs(IP - 5.5) - 0.5 * np.abs(Es1 - 3) + np.log10(fosc_1 + 1e-10)
265 | |         where IP is the ionisation potential, Es1 is the first excited state energy and fosc_1 is the first excited state oscillator strength.
266 | | 
267 | |         Parameters
268 | |         ----------
269 | |             element: list
270 | |             list of building blocks
271 | |             multiFidelity: bool
272 | |             if True, the function will return the fitness and the fidelity of the element
273 | | 
274 | |         Returns
275 | |         -------
276 | |             float
277 | |             the fitness of the element
278 | |             str
279 | |             the identifier of the element in the form of an InChIKey
280 | | 
281 | |         """
    | |___________^ D401
282 |           # initialise the database
283 |           client = pymongo.MongoClient(self.client)
    |

Objective_function.py:290:9: N806 Variable `STDA_bin_path` in function should be lowercase
    |
288 |         # define the path to xtb and stda
289 |         xtb_path = self.xtb_path
290 |         STDA_bin_path = self.STDA_bin_path
    |         ^^^^^^^^^^^^^ N806
291 |         # define the output directories
292 |         Db_folder = self.Db_folder
    |

Objective_function.py:292:9: N806 Variable `Db_folder` in function should be lowercase
    |
290 |         STDA_bin_path = self.STDA_bin_path
291 |         # define the output directories
292 |         Db_folder = self.Db_folder
    |         ^^^^^^^^^ N806
293 |         output_dir_ipea = os.path.join(
294 |             Db_folder, "Database", "xtb_calculations"
    |

Objective_function.py:293:27: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
291 |         # define the output directories
292 |         Db_folder = self.Db_folder
293 |         output_dir_ipea = os.path.join(
    |                           ^^^^^^^^^^^^ PTH118
294 |             Db_folder, "Database", "xtb_calculations"
295 |         )
    |

Objective_function.py:296:30: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
294 |             Db_folder, "Database", "xtb_calculations"
295 |         )
296 |         xtb_opt_output_dir = os.path.join(
    |                              ^^^^^^^^^^^^ PTH118
297 |             Db_folder, "Database", "xtb_opt_output_dir"
298 |         )
    |

Objective_function.py:299:27: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
297 |             Db_folder, "Database", "xtb_opt_output_dir"
298 |         )
299 |         output_dir_stda = os.path.join(
    |                           ^^^^^^^^^^^^ PTH118
300 |             Db_folder, "Database", "stda_output_dir"
301 |         )
    |

Objective_function.py:302:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
    |
300 |             Db_folder, "Database", "stda_output_dir"
301 |         )
302 |         os.makedirs(output_dir_ipea, exist_ok=True)
    |         ^^^^^^^^^^^ PTH103
303 |         os.makedirs(xtb_opt_output_dir, exist_ok=True)
304 |         os.makedirs(output_dir_stda, exist_ok=True)
    |

Objective_function.py:303:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
    |
301 |         )
302 |         os.makedirs(output_dir_ipea, exist_ok=True)
303 |         os.makedirs(xtb_opt_output_dir, exist_ok=True)
    |         ^^^^^^^^^^^ PTH103
304 |         os.makedirs(output_dir_stda, exist_ok=True)
305 |         # define the database and collection name
    |

Objective_function.py:304:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
    |
302 |         os.makedirs(output_dir_ipea, exist_ok=True)
303 |         os.makedirs(xtb_opt_output_dir, exist_ok=True)
304 |         os.makedirs(output_dir_stda, exist_ok=True)
    |         ^^^^^^^^^^^ PTH103
305 |         # define the database and collection name
306 |         database_new_calc = self.database_new_calc
    |

Objective_function.py:308:9: ERA001 Found commented-out code
    |
306 |         database_new_calc = self.database_new_calc
307 |         collection_name = self.collection_name
308 |         # print(collection_name)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
309 |         # build the polymer
310 |         polymer = self.Build_polymer(element, db=db_mol)
    |
    = help: Remove commented-out code

Objective_function.py:319:9: N806 Variable `Inchikey` in function should be lowercase
    |
317 |             client=client,
318 |         )
319 |         Inchikey = stk.InchiKey().get_key(polymer)
    |         ^^^^^^^^ N806
320 | 
321 |         IP = self.run_xtb_ipea(
    |

Objective_function.py:321:9: N806 Variable `IP` in function should be lowercase
    |
319 |         Inchikey = stk.InchiKey().get_key(polymer)
320 | 
321 |         IP = self.run_xtb_ipea(
    |         ^^ N806
322 |             polymer,
323 |             xtb_path,
    |

Objective_function.py:330:9: N806 Variable `Es1` in function should be lowercase
    |
328 |             client=client,
329 |         )
330 |         Es1 = self.run_stda(
    |         ^^^ N806
331 |             polymer,
332 |             STDA_bin_path,
    |

Objective_function.py:357:9: N802 Function name `Build_polymer` should be lowercase
    |
355 |         return fitness_function, Inchikey
356 | 
357 |     def Build_polymer(
    |         ^^^^^^^^^^^^^ N802
358 |         self, element: pd.DataFrame, db: stk.MoleculeMongoDb = None
359 |     ):
    |

Objective_function.py:357:9: D417 Missing argument descriptions in the docstring for `Build_polymer`: `db`, `element`
    |
355 |         return fitness_function, Inchikey
356 | 
357 |     def Build_polymer(
    |         ^^^^^^^^^^^^^ D417
358 |         self, element: pd.DataFrame, db: stk.MoleculeMongoDb = None
359 |     ):
    |

Objective_function.py:360:9: D205 1 blank line required between summary line and description
    |
358 |           self, element: pd.DataFrame, db: stk.MoleculeMongoDb = None
359 |       ):
360 |           """Builds the polymer from the building blocks
    |  _________^
361 | |         takes as an input a list of building blocks and a database containing the building blocks
362 | |         returns the polymer.
363 | | 
364 | |         Parameters
365 | |         ----------
366 | |             element: pd.DataFrame
367 | |             the dataframe containing the building blocks
368 | |             db: stk.MoleculeMongoDb
369 | |             the database containing the building blocks
370 | | 
371 | |         Returns
372 | |         -------
373 | |             stk.ConstructedMolecule
374 | |             the polymer
375 | | 
376 | |         """
    | |___________^ D205
377 |           precursors = []
378 |           genes = "ABCDEFGH"
    |
    = help: Insert single blank line

Objective_function.py:360:9: D401 First line of docstring should be in imperative mood: "Builds the polymer from the building blocks"
    |
358 |           self, element: pd.DataFrame, db: stk.MoleculeMongoDb = None
359 |       ):
360 |           """Builds the polymer from the building blocks
    |  _________^
361 | |         takes as an input a list of building blocks and a database containing the building blocks
362 | |         returns the polymer.
363 | | 
364 | |         Parameters
365 | |         ----------
366 | |             element: pd.DataFrame
367 | |             the dataframe containing the building blocks
368 | |             db: stk.MoleculeMongoDb
369 | |             the database containing the building blocks
370 | | 
371 | |         Returns
372 | |         -------
373 | |             stk.ConstructedMolecule
374 | |             the polymer
375 | | 
376 | |         """
    | |___________^ D401
377 |           precursors = []
378 |           genes = "ABCDEFGH"
    |

Objective_function.py:380:9: ERA001 Found commented-out code
    |
378 |         genes = "ABCDEFGH"
379 |         genes = genes[: self.oligomer_size]
380 |         # print(genes)
    |         ^^^^^^^^^^^^^^ ERA001
381 |         repeating_unit = ""
382 |         # joins the Genes to make a repeating unit string
    |
    = help: Remove commented-out code

Objective_function.py:384:9: N806 Variable `InchiKey_cols` in function should be lowercase
    |
382 |         # joins the Genes to make a repeating unit string
383 |         repeating_unit = repeating_unit.join(genes)
384 |         InchiKey_cols = [col for col in element.columns if "InChIKey_" in col]
    |         ^^^^^^^^^^^^^ N806
385 |         # print(element[InchiKey_cols].values.flatten())
386 |         for fragment in element[InchiKey_cols].values.flatten():
    |

Objective_function.py:385:9: ERA001 Found commented-out code
    |
383 |         repeating_unit = repeating_unit.join(genes)
384 |         InchiKey_cols = [col for col in element.columns if "InChIKey_" in col]
385 |         # print(element[InchiKey_cols].values.flatten())
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
386 |         for fragment in element[InchiKey_cols].values.flatten():
387 |             mol = db.get({"InChIKey": fragment})
    |
    = help: Remove commented-out code

Objective_function.py:386:25: PD011 Use `.to_numpy()` instead of `.values`
    |
384 |         InchiKey_cols = [col for col in element.columns if "InChIKey_" in col]
385 |         # print(element[InchiKey_cols].values.flatten())
386 |         for fragment in element[InchiKey_cols].values.flatten():
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
387 |             mol = db.get({"InChIKey": fragment})
388 |             bb = stk.BuildingBlock.init_from_molecule(
    |

Objective_function.py:397:17: ERA001 Found commented-out code
    |
395 |                 repeating_unit=repeating_unit,
396 |                 num_repeating_units=1,
397 |                 # optimizer=stk.MCHammer()
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
398 |             )
399 |         )
    |
    = help: Remove commented-out code

Objective_function.py:401:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
399 |         )
400 | 
401 |     def run_xtb_opt(
    |         ^^^^^^^^^^^ PLR0913
402 |         self,
403 |         polymer,
    |

Objective_function.py:401:9: D417 Missing argument descriptions in the docstring for `run_xtb_opt`: `client`, `collection`, `database`, `polymer`, `xtb_opt_output_dir`, `xtb_path`
    |
399 |         )
400 | 
401 |     def run_xtb_opt(
    |         ^^^^^^^^^^^ D417
402 |         self,
403 |         polymer,
    |

Objective_function.py:410:9: D401 First line of docstring should be in imperative mood: "Runs the xtb optimisation of the polymer."
    |
408 |           client=None,
409 |       ):
410 |           """Runs the xtb optimisation of the polymer.
    |  _________^
411 | | 
412 | |         Parameters
413 | |         ----------
414 | |             polymer: stk.ConstructedMolecule
415 | |             the polymer
416 | |             xtb_path: str
417 | |             the path to the xtb executable
418 | |             xtb_opt_output_dir: str
419 | |             the output directory
420 | |             database: str
421 | |             the name of the database
422 | |             collection: str
423 | |             the name of the collection
424 | |             client: pymongo.MongoClient
425 | |             the client
426 | | 
427 | |         Returns
428 | |         -------
429 | |             stk.ConstructedMolecule
430 | |             the optimised polymer
431 | | 
432 | |         """
    | |___________^ D401
433 |   
434 |           def save_xtb_opt_calculation(
    |

Objective_function.py:434:13: D417 Missing argument descriptions in the docstring for `save_xtb_opt_calculation`: `InchiKey_initial`, `collection`, `polymer`, `xtb_opt_output_dir`
    |
432 |         """
433 | 
434 |         def save_xtb_opt_calculation(
    |             ^^^^^^^^^^^^^^^^^^^^^^^^ D417
435 |             polymer, xtb_opt_output_dir, collection=None, InchiKey_initial=None
436 |         ) -> None:
    |

Objective_function.py:435:59: N803 Argument name `InchiKey_initial` should be lowercase
    |
434 |         def save_xtb_opt_calculation(
435 |             polymer, xtb_opt_output_dir, collection=None, InchiKey_initial=None
    |                                                           ^^^^^^^^^^^^^^^^ N803
436 |         ) -> None:
437 |             """Saves the xtb optimisation calculation.
    |

Objective_function.py:437:13: D401 First line of docstring should be in imperative mood: "Saves the xtb optimisation calculation."
    |
435 |               polymer, xtb_opt_output_dir, collection=None, InchiKey_initial=None
436 |           ) -> None:
437 |               """Saves the xtb optimisation calculation.
    |  _____________^
438 | |             
439 | |             Parameters
440 | |             ----------
441 | |                 polymer: stk.ConstructedMolecule
442 | |                 the polymer
443 | |                 xtb_opt_output_dir: str
444 | |                 the output directory
445 | |                 collection: pymongo.collection
446 | |                 the collection
447 | |                 InchiKey_initial: str
448 | |                 the initial InChIKey
449 | |                 
450 | |             
451 | |             Returns
452 | |             -------
453 | |             None
454 | | 
455 | |             """
    | |_______________^ D401
456 |               def get_property_value(data, property_name):
457 |                   for line in data:
    |

Objective_function.py:456:17: ANN202 Missing return type annotation for private function `get_property_value`
    |
455 |             """
456 |             def get_property_value(data, property_name):
    |                 ^^^^^^^^^^^^^^^^^^ ANN202
457 |                 for line in data:
458 |                     if property_name in line:
    |
    = help: Add return type annotation

Objective_function.py:475:31: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
473 |             polymer_xtb_opt_calc = {
474 |                 "InChIKey": stk.InchiKey().get_key(polymer),
475 |                 "cal_folder": os.path.join(
    |                               ^^^^^^^^^^^^ PTH118
476 |                     xtb_opt_output_dir, stk.InchiKey().get_key(polymer)
477 |                 ),
    |

Objective_function.py:481:23: SIM115 Use context handler for opening files
    |
479 |                 "InChIKey_initial": InchiKey_initial,
480 |             }
481 |             outfile = open(
    |                       ^^^^ SIM115
482 |                 os.path.join(
483 |                     polymer_xtb_opt_calc["cal_folder"], "optimization_1.output"
    |

Objective_function.py:481:23: PTH123 `open()` should be replaced by `Path.open()`
    |
479 |                 "InChIKey_initial": InchiKey_initial,
480 |             }
481 |             outfile = open(
    |                       ^^^^ PTH123
482 |                 os.path.join(
483 |                     polymer_xtb_opt_calc["cal_folder"], "optimization_1.output"
    |

Objective_function.py:482:17: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
480 |             }
481 |             outfile = open(
482 |                 os.path.join(
    |                 ^^^^^^^^^^^^ PTH118
483 |                     polymer_xtb_opt_calc["cal_folder"], "optimization_1.output"
484 |                 ),
    |

Objective_function.py:509:13: ERA001 Found commented-out code
    |
507 |             is not None
508 |         ):
509 |             # print("already calculated", end="\r")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
510 | 
511 |             db_polymer = stk.ConstructedMoleculeMongoDb(
    |
    = help: Remove commented-out code

Objective_function.py:516:13: ERA001 Found commented-out code
    |
514 |             )
515 |             return db_polymer.get({"InChIKey": get_inchi_key(polymer)})
516 |             # print(get_inchi_key(polymer), ' opt geom already calculated')
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
517 |         if (
518 |             collection.find_one({"InChIKey_initial": get_inchi_key(polymer)})
    |
    = help: Remove commented-out code

Objective_function.py:521:13: ERA001 Found commented-out code
    |
519 |             is not None
520 |         ):
521 |             # print("already calculated", end="\r")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
522 |             db_polymer = stk.ConstructedMoleculeMongoDb(
523 |                 client,
    |
    = help: Remove commented-out code

Objective_function.py:529:13: ERA001 Found commented-out code
    |
527 |                 {"InChIKey_initial": get_inchi_key(polymer)}
528 |             )
529 |             # print(get_inchi_key(polymer), ' opt geom already calculated with old geom')
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
530 | 
531 |             return db_polymer.get({"InChIKey": data["InChIKey"]})
    |
    = help: Remove commented-out code

Objective_function.py:532:22: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
531 |             return db_polymer.get({"InChIKey": data["InChIKey"]})
532 |         output_dir = os.path.join(xtb_opt_output_dir, get_inchi_key(polymer))
    |                      ^^^^^^^^^^^^ PTH118
533 |         InchiKey_initial = get_inchi_key(polymer)
534 |         xtb = stko.OptimizerSequence(
    |

Objective_function.py:533:9: N806 Variable `InchiKey_initial` in function should be lowercase
    |
531 |             return db_polymer.get({"InChIKey": data["InChIKey"]})
532 |         output_dir = os.path.join(xtb_opt_output_dir, get_inchi_key(polymer))
533 |         InchiKey_initial = get_inchi_key(polymer)
    |         ^^^^^^^^^^^^^^^^ N806
534 |         xtb = stko.OptimizerSequence(
535 |             stko.ETKDG(),
    |

Objective_function.py:544:26: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
542 |         )
543 |         polymer = xtb.optimize(polymer)
544 |         new_output_dir = os.path.join(
    |                          ^^^^^^^^^^^^ PTH118
545 |             xtb_opt_output_dir, get_inchi_key(polymer)
546 |         )
    |

Objective_function.py:547:9: PTH104 `os.rename()` should be replaced by `Path.rename()`
    |
545 |             xtb_opt_output_dir, get_inchi_key(polymer)
546 |         )
547 |         os.rename(output_dir, new_output_dir)
    |         ^^^^^^^^^ PTH104
548 |         save_xtb_opt_calculation(
549 |             polymer,
    |

Objective_function.py:561:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
559 |         return polymer
560 | 
561 |     def run_xtb_ipea(
    |         ^^^^^^^^^^^^ PLR0913
562 |         self,
563 |         polymer,
    |

Objective_function.py:561:9: D417 Missing argument descriptions in the docstring for `run_xtb_ipea`: `client`, `collection`, `database`, `polymer`, `target`, `xtb_opt_output_dir`, `xtb_path`
    |
559 |         return polymer
560 | 
561 |     def run_xtb_ipea(
    |         ^^^^^^^^^^^^ D417
562 |         self,
563 |         polymer,
    |

Objective_function.py:571:9: D401 First line of docstring should be in imperative mood: "Runs the xtb calculation of the ionisation potential."
    |
569 |           client=None,
570 |       ):
571 |           """Runs the xtb calculation of the ionisation potential.
    |  _________^
572 | | 
573 | |         Parameters
574 | |         ----------
575 | |             polymer: stk.ConstructedMolecule
576 | |             the polymer
577 | |             xtb_path: str
578 | |             the path to the xtb executable
579 | |             xtb_opt_output_dir: str
580 | |             the output directory
581 | |             database: str
582 | |             the name of the database
583 | |             collection: str
584 | |             the name of the collection
585 | |             target: str
586 | |             the target
587 | |             client: pymongo.MongoClient
588 | |             the client
589 | | 
590 | |         Returns
591 | |         -------
592 | |             float
593 | |             the ionisation potential
594 | | 
595 | |         """
    | |___________^ D401
596 |           collection = client[database][collection]
597 |           XTB_results = collection.find_one({"InChIKey": get_inchi_key(polymer)})
    |

Objective_function.py:597:9: N806 Variable `XTB_results` in function should be lowercase
    |
595 |         """
596 |         collection = client[database][collection]
597 |         XTB_results = collection.find_one({"InChIKey": get_inchi_key(polymer)})
    |         ^^^^^^^^^^^ N806
598 |         if XTB_results is not None:
599 |             # print("already calculated", end="\r")
    |

Objective_function.py:599:13: ERA001 Found commented-out code
    |
597 |         XTB_results = collection.find_one({"InChIKey": get_inchi_key(polymer)})
598 |         if XTB_results is not None:
599 |             # print("already calculated", end="\r")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
600 |             # print(get_inchi_key(polymer), ' ipea geom already calculated')
601 |             return XTB_results[target]
    |
    = help: Remove commented-out code

Objective_function.py:600:13: ERA001 Found commented-out code
    |
598 |         if XTB_results is not None:
599 |             # print("already calculated", end="\r")
600 |             # print(get_inchi_key(polymer), ' ipea geom already calculated')
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
601 |             return XTB_results[target]
602 |         xtb = XTBEnergy2(
    |
    = help: Remove commented-out code

Objective_function.py:604:24: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
602 |         xtb = XTBEnergy2(
603 |             xtb_path=xtb_path,
604 |             output_dir=os.path.join(
    |                        ^^^^^^^^^^^^ PTH118
605 |                 xtb_opt_output_dir, get_inchi_key(polymer)
606 |             ),
    |

Objective_function.py:612:9: N806 Variable `XTB_results` in function should be lowercase
    |
610 |         )
611 |         xtb_results = xtb.get_results(polymer)
612 |         XTB_results = {
    |         ^^^^^^^^^^^ N806
613 |             "total energy (au)": xtb_results.get_total_energy()[0],
614 |             "homo lumo_gap (eV)": xtb_results.get_homo_lumo_gap()[0],
    |

Objective_function.py:620:27: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
618 |             ],
619 |             "InChIKey": get_inchi_key(polymer),
620 |             "cal_folder": os.path.join(
    |                           ^^^^^^^^^^^^ PTH118
621 |                 xtb_opt_output_dir, get_inchi_key(polymer)
622 |             ),
    |

Objective_function.py:632:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
630 |         return XTB_results[target]
631 | 
632 |     def run_stda(
    |         ^^^^^^^^ PLR0913
633 |         self,
634 |         polymer,
    |

Objective_function.py:632:9: D417 Missing argument descriptions in the docstring for `run_stda`: `STDA_bin_path`, `client`, `collection`, `database`, `output_dir`, `polymer`, `property`, `state`
    |
630 |         return XTB_results[target]
631 | 
632 |     def run_stda(
    |         ^^^^^^^^ D417
633 |         self,
634 |         polymer,
    |

Objective_function.py:635:9: N803 Argument name `STDA_bin_path` should be lowercase
    |
633 |         self,
634 |         polymer,
635 |         STDA_bin_path,
    |         ^^^^^^^^^^^^^ N803
636 |         output_dir,
637 |         property="Excited state energy (eV)",
    |

Objective_function.py:637:9: A002 Argument `property` is shadowing a Python builtin
    |
635 |         STDA_bin_path,
636 |         output_dir,
637 |         property="Excited state energy (eV)",
    |         ^^^^^^^^ A002
638 |         state=1,
639 |         database="stk_mohammed",
    |

Objective_function.py:673:9: N806 Variable `STDA_results` in function should be lowercase
    |
671 |         """
672 |         collection = client[database][collection]
673 |         STDA_results = collection.find_one(
    |         ^^^^^^^^^^^^ N806
674 |             {"InChIKey": get_inchi_key(polymer)}
675 |         )
    |

Objective_function.py:677:13: ERA001 Found commented-out code
    |
675 |         )
676 |         if STDA_results is not None:
677 |             # print(get_inchi_key(polymer), ' stda geom already calculated')
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
678 |             # print(STDA_results[property][state])
679 |             return STDA_results[property][state]
    |
    = help: Remove commented-out code

Objective_function.py:678:13: ERA001 Found commented-out code
    |
676 |         if STDA_results is not None:
677 |             # print(get_inchi_key(polymer), ' stda geom already calculated')
678 |             # print(STDA_results[property][state])
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
679 |             return STDA_results[property][state]
680 |         stda = sTDA_XTB(
    |
    = help: Remove commented-out code

Objective_function.py:683:24: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
681 |             STDA_bin_path=STDA_bin_path,
682 |             Num_threads=25,
683 |             output_dir=os.path.join(output_dir, get_inchi_key(polymer)),
    |                        ^^^^^^^^^^^^ PTH118
684 |         )
685 |         Excited_state_energy, Excited_state_osc = stda.get_results(polymer)
    |

Objective_function.py:685:9: N806 Variable `Excited_state_energy` in function should be lowercase
    |
683 |             output_dir=os.path.join(output_dir, get_inchi_key(polymer)),
684 |         )
685 |         Excited_state_energy, Excited_state_osc = stda.get_results(polymer)
    |         ^^^^^^^^^^^^^^^^^^^^ N806
686 |         STDA_results = {
687 |             "Excited state energy (eV)": Excited_state_energy,
    |

Objective_function.py:685:31: N806 Variable `Excited_state_osc` in function should be lowercase
    |
683 |             output_dir=os.path.join(output_dir, get_inchi_key(polymer)),
684 |         )
685 |         Excited_state_energy, Excited_state_osc = stda.get_results(polymer)
    |                               ^^^^^^^^^^^^^^^^^ N806
686 |         STDA_results = {
687 |             "Excited state energy (eV)": Excited_state_energy,
    |

Objective_function.py:686:9: N806 Variable `STDA_results` in function should be lowercase
    |
684 |         )
685 |         Excited_state_energy, Excited_state_osc = stda.get_results(polymer)
686 |         STDA_results = {
    |         ^^^^^^^^^^^^ N806
687 |             "Excited state energy (eV)": Excited_state_energy,
688 |             "Excited state oscillator strength": Excited_state_osc,
    |

Objective_function.py:690:27: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
688 |             "Excited state oscillator strength": Excited_state_osc,
689 |             "InChIKey": get_inchi_key(polymer),
690 |             "cal_folder": os.path.join(output_dir, get_inchi_key(polymer)),
    |                           ^^^^^^^^^^^^ PTH118
691 |             "Host IP": self.host_IP,
692 |         }
    |

Representation\Representation_3d_from_fragment.py:1:1: INP001 File `Representation\Representation_3d_from_fragment.py` is part of an implicit namespace package. Add an `__init__.py`.
Representation\Representation_3d_from_fragment.py:1:1: D404 First word of the docstring should not be "This"
  |
1 | """this script is to encode the representation of the oligomer from the representation of the fragments."""
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D404
2 | 
3 | import numpy as np
  |

Representation\Representation_3d_from_fragment.py:10:7: N801 Class name `Representation_3d_from_fragment` should use CapWords convention
   |
10 | class Representation_3d_from_fragment:
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N801
11 |     def __init__(
12 |         self,
   |

Representation\Representation_3d_from_fragment.py:10:7: D101 Missing docstring in public class
   |
10 | class Representation_3d_from_fragment:
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
11 |     def __init__(
12 |         self,
   |

Representation\Representation_3d_from_fragment.py:11:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
10 | class Representation_3d_from_fragment:
11 |     def __init__(
   |         ^^^^^^^^ PLR0913
12 |         self,
13 |         model_encoding,
   |

Representation\Representation_3d_from_fragment.py:75:13: N806 Variable `InChIKeys` in function should be lowercase
   |
73 |             # Create a dictionary that maps InChIKeys to data
74 |             dataset_dict = {x.InChIKey: x for x in self.dataset}
75 |             InChIKeys = self._find_elem_InchiKey(elements_copy)
   |             ^^^^^^^^^ N806
76 |             for id, InChIKey in enumerate(InChIKeys):
77 |                 data = dataset_dict.get(InChIKey)  # self.find_data(InChIKey)
   |

Representation\Representation_3d_from_fragment.py:76:17: A001 Variable `id` is shadowing a Python builtin
   |
74 |             dataset_dict = {x.InChIKey: x for x in self.dataset}
75 |             InChIKeys = self._find_elem_InchiKey(elements_copy)
76 |             for id, InChIKey in enumerate(InChIKeys):
   |                 ^^ A001
77 |                 data = dataset_dict.get(InChIKey)  # self.find_data(InChIKey)
78 |                 if data is not None:
   |

Representation\Representation_3d_from_fragment.py:76:21: N806 Variable `InChIKey` in function should be lowercase
   |
74 |             dataset_dict = {x.InChIKey: x for x in self.dataset}
75 |             InChIKeys = self._find_elem_InchiKey(elements_copy)
76 |             for id, InChIKey in enumerate(InChIKeys):
   |                     ^^^^^^^^ N806
77 |                 data = dataset_dict.get(InChIKey)  # self.find_data(InChIKey)
78 |                 if data is not None:
   |

Representation\Representation_3d_from_fragment.py:81:54: PD011 Use `.to_numpy()` instead of `.values`
   |
79 |                     opt_geom_encoding.append(data.learned_rpr)
80 |                 else:
81 |                     molecule, key = self._getinfo_db(elements_copy.values[id])
   |                                                      ^^^^^^^^^^^^^^^^^^^^ PD011
82 |                     with torch.no_grad():
83 |                         encoding = self.model_encoding(molecule)
   |

Representation\Representation_3d_from_fragment.py:94:13: ERA001 Found commented-out code
   |
92 |                         )
93 |         else:
94 |             #self.add_representation_to_local_dataset(elements_copy)
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
95 |             dataset_local_new = {}
96 |             for x in elements_copy.values:
   |
   = help: Remove commented-out code

Representation\Representation_3d_from_fragment.py:96:22: PD011 Use `.to_numpy()` instead of `.values`
   |
94 |             #self.add_representation_to_local_dataset(elements_copy)
95 |             dataset_local_new = {}
96 |             for x in elements_copy.values:
   |                      ^^^^^^^^^^^^^^^^^^^^ PD011
97 |                 key = ""
98 |                 for elm in x:
   |

Representation\Representation_3d_from_fragment.py:113:13: ERA001 Found commented-out code
    |
111 |                             encoding[0][0].type(torch.float16).detach()
112 |                         )
113 |             #self.save_representation_to_database(dataset_local_new)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
114 |             #self.save_dataset_local()
115 |         return torch.stack(opt_geom_encoding)
    |
    = help: Remove commented-out code

Representation\Representation_3d_from_fragment.py:114:13: ERA001 Found commented-out code
    |
112 |                         )
113 |             #self.save_representation_to_database(dataset_local_new)
114 |             #self.save_dataset_local()
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
115 |         return torch.stack(opt_geom_encoding)
    |
    = help: Remove commented-out code

Representation\Representation_3d_from_fragment.py:117:9: ANN202 Missing return type annotation for private function `_getinfo_db`
    |
115 |         return torch.stack(opt_geom_encoding)
116 | 
117 |     def _getinfo_db(self, elements):
    |         ^^^^^^^^^^^ ANN202
118 |         """Get the information from the database.
    |
    = help: Add return type annotation

Representation\Representation_3d_from_fragment.py:156:9: N802 Function name `_find_elem_InchiKey` should be lowercase
    |
154 |         return frags, key
155 | 
156 |     def _find_elem_InchiKey(self, elements):
    |         ^^^^^^^^^^^^^^^^^^^ N802
157 |         """Find the InChIKey of the elements.
    |

Representation\Representation_3d_from_fragment.py:156:9: ANN202 Missing return type annotation for private function `_find_elem_InchiKey`
    |
154 |         return frags, key
155 | 
156 |     def _find_elem_InchiKey(self, elements):
    |         ^^^^^^^^^^^^^^^^^^^ ANN202
157 |         """Find the InChIKey of the elements.
    |
    = help: Add return type annotation

Representation\Representation_3d_from_fragment.py:179:16: PD011 Use `.to_numpy()` instead of `.values`
    |
177 |             raise ValueError(msg)
178 | 
179 |         return results["InChIKey"].values
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
180 | 
181 |     def save_dataset_local(self):
    |

Representation\Representation_3d_from_fragment.py:211:9: D102 Missing docstring in public method
    |
209 |         return self.dataset_local
210 | 
211 |     def save_representation_to_database(self, local_dataset_new):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
212 |         client = pymongo.MongoClient("mongodb://ch-atarzia.ch.ic.ac.uk/")
213 |         db = client["learned_representations"]
    |

Representation\Representation_from_fragment.py:1:1: INP001 File `Representation\Representation_from_fragment.py` is part of an implicit namespace package. Add an `__init__.py`.
Representation\Representation_from_fragment.py:1:1: D100 Missing docstring in public module
Representation\Representation_from_fragment.py:6:7: N801 Class name `Representation_from_fragment` should use CapWords convention
  |
6 | class Representation_from_fragment:
  |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N801
7 |     """This class is used to generate the representation of the elements."""
  |

Representation\Representation_from_fragment.py:7:5: D404 First word of the docstring should not be "This"
  |
6 | class Representation_from_fragment:
7 |     """This class is used to generate the representation of the elements."""
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D404
8 | 
9 |     def __init__(self, df_precursors, frag_properties):
  |

Representation\Representation_from_fragment.py:39:23: PD015 Use `.merge` method instead of `pd.merge` function. They have equivalent functionality.
   |
37 |         for i in range(num_frag):
38 |             elements_curr["InChIKey"]=elements_curr[f"InChIKey_{i}"].astype(str)
39 |             df_eval = pd.merge(elements_curr,self.df_precursors[frag_properties], on="InChIKey", how="left", suffixes=("", f"_{i}"))
   |                       ^^^^^^^^ PD015
40 |             if len(init_rpr)==0:
41 |                 init_rpr = df_eval[df_eval.columns[num_frag+1:]].values
   |

Representation\Representation_from_fragment.py:41:28: PD011 Use `.to_numpy()` instead of `.values`
   |
39 |             df_eval = pd.merge(elements_curr,self.df_precursors[frag_properties], on="InChIKey", how="left", suffixes=("", f"_{i}"))
40 |             if len(init_rpr)==0:
41 |                 init_rpr = df_eval[df_eval.columns[num_frag+1:]].values
   |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
42 |             else:
43 |                 init_rpr = np.concatenate([init_rpr,df_eval[df_eval.columns[num_frag+1:]].values],axis=1)
   |

Representation\Representation_from_fragment.py:43:53: PD011 Use `.to_numpy()` instead of `.values`
   |
41 |                 init_rpr = df_eval[df_eval.columns[num_frag+1:]].values
42 |             else:
43 |                 init_rpr = np.concatenate([init_rpr,df_eval[df_eval.columns[num_frag+1:]].values],axis=1)
   |                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
44 | 
45 |         return torch.tensor(np.array(init_rpr.astype(float)), dtype=torch.float32)
   |

Representation\Representation_poly_3d.py:1:1: INP001 File `Representation\Representation_poly_3d.py` is part of an implicit namespace package. Add an `__init__.py`.
Representation\Representation_poly_3d.py:1:1: D404 First word of the docstring should not be "This"
  |
1 | """this script is to encode the representation of the oligomer from the representation of the fragments."""
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D404
2 | 
3 | import numpy as np
  |

Representation\Representation_poly_3d.py:12:7: N801 Class name `Representation_poly_3d` should use CapWords convention
   |
12 | class Representation_poly_3d:
   |       ^^^^^^^^^^^^^^^^^^^^^^ N801
13 |     def __init__(
14 |         self,
   |

Representation\Representation_poly_3d.py:12:7: D101 Missing docstring in public class
   |
12 | class Representation_poly_3d:
   |       ^^^^^^^^^^^^^^^^^^^^^^ D101
13 |     def __init__(
14 |         self,
   |

Representation\Representation_poly_3d.py:13:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
12 | class Representation_poly_3d:
13 |     def __init__(
   |         ^^^^^^^^ PLR0913
14 |         self,
15 |         model_encoding,
   |

Representation\Representation_poly_3d.py:13:9: D417 Missing argument descriptions in the docstring for `__init__`: `database`, `mongo_client`, `oligomer_size`
   |
12 | class Representation_poly_3d:
13 |     def __init__(
   |         ^^^^^^^^ D417
14 |         self,
15 |         model_encoding,
   |

Representation\Representation_poly_3d.py:16:9: ARG002 Unused method argument: `df_results`
   |
14 |         self,
15 |         model_encoding,
16 |         df_results=None,
   |         ^^^^^^^^^^ ARG002
17 |         data=None,
18 |         db_poly=None,
   |

Representation\Representation_poly_3d.py:17:9: ARG002 Unused method argument: `data`
   |
15 |         model_encoding,
16 |         df_results=None,
17 |         data=None,
   |         ^^^^ ARG002
18 |         db_poly=None,
19 |         db_frag=None,
   |

Representation\Representation_poly_3d.py:18:9: ARG002 Unused method argument: `db_poly`
   |
16 |         df_results=None,
17 |         data=None,
18 |         db_poly=None,
   |         ^^^^^^^ ARG002
19 |         db_frag=None,
20 |         device=None,
   |

Representation\Representation_poly_3d.py:19:9: ARG002 Unused method argument: `db_frag`
   |
17 |         data=None,
18 |         db_poly=None,
19 |         db_frag=None,
   |         ^^^^^^^ ARG002
20 |         device=None,
21 |         oligomer_size=6,
   |

Representation\Representation_poly_3d.py:43:9: ERA001 Found commented-out code
   |
41 |         else:
42 |             self.device = device
43 |         # self.model_encoding = model_encoding
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
44 |         # self.model_encoding.eval()
45 |         # self.model_encoding.to(self.device)
   |
   = help: Remove commented-out code

Representation\Representation_poly_3d.py:44:9: ERA001 Found commented-out code
   |
42 |             self.device = device
43 |         # self.model_encoding = model_encoding
44 |         # self.model_encoding.eval()
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
45 |         # self.model_encoding.to(self.device)
46 |         self.get_bbs_dict(
   |
   = help: Remove commented-out code

Representation\Representation_poly_3d.py:45:9: ERA001 Found commented-out code
   |
43 |         # self.model_encoding = model_encoding
44 |         # self.model_encoding.eval()
45 |         # self.model_encoding.to(self.device)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
46 |         self.get_bbs_dict(
47 |             mongo_client, database
   |
   = help: Remove commented-out code

Representation\Representation_poly_3d.py:93:13: PERF401 Use a list comprehension to create a transformed list
   |
91 |         data_loader = self.get_data_loader(dataset_poly)
92 |         for data in data_loader:
93 |             opt_geom_encoding_add.append(self.model_encoding(data))
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PERF401
94 |         opt_geom_encoding_add = torch.vstack(opt_geom_encoding_add)
95 |         for ii, bb_key in enumerate(elements_copy["bb_key"]):
   |

Representation\Representation_poly_3d.py:147:9: D205 1 blank line required between summary line and description
    |
146 |       def get_data_loader(self, dataset):
147 |           """Get the dataloader
    |  _________^
148 | |         Args:
149 | |             dataset: list
150 | |                 list of the dataset
151 | |             config: dict
152 | |                 configuration file.
153 | | 
154 | |         Returns
155 | |         -------
156 | |             loader: torch_geometric.loader.DataLoader
157 | |                 dataloader for the dataset
158 | | 
159 | |         """
    | |___________^ D205
160 |           # Set dataloaders
161 |           return DataLoader(
    |
    = help: Insert single blank line

Representation\Representation_poly_3d.py:165:13: ERA001 Found commented-out code
    |
163 |             batch_size=self.batch_size,
164 |             shuffle=False,
165 |             # drop_last=True,
    |             ^^^^^^^^^^^^^^^^^ ERA001
166 |         )
    |
    = help: Remove commented-out code

Representation\Representation_poly_3d.py:169:9: D102 Missing docstring in public method
    |
169 |     def join_keys(self, polymer):
    |         ^^^^^^^^^ D102
170 |         keys = [
171 |             stk.InchiKey().get_key(bb) for bb in polymer.get_building_blocks()
    |

Representation\Representation_poly_3d.py:175:9: D102 Missing docstring in public method
    |
173 |         return "_".join(keys)
174 | 
175 |     def join_keys_elem(self, element):
    |         ^^^^^^^^^^^^^^ D102
176 |         keys = list(element[
177 |                 [f"InChIKey_{x}" for x in range(self.oligomer_size)]
    |

Representation\Representation_poly_3d.py:179:9: ERA001 Found commented-out code
    |
177 |                 [f"InChIKey_{x}" for x in range(self.oligomer_size)]
178 |             ].values)
179 |         # print(keys)
    |         ^^^^^^^^^^^^^ ERA001
180 |         return "_".join(keys)
    |
    = help: Remove commented-out code

Representation\Representation_poly_3d.py:182:9: D102 Missing docstring in public method
    |
180 |         return "_".join(keys)
181 | 
182 |     def get_bbs_dict(self, client, database):
    |         ^^^^^^^^^^^^ D102
183 |         client = pymongo.MongoClient(client)
184 |         db_mol = stk.MoleculeMongoDb(
    |

Representation\Representation_poly_3d.py:199:9: N802 Function name `Build_polymers` should be lowercase
    |
197 |         return bbs_dict
198 | 
199 |     def Build_polymers(self, element: pd.DataFrame):
    |         ^^^^^^^^^^^^^^ N802
200 |         bbs_dict = self.bbs_dict
    |

Representation\Representation_poly_3d.py:199:9: D102 Missing docstring in public method
    |
197 |         return bbs_dict
198 | 
199 |     def Build_polymers(self, element: pd.DataFrame):
    |         ^^^^^^^^^^^^^^ D102
200 |         bbs_dict = self.bbs_dict
    |

Representation\Representation_poly_3d.py:204:9: ERA001 Found commented-out code
    |
202 |         genes = "ABCDEFGH"
203 |         genes = genes[: self.oligomer_size]
204 |         # print(genes)
    |         ^^^^^^^^^^^^^^ ERA001
205 |         repeating_unit = ""
206 |         # joins the Genes to make a repeating unit string
    |
    = help: Remove commented-out code

Representation\Representation_poly_3d.py:208:9: N806 Variable `InchiKey_cols` in function should be lowercase
    |
206 |         # joins the Genes to make a repeating unit string
207 |         repeating_unit = repeating_unit.join(genes)
208 |         InchiKey_cols = [col for col in element.columns if "InChIKey_" in col]
    |         ^^^^^^^^^^^^^ N806
209 | 
210 |         # print(element[InchiKey_cols].values.flatten())
    |

Representation\Representation_poly_3d.py:210:9: ERA001 Found commented-out code
    |
208 |         InchiKey_cols = [col for col in element.columns if "InChIKey_" in col]
209 | 
210 |         # print(element[InchiKey_cols].values.flatten())
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
211 |         def gen_mol(elem):
212 |             precursors = []
    |
    = help: Remove commented-out code

Representation\Representation_poly_3d.py:211:13: ANN202 Missing return type annotation for private function `gen_mol`
    |
210 |         # print(element[InchiKey_cols].values.flatten())
211 |         def gen_mol(elem):
    |             ^^^^^^^ ANN202
212 |             precursors = []
213 |             for fragment in elem[InchiKey_cols].values.flatten():
    |
    = help: Add return type annotation

Representation\Representation_poly_3d.py:213:29: PD011 Use `.to_numpy()` instead of `.values`
    |
211 |         def gen_mol(elem):
212 |             precursors = []
213 |             for fragment in elem[InchiKey_cols].values.flatten():
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
214 |                 bb = bbs_dict[fragment]
215 |                 precursors.append(bb)
    |

Representation\Representation_poly_3d.py:239:17: ERA001 Found commented-out code
    |
237 |                 InChIKey=stk.InchiKey().get_key(polymer),
238 |                 bb_key=bb_key,
239 |                 # y=elem['target']
    |                 ^^^^^^^^^^^^^^^^^^ ERA001
240 |             )
    |
    = help: Remove commented-out code

Representation\representation.py:1:1: INP001 File `Representation\representation.py` is part of an implicit namespace package. Add an `__init__.py`.
Representation\representation.py:1:1: D404 First word of the docstring should not be "This"
  |
1 | """This module contains the molecular representation class for the bayesian optimisation."""
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D404
2 | import numpy as np
3 | import torch
  |

Representation\representation.py:6:7: D101 Missing docstring in public class
  |
6 | class Representation:
  |       ^^^^^^^^^^^^^^ D101
7 |     def __init__(self):
8 |         self.name = "default"
  |

Representation\representation.py:7:9: D107 Missing docstring in `__init__`
  |
6 | class Representation:
7 |     def __init__(self):
  |         ^^^^^^^^ D107
8 |         self.name = "default"
  |

SearchExp.py:1:1: N999 Invalid module name: 'SearchExp'
SearchExp.py:1:1: D100 Missing docstring in public module
SearchExp.py:7:1: ERA001 Found commented-out code
  |
5 | from datetime import datetime
6 | 
7 | # from Scripts.Search_algorithm import Search_Algorithm
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
8 | from stk_search.Objective_function import Objective_Function
9 | from stk_search.SearchSpace import SearchSpace
  |
  = help: Remove commented-out code

SearchExp.py:97:9: D107 Missing docstring in `__init__`
   |
95 |     """
96 | 
97 |     def __init__(
   |         ^^^^^^^^ D107
98 |         self,
99 |         searchspace: SearchSpace,
   |

SearchExp.py:103:9: FBT002 Boolean default positional argument in function definition
    |
101 |         objective_function,
102 |         number_of_iterations,
103 |         verbose=False,
    |         ^^^^^^^ FBT002
104 |     ):
105 |         self.search_space = searchspace
    |

SearchExp.py:124:21: DTZ005 `datetime.datetime.now()` called without a `tz` argument
    |
122 |         self.benchmark = False
123 |         self.df_total = None
124 |         self.date = datetime.now().strftime("%Y%m%d")
    |                     ^^^^^^^^^^^^^^ DTZ005
125 |         self.search_exp_name = uuid.uuid4().hex
    |
    = help: Pass a `datetime.timezone` object to the `tz` parameter

SearchExp.py:129:9: D205 1 blank line required between summary line and description
    |
128 |       def run_seach(self):
129 |           """Run the search experiment
    |  _________^
130 | |         the search experiment will initialise the search space, get the initial elements, evaluate the elements, \
131 | |             run the search algorithm and suggest the next element to evaluate
132 | |             for the moment we cannot rerun a same search experiment.
133 | |             
134 | |         Returns
135 | |         -------
136 | |             results_dict : dict
137 | |                 The results of the search experiment    
138 | | 
139 | |         """
    | |___________^ D205
140 |           # get initial elements
141 |           if self.ids_acquired ==[]:
    |
    = help: Insert single blank line

SearchExp.py:155:23: TRY002 Create your own exception
    |
153 |             ):
154 |                 msg = "Budget exhausted by Initial Sample"
155 |                 raise Exception(msg)
    |                       ^^^^^^^^^^^^^^ TRY002
156 | 
157 |             self.df_search_space = df_search_space
    |

SearchExp.py:158:17: A001 Variable `id` is shadowing a Python builtin
    |
157 |             self.df_search_space = df_search_space
158 |             for id in range(len(ids_acquired)):
    |                 ^^ A001
159 |                 # evaluate the element
160 |                 self.evaluate_element(
    |

SearchExp.py:170:13: A001 Variable `id` is shadowing a Python builtin
    |
168 |         if number_of_iterations_run > self.number_of_iterations:
169 |             return None
170 |         for id in range(number_of_iterations_run, self.number_of_iterations):
    |             ^^ A001
171 |             # suggest the next element
172 |             ids_acquired, df_search_space = (
    |

SearchExp.py:170:13: B007 Loop control variable `id` not used within loop body
    |
168 |         if number_of_iterations_run > self.number_of_iterations:
169 |             return None
170 |         for id in range(number_of_iterations_run, self.number_of_iterations):
    |             ^^ B007
171 |             # suggest the next element
172 |             ids_acquired, df_search_space = (
    |
    = help: Rename unused `id` to `_id`

SearchExp.py:189:13: ERA001 Found commented-out code
    |
187 |             # evaluate the element
188 |             # if self.verbose:
189 |             # print(f"element id suggested: {ids_acquired}, inchikey suggested: {self.df_search_space.loc[ids_acquired]}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
190 |             self.evaluate_element(
191 |                 element_id=ids_acquired,
    |
    = help: Remove commented-out code

SearchExp.py:194:13: ERA001 Found commented-out code
    |
192 |                 objective_function=self.objective_function,
193 |             )
194 |             # self.fitness_acquired.append(Eval)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
195 |             # self.InchiKey_acquired.append(InchiKey)
196 |             # save the results
    |
    = help: Remove commented-out code

SearchExp.py:195:13: ERA001 Found commented-out code
    |
193 |             )
194 |             # self.fitness_acquired.append(Eval)
195 |             # self.InchiKey_acquired.append(InchiKey)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
196 |             # save the results
197 |             self.save_results()
    |
    = help: Remove commented-out code

SearchExp.py:199:17: ERA001 Found commented-out code
    |
197 |             self.save_results()
198 |             if self.verbose:
199 |                 # print(f"ids acquired: {self.ids_acquired}")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
200 |                 pass
201 |         # save the results
    |
    = help: Remove commented-out code

SearchExp.py:204:9: D102 Missing docstring in public method
    |
202 |         return self.save_results()
203 | 
204 |     def evaluate_element(
    |         ^^^^^^^^^^^^^^^^ D102
205 |         self,
206 |         element_id: int,
    |

SearchExp.py:211:21: DTZ005 `datetime.datetime.now()` called without a `tz` argument
    |
209 |         # get the element
210 |         element = self.df_search_space.loc[[element_id], :]
211 |         time_calc = datetime.now()
    |                     ^^^^^^^^^^^^^^ DTZ005
212 |         # evaluate the element
213 |         try:
    |
    = help: Pass a `datetime.timezone` object to the `tz` parameter

SearchExp.py:214:13: N806 Variable `Eval` in function should be lowercase
    |
212 |         # evaluate the element
213 |         try:
214 |             Eval, InchiKey = objective_function.evaluate_element(
    |             ^^^^ N806
215 |                 element=element,
216 |                 multiFidelity=self.search_algorithm.multiFidelity,
    |

SearchExp.py:214:19: N806 Variable `InchiKey` in function should be lowercase
    |
212 |         # evaluate the element
213 |         try:
214 |             Eval, InchiKey = objective_function.evaluate_element(
    |                   ^^^^^^^^ N806
215 |                 element=element,
216 |                 multiFidelity=self.search_algorithm.multiFidelity,
    |

SearchExp.py:229:35: DTZ005 `datetime.datetime.now()` called without a `tz` argument
    |
227 |             self.InchiKey_acquired.append(InchiKey)
228 |             self.ids_acquired.append(element_id)
229 |             self.time_calc.append(datetime.now() - time_calc)
    |                                   ^^^^^^^^^^^^^^ DTZ005
230 |             self.overall_time.append(datetime.now())
231 |             return Eval, InchiKey
    |
    = help: Pass a `datetime.timezone` object to the `tz` parameter

SearchExp.py:230:38: DTZ005 `datetime.datetime.now()` called without a `tz` argument
    |
228 |             self.ids_acquired.append(element_id)
229 |             self.time_calc.append(datetime.now() - time_calc)
230 |             self.overall_time.append(datetime.now())
    |                                      ^^^^^^^^^^^^^^ DTZ005
231 |             return Eval, InchiKey
232 |         except Exception:
    |
    = help: Pass a `datetime.timezone` object to the `tz` parameter

SearchExp.py:231:13: TRY300 Consider moving this statement to an `else` block
    |
229 |             self.time_calc.append(datetime.now() - time_calc)
230 |             self.overall_time.append(datetime.now())
231 |             return Eval, InchiKey
    |             ^^^^^^^^^^^^^^^^^^^^^ TRY300
232 |         except Exception:
233 |             self.bad_ids.append(element_id)
    |

SearchExp.py:232:16: BLE001 Do not catch blind exception: `Exception`
    |
230 |             self.overall_time.append(datetime.now())
231 |             return Eval, InchiKey
232 |         except Exception:
    |                ^^^^^^^^^ BLE001
233 |             self.bad_ids.append(element_id)
234 |             return None, None
    |

SearchExp.py:236:9: D102 Missing docstring in public method
    |
234 |             return None, None
235 | 
236 |     def save_search_experiment(self):
    |         ^^^^^^^^^^^^^^^^^^^^^^ D102
237 |         # save the search experiment
238 |         datetime.now().strftime("%Y%m%d_%H%M%S")
    |

SearchExp.py:238:9: DTZ005 `datetime.datetime.now()` called without a `tz` argument
    |
236 |     def save_search_experiment(self):
237 |         # save the search experiment
238 |         datetime.now().strftime("%Y%m%d_%H%M%S")
    |         ^^^^^^^^^^^^^^ DTZ005
239 |         date_now = datetime.now().strftime("%Y%m%d")
240 |         os.makedirs(self.output_folder + f"/{date_now}", exist_ok=True)
    |
    = help: Pass a `datetime.timezone` object to the `tz` parameter

SearchExp.py:239:20: DTZ005 `datetime.datetime.now()` called without a `tz` argument
    |
237 |         # save the search experiment
238 |         datetime.now().strftime("%Y%m%d_%H%M%S")
239 |         date_now = datetime.now().strftime("%Y%m%d")
    |                    ^^^^^^^^^^^^^^ DTZ005
240 |         os.makedirs(self.output_folder + f"/{date_now}", exist_ok=True)
241 |         with open(
    |
    = help: Pass a `datetime.timezone` object to the `tz` parameter

SearchExp.py:240:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
    |
238 |         datetime.now().strftime("%Y%m%d_%H%M%S")
239 |         date_now = datetime.now().strftime("%Y%m%d")
240 |         os.makedirs(self.output_folder + f"/{date_now}", exist_ok=True)
    |         ^^^^^^^^^^^ PTH103
241 |         with open(
242 |             self.output_folder
    |

SearchExp.py:241:14: PTH123 `open()` should be replaced by `Path.open()`
    |
239 |         date_now = datetime.now().strftime("%Y%m%d")
240 |         os.makedirs(self.output_folder + f"/{date_now}", exist_ok=True)
241 |         with open(
    |              ^^^^ PTH123
242 |             self.output_folder
243 |             + f"/{date_now}"
    |

SearchExp.py:249:9: D102 Missing docstring in public method
    |
247 |             pickle.dump(self, f)
248 | 
249 |     def save_results(self):
    |         ^^^^^^^^^^^^ D102
250 |         # save the results
251 |         # time_now = datetime.now().strftime("%Y%m%d_%H")
    |

SearchExp.py:251:9: ERA001 Found commented-out code
    |
249 |     def save_results(self):
250 |         # save the results
251 |         # time_now = datetime.now().strftime("%Y%m%d_%H")
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
252 | 
253 |         resutls_dict = {
    |
    = help: Remove commented-out code

SearchExp.py:263:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
    |
262 |         path = self.output_folder + f"/{self.date}"
263 |         os.makedirs(path, exist_ok=True)
    |         ^^^^^^^^^^^ PTH103
264 |         with open(path + f"/results_{self.search_exp_name}.pkl", "wb") as f:
    |

SearchExp.py:264:14: PTH123 `open()` should be replaced by `Path.open()`
    |
262 |         path = self.output_folder + f"/{self.date}"
263 |         os.makedirs(path, exist_ok=True)
264 |         with open(path + f"/results_{self.search_exp_name}.pkl", "wb") as f:
    |              ^^^^ PTH123
265 | 
266 |             pickle.dump(resutls_dict, f)
    |

SearchSpace.py:1:1: N999 Invalid module name: 'SearchSpace'
SearchSpace.py:1:1: D100 Missing docstring in public module
SearchSpace.py:8:5: D205 1 blank line required between summary line and description
   |
 7 |   class SearchSpace:
 8 |       """class that contains the chemical space to search over
   |  _____^
 9 | |     it is defined by the number of fragments and the syntax of the fragment forming the oligomer
10 | |     it also contains the conditions that need to be respected by the building blocks.
11 | | 
12 | |     Attributes
13 | |     ----------
14 | |     number_of_fragments : int
15 | |         number of fragments in the oligomer
16 | |     df_precursors : pd.DataFrame
17 | |         dataframe containing the building blocks inchikeys and features
18 | |     generation_type : str
19 | |         type of generation of the search space
20 | |     syntax : list
21 | |         list of the syntax of the oligomer
22 | |     conditions_list : list
23 | |         list of the conditions that need to be respected by the building blocks
24 | | 
25 | | 
26 | |     """
   | |_______^ D205
27 |   
28 |       def __init__(
   |
   = help: Insert single blank line

SearchSpace.py:35:9: D205 1 blank line required between summary line and description
   |
33 |           generation_type: str = "conditional",
34 |       ):
35 |           """Parameters
   |  _________^
36 | |         ----------
37 | |         number_of_fragments : int
38 | |             number of fragments in the oligomer
39 | |         df : pd.DataFrame
40 | |             dataframe containing the building blocks inchikeys and features
41 | |         features_frag : list
42 | |             list of the features of the building blocks
43 | |         generation_type : str
44 | |             type of generation of the search space
45 | | 
46 | |         """
   | |___________^ D205
47 |           self.number_of_fragments = number_of_fragments
48 |           self.df_precursors = df
   |
   = help: Insert single blank line

SearchSpace.py:49:9: ERA001 Found commented-out code
   |
47 |         self.number_of_fragments = number_of_fragments
48 |         self.df_precursors = df
49 |         # self.features_frag = features_frag
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
50 |         self.syntax = [0, 1, 2, 3, 4, 5]
51 |         self.conditions_list = [[] for i in range(self.number_of_fragments)]
   |
   = help: Remove commented-out code

SearchSpace.py:56:9: D205 1 blank line required between summary line and description
   |
55 |       def add_condition(self, condition: str, fragment: int):
56 |           """Add a condition to the condition list
   |  _________^
57 | |         # condition syntax should follow the following condition:
58 | |         # "'column'#operation#value" e.g. "'IP (eV)'#>=#6.5".
59 | | 
60 | |         Parameters
61 | |         ----------
62 | |         condition : str
63 | |             condition to add
64 | |         fragment : int
65 | |             fragment position to which the condition is added
66 | | 
67 | |         """
   | |___________^ D205
68 |           # condition syntax should follow the following condition:
69 |           # "'column'#operation#value" e.g. "'IP (eV)'#>=#6.5"
   |
   = help: Insert single blank line

SearchSpace.py:72:9: D102 Missing docstring in public method
   |
70 |         self.conditions_list[fragment].append(condition)
71 | 
72 |     def remove_condition(self, condition: str, fragment: int):
   |         ^^^^^^^^^^^^^^^^ D102
73 |         # condition syntax should follow the following condition:
74 |         # "'column'#operation#value" e.g. "'IP (eV)'#>=#6.5"
   |

SearchSpace.py:77:9: N802 Function name `check_df_for_element_from_SP` should be lowercase
   |
75 |         self.conditions_list[fragment].remove(condition)
76 | 
77 |     def check_df_for_element_from_SP(self, df_to_check: pd.DataFrame):
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
78 |         # check if the condition is respected by the search space
79 |         # show that each fragment respect the condition
   |

SearchSpace.py:77:9: D102 Missing docstring in public method
   |
75 |         self.conditions_list[fragment].remove(condition)
76 | 
77 |     def check_df_for_element_from_SP(self, df_to_check: pd.DataFrame):
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
78 |         # check if the condition is respected by the search space
79 |         # show that each fragment respect the condition
   |

SearchSpace.py:93:59: S307 Use of possibly insecure function; consider using `ast.literal_eval`
   |
91 |                     + condition_exp[2]
92 |                 )
93 |                 df_precursor_filter = df_precursor_filter[eval(expression)]
   |                                                           ^^^^^^^^^^^^^^^^ S307
94 | 
95 |             df_mult_filtered = df_mult_filtered[
   |

SearchSpace.py:101:18: A001 Variable `id` is shadowing a Python builtin
    |
 99 |             ]
100 |         # check if the fragment in the dataframe respect the syntax in the syntax list
101 |         for pos, id in enumerate(self.syntax):
    |                  ^^ A001
102 |             if id == pos:
103 |                 pass
    |

SearchSpace.py:112:9: D205 1 blank line required between summary line and description
    |
111 |       def update(self):
112 |           """Update the search space based on the conditions
    |  _________^
113 | |         changes the list of fragment and recomputes the space size.
114 | |         """
    | |___________^ D205
115 |           self.list_fragment = (
116 |               self.generate_list_fragment()
    |
    = help: Insert single blank line

SearchSpace.py:120:9: D102 Missing docstring in public method
    |
118 |         self.get_space_size()
119 | 
120 |     def generate_list_fragment(self):
    |         ^^^^^^^^^^^^^^^^^^^^^^ D102
121 |         # generate the list of list of index of the fragment ( need to be the same length as the number of fragments)
122 |         # generation type can either be random or most_diverse or manual or conditional
    |

SearchSpace.py:137:47: S307 Use of possibly insecure function; consider using `ast.literal_eval`
    |
135 |                         + condition_exp[2]
136 |                     )
137 |                     df_filtered = df_filtered[eval(expression)]
    |                                               ^^^^^^^^^^^^^^^^ S307
138 |                 list_fragment.append(df_filtered.index.to_list())
139 |         elif self.generation_type == "manual":
    |

SearchSpace.py:150:9: D102 Missing docstring in public method
    |
148 |         return list_fragment
149 | 
150 |     def get_space_size(self):
    |         ^^^^^^^^^^^^^^ D102
151 |         x = 1
    |

SearchSpace.py:163:9: D102 Missing docstring in public method
    |
161 |         return x
162 | 
163 |     def generate_syntax(self):
    |         ^^^^^^^^^^^^^^^ D102
164 |         # generate the syntax of the oligomer
165 |         syntax = []
    |

SearchSpace.py:167:13: PERF401 Use a list comprehension to create a transformed list
    |
165 |         syntax = []
166 |         for i in range(self.number_of_fragments):
167 |             syntax.append([f"frag_{i}_{x}" for x in self.features_frag])
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PERF401
168 |         return syntax
    |

SearchSpace.py:170:9: D102 Missing docstring in public method
    |
168 |         return syntax
169 | 
170 |     def generate_dataframe_with_search_space(self):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
171 |         id_list_not_to_merge = []
172 |         for i in set(self.syntax):
    |

SearchSpace.py:194:18: A001 Variable `id` is shadowing a Python builtin
    |
192 |         )
193 | 
194 |         for pos, id in enumerate(self.syntax):
    |                  ^^ A001
195 |             if pos in id_list_not_to_merge:
196 |                 continue
    |

SearchSpace.py:197:13: RET507 Unnecessary `else` after `continue` statement
    |
195 |             if pos in id_list_not_to_merge:
196 |                 continue
197 |             else:
    |             ^^^^ RET507
198 |                 df_multi = df_multi.merge(
199 |                     self.df_precursors.loc[list(self.list_fragment[id])][
    |
    = help: Remove unnecessary `else`

SearchSpace.py:214:9: ERA001 Found commented-out code
    |
212 |                 )
213 | 
214 |         # print(f"shape of the dataframe {df_multi.shape}")
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
215 |         return df_multi
    |
    = help: Remove commented-out code

SearchSpace.py:217:9: D102 Missing docstring in public method
    |
215 |         return df_multi
216 | 
217 |     def plot_histogram_precursor(self):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^ D102
218 |         def plot_histogram(column_name) -> None:
219 |             plt.figure(figsize=(6, 4))
    |

SearchSpace.py:226:9: PD901 Avoid using the generic variable name `df` for DataFrames
    |
224 |             plt.show()
225 | 
226 |         df = self.df_precursors
    |         ^^ PD901
227 |         # Interactive widget for column selection
228 |         columns_dropdown = widgets.Dropdown(
    |

Search_algorithm\BayesianOptimisation.py:1:1: INP001 File `Search_algorithm\BayesianOptimisation.py` is part of an implicit namespace package. Add an `__init__.py`.
Search_algorithm\BayesianOptimisation.py:1:1: D100 Missing docstring in public module
Search_algorithm\BayesianOptimisation.py:11:5: F811 Redefinition of unused `ExpectedImprovement` from line 9
   |
 9 | from botorch.acquisition import ExpectedImprovement, qKnowledgeGradient
10 | from botorch.acquisition.analytic import (
11 |     ExpectedImprovement,
   |     ^^^^^^^^^^^^^^^^^^^ F811
12 |     LogExpectedImprovement,
13 | )
   |
   = help: Remove definition: `ExpectedImprovement`

Search_algorithm\BayesianOptimisation.py:26:5: D205 1 blank line required between summary line and description
   |
25 |   class BayesianOptimisation(Search_Algorithm):
26 |       """This class is to define the Bayesian Optimisation search algorithm.
   |  _____^
27 | |     Here the Bayesian Optimisation search algorithm is defined and is a subclass of Search_Algorithm.
28 | |     The Bayesian Optimisation search algorithm is used to optimise the acquisition function and suggest the next element to evaluate.
29 | |     the different step of the algorithm are:
30 | |     1. Prepare input for the BO
31 | |     2. Train the model
32 | |     3. Optimise the acquisition function
33 | |     4. Generate elements to evaluate
34 | |     5. Suggest a new element to evaluate.
35 | |     
36 | |     """
   | |_______^ D205
37 |   
38 |       def __init__(
   |
   = help: Insert single blank line

Search_algorithm\BayesianOptimisation.py:26:5: D404 First word of the docstring should not be "This"
   |
25 |   class BayesianOptimisation(Search_Algorithm):
26 |       """This class is to define the Bayesian Optimisation search algorithm.
   |  _____^
27 | |     Here the Bayesian Optimisation search algorithm is defined and is a subclass of Search_Algorithm.
28 | |     The Bayesian Optimisation search algorithm is used to optimise the acquisition function and suggest the next element to evaluate.
29 | |     the different step of the algorithm are:
30 | |     1. Prepare input for the BO
31 | |     2. Train the model
32 | |     3. Optimise the acquisition function
33 | |     4. Generate elements to evaluate
34 | |     5. Suggest a new element to evaluate.
35 | |     
36 | |     """
   | |_______^ D404
37 |   
38 |       def __init__(
   |

Search_algorithm\BayesianOptimisation.py:38:9: PLR0913 Too many arguments in function definition (7 > 5)
   |
36 |     """
37 | 
38 |     def __init__(
   |         ^^^^^^^^ PLR0913
39 |         self,
40 |         verbose=False,
   |

Search_algorithm\BayesianOptimisation.py:40:9: FBT002 Boolean default positional argument in function definition
   |
38 |     def __init__(
39 |         self,
40 |         verbose=False,
   |         ^^^^^^^ FBT002
41 |         which_acquisition="EI",
42 |         kernel=RBFKernel,
   |

Search_algorithm\BayesianOptimisation.py:46:9: N803 Argument name `Representation` should be lowercase
   |
44 |         model=None,
45 |         lim_counter=2,
46 |         Representation=None,
   |         ^^^^^^^^^^^^^^ N803
47 |     ):
48 |         """Initialise the class.
   |

Search_algorithm\BayesianOptimisation.py:64:9: ERA001 Found commented-out code
   |
62 |         """
63 |         self.verbose = verbose
64 |         # self.normalise_input = normalise_input
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
65 |         self.which_acquisition = which_acquisition
66 |         self.kernel = kernel
   |
   = help: Remove commented-out code

Search_algorithm\BayesianOptimisation.py:75:9: D102 Missing docstring in public method
   |
73 |         self.pred_model = None
74 | 
75 |     def update_representation(self, Representation):
   |         ^^^^^^^^^^^^^^^^^^^^^ D102
76 |         self.Representation = Representation
   |

Search_algorithm\BayesianOptimisation.py:75:37: N803 Argument name `Representation` should be lowercase
   |
73 |         self.pred_model = None
74 | 
75 |     def update_representation(self, Representation):
   |                                     ^^^^^^^^^^^^^^ N803
76 |         self.Representation = Representation
   |

Search_algorithm\BayesianOptimisation.py:78:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
76 |         self.Representation = Representation
77 | 
78 |     def suggest_element(
   |         ^^^^^^^^^^^^^^^ PLR0913
79 |         self,
80 |         search_space_df,
   |

Search_algorithm\BayesianOptimisation.py:78:9: D417 Missing argument descriptions in the docstring for `suggest_element`: `SP`, `benchmark`, `df_total`, `fitness_acquired`, `ids_acquired`
   |
76 |         self.Representation = Representation
77 | 
78 |     def suggest_element(
   |         ^^^^^^^^^^^^^^^ D417
79 |         self,
80 |         search_space_df,
   |

Search_algorithm\BayesianOptimisation.py:83:9: N803 Argument name `SP` should be lowercase
   |
81 |         fitness_acquired,
82 |         ids_acquired,
83 |         SP: SearchSpace,
   |         ^^^^^^^^^^^^^^^ N803
84 |         benchmark=True,
85 |         df_total: pd.DataFrame = None,
   |

Search_algorithm\BayesianOptimisation.py:84:9: FBT002 Boolean default positional argument in function definition
   |
82 |         ids_acquired,
83 |         SP: SearchSpace,
84 |         benchmark=True,
   |         ^^^^^^^^^ FBT002
85 |         df_total: pd.DataFrame = None,
86 |     ):
   |

Search_algorithm\BayesianOptimisation.py:105:9: N806 Variable `X_rpr` in function should be lowercase
    |
103 |         fitness_acquired = np.array(fitness_acquired)
104 |         # prepare input for the BO
105 |         X_rpr = self.Representation.generate_repr(
    |         ^^^^^ N806
106 |             df_search.loc[ids_acquired, :]
107 |         )
    |

Search_algorithm\BayesianOptimisation.py:108:9: N806 Variable `X_rpr` in function should be lowercase
    |
106 |             df_search.loc[ids_acquired, :]
107 |         )
108 |         X_rpr = X_rpr.double()
    |         ^^^^^ N806
109 |         X_rpr = self.normalise_input(X_rpr)
110 |         y_explored_BO_norm = torch.tensor(
    |

Search_algorithm\BayesianOptimisation.py:109:9: N806 Variable `X_rpr` in function should be lowercase
    |
107 |         )
108 |         X_rpr = X_rpr.double()
109 |         X_rpr = self.normalise_input(X_rpr)
    |         ^^^^^ N806
110 |         y_explored_BO_norm = torch.tensor(
111 |             fitness_acquired, dtype=torch.float64
    |

Search_algorithm\BayesianOptimisation.py:110:9: N806 Variable `y_explored_BO_norm` in function should be lowercase
    |
108 |         X_rpr = X_rpr.double()
109 |         X_rpr = self.normalise_input(X_rpr)
110 |         y_explored_BO_norm = torch.tensor(
    |         ^^^^^^^^^^^^^^^^^^ N806
111 |             fitness_acquired, dtype=torch.float64
112 |         )
    |

Search_algorithm\BayesianOptimisation.py:113:9: N806 Variable `y_explored_BO_norm` in function should be lowercase
    |
111 |             fitness_acquired, dtype=torch.float64
112 |         )
113 |         y_explored_BO_norm = (
    |         ^^^^^^^^^^^^^^^^^^ N806
114 |             y_explored_BO_norm - y_explored_BO_norm.mean(axis=0)
115 |         ) / (y_explored_BO_norm.std(axis=0))
    |

Search_algorithm\BayesianOptimisation.py:116:9: N806 Variable `y_explored_BO_norm` in function should be lowercase
    |
114 |             y_explored_BO_norm - y_explored_BO_norm.mean(axis=0)
115 |         ) / (y_explored_BO_norm.std(axis=0))
116 |         y_explored_BO_norm = y_explored_BO_norm.reshape(-1, 1)
    |         ^^^^^^^^^^^^^^^^^^ N806
117 |         # train model
118 |         self.train_model(X_rpr, y_explored_BO_norm)
    |

Search_algorithm\BayesianOptimisation.py:139:39: PD011 Use `.to_numpy()` instead of `.values`
    |
138 |         for element_id in ids_sorted_by_aquisition:
139 |             if add_element(df_search, df_elements.values[element_id.item()]):
    |                                       ^^^^^^^^^^^^^^^^^^ PD011
140 |                 break
141 |         return len(df_search) - 1, df_search
    |

Search_algorithm\BayesianOptimisation.py:143:9: D102 Missing docstring in public method
    |
141 |         return len(df_search) - 1, df_search
142 | 
143 |     def normalise_input(self, X_rpr):
    |         ^^^^^^^^^^^^^^^ D102
144 |         X_rpr = X_rpr.double()
145 |         # min max scaling the input
    |

Search_algorithm\BayesianOptimisation.py:143:31: N803 Argument name `X_rpr` should be lowercase
    |
141 |         return len(df_search) - 1, df_search
142 | 
143 |     def normalise_input(self, X_rpr):
    |                               ^^^^^ N803
144 |         X_rpr = X_rpr.double()
145 |         # min max scaling the input
    |

Search_algorithm\BayesianOptimisation.py:144:9: N806 Variable `X_rpr` in function should be lowercase
    |
143 |     def normalise_input(self, X_rpr):
144 |         X_rpr = X_rpr.double()
    |         ^^^^^ N806
145 |         # min max scaling the input
146 |         return (X_rpr - X_rpr.min(dim=0)[0]) / (
    |

Search_algorithm\BayesianOptimisation.py:150:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
148 |         )
149 | 
150 |     def optimise_acquisition_function(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
151 |         self,
152 |         best_f,
    |

Search_algorithm\BayesianOptimisation.py:150:9: D417 Missing argument descriptions in the docstring for `optimise_acquisition_function`: `SP`, `benchmark`, `df_search`, `df_total`, `fitness_acquired`
    |
148 |         )
149 | 
150 |     def optimise_acquisition_function(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D417
151 |         self,
152 |         best_f,
    |

Search_algorithm\BayesianOptimisation.py:155:9: N803 Argument name `SP` should be lowercase
    |
153 |         fitness_acquired,
154 |         df_search,
155 |         SP,
    |         ^^ N803
156 |         benchmark=False,
157 |         df_total=None,
    |

Search_algorithm\BayesianOptimisation.py:156:9: FBT002 Boolean default positional argument in function definition
    |
154 |         df_search,
155 |         SP,
156 |         benchmark=False,
    |         ^^^^^^^^^ FBT002
157 |         df_total=None,
158 |     ):
    |

Search_algorithm\BayesianOptimisation.py:179:9: N806 Variable `Xrpr` in function should be lowercase
    |
177 |             fitness_acquired, df_search, SP, benchmark, df_total
178 |         )
179 |         Xrpr = self.Representation.generate_repr(df_elements)
    |         ^^^^ N806
180 |         Xrpr = self.normalise_input(Xrpr)
181 |         acquisition_values = self.get_acquisition_values(
    |

Search_algorithm\BayesianOptimisation.py:180:9: N806 Variable `Xrpr` in function should be lowercase
    |
178 |         )
179 |         Xrpr = self.Representation.generate_repr(df_elements)
180 |         Xrpr = self.normalise_input(Xrpr)
    |         ^^^^ N806
181 |         acquisition_values = self.get_acquisition_values(
182 |             self.model,
    |

Search_algorithm\BayesianOptimisation.py:203:13: N806 Variable `Xrpr` in function should be lowercase
    |
201 |                 df_total,
202 |             )
203 |             Xrpr = self.Representation.generate_repr(df_elements)
    |             ^^^^ N806
204 |             Xrpr = self.normalise_input(Xrpr)
205 |             # if benchmark:
    |

Search_algorithm\BayesianOptimisation.py:204:13: N806 Variable `Xrpr` in function should be lowercase
    |
202 |             )
203 |             Xrpr = self.Representation.generate_repr(df_elements)
204 |             Xrpr = self.normalise_input(Xrpr)
    |             ^^^^ N806
205 |             # if benchmark:
206 |             acquisition_values = self.get_acquisition_values(
    |

Search_algorithm\BayesianOptimisation.py:228:9: N802 Function name `Generate_element_to_evaluate` should be lowercase
    |
226 |         return ids_sorted_by_aquisition, df_elements
227 | 
228 |     def Generate_element_to_evaluate(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
229 |         self,
230 |         fitness_acquired,
    |

Search_algorithm\BayesianOptimisation.py:228:9: C901 `Generate_element_to_evaluate` is too complex (12 > 10)
    |
226 |         return ids_sorted_by_aquisition, df_elements
227 | 
228 |     def Generate_element_to_evaluate(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ C901
229 |         self,
230 |         fitness_acquired,
    |

Search_algorithm\BayesianOptimisation.py:232:9: N803 Argument name `SP` should be lowercase
    |
230 |         fitness_acquired,
231 |         df_search,
232 |         SP: SearchSpace,
    |         ^^^^^^^^^^^^^^^ N803
233 |         benchmark=False,
234 |         df_total=None,
    |

Search_algorithm\BayesianOptimisation.py:233:9: FBT002 Boolean default positional argument in function definition
    |
231 |         df_search,
232 |         SP: SearchSpace,
233 |         benchmark=False,
    |         ^^^^^^^^^ FBT002
234 |         df_total=None,
235 |     ):
    |

Search_algorithm\BayesianOptimisation.py:250:13: ANN202 Missing return type annotation for private function `mutate_element`
    |
248 |         """
249 | 
250 |         def mutate_element(element):
    |             ^^^^^^^^^^^^^^ ANN202
251 |             elements_val = []
252 |             for i in range(element.shape[0]):
    |
    = help: Add return type annotation

Search_algorithm\BayesianOptimisation.py:259:13: ANN202 Missing return type annotation for private function `cross_element`
    |
257 |             return elements_val
258 | 
259 |         def cross_element(element1, element2):
    |             ^^^^^^^^^^^^^ ANN202
260 |             elements_val = []
261 |             for i in range(element.shape[0]):
    |
    = help: Add return type annotation

Search_algorithm\BayesianOptimisation.py:269:24: PD011 Use `.to_numpy()` instead of `.values`
    |
267 |         # select the 3 best one and add two random element from the search space
268 |         best_element_arg = fitness_acquired.argsort()[-3:][::-1]
269 |         list_parents = df_search.loc[best_element_arg, :].values
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
270 |         list_parents = np.append(
271 |             list_parents, df_search.sample(2).values, axis=0
    |

Search_algorithm\BayesianOptimisation.py:311:36: PLR2004 Magic value used in comparison, consider replacing `1000` with a constant variable
    |
309 |             df_elements = df_elements.drop_duplicates()
310 |         if (
311 |             df_elements.shape[0] > 1000
    |                                    ^^^^ PLR2004
312 |         ):  # limit the number of elements to evaluate each time
313 |             df_elements = df_elements.sample(1000)
    |

Search_algorithm\BayesianOptimisation.py:316:27: N803 Argument name `X_train` should be lowercase
    |
314 |         return df_elements.reset_index(drop=True)
315 | 
316 |     def train_model(self, X_train, y_train):
    |                           ^^^^^^^ N803
317 |         """Train the model.
    |

Search_algorithm\BayesianOptimisation.py:332:9: D417 Missing argument descriptions in the docstring for `get_acquisition_values`: `Xrpr`, `best_f`
    |
330 |         fit_gpytorch_mll(mll)
331 | 
332 |     def get_acquisition_values(self, model, best_f, Xrpr):
    |         ^^^^^^^^^^^^^^^^^^^^^^ D417
333 |         """Get the acquisition values.
    |

Search_algorithm\BayesianOptimisation.py:332:53: N803 Argument name `Xrpr` should be lowercase
    |
330 |         fit_gpytorch_mll(mll)
331 | 
332 |     def get_acquisition_values(self, model, best_f, Xrpr):
    |                                                     ^^^^ N803
333 |         """Get the acquisition values.
    |

Search_algorithm\BayesianOptimisation.py:344:9: N806 Variable `X_unsqueezed` in function should be lowercase
    |
343 |         """
344 |         X_unsqueezed = Xrpr.double()
    |         ^^^^^^^^^^^^ N806
345 |         X_unsqueezed = X_unsqueezed.reshape(-1, 1, X_unsqueezed.shape[1])
346 |         # set up acquisition function
    |

Search_algorithm\BayesianOptimisation.py:345:9: N806 Variable `X_unsqueezed` in function should be lowercase
    |
343 |         """
344 |         X_unsqueezed = Xrpr.double()
345 |         X_unsqueezed = X_unsqueezed.reshape(-1, 1, X_unsqueezed.shape[1])
    |         ^^^^^^^^^^^^ N806
346 |         # set up acquisition function
347 |         if self.which_acquisition == "EI":
    |

Search_algorithm\BayesianOptimisation.py:385:17: PLW0127 Self-assignment of variable `acquisition_values`
    |
383 |         elif self.which_acquisition == "UCB":
384 |             with torch.no_grad():
385 |                 acquisition_values = acquisition_values = (
    |                 ^^^^^^^^^^^^^^^^^^ PLW0127
386 |                     model.posterior(X_unsqueezed).mean.squeeze()
387 |                     + self.model.posterior(X_unsqueezed).variance.squeeze()
    |

Search_algorithm\BayesianOptimisation.py:385:38: PLW0128 Redeclared variable `acquisition_values` in assignment
    |
383 |         elif self.which_acquisition == "UCB":
384 |             with torch.no_grad():
385 |                 acquisition_values = acquisition_values = (
    |                                      ^^^^^^^^^^^^^^^^^^ PLW0128
386 |                     model.posterior(X_unsqueezed).mean.squeeze()
387 |                     + self.model.posterior(X_unsqueezed).variance.squeeze()
    |

Search_algorithm\Botorch_kernels.py:1:1: INP001 File `Search_algorithm\Botorch_kernels.py` is part of an implicit namespace package. Add an `__init__.py`.
Search_algorithm\Botorch_kernels.py:1:1: D100 Missing docstring in public module
Search_algorithm\Botorch_kernels.py:11:5: D205 1 blank line required between summary line and description
   |
 9 |   # We define our custom GP surrogate model using the Tanimoto kernel
10 |   class TanimotoGP(SingleTaskGP):
11 |       """This class is to define the surrogate model using the Tanimoto kernel.
   |  _____^
12 | |     Here the Surrogate model is defined using the Tanimoto kernel and is a subclass of SingleTaskGP.
13 | | 
14 | |     Args:
15 | |     ----
16 | |         train_X (torch.tensor): training input
17 | |         train_Y (torch.tensor): training output
18 | | 
19 | |     """
   | |_______^ D205
20 |   
21 |       def __init__(self, train_X, train_Y):
   |
   = help: Insert single blank line

Search_algorithm\Botorch_kernels.py:11:5: D404 First word of the docstring should not be "This"
   |
 9 |   # We define our custom GP surrogate model using the Tanimoto kernel
10 |   class TanimotoGP(SingleTaskGP):
11 |       """This class is to define the surrogate model using the Tanimoto kernel.
   |  _____^
12 | |     Here the Surrogate model is defined using the Tanimoto kernel and is a subclass of SingleTaskGP.
13 | | 
14 | |     Args:
15 | |     ----
16 | |         train_X (torch.tensor): training input
17 | |         train_Y (torch.tensor): training output
18 | | 
19 | |     """
   | |_______^ D404
20 |   
21 |       def __init__(self, train_X, train_Y):
   |

Search_algorithm\Botorch_kernels.py:21:9: D107 Missing docstring in `__init__`
   |
19 |     """
20 | 
21 |     def __init__(self, train_X, train_Y):
   |         ^^^^^^^^ D107
22 |         super().__init__(train_X, train_Y)
23 |         self.mean_module = ConstantMean()
   |

Search_algorithm\Botorch_kernels.py:21:24: N803 Argument name `train_X` should be lowercase
   |
19 |     """
20 | 
21 |     def __init__(self, train_X, train_Y):
   |                        ^^^^^^^ N803
22 |         super().__init__(train_X, train_Y)
23 |         self.mean_module = ConstantMean()
   |

Search_algorithm\Botorch_kernels.py:21:33: N803 Argument name `train_Y` should be lowercase
   |
19 |     """
20 | 
21 |     def __init__(self, train_X, train_Y):
   |                                 ^^^^^^^ N803
22 |         super().__init__(train_X, train_Y)
23 |         self.mean_module = ConstantMean()
   |

Search_algorithm\Botorch_kernels.py:27:9: D102 Missing docstring in public method
   |
25 |         self.to(train_X)
26 | 
27 |     def forward(self, x):
   |         ^^^^^^^ D102
28 |         mean_x = self.mean_module(x)
29 |         covar_x = self.covar_module(x)
   |

Search_algorithm\Botorch_kernels.py:34:5: D205 1 blank line required between summary line and description
   |
33 |   class MaternKernel(SingleTaskGP):
34 |       """This class is to define the surrogate model using the Matern kernel.
   |  _____^
35 | |     Here the Surrogate model is defined using the Matern kernel from GPYtorch and is a subclass of SingleTaskGP.
36 | | 
37 | |     Args:
38 | |     ----
39 | |         train_X (torch.tensor): training input
40 | |         train_Y (torch.tensor): training output
41 | | 
42 | |     """
   | |_______^ D205
43 |   
44 |       def __init__(self, train_X, train_Y):
   |
   = help: Insert single blank line

Search_algorithm\Botorch_kernels.py:34:5: D404 First word of the docstring should not be "This"
   |
33 |   class MaternKernel(SingleTaskGP):
34 |       """This class is to define the surrogate model using the Matern kernel.
   |  _____^
35 | |     Here the Surrogate model is defined using the Matern kernel from GPYtorch and is a subclass of SingleTaskGP.
36 | | 
37 | |     Args:
38 | |     ----
39 | |         train_X (torch.tensor): training input
40 | |         train_Y (torch.tensor): training output
41 | | 
42 | |     """
   | |_______^ D404
43 |   
44 |       def __init__(self, train_X, train_Y):
   |

Search_algorithm\Botorch_kernels.py:44:9: D107 Missing docstring in `__init__`
   |
42 |     """
43 | 
44 |     def __init__(self, train_X, train_Y):
   |         ^^^^^^^^ D107
45 |         super().__init__(train_X, train_Y)
46 |         self.mean_module = ConstantMean()
   |

Search_algorithm\Botorch_kernels.py:44:24: N803 Argument name `train_X` should be lowercase
   |
42 |     """
43 | 
44 |     def __init__(self, train_X, train_Y):
   |                        ^^^^^^^ N803
45 |         super().__init__(train_X, train_Y)
46 |         self.mean_module = ConstantMean()
   |

Search_algorithm\Botorch_kernels.py:44:33: N803 Argument name `train_Y` should be lowercase
   |
42 |     """
43 | 
44 |     def __init__(self, train_X, train_Y):
   |                                 ^^^^^^^ N803
45 |         super().__init__(train_X, train_Y)
46 |         self.mean_module = ConstantMean()
   |

Search_algorithm\Botorch_kernels.py:52:9: D102 Missing docstring in public method
   |
50 |         self.to(train_X)
51 | 
52 |     def change_kernel(self, kernel):
   |         ^^^^^^^^^^^^^ D102
53 |         self.covar_module = ScaleKernel(base_kernel=kernel)
   |

Search_algorithm\Botorch_kernels.py:55:9: D102 Missing docstring in public method
   |
53 |         self.covar_module = ScaleKernel(base_kernel=kernel)
54 | 
55 |     def forward(self, x):
   |         ^^^^^^^ D102
56 |         mean_x = self.mean_module(x)
57 |         covar_x = self.covar_module(x)
   |

Search_algorithm\Botorch_kernels.py:62:5: D404 First word of the docstring should not be "This"
   |
61 |   class RBFKernel(SingleTaskGP):
62 |       """This class is to define the surrogate model using the RBF kernel.
   |  _____^
63 | |     
64 | |     Here the Surrogate model is defined using the RBF kernel from GPYtorch and is a subclass of SingleTaskGP.
65 | | 
66 | |     Args:
67 | |     ----
68 | |         train_X (torch.tensor): training input
69 | |         train_Y (torch.tensor): training output
70 | | 
71 | |     """
   | |_______^ D404
72 |   
73 |       def __init__(self, train_X, train_Y):
   |

Search_algorithm\Botorch_kernels.py:73:9: D107 Missing docstring in `__init__`
   |
71 |     """
72 | 
73 |     def __init__(self, train_X, train_Y):
   |         ^^^^^^^^ D107
74 |         super().__init__(train_X, train_Y)
75 |         self.mean_module = ConstantMean()
   |

Search_algorithm\Botorch_kernels.py:73:24: N803 Argument name `train_X` should be lowercase
   |
71 |     """
72 | 
73 |     def __init__(self, train_X, train_Y):
   |                        ^^^^^^^ N803
74 |         super().__init__(train_X, train_Y)
75 |         self.mean_module = ConstantMean()
   |

Search_algorithm\Botorch_kernels.py:73:33: N803 Argument name `train_Y` should be lowercase
   |
71 |     """
72 | 
73 |     def __init__(self, train_X, train_Y):
   |                                 ^^^^^^^ N803
74 |         super().__init__(train_X, train_Y)
75 |         self.mean_module = ConstantMean()
   |

Search_algorithm\Botorch_kernels.py:81:9: D102 Missing docstring in public method
   |
79 |         self.to(train_X)
80 | 
81 |     def change_kernel(self, kernel):
   |         ^^^^^^^^^^^^^ D102
82 |         self.covar_module = ScaleKernel(base_kernel=kernel)
   |

Search_algorithm\Botorch_kernels.py:84:9: D102 Missing docstring in public method
   |
82 |         self.covar_module = ScaleKernel(base_kernel=kernel)
83 | 
84 |     def forward(self, x):
   |         ^^^^^^^ D102
85 |         mean_x = self.mean_module(x)
86 |         covar_x = self.covar_module(x)
   |

Search_algorithm\Ea_surrogate.py:1:1: INP001 File `Search_algorithm\Ea_surrogate.py` is part of an implicit namespace package. Add an `__init__.py`.
Search_algorithm\Ea_surrogate.py:1:1: D100 Missing docstring in public module
Search_algorithm\Ea_surrogate.py:12:7: N801 Class name `Ea_surrogate` should use CapWords convention
   |
12 | class Ea_surrogate(evolution_algorithm):
   |       ^^^^^^^^^^^^ N801
13 |     """Class to run the surrogate EA algorithm
14 |     Compared to the EA, here we need a surrogate model and a molecule representation to run the search
   |

Search_algorithm\Ea_surrogate.py:13:5: D205 1 blank line required between summary line and description
   |
12 |   class Ea_surrogate(evolution_algorithm):
13 |       """Class to run the surrogate EA algorithm
   |  _____^
14 | |     Compared to the EA, here we need a surrogate model and a molecule representation to run the search
15 | |     the surrogate model applied on the molecule representation is used to select a new molecule to evaluate. 
16 | |     
17 | |     the generation of offspring is the same as in the EA
18 | |     
19 | |     Args:
20 | |     ----
21 | |     
22 | |     """
   | |_______^ D205
23 |   
24 |       def __init__(self):
   |
   = help: Insert single blank line

Search_algorithm\Ea_surrogate.py:19:5: D414 Section has no content ("Args")
   |
17 |     the generation of offspring is the same as in the EA
18 |     
19 |     Args:
   |     ^^^^ D414
20 |     ----
   |

Search_algorithm\Ea_surrogate.py:24:9: D107 Missing docstring in `__init__`
   |
22 |     """
23 | 
24 |     def __init__(self):
   |         ^^^^^^^^ D107
25 |         self.device = "cuda:0" if torch.cuda.is_available() else "cpu"
26 |         self.model = None
   |

Search_algorithm\Ea_surrogate.py:37:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
35 |         self.budget = None
36 | 
37 |     def suggest_element(
   |         ^^^^^^^^^^^^^^^ PLR0913
38 |         self,
39 |         search_space_df,
   |

Search_algorithm\Ea_surrogate.py:37:9: D102 Missing docstring in public method
   |
35 |         self.budget = None
36 | 
37 |     def suggest_element(
   |         ^^^^^^^^^^^^^^^ D102
38 |         self,
39 |         search_space_df,
   |

Search_algorithm\Ea_surrogate.py:41:9: ARG002 Unused method argument: `ids_acquired`
   |
39 |         search_space_df,
40 |         fitness_acquired,
41 |         ids_acquired,
   |         ^^^^^^^^^^^^ ARG002
42 |         SP: SearchSpace,
43 |         benchmark=True,
   |

Search_algorithm\Ea_surrogate.py:42:9: N803 Argument name `SP` should be lowercase
   |
40 |         fitness_acquired,
41 |         ids_acquired,
42 |         SP: SearchSpace,
   |         ^^^^^^^^^^^^^^^ N803
43 |         benchmark=True,
44 |         df_total: pd.DataFrame = None,
   |

Search_algorithm\Ea_surrogate.py:43:9: FBT002 Boolean default positional argument in function definition
   |
41 |         ids_acquired,
42 |         SP: SearchSpace,
43 |         benchmark=True,
   |         ^^^^^^^^^ FBT002
44 |         df_total: pd.DataFrame = None,
45 |     ):
   |

Search_algorithm\Ea_surrogate.py:54:9: N806 Variable `X_unsqueezed` in function should be lowercase
   |
52 |         )
53 |         # get the best using the surrogate model
54 |         X_unsqueezed = self.Representation.generate_repr(df_elements)
   |         ^^^^^^^^^^^^ N806
55 |         if self.verbose:
56 |             pass
   |

Search_algorithm\Ea_surrogate.py:59:9: N806 Variable `X_unsqueezed` in function should be lowercase
   |
57 |         # get model prediction
58 |         # make sure that the model and the data have the same dtype
59 |         X_unsqueezed = X_unsqueezed.to(self.device)
   |         ^^^^^^^^^^^^ N806
60 |         model_dtype = next(self.pred_model.parameters()).dtype
61 |         if X_unsqueezed.dtype != model_dtype:
   |

Search_algorithm\Ea_surrogate.py:62:13: N806 Variable `X_unsqueezed` in function should be lowercase
   |
60 |         model_dtype = next(self.pred_model.parameters()).dtype
61 |         if X_unsqueezed.dtype != model_dtype:
62 |             X_unsqueezed = X_unsqueezed.type(model_dtype)
   |             ^^^^^^^^^^^^ N806
63 |         acquisition_values = (
64 |             self.pred_model(X_unsqueezed).squeeze().cpu().detach().numpy()
   |

Search_algorithm\Ea_surrogate.py:78:23: PD011 Use `.to_numpy()` instead of `.values`
   |
77 |         for elem_id in ids_sorted_by_aquisition:
78 |             element = df_elements.values[elem_id.item()]
   |                       ^^^^^^^^^^^^^^^^^^ PD011
79 |             if add_element(df_search, element):
80 |                 break
   |

Search_algorithm\Ea_surrogate.py:81:17: ERA001 Found commented-out code
   |
79 |             if add_element(df_search, element):
80 |                 break
81 |                 # index = id.item()
   |                 ^^^^^^^^^^^^^^^^^^^ ERA001
82 |                 # return df_search_space_frag
83 |         return len(df_search) - 1, df_search
   |
   = help: Remove commented-out code

Search_algorithm\Ea_surrogate.py:82:17: ERA001 Found commented-out code
   |
80 |                 break
81 |                 # index = id.item()
82 |                 # return df_search_space_frag
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
83 |         return len(df_search) - 1, df_search
   |
   = help: Remove commented-out code

Search_algorithm\MultifidelityBayesianOptimisation.py:1:1: INP001 File `Search_algorithm\MultifidelityBayesianOptimisation.py` is part of an implicit namespace package. Add an `__init__.py`.
Search_algorithm\MultifidelityBayesianOptimisation.py:1:1: D100 Missing docstring in public module
Search_algorithm\MultifidelityBayesianOptimisation.py:31:7: D101 Missing docstring in public class
   |
31 | class MultifidelityBayesianOptimisation(Search_Algorithm):
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
32 |     def __init__(
33 |         self,
   |

Search_algorithm\MultifidelityBayesianOptimisation.py:32:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
31 | class MultifidelityBayesianOptimisation(Search_Algorithm):
32 |     def __init__(
   |         ^^^^^^^^ PLR0913
33 |         self,
34 |         verbose=False,
   |

Search_algorithm\MultifidelityBayesianOptimisation.py:32:9: D417 Missing argument descriptions in the docstring for `__init__`: `budget`, `fidelity_col`
   |
31 | class MultifidelityBayesianOptimisation(Search_Algorithm):
32 |     def __init__(
   |         ^^^^^^^^ D417
33 |         self,
34 |         verbose=False,
   |

Search_algorithm\MultifidelityBayesianOptimisation.py:34:9: FBT002 Boolean default positional argument in function definition
   |
32 |     def __init__(
33 |         self,
34 |         verbose=False,
   |         ^^^^^^^ FBT002
35 |         which_acquisition="KG",
36 |         kernel=SingleTaskMultiFidelityGP,
   |

Search_algorithm\MultifidelityBayesianOptimisation.py:40:9: N803 Argument name `Representation` should be lowercase
   |
38 |         model=None,
39 |         lim_counter=2,
40 |         Representation=None,
   |         ^^^^^^^^^^^^^^ N803
41 |         fidelity_col=72,
42 |         budget=None
   |

Search_algorithm\MultifidelityBayesianOptimisation.py:61:9: ERA001 Found commented-out code
   |
59 |         self.verbose = verbose
60 |         self.which_acquisition=which_acquisition
61 |         #self.normalise_input = normalise_input
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
62 |         self.kernel = kernel
63 |         self.device = "cuda:0" if torch.cuda.is_available() else "cpu"
   |
   = help: Remove commented-out code

Search_algorithm\MultifidelityBayesianOptimisation.py:74:9: D102 Missing docstring in public method
   |
72 |         self.budget = budget
73 | 
74 |     def initial_suggestion(
   |         ^^^^^^^^^^^^^^^^^^ D102
75 |         self,
76 |         SP: SearchSpace = None,
   |

Search_algorithm\MultifidelityBayesianOptimisation.py:76:9: N803 Argument name `SP` should be lowercase
   |
74 |     def initial_suggestion(
75 |         self,
76 |         SP: SearchSpace = None,
   |         ^^^^^^^^^^^^^^^ N803
77 |         num_elem_initialisation: int = 10,
78 |         benchmark=False,
   |

Search_algorithm\MultifidelityBayesianOptimisation.py:78:9: FBT002 Boolean default positional argument in function definition
   |
76 |         SP: SearchSpace = None,
77 |         num_elem_initialisation: int = 10,
78 |         benchmark=False,
   |         ^^^^^^^^^ FBT002
79 |         df_total: pd.DataFrame = None,
80 |     ):
   |

Search_algorithm\MultifidelityBayesianOptimisation.py:82:13: N806 Variable `SP` in function should be lowercase
   |
80 |     ):
81 |         if SP is None:
82 |             SP = []
   |             ^^ N806
83 |         if benchmark:
84 |             searched_space_df = SP.check_df_for_element_from_SP(
   |

Search_algorithm\MultifidelityBayesianOptimisation.py:128:9: D102 Missing docstring in public method
    |
126 |         return searched_space_df.index.tolist(), searched_space_df
127 | 
128 |     def update_representation(self, Representation):
    |         ^^^^^^^^^^^^^^^^^^^^^ D102
129 |         self.Representation = Representation
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:128:37: N803 Argument name `Representation` should be lowercase
    |
126 |         return searched_space_df.index.tolist(), searched_space_df
127 | 
128 |     def update_representation(self, Representation):
    |                                     ^^^^^^^^^^^^^^ N803
129 |         self.Representation = Representation
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:131:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
129 |         self.Representation = Representation
130 | 
131 |     def suggest_element(
    |         ^^^^^^^^^^^^^^^ PLR0913
132 |         self,
133 |         search_space_df,
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:131:9: D417 Missing argument descriptions in the docstring for `suggest_element`: `SP`, `benchmark`, `df_total`, `fitness_acquired`, `ids_acquired`
    |
129 |         self.Representation = Representation
130 | 
131 |     def suggest_element(
    |         ^^^^^^^^^^^^^^^ D417
132 |         self,
133 |         search_space_df,
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:136:9: N803 Argument name `SP` should be lowercase
    |
134 |         fitness_acquired,
135 |         ids_acquired,
136 |         SP: SearchSpace,
    |         ^^^^^^^^^^^^^^^ N803
137 |         benchmark=True,
138 |         df_total: pd.DataFrame = None,
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:137:9: FBT002 Boolean default positional argument in function definition
    |
135 |         ids_acquired,
136 |         SP: SearchSpace,
137 |         benchmark=True,
    |         ^^^^^^^^^ FBT002
138 |         df_total: pd.DataFrame = None,
139 |     ):
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:157:9: A001 Variable `repr` is shadowing a Python builtin
    |
155 |         df_search = search_space_df.copy()
156 |         fitness_acquired = np.array(fitness_acquired)
157 |         repr = df_search.loc[ids_acquired, :]
    |         ^^^^ A001
158 | 
159 |         X_rpr = self.generate_rep_with_fidelity(repr)
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:159:9: N806 Variable `X_rpr` in function should be lowercase
    |
157 |         repr = df_search.loc[ids_acquired, :]
158 | 
159 |         X_rpr = self.generate_rep_with_fidelity(repr)
    |         ^^^^^ N806
160 |         y_explored_BO_norm = torch.tensor(
161 |             fitness_acquired, dtype=torch.float64
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:160:9: N806 Variable `y_explored_BO_norm` in function should be lowercase
    |
159 |         X_rpr = self.generate_rep_with_fidelity(repr)
160 |         y_explored_BO_norm = torch.tensor(
    |         ^^^^^^^^^^^^^^^^^^ N806
161 |             fitness_acquired, dtype=torch.float64
162 |         )
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:163:9: N806 Variable `y_explored_BO_norm` in function should be lowercase
    |
161 |             fitness_acquired, dtype=torch.float64
162 |         )
163 |         y_explored_BO_norm = (
    |         ^^^^^^^^^^^^^^^^^^ N806
164 |             y_explored_BO_norm - y_explored_BO_norm.mean(axis=0)
165 |         ) / (y_explored_BO_norm.std(axis=0))
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:166:9: N806 Variable `y_explored_BO_norm` in function should be lowercase
    |
164 |             y_explored_BO_norm - y_explored_BO_norm.mean(axis=0)
165 |         ) / (y_explored_BO_norm.std(axis=0))
166 |         y_explored_BO_norm = y_explored_BO_norm.reshape(-1, 1)
    |         ^^^^^^^^^^^^^^^^^^ N806
167 | 
168 |         # train model
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:183:44: PD011 Use `.to_numpy()` instead of `.values`
    |
182 |         for element_id in ids_sorted_by_aquisition:
183 |             if self.add_element(df_search, df_elements.values[element_id.item()]):
    |                                            ^^^^^^^^^^^^^^^^^^ PD011
184 |                 break
185 |         return len(df_search) - 1, df_search
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:189:9: D102 Missing docstring in public method
    |
187 |     # Add the new element to the search space. It checks if the element is already in the
188 |     # df which is usually the df_search (i.e. those elts formally evaulated by the OF).
189 |     def add_element(self, df, element):
    |         ^^^^^^^^^^^ D102
190 |         if ~(df == element).all(1).any():
191 |             if self.budget is not None:
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:197:9: D102 Missing docstring in public method
    |
195 |         return False
196 | 
197 |     def normalise_input(self, X_rpr):
    |         ^^^^^^^^^^^^^^^ D102
198 |         X_rpr = X_rpr.double()
199 |         # min max scaling the input
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:197:31: N803 Argument name `X_rpr` should be lowercase
    |
195 |         return False
196 | 
197 |     def normalise_input(self, X_rpr):
    |                               ^^^^^ N803
198 |         X_rpr = X_rpr.double()
199 |         # min max scaling the input
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:198:9: N806 Variable `X_rpr` in function should be lowercase
    |
197 |     def normalise_input(self, X_rpr):
198 |         X_rpr = X_rpr.double()
    |         ^^^^^ N806
199 |         # min max scaling the input
200 |         X_rpr = (X_rpr - X_rpr.min(dim=0)[0]) / (X_rpr.max(dim=0)[0] - X_rpr.min(dim=0)[0])
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:200:9: N806 Variable `X_rpr` in function should be lowercase
    |
198 |         X_rpr = X_rpr.double()
199 |         # min max scaling the input
200 |         X_rpr = (X_rpr - X_rpr.min(dim=0)[0]) / (X_rpr.max(dim=0)[0] - X_rpr.min(dim=0)[0])
    |         ^^^^^ N806
201 |         return torch.tensor(pd.DataFrame(X_rpr).fillna(0.5).to_numpy())
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:204:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
203 | # This should be edited since how we evaluate the generated elements needs to change. -EJ
204 |     def optimise_acquisition_function(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
205 |         self,
206 |         best_f,
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:204:9: D417 Missing argument descriptions in the docstring for `optimise_acquisition_function`: `SP`, `benchmark`, `df_search`, `df_total`, `fitness_acquired`
    |
203 | # This should be edited since how we evaluate the generated elements needs to change. -EJ
204 |     def optimise_acquisition_function(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D417
205 |         self,
206 |         best_f,
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:209:9: N803 Argument name `SP` should be lowercase
    |
207 |         fitness_acquired,
208 |         df_search,
209 |         SP,
    |         ^^ N803
210 |         benchmark=False,
211 |         df_total=None,
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:210:9: FBT002 Boolean default positional argument in function definition
    |
208 |         df_search,
209 |         SP,
210 |         benchmark=False,
    |         ^^^^^^^^^ FBT002
211 |         df_total=None,
212 |     ):
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:234:9: N806 Variable `Xrpr` in function should be lowercase
    |
232 |         )
233 | 
234 |         Xrpr = self.generate_rep_with_fidelity(df_elements)
    |         ^^^^ N806
235 | 
236 |         acquisition_values = self.get_acquisition_values(
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:256:13: N806 Variable `Xrpr` in function should be lowercase
    |
254 |             )
255 | 
256 |             Xrpr = self.generate_rep_with_fidelity(df_elements)
    |             ^^^^ N806
257 | 
258 |             acquisition_values = self.get_acquisition_values(
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:274:18: ERA001 Found commented-out code
    |
272 |                 max_acquisition_value = max_acquisition_value_current
273 |                 #print(
274 |                  #   f"counter is {max_counter}, max_acquisition_value is {max_acquisition_value}"
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
275 |                 #)
276 |                 counter = 0
    |
    = help: Remove commented-out code

Search_algorithm\MultifidelityBayesianOptimisation.py:275:17: ERA001 Found commented-out code
    |
273 |                 #print(
274 |                  #   f"counter is {max_counter}, max_acquisition_value is {max_acquisition_value}"
275 |                 #)
    |                 ^^ ERA001
276 |                 counter = 0
277 |             if max_counter > max_optimisation_iteration:
    |
    = help: Remove commented-out code

Search_algorithm\MultifidelityBayesianOptimisation.py:283:9: C901 `generate_element_to_evaluate` is too complex (12 > 10)
    |
281 | # Similar to the BO case, except when the elements are generated at the end we add the fidelity
282 | # data as well -EJ
283 |     def generate_element_to_evaluate(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ C901
284 |         self,
285 |         fitness_acquired,
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:287:9: N803 Argument name `SP` should be lowercase
    |
285 |         fitness_acquired,
286 |         df_search,
287 |         SP: SearchSpace,
    |         ^^^^^^^^^^^^^^^ N803
288 |         benchmark=False,
289 |         df_total=None,
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:288:9: FBT002 Boolean default positional argument in function definition
    |
286 |         df_search,
287 |         SP: SearchSpace,
288 |         benchmark=False,
    |         ^^^^^^^^^ FBT002
289 |         df_total=None,
290 |     ):
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:304:13: ANN202 Missing return type annotation for private function `mutate_element`
    |
303 |         """
304 |         def mutate_element(element):
    |             ^^^^^^^^^^^^^^ ANN202
305 |             elements_val = []
306 |             for i in range(element.shape[0]):
    |
    = help: Add return type annotation

Search_algorithm\MultifidelityBayesianOptimisation.py:313:13: ANN202 Missing return type annotation for private function `cross_element`
    |
311 |             return elements_val
312 | 
313 |         def cross_element(element1, element2):
    |             ^^^^^^^^^^^^^ ANN202
314 |             elements_val = []
315 |             for i in range(element.shape[0]):
    |
    = help: Add return type annotation

Search_algorithm\MultifidelityBayesianOptimisation.py:323:24: PD011 Use `.to_numpy()` instead of `.values`
    |
321 |         # select the 3 best one and add two random element from the search space
322 |         best_element_arg = fitness_acquired.argsort()[-3:][::-1]
323 |         list_parents = df_search.loc[best_element_arg, :].values
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
324 |         list_parents = np.append(
325 |             list_parents, df_search.sample(2).values, axis=0
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:367:36: PLR2004 Magic value used in comparison, consider replacing `10` with a constant variable
    |
365 |             df_elements = df_elements.drop_duplicates()
366 |         if (
367 |             df_elements.shape[0] > 10
    |                                    ^^ PLR2004
368 |         ):  # limit the number of elements to evaluate each time
369 |             df_elements = df_elements.sample(10)
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:373:27: N803 Argument name `X_train` should be lowercase
    |
372 | # Hardcoded values for the columns at the moment for the data-fidelities - EJ
373 |     def train_model(self, X_train, y_train):
    |                           ^^^^^^^ N803
374 |         """Train the model.
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:390:9: D417 Missing argument descriptions in the docstring for `get_acquisition_values`: `Xrpr`, `best_f`
    |
388 |         fit_gpytorch_mll(mll)
389 | 
390 |     def get_acquisition_values(self, model, best_f, Xrpr):
    |         ^^^^^^^^^^^^^^^^^^^^^^ D417
391 |         """Get the acquisition values.
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:390:53: N803 Argument name `Xrpr` should be lowercase
    |
388 |         fit_gpytorch_mll(mll)
389 | 
390 |     def get_acquisition_values(self, model, best_f, Xrpr):
    |                                                     ^^^^ N803
391 |         """Get the acquisition values.
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:402:9: N806 Variable `X_unsqueezed` in function should be lowercase
    |
401 |         """
402 |         X_unsqueezed = Xrpr.double()
    |         ^^^^^^^^^^^^ N806
403 |         X_unsqueezed = X_unsqueezed.reshape(-1, 1, X_unsqueezed.shape[1])
404 |         # set up acquisition function
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:403:9: N806 Variable `X_unsqueezed` in function should be lowercase
    |
401 |         """
402 |         X_unsqueezed = Xrpr.double()
403 |         X_unsqueezed = X_unsqueezed.reshape(-1, 1, X_unsqueezed.shape[1])
    |         ^^^^^^^^^^^^ N806
404 |         # set up acquisition function
405 |         if self.which_acquisition == "KG":
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:455:9: N802 Function name `TVR` should be lowercase
    |
453 |         return acquisition_values
454 | 
455 |     def TVR(self, model, Xrpr, best_f):
    |         ^^^ N802
456 |         Xrpr_hf = Xrpr[np.where(Xrpr[:,-1]==1)]
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:455:9: D102 Missing docstring in public method
    |
453 |         return acquisition_values
454 | 
455 |     def TVR(self, model, Xrpr, best_f):
    |         ^^^ D102
456 |         Xrpr_hf = Xrpr[np.where(Xrpr[:,-1]==1)]
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:455:26: N803 Argument name `Xrpr` should be lowercase
    |
453 |         return acquisition_values
454 | 
455 |     def TVR(self, model, Xrpr, best_f):
    |                          ^^^^ N803
456 |         Xrpr_hf = Xrpr[np.where(Xrpr[:,-1]==1)]
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:456:9: N806 Variable `Xrpr_hf` in function should be lowercase
    |
455 |     def TVR(self, model, Xrpr, best_f):
456 |         Xrpr_hf = Xrpr[np.where(Xrpr[:,-1]==1)]
    |         ^^^^^^^ N806
457 | 
458 |         acquisition = ExpectedImprovement( model=model, best_f= best_f)
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:475:9: N802 Function name `MES` should be lowercase
    |
473 |         return hf_max_cov ** 2 / (p_var.reshape(-1) * hf_max_var * cost)
474 | 
475 |     def MES(self, model, Xrpr, X_unsqueezed):
    |         ^^^ N802
476 |         fidelities = np.unique(Xrpr[:, -1])
477 |         bounds = torch.tensor([[0.0] * (Xrpr.shape[1]-1), [1.0] * (Xrpr.shape[1]-1)], dtype=torch.float64)
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:475:9: D102 Missing docstring in public method
    |
473 |         return hf_max_cov ** 2 / (p_var.reshape(-1) * hf_max_var * cost)
474 | 
475 |     def MES(self, model, Xrpr, X_unsqueezed):
    |         ^^^ D102
476 |         fidelities = np.unique(Xrpr[:, -1])
477 |         bounds = torch.tensor([[0.0] * (Xrpr.shape[1]-1), [1.0] * (Xrpr.shape[1]-1)], dtype=torch.float64)
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:475:26: N803 Argument name `Xrpr` should be lowercase
    |
473 |         return hf_max_cov ** 2 / (p_var.reshape(-1) * hf_max_var * cost)
474 | 
475 |     def MES(self, model, Xrpr, X_unsqueezed):
    |                          ^^^^ N803
476 |         fidelities = np.unique(Xrpr[:, -1])
477 |         bounds = torch.tensor([[0.0] * (Xrpr.shape[1]-1), [1.0] * (Xrpr.shape[1]-1)], dtype=torch.float64)
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:475:32: N803 Argument name `X_unsqueezed` should be lowercase
    |
473 |         return hf_max_cov ** 2 / (p_var.reshape(-1) * hf_max_var * cost)
474 | 
475 |     def MES(self, model, Xrpr, X_unsqueezed):
    |                                ^^^^^^^^^^^^ N803
476 |         fidelities = np.unique(Xrpr[:, -1])
477 |         bounds = torch.tensor([[0.0] * (Xrpr.shape[1]-1), [1.0] * (Xrpr.shape[1]-1)], dtype=torch.float64)
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:479:86: S311 Standard pseudo-random generators are not suitable for cryptographic purposes
    |
477 |         bounds = torch.tensor([[0.0] * (Xrpr.shape[1]-1), [1.0] * (Xrpr.shape[1]-1)], dtype=torch.float64)
478 |         candidate_set_no_hf = bounds[0] + np.multiply(bounds[1] - bounds[0], torch.rand(10000,  Xrpr.shape[1] -1))
479 |         candidate_set = torch.tensor(np.concatenate((candidate_set_no_hf, np.array([[random.choice(fidelities) for x in range(10000)]]).T), axis=1))
    |                                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^ S311
480 |         target_fidelities = {self.fidelity_col:1}
481 |         cost_model = AffineFidelityCostModel(fidelity_weights=target_fidelities, fixed_cost=1.0)
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:495:9: D102 Missing docstring in public method
    |
493 |                 ).detach()  # runs out of memory
494 | 
495 |     def generate_rep_with_fidelity(self, df_elements):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
496 |         repr = df_elements.drop(columns = df_elements.columns[-1])
497 |         Xrpr = self.Representation.generate_repr(repr)
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:496:9: A001 Variable `repr` is shadowing a Python builtin
    |
495 |     def generate_rep_with_fidelity(self, df_elements):
496 |         repr = df_elements.drop(columns = df_elements.columns[-1])
    |         ^^^^ A001
497 |         Xrpr = self.Representation.generate_repr(repr)
498 |         Xrpr = self.normalise_input(Xrpr)
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:497:9: N806 Variable `Xrpr` in function should be lowercase
    |
495 |     def generate_rep_with_fidelity(self, df_elements):
496 |         repr = df_elements.drop(columns = df_elements.columns[-1])
497 |         Xrpr = self.Representation.generate_repr(repr)
    |         ^^^^ N806
498 |         Xrpr = self.normalise_input(Xrpr)
499 |         fid = torch.tensor(df_elements[["fidelity"]].to_numpy(), dtype=torch.float64)
    |

Search_algorithm\MultifidelityBayesianOptimisation.py:498:9: N806 Variable `Xrpr` in function should be lowercase
    |
496 |         repr = df_elements.drop(columns = df_elements.columns[-1])
497 |         Xrpr = self.Representation.generate_repr(repr)
498 |         Xrpr = self.normalise_input(Xrpr)
    |         ^^^^ N806
499 |         fid = torch.tensor(df_elements[["fidelity"]].to_numpy(), dtype=torch.float64)
500 |         return torch.concat([Xrpr, fid], dim=1)
    |

Search_algorithm\Search_algorithm.py:1:1: INP001 File `Search_algorithm\Search_algorithm.py` is part of an implicit namespace package. Add an `__init__.py`.
Search_algorithm\Search_algorithm.py:1:1: D100 Missing docstring in public module
Search_algorithm\Search_algorithm.py:13:7: N801 Class name `Search_Algorithm` should use CapWords convention
   |
13 | class Search_Algorithm:
   |       ^^^^^^^^^^^^^^^^ N801
14 |     """Search algorithm  base class.
   |

Search_algorithm\Search_algorithm.py:39:9: D107 Missing docstring in `__init__`
   |
37 |     """
38 | 
39 |     def __init__(self):
   |         ^^^^^^^^ D107
40 |         self.name = "default"
41 |         self.multiFidelity = False
   |

Search_algorithm\Search_algorithm.py:46:9: N803 Argument name `SP` should be lowercase
   |
44 |     def suggest_element(
45 |         self,
46 |         SP: SearchSpace,
   |         ^^^^^^^^^^^^^^^ N803
47 |         search_space_df: pd.DataFrame = None,
48 |         fitness_acquired: Optional[list] = None,
   |

Search_algorithm\Search_algorithm.py:48:27: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
46 |         SP: SearchSpace,
47 |         search_space_df: pd.DataFrame = None,
48 |         fitness_acquired: Optional[list] = None,
   |                           ^^^^^^^^ FA100
49 |         ids_acquired: Optional[list] = None,
50 |         bad_ids: Optional[list] = None,
   |

Search_algorithm\Search_algorithm.py:49:23: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
47 |         search_space_df: pd.DataFrame = None,
48 |         fitness_acquired: Optional[list] = None,
49 |         ids_acquired: Optional[list] = None,
   |                       ^^^^^^^^ FA100
50 |         bad_ids: Optional[list] = None,
51 |     ) -> float:
   |

Search_algorithm\Search_algorithm.py:50:18: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
48 |         fitness_acquired: Optional[list] = None,
49 |         ids_acquired: Optional[list] = None,
50 |         bad_ids: Optional[list] = None,
   |                  ^^^^^^^^ FA100
51 |     ) -> float:
52 |         """Suggest an element to evaluate
   |

Search_algorithm\Search_algorithm.py:52:9: D205 1 blank line required between summary line and description
   |
50 |           bad_ids: Optional[list] = None,
51 |       ) -> float:
52 |           """Suggest an element to evaluate
   |  _________^
53 | |         Args:
54 | |             search_space_df (pd.DataFrame): dataframe containing the searched space.
55 | | 
56 | |             fitness_acquired (list): list of the fitness of the elements
57 | |             ids_acquired (list): list of the ids of the elements
58 | |             bad_ids (list): list of the ids of the bad elements
59 | |             SP (Search_Space): search space
60 | | 
61 | |         Returns
62 | |         -------
63 | |             float: id of the element to evaluate
64 | | 
65 | |         """
   | |___________^ D205
66 |   
67 |       def initial_suggestion(
   |
   = help: Insert single blank line

Search_algorithm\Search_algorithm.py:69:9: N803 Argument name `SP` should be lowercase
   |
67 |     def initial_suggestion(
68 |         self,
69 |         SP: SearchSpace = None,
   |         ^^^^^^^^^^^^^^^ N803
70 |         num_elem_initialisation: int = 10,
71 |         benchmark=False,
   |

Search_algorithm\Search_algorithm.py:71:9: FBT002 Boolean default positional argument in function definition
   |
69 |         SP: SearchSpace = None,
70 |         num_elem_initialisation: int = 10,
71 |         benchmark=False,
   |         ^^^^^^^^^ FBT002
72 |         df_total: pd.DataFrame = None,
73 |     ):
   |

Search_algorithm\Search_algorithm.py:74:9: D205 1 blank line required between summary line and description
   |
72 |           df_total: pd.DataFrame = None,
73 |       ):
74 |           """Initial suggestion of the search space
   |  _________^
75 | |         Args:
76 | |             SP (Search_Space): search space
77 | |             num_elem_initialisation (int): number of element to initialise
78 | |             benchmark (bool): if the search is a benchmark
79 | |             df_total (pd.DataFrame): dataframe containing the results
80 | |         Returns:
81 | |             list: list of index of the elements
82 | |         pd.DataFrame: dataframe containing the elements.
83 | |         """
   | |___________^ D205
84 |           if SP is None:
85 |               SP = []
   |
   = help: Insert single blank line

Search_algorithm\Search_algorithm.py:74:9: D401 First line of docstring should be in imperative mood: "Initial suggestion of the search space"
   |
72 |           df_total: pd.DataFrame = None,
73 |       ):
74 |           """Initial suggestion of the search space
   |  _________^
75 | |         Args:
76 | |             SP (Search_Space): search space
77 | |             num_elem_initialisation (int): number of element to initialise
78 | |             benchmark (bool): if the search is a benchmark
79 | |             df_total (pd.DataFrame): dataframe containing the results
80 | |         Returns:
81 | |             list: list of index of the elements
82 | |         pd.DataFrame: dataframe containing the elements.
83 | |         """
   | |___________^ D401
84 |           if SP is None:
85 |               SP = []
   |

Search_algorithm\Search_algorithm.py:85:13: N806 Variable `SP` in function should be lowercase
   |
83 |         """
84 |         if SP is None:
85 |             SP = []
   |             ^^ N806
86 |         if benchmark:
87 |             searched_space_df = SP.check_df_for_element_from_SP(
   |

Search_algorithm\Search_algorithm.py:120:7: N801 Class name `random_search` should use CapWords convention
    |
120 | class random_search(Search_Algorithm):
    |       ^^^^^^^^^^^^^ N801
121 |     """Random search algorithm.
    |

Search_algorithm\Search_algorithm.py:143:9: D107 Missing docstring in `__init__`
    |
141 |     """
142 | 
143 |     def __init__(self, seed=None):
    |         ^^^^^^^^ D107
144 |         self.name = "Random"
145 |         self.seed = seed
    |

Search_algorithm\Search_algorithm.py:149:13: NPY002 Replace legacy `np.random.seed` call with `np.random.Generator`
    |
147 |         self.budget = None
148 |         if seed is not None:
149 |             np.random.seed(seed)
    |             ^^^^^^^^^^^^^^ NPY002
150 | 
151 |     def suggest_element(
    |

Search_algorithm\Search_algorithm.py:151:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
149 |             np.random.seed(seed)
150 | 
151 |     def suggest_element(
    |         ^^^^^^^^^^^^^^^ PLR0913
152 |         self,
153 |         search_space_df,
    |

Search_algorithm\Search_algorithm.py:151:9: D102 Missing docstring in public method
    |
149 |             np.random.seed(seed)
150 | 
151 |     def suggest_element(
    |         ^^^^^^^^^^^^^^^ D102
152 |         self,
153 |         search_space_df,
    |

Search_algorithm\Search_algorithm.py:154:9: ARG002 Unused method argument: `ids_acquired`
    |
152 |         self,
153 |         search_space_df,
154 |         ids_acquired,
    |         ^^^^^^^^^^^^ ARG002
155 |         fitness_acquired,
156 |         SP: SearchSpace,
    |

Search_algorithm\Search_algorithm.py:155:9: ARG002 Unused method argument: `fitness_acquired`
    |
153 |         search_space_df,
154 |         ids_acquired,
155 |         fitness_acquired,
    |         ^^^^^^^^^^^^^^^^ ARG002
156 |         SP: SearchSpace,
157 |         benchmark=True,
    |

Search_algorithm\Search_algorithm.py:156:9: N803 Argument name `SP` should be lowercase
    |
154 |         ids_acquired,
155 |         fitness_acquired,
156 |         SP: SearchSpace,
    |         ^^^^^^^^^^^^^^^ N803
157 |         benchmark=True,
158 |         df_total: pd.DataFrame = None,
    |

Search_algorithm\Search_algorithm.py:157:9: FBT002 Boolean default positional argument in function definition
    |
155 |         fitness_acquired,
156 |         SP: SearchSpace,
157 |         benchmark=True,
    |         ^^^^^^^^^ FBT002
158 |         df_total: pd.DataFrame = None,
159 |     ):
    |

Search_algorithm\Search_algorithm.py:180:17: A001 Variable `id` is shadowing a Python builtin
    |
178 |                 ["InChIKey_" + str(i) for i in range(SP.number_of_fragments)]
179 |             ]
180 |             for id in df_elements.values:
    |                 ^^ A001
181 |                 if add_element(df_search, id):
182 |                     leav_loop = True
    |

Search_algorithm\Search_algorithm.py:180:23: PD011 Use `.to_numpy()` instead of `.values`
    |
178 |                 ["InChIKey_" + str(i) for i in range(SP.number_of_fragments)]
179 |             ]
180 |             for id in df_elements.values:
    |                       ^^^^^^^^^^^^^^^^^^ PD011
181 |                 if add_element(df_search, id):
182 |                     leav_loop = True
    |

Search_algorithm\Search_algorithm.py:190:7: N801 Class name `evolution_algorithm` should use CapWords convention
    |
190 | class evolution_algorithm(Search_Algorithm):
    |       ^^^^^^^^^^^^^^^^^^^ N801
191 |     """Evolution algorithm.
    |

Search_algorithm\Search_algorithm.py:232:9: D107 Missing docstring in `__init__`
    |
230 |     """
231 | 
232 |     def __init__(self):
    |         ^^^^^^^^ D107
233 |         self.name = "Evolution_algorithm"
234 |         self.selection_method_mutation = "top"
    |

Search_algorithm\Search_algorithm.py:240:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
238 |         self.budget = None
239 | 
240 |     def suggest_element(
    |         ^^^^^^^^^^^^^^^ PLR0913
241 |         self,
242 |         search_space_df,
    |

Search_algorithm\Search_algorithm.py:243:9: ARG002 Unused method argument: `ids_acquired`
    |
241 |         self,
242 |         search_space_df,
243 |         ids_acquired,
    |         ^^^^^^^^^^^^ ARG002
244 |         fitness_acquired,
245 |         SP: SearchSpace,
    |

Search_algorithm\Search_algorithm.py:245:9: N803 Argument name `SP` should be lowercase
    |
243 |         ids_acquired,
244 |         fitness_acquired,
245 |         SP: SearchSpace,
    |         ^^^^^^^^^^^^^^^ N803
246 |         benchmark=True,
247 |         df_total: pd.DataFrame = None,
    |

Search_algorithm\Search_algorithm.py:246:9: FBT002 Boolean default positional argument in function definition
    |
244 |         fitness_acquired,
245 |         SP: SearchSpace,
246 |         benchmark=True,
    |         ^^^^^^^^^ FBT002
247 |         df_total: pd.DataFrame = None,
248 |     ):
    |

Search_algorithm\Search_algorithm.py:249:9: D205 1 blank line required between summary line and description
    |
247 |           df_total: pd.DataFrame = None,
248 |       ):
249 |           """Suggest an element to evaluate
    |  _________^
250 | |         Start the algorithm by generating a list of offspring from the parents
251 | |         the list of offspring is generated by mutation and cross-over of the parents
252 | |         the selection of the parents is done using the selection method over the list of molecules in the searched space
253 | |         the selection method is defined by the user
254 | |         the selection method can be "roulette", "tournament", "rank" or "top".
255 | |         """
    | |___________^ D205
256 |           import time
257 |           random_seed = int(time.time()*1000) - int(time.time())*1000
    |
    = help: Insert single blank line

Search_algorithm\Search_algorithm.py:258:9: NPY002 Replace legacy `np.random.seed` call with `np.random.Generator`
    |
256 |         import time
257 |         random_seed = int(time.time()*1000) - int(time.time())*1000
258 |         np.random.seed(random_seed)
    |         ^^^^^^^^^^^^^^ NPY002
259 |         df_search = search_space_df
260 |         df_elements = search_space_df
    |

Search_algorithm\Search_algorithm.py:271:30: PLR2004 Magic value used in comparison, consider replacing `10` with a constant variable
    |
269 |             )
270 |             error_counter =error_counter+1
271 |             if error_counter>10:
    |                              ^^ PLR2004
272 |                 df_elements = df_elements.drop_duplicates()
273 |                 msg = "no new element found"
    |

Search_algorithm\Search_algorithm.py:281:24: PD011 Use `.to_numpy()` instead of `.values`
    |
279 |                 return True
280 |             return False
281 |         for element in df_elements.sample(frac=1).values:
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
282 |             if add_element(df_search, element):
283 |                 break
    |

Search_algorithm\Search_algorithm.py:288:9: ANN202 Missing return type annotation for private function `_check_new_element_in_search_space`
    |
288 |     def _check_new_element_in_search_space(self, df_search, df_elements):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ANN202
289 |         """Check if the element is already in the search space."""
290 |         df_search_copy = df_search.copy()
    |
    = help: Add return type annotation

Search_algorithm\Search_algorithm.py:292:18: PD015 Use `.merge` method instead of `pd.merge` function. They have equivalent functionality.
    |
290 |         df_search_copy = df_search.copy()
291 |         df_search_copy = df_search_copy[df_elements.columns]
292 |         all_df = pd.merge(df_elements,df_search_copy, how="left",indicator="exists")
    |                  ^^^^^^^^ PD015
293 |         all_df["exists"] = np.where(all_df.exists == "both", True, False)
    |

Search_algorithm\Search_algorithm.py:293:62: FBT003 Boolean positional value in function call
    |
291 |         df_search_copy = df_search_copy[df_elements.columns]
292 |         all_df = pd.merge(df_elements,df_search_copy, how="left",indicator="exists")
293 |         all_df["exists"] = np.where(all_df.exists == "both", True, False)
    |                                                              ^^^^ FBT003
294 | 
295 |         return all_df[all_df.exists is False].shape[0] > 0
    |

Search_algorithm\Search_algorithm.py:293:68: FBT003 Boolean positional value in function call
    |
291 |         df_search_copy = df_search_copy[df_elements.columns]
292 |         all_df = pd.merge(df_elements,df_search_copy, how="left",indicator="exists")
293 |         all_df["exists"] = np.where(all_df.exists == "both", True, False)
    |                                                                    ^^^^^ FBT003
294 | 
295 |         return all_df[all_df.exists is False].shape[0] > 0
    |

Search_algorithm\Search_algorithm.py:301:9: N803 Argument name `SP` should be lowercase
    |
299 |         search_space_df,
300 |         fitness_acquired,
301 |         SP: SearchSpace,
    |         ^^^^^^^^^^^^^^^ N803
302 |         benchmark=True,
303 |         df_total: pd.DataFrame = None,
    |

Search_algorithm\Search_algorithm.py:302:9: FBT002 Boolean default positional argument in function definition
    |
300 |         fitness_acquired,
301 |         SP: SearchSpace,
302 |         benchmark=True,
    |         ^^^^^^^^^ FBT002
303 |         df_total: pd.DataFrame = None,
304 |     ):
    |

Search_algorithm\Search_algorithm.py:346:13: ERA001 Found commented-out code
    |
344 |                 [f"InChIKey_{i}" for i in range(elements.shape[1])]
345 |             ]  # check this for generalization
346 |             # print(df_elements.shape)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
347 |         return df_elements, df_search
    |
    = help: Remove commented-out code

Search_algorithm\Search_algorithm.py:349:9: D102 Missing docstring in public method
    |
347 |         return df_elements, df_search
348 | 
349 |     def mutate_element(self, element, SP: SearchSpace):
    |         ^^^^^^^^^^^^^^ D102
350 |         elements = []
351 |         for i in range(element.shape[0]):  # check this for generalization
    |

Search_algorithm\Search_algorithm.py:349:39: N803 Argument name `SP` should be lowercase
    |
347 |         return df_elements, df_search
348 | 
349 |     def mutate_element(self, element, SP: SearchSpace):
    |                                       ^^^^^^^^^^^^^^^ N803
350 |         elements = []
351 |         for i in range(element.shape[0]):  # check this for generalization
    |

Search_algorithm\Search_algorithm.py:359:9: D102 Missing docstring in public method
    |
357 |         return elements
358 | 
359 |     def cross_element(self, element1, element2):
    |         ^^^^^^^^^^^^^ D102
360 |         elements = []
361 |         for i in range(element1.shape[0]):  # check this for generalization
    |

Search_algorithm\Search_algorithm.py:367:9: D102 Missing docstring in public method
    |
365 |         return elements
366 | 
367 |     def roulette_wheel_selection(self, fitness_acquired, df_search, size=3):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^ D102
368 |         total_fitness = np.sum(fitness_acquired)
369 |         selection_probs = fitness_acquired / total_fitness
    |

Search_algorithm\Search_algorithm.py:370:28: NPY002 Replace legacy `np.random.choice` call with `np.random.Generator`
    |
368 |         total_fitness = np.sum(fitness_acquired)
369 |         selection_probs = fitness_acquired / total_fitness
370 |         selected_indices = np.random.choice(
    |                            ^^^^^^^^^^^^^^^^ NPY002
371 |             df_search.index, size=size, p=selection_probs
372 |         )
    |

Search_algorithm\Search_algorithm.py:373:16: PD011 Use `.to_numpy()` instead of `.values`
    |
371 |             df_search.index, size=size, p=selection_probs
372 |         )
373 |         return df_search.loc[selected_indices].values
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
374 | 
375 |     def tournament_selection(self, fitness_acquired, df_search, size=3):
    |

Search_algorithm\Search_algorithm.py:375:9: D102 Missing docstring in public method
    |
373 |         return df_search.loc[selected_indices].values
374 | 
375 |     def tournament_selection(self, fitness_acquired, df_search, size=3):
    |         ^^^^^^^^^^^^^^^^^^^^ D102
376 |         selected_indices = []
377 |         for _ in range(size):
    |

Search_algorithm\Search_algorithm.py:378:34: NPY002 Replace legacy `np.random.choice` call with `np.random.Generator`
    |
376 |         selected_indices = []
377 |         for _ in range(size):
378 |             tournament_indices = np.random.choice(df_search.index, size=2)
    |                                  ^^^^^^^^^^^^^^^^ NPY002
379 |             tournament_fitness = fitness_acquired[tournament_indices]
380 |             winner_index = tournament_indices[np.argmax(tournament_fitness)]
    |

Search_algorithm\Search_algorithm.py:382:16: PD011 Use `.to_numpy()` instead of `.values`
    |
380 |             winner_index = tournament_indices[np.argmax(tournament_fitness)]
381 |             selected_indices.append(winner_index)
382 |         return df_search.loc[selected_indices].values
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
383 | 
384 |     def rank_selection(self, fitness_acquired, df_search, size=3):
    |

Search_algorithm\Search_algorithm.py:384:9: D102 Missing docstring in public method
    |
382 |         return df_search.loc[selected_indices].values
383 | 
384 |     def rank_selection(self, fitness_acquired, df_search, size=3):
    |         ^^^^^^^^^^^^^^ D102
385 |         ranks = np.argsort(np.argsort(fitness_acquired))
386 |         total_ranks = np.sum(ranks)
    |

Search_algorithm\Search_algorithm.py:388:28: NPY002 Replace legacy `np.random.choice` call with `np.random.Generator`
    |
386 |         total_ranks = np.sum(ranks)
387 |         selection_probs = ranks / total_ranks
388 |         selected_indices = np.random.choice(
    |                            ^^^^^^^^^^^^^^^^ NPY002
389 |             df_search.index, size=size, p=selection_probs
390 |         )
    |

Search_algorithm\Search_algorithm.py:391:16: PD011 Use `.to_numpy()` instead of `.values`
    |
389 |             df_search.index, size=size, p=selection_probs
390 |         )
391 |         return df_search.loc[selected_indices].values
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
392 | 
393 |     def top_selection(
    |

Search_algorithm\Search_algorithm.py:393:9: D102 Missing docstring in public method
    |
391 |         return df_search.loc[selected_indices].values
392 | 
393 |     def top_selection(
    |         ^^^^^^^^^^^^^ D102
394 |         self, fitness_acquired, df_search, size=3, number_of_random=2
395 |     ):
    |

Search_algorithm\Search_algorithm.py:397:26: NPY002 Replace legacy `np.random.choice` call with `np.random.Generator`
    |
395 |     ):
396 |         top_indices = np.argsort(fitness_acquired)[-size + number_of_random :]
397 |         random_indices = np.random.choice(df_search.shape[0], size=number_of_random)
    |                          ^^^^^^^^^^^^^^^^ NPY002
398 |         indices_considered = np.append(top_indices, random_indices)
399 |         return df_search.loc[indices_considered].values
    |

Search_algorithm\Search_algorithm.py:399:16: PD011 Use `.to_numpy()` instead of `.values`
    |
397 |         random_indices = np.random.choice(df_search.shape[0], size=number_of_random)
398 |         indices_considered = np.append(top_indices, random_indices)
399 |         return df_search.loc[indices_considered].values
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
400 | 
401 |     def run_selection_method(
    |

Search_algorithm\Search_algorithm.py:401:9: D102 Missing docstring in public method
    |
399 |         return df_search.loc[indices_considered].values
400 | 
401 |     def run_selection_method(
    |         ^^^^^^^^^^^^^^^^^^^^ D102
402 |         self, selection_method, fitness_acquired, df_search
403 |     ):
    |

Search_algorithm\Search_algorithm.py:428:9: N802 Function name `Generate_element_to_evaluate` should be lowercase
    |
426 |         return list_parents
427 | 
428 |     def Generate_element_to_evaluate(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
429 |         self, fitness_acquired, df_search, SP: SearchSpace
430 |     ):
    |

Search_algorithm\Search_algorithm.py:428:9: D102 Missing docstring in public method
    |
426 |         return list_parents
427 | 
428 |     def Generate_element_to_evaluate(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
429 |         self, fitness_acquired, df_search, SP: SearchSpace
430 |     ):
    |

Search_algorithm\Search_algorithm.py:429:44: N803 Argument name `SP` should be lowercase
    |
428 |     def Generate_element_to_evaluate(
429 |         self, fitness_acquired, df_search, SP: SearchSpace
    |                                            ^^^^^^^^^^^^^^^ N803
430 |     ):
431 |         elements = []
    |

Search_algorithm\tanimoto_kernel.py:1:1: INP001 File `Search_algorithm\tanimoto_kernel.py` is part of an implicit namespace package. Add an `__init__.py`.
Search_algorithm\tanimoto_kernel.py:1:1: D205 1 blank line required between summary line and description
  |
1 | / """Tanimoto Kernel. Operates on representations including bit vectors e.g. Morgan/ECFP6 fingerprints count vectors e.g.
2 | | RDKit fragment features.
3 | | """
  | |___^ D205
4 |   
5 |   import torch
  |
  = help: Insert single blank line

Search_algorithm\tanimoto_kernel.py:9:5: D417 Missing argument descriptions in the docstring for `batch_tanimoto_sim`: `eps`, `x2`
   |
 9 | def batch_tanimoto_sim(
   |     ^^^^^^^^^^^^^^^^^^ D417
10 |     x1: torch.Tensor, x2: torch.Tensor, eps: float = 1e-6
11 | ) -> torch.Tensor:
   |

Search_algorithm\tanimoto_kernel.py:12:5: D205 1 blank line required between summary line and description
   |
10 |       x1: torch.Tensor, x2: torch.Tensor, eps: float = 1e-6
11 |   ) -> torch.Tensor:
12 |       r"""Tanimoto similarity between two batched tensors, across last 2 dimensions.
   |  _____^
13 | |     eps argument ensures numerical stability if all zero tensors are added. Tanimoto similarity is proportional to:
14 | | 
15 | |     (<x, y>) / (||x||^2 + ||y||^2 - <x, y>)
16 | | 
17 | |     where x and y may be bit or count vectors or in set notation:
18 | | 
19 | |     |A \cap B | / |A| + |B| - |A \cap B |
20 | | 
21 | |     Args:
22 | |     ----
23 | |         x1: `[b x n x d]` Tensor where b is the batch dimension
24 | |         x2: `[b x m x d]` Tensor
25 | |         eps: Float for numerical stability. Default value is 1e-6
26 | |     Returns:
27 | |         Tensor denoting the Tanimoto similarity.
28 | | 
29 | |     """
   | |_______^ D205
30 |       if x1.ndim < 2 or x2.ndim < 2:
31 |           msg = "Tensors must have a batch dimension"
   |
   = help: Insert single blank line

Search_algorithm\tanimoto_kernel.py:12:5: D400 First line should end with a period
   |
10 |       x1: torch.Tensor, x2: torch.Tensor, eps: float = 1e-6
11 |   ) -> torch.Tensor:
12 |       r"""Tanimoto similarity between two batched tensors, across last 2 dimensions.
   |  _____^
13 | |     eps argument ensures numerical stability if all zero tensors are added. Tanimoto similarity is proportional to:
14 | | 
15 | |     (<x, y>) / (||x||^2 + ||y||^2 - <x, y>)
16 | | 
17 | |     where x and y may be bit or count vectors or in set notation:
18 | | 
19 | |     |A \cap B | / |A| + |B| - |A \cap B |
20 | | 
21 | |     Args:
22 | |     ----
23 | |         x1: `[b x n x d]` Tensor where b is the batch dimension
24 | |         x2: `[b x m x d]` Tensor
25 | |         eps: Float for numerical stability. Default value is 1e-6
26 | |     Returns:
27 | |         Tensor denoting the Tanimoto similarity.
28 | | 
29 | |     """
   | |_______^ D400
30 |       if x1.ndim < 2 or x2.ndim < 2:
31 |           msg = "Tensors must have a batch dimension"
   |
   = help: Add period

Search_algorithm\tanimoto_kernel.py:12:5: D415 First line should end with a period, question mark, or exclamation point
   |
10 |       x1: torch.Tensor, x2: torch.Tensor, eps: float = 1e-6
11 |   ) -> torch.Tensor:
12 |       r"""Tanimoto similarity between two batched tensors, across last 2 dimensions.
   |  _____^
13 | |     eps argument ensures numerical stability if all zero tensors are added. Tanimoto similarity is proportional to:
14 | | 
15 | |     (<x, y>) / (||x||^2 + ||y||^2 - <x, y>)
16 | | 
17 | |     where x and y may be bit or count vectors or in set notation:
18 | | 
19 | |     |A \cap B | / |A| + |B| - |A \cap B |
20 | | 
21 | |     Args:
22 | |     ----
23 | |         x1: `[b x n x d]` Tensor where b is the batch dimension
24 | |         x2: `[b x m x d]` Tensor
25 | |         eps: Float for numerical stability. Default value is 1e-6
26 | |     Returns:
27 | |         Tensor denoting the Tanimoto similarity.
28 | | 
29 | |     """
   | |_______^ D415
30 |       if x1.ndim < 2 or x2.ndim < 2:
31 |           msg = "Tensors must have a batch dimension"
   |
   = help: Add closing punctuation

Search_algorithm\tanimoto_kernel.py:30:18: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   |
29 |     """
30 |     if x1.ndim < 2 or x2.ndim < 2:
   |                  ^ PLR2004
31 |         msg = "Tensors must have a batch dimension"
32 |         raise ValueError(msg)
   |

Search_algorithm\tanimoto_kernel.py:30:33: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   |
29 |     """
30 |     if x1.ndim < 2 or x2.ndim < 2:
   |                                 ^ PLR2004
31 |         msg = "Tensors must have a batch dimension"
32 |         raise ValueError(msg)
   |

Search_algorithm\tanimoto_kernel.py:48:5: D205 1 blank line required between summary line and description
   |
47 |   class TanimotoKernel(Kernel):
48 |       r"""Computes a covariance matrix based on the Tanimoto kernel
   |  _____^
49 | |      between inputs :math:`\mathbf{x_1}` and :math:`\mathbf{x_2}`:
50 | | 
51 | |      .. math::
52 | | 
53 | |     \begin{equation*}
54 | |      k_{\text{Tanimoto}}(\mathbf{x}, \mathbf{x'}) = \frac{\langle\mathbf{x},
55 | |      \mathbf{x'}\rangle}{\left\lVert\mathbf{x}\right\rVert^2 + \left\lVert\mathbf{x'}\right\rVert^2 -
56 | |      \langle\mathbf{x}, \mathbf{x'}\rangle}
57 | |     \end{equation*}
58 | | 
59 | |     .. note::
60 | | 
61 | |      This kernel does not have an `outputscale` parameter. To add a scaling parameter,
62 | |      decorate this kernel with a :class:`gpytorch.test_kernels.ScaleKernel`.
63 | | 
64 | |     Example:
65 | |     -------
66 | |          >>> x = torch.randint(0, 2, (10, 5))
67 | |          >>> # Non-batch: Simple option
68 | |          >>> covar_module = gpytorch.kernels.ScaleKernel(TanimotoKernel())
69 | |          >>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)
70 | |          >>>
71 | |          >>> batch_x = torch.randint(0, 2, (2, 10, 5))
72 | |          >>> # Batch: Simple option
73 | |          >>> covar_module = gpytorch.kernels.ScaleKernel(TanimotoKernel())
74 | |          >>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)
75 | | 
76 | |     """
   | |_______^ D205
77 |   
78 |       is_stationary = False
   |
   = help: Insert single blank line

Search_algorithm\tanimoto_kernel.py:48:5: D400 First line should end with a period
   |
47 |   class TanimotoKernel(Kernel):
48 |       r"""Computes a covariance matrix based on the Tanimoto kernel
   |  _____^
49 | |      between inputs :math:`\mathbf{x_1}` and :math:`\mathbf{x_2}`:
50 | | 
51 | |      .. math::
52 | | 
53 | |     \begin{equation*}
54 | |      k_{\text{Tanimoto}}(\mathbf{x}, \mathbf{x'}) = \frac{\langle\mathbf{x},
55 | |      \mathbf{x'}\rangle}{\left\lVert\mathbf{x}\right\rVert^2 + \left\lVert\mathbf{x'}\right\rVert^2 -
56 | |      \langle\mathbf{x}, \mathbf{x'}\rangle}
57 | |     \end{equation*}
58 | | 
59 | |     .. note::
60 | | 
61 | |      This kernel does not have an `outputscale` parameter. To add a scaling parameter,
62 | |      decorate this kernel with a :class:`gpytorch.test_kernels.ScaleKernel`.
63 | | 
64 | |     Example:
65 | |     -------
66 | |          >>> x = torch.randint(0, 2, (10, 5))
67 | |          >>> # Non-batch: Simple option
68 | |          >>> covar_module = gpytorch.kernels.ScaleKernel(TanimotoKernel())
69 | |          >>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)
70 | |          >>>
71 | |          >>> batch_x = torch.randint(0, 2, (2, 10, 5))
72 | |          >>> # Batch: Simple option
73 | |          >>> covar_module = gpytorch.kernels.ScaleKernel(TanimotoKernel())
74 | |          >>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)
75 | | 
76 | |     """
   | |_______^ D400
77 |   
78 |       is_stationary = False
   |
   = help: Add period

Search_algorithm\tanimoto_kernel.py:48:5: D415 First line should end with a period, question mark, or exclamation point
   |
47 |   class TanimotoKernel(Kernel):
48 |       r"""Computes a covariance matrix based on the Tanimoto kernel
   |  _____^
49 | |      between inputs :math:`\mathbf{x_1}` and :math:`\mathbf{x_2}`:
50 | | 
51 | |      .. math::
52 | | 
53 | |     \begin{equation*}
54 | |      k_{\text{Tanimoto}}(\mathbf{x}, \mathbf{x'}) = \frac{\langle\mathbf{x},
55 | |      \mathbf{x'}\rangle}{\left\lVert\mathbf{x}\right\rVert^2 + \left\lVert\mathbf{x'}\right\rVert^2 -
56 | |      \langle\mathbf{x}, \mathbf{x'}\rangle}
57 | |     \end{equation*}
58 | | 
59 | |     .. note::
60 | | 
61 | |      This kernel does not have an `outputscale` parameter. To add a scaling parameter,
62 | |      decorate this kernel with a :class:`gpytorch.test_kernels.ScaleKernel`.
63 | | 
64 | |     Example:
65 | |     -------
66 | |          >>> x = torch.randint(0, 2, (10, 5))
67 | |          >>> # Non-batch: Simple option
68 | |          >>> covar_module = gpytorch.kernels.ScaleKernel(TanimotoKernel())
69 | |          >>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)
70 | |          >>>
71 | |          >>> batch_x = torch.randint(0, 2, (2, 10, 5))
72 | |          >>> # Batch: Simple option
73 | |          >>> covar_module = gpytorch.kernels.ScaleKernel(TanimotoKernel())
74 | |          >>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)
75 | | 
76 | |     """
   | |_______^ D415
77 |   
78 |       is_stationary = False
   |
   = help: Add closing punctuation

Search_algorithm\tanimoto_kernel.py:81:9: D107 Missing docstring in `__init__`
   |
79 |     has_lengthscale = False
80 | 
81 |     def __init__(self, **kwargs):
   |         ^^^^^^^^ D107
82 |         super().__init__(**kwargs)
   |

Search_algorithm\tanimoto_kernel.py:81:24: ANN003 Missing type annotation for `**kwargs`
   |
79 |     has_lengthscale = False
80 | 
81 |     def __init__(self, **kwargs):
   |                        ^^^^^^^^ ANN003
82 |         super().__init__(**kwargs)
   |

Search_algorithm\tanimoto_kernel.py:84:9: D102 Missing docstring in public method
   |
82 |         super().__init__(**kwargs)
83 | 
84 |     def forward(self, x1, x2, diag=False, **params):
   |         ^^^^^^^ D102
85 |         if diag:
86 |             assert x1.size() == x2.size()
   |

Search_algorithm\tanimoto_kernel.py:84:31: FBT002 Boolean default positional argument in function definition
   |
82 |         super().__init__(**kwargs)
83 | 
84 |     def forward(self, x1, x2, diag=False, **params):
   |                               ^^^^ FBT002
85 |         if diag:
86 |             assert x1.size() == x2.size()
   |

Search_algorithm\tanimoto_kernel.py:84:43: ANN003 Missing type annotation for `**params`
   |
82 |         super().__init__(**kwargs)
83 | 
84 |     def forward(self, x1, x2, diag=False, **params):
   |                                           ^^^^^^^^ ANN003
85 |         if diag:
86 |             assert x1.size() == x2.size()
   |

Search_algorithm\tanimoto_kernel.py:86:13: S101 Use of `assert` detected
   |
84 |     def forward(self, x1, x2, diag=False, **params):
85 |         if diag:
86 |             assert x1.size() == x2.size()
   |             ^^^^^^ S101
87 |             assert torch.equal(x1, x2)
88 |             return torch.ones(
   |

Search_algorithm\tanimoto_kernel.py:87:13: S101 Use of `assert` detected
   |
85 |         if diag:
86 |             assert x1.size() == x2.size()
87 |             assert torch.equal(x1, x2)
   |             ^^^^^^ S101
88 |             return torch.ones(
89 |                 *x1.shape[:-2], x1.shape[-2], dtype=x1.dtype, device=x1.device
   |

Search_algorithm\tanimoto_kernel.py:91:9: RET505 Unnecessary `else` after `return` statement
   |
89 |                 *x1.shape[:-2], x1.shape[-2], dtype=x1.dtype, device=x1.device
90 |             )
91 |         else:
   |         ^^^^ RET505
92 |             return self.covar_dist(x1, x2, **params)
   |
   = help: Remove unnecessary `else`

Search_algorithm\tanimoto_kernel.py:94:9: D417 Missing argument descriptions in the docstring for `covar_dist`: `**params`, `last_dim_is_batch`, `x1`, `x2`
   |
92 |             return self.covar_dist(x1, x2, **params)
93 | 
94 |     def covar_dist(
   |         ^^^^^^^^^^ D417
95 |         self,
96 |         x1,
   |

Search_algorithm\tanimoto_kernel.py:98:9: FBT002 Boolean default positional argument in function definition
    |
 96 |         x1,
 97 |         x2,
 98 |         last_dim_is_batch=False,
    |         ^^^^^^^^^^^^^^^^^ FBT002
 99 |         **params,
100 |     ):
    |

Search_algorithm\tanimoto_kernel.py:99:9: ANN003 Missing type annotation for `**params`
    |
 97 |         x2,
 98 |         last_dim_is_batch=False,
 99 |         **params,
    |         ^^^^^^^^ ANN003
100 |     ):
101 |         r"""This is a helper method for computing the bit vector similarity between
    |

Search_algorithm\tanimoto_kernel.py:99:11: ARG002 Unused method argument: `params`
    |
 97 |         x2,
 98 |         last_dim_is_batch=False,
 99 |         **params,
    |           ^^^^^^ ARG002
100 |     ):
101 |         r"""This is a helper method for computing the bit vector similarity between
    |

Search_algorithm\tanimoto_kernel.py:101:9: D205 1 blank line required between summary line and description
    |
 99 |           **params,
100 |       ):
101 |           r"""This is a helper method for computing the bit vector similarity between
    |  _________^
102 | |         all pairs of points in x1 and x2.
103 | | 
104 | |         Args:
105 | |         ----
106 | |             :attr:`x1` (Tensor `n x d` or `b1 x ... x bk x n x d`):
107 | |                 First set of data.
108 | |             :attr:`x2` (Tensor `m x d` or `b1 x ... x bk x m x d`):
109 | |                 Second set of data.
110 | |             :attr:`last_dim_is_batch` (tuple, optional):
111 | |                 Is the last dimension of the data a batch dimension or not?
112 | | 
113 | |         Returns:
114 | |         -------
115 | |             (:class:`Tensor`, :class:`Tensor) corresponding to the distance matrix between `x1` and `x2`.
116 | |             The shape depends on the kernel's mode
117 | |             * `diag=False`
118 | |             * `diag=False` and `last_dim_is_batch=True`: (`b x d x n x n`)
119 | |             * `diag=True`
120 | |             * `diag=True` and `last_dim_is_batch=True`: (`b x d x n`)
121 | | 
122 | |         """
    | |___________^ D205
123 |           if last_dim_is_batch:
124 |               x1 = x1.transpose(-1, -2).unsqueeze(-1)
    |
    = help: Insert single blank line

Search_algorithm\tanimoto_kernel.py:101:9: D401 First line of docstring should be in imperative mood: "This is a helper method for computing the bit vector similarity between"
    |
 99 |           **params,
100 |       ):
101 |           r"""This is a helper method for computing the bit vector similarity between
    |  _________^
102 | |         all pairs of points in x1 and x2.
103 | | 
104 | |         Args:
105 | |         ----
106 | |             :attr:`x1` (Tensor `n x d` or `b1 x ... x bk x n x d`):
107 | |                 First set of data.
108 | |             :attr:`x2` (Tensor `m x d` or `b1 x ... x bk x m x d`):
109 | |                 Second set of data.
110 | |             :attr:`last_dim_is_batch` (tuple, optional):
111 | |                 Is the last dimension of the data a batch dimension or not?
112 | | 
113 | |         Returns:
114 | |         -------
115 | |             (:class:`Tensor`, :class:`Tensor) corresponding to the distance matrix between `x1` and `x2`.
116 | |             The shape depends on the kernel's mode
117 | |             * `diag=False`
118 | |             * `diag=False` and `last_dim_is_batch=True`: (`b x d x n x n`)
119 | |             * `diag=True`
120 | |             * `diag=True` and `last_dim_is_batch=True`: (`b x d x n`)
121 | | 
122 | |         """
    | |___________^ D401
123 |           if last_dim_is_batch:
124 |               x1 = x1.transpose(-1, -2).unsqueeze(-1)
    |

Search_algorithm\tanimoto_kernel.py:101:9: D404 First word of the docstring should not be "This"
    |
 99 |           **params,
100 |       ):
101 |           r"""This is a helper method for computing the bit vector similarity between
    |  _________^
102 | |         all pairs of points in x1 and x2.
103 | | 
104 | |         Args:
105 | |         ----
106 | |             :attr:`x1` (Tensor `n x d` or `b1 x ... x bk x n x d`):
107 | |                 First set of data.
108 | |             :attr:`x2` (Tensor `m x d` or `b1 x ... x bk x m x d`):
109 | |                 Second set of data.
110 | |             :attr:`last_dim_is_batch` (tuple, optional):
111 | |                 Is the last dimension of the data a batch dimension or not?
112 | | 
113 | |         Returns:
114 | |         -------
115 | |             (:class:`Tensor`, :class:`Tensor) corresponding to the distance matrix between `x1` and `x2`.
116 | |             The shape depends on the kernel's mode
117 | |             * `diag=False`
118 | |             * `diag=False` and `last_dim_is_batch=True`: (`b x d x n x n`)
119 | |             * `diag=True`
120 | |             * `diag=True` and `last_dim_is_batch=True`: (`b x d x n`)
121 | | 
122 | |         """
    | |___________^ D404
123 |           if last_dim_is_batch:
124 |               x1 = x1.transpose(-1, -2).unsqueeze(-1)
    |

SearchedSpace.py:1:1: N999 Invalid module name: 'SearchedSpace'
SearchedSpace.py:1:1: D205 1 blank line required between summary line and description
  |
1 | / """define a class to store the searched space
2 | | this is a sub class of the search space class.
3 | | """
  | |___^ D205
4 |   
5 |   from itertools import product
  |
  = help: Insert single blank line

SearchedSpace.py:16:7: D101 Missing docstring in public class
   |
16 | class SearchedSpace(SearchSpace):
   |       ^^^^^^^^^^^^^ D101
17 |     def plot_hist_compare(self, df_all, df_list, label_list,properties_to_plot=None):
18 |         if properties_to_plot is None:
   |

SearchedSpace.py:17:9: D102 Missing docstring in public method
   |
16 | class SearchedSpace(SearchSpace):
17 |     def plot_hist_compare(self, df_all, df_list, label_list,properties_to_plot=None):
   |         ^^^^^^^^^^^^^^^^^ D102
18 |         if properties_to_plot is None:
19 |             properties_to_plot = []
   |

SearchedSpace.py:23:26: A001 Variable `property` is shadowing a Python builtin
   |
21 |         ax = ax.flatten()
22 |         def plot_hist(df, ax, color, label="all data") -> None:
23 |             for axis_num,property in enumerate(properties_to_plot):
   |                          ^^^^^^^^ A001
24 |                 df[property].hist(
25 |                     ax=ax[axis_num],
   |

SearchedSpace.py:48:13: A001 Variable `id` is shadowing a Python builtin
   |
46 |             "#457b9d",
47 |         ]
48 |         for id, df in enumerate(df_list):
   |             ^^ A001
49 |             plot_hist(df, ax, color=color_list[id], label=label_list[id])
50 |         for _ax in ax.flatten():
   |

SearchedSpace.py:51:13: ERA001 Found commented-out code
   |
49 |             plot_hist(df, ax, color=color_list[id], label=label_list[id])
50 |         for _ax in ax.flatten():
51 |             # ax.set_yscale('log')
   |             ^^^^^^^^^^^^^^^^^^^^^^ ERA001
52 |             _ax.grid(False)
53 |             _ax.set_ylabel("Density")
   |
   = help: Remove commented-out code

SearchedSpace.py:52:22: FBT003 Boolean positional value in function call
   |
50 |         for _ax in ax.flatten():
51 |             # ax.set_yscale('log')
52 |             _ax.grid(False)
   |                      ^^^^^ FBT003
53 |             _ax.set_ylabel("Density")
54 |             _ax.set_yticks([])
   |

SearchedSpace.py:59:9: D102 Missing docstring in public method
   |
57 |         return fig, ax
58 | 
59 |     def plot_histogram_fragment(
   |         ^^^^^^^^^^^^^^^^^^^^^^^ D102
60 |         self, column_name, df_list, df_total, number_of_fragments, label_list
61 |     ):
   |

SearchedSpace.py:92:17: A001 Variable `id` is shadowing a Python builtin
   |
90 |                 range=(range_min, range_max),
91 |             )
92 |             for id, df in enumerate(df_list):
   |                 ^^ A001
93 |                 df[f"{column_name}_{i}"].hist(
94 |                     ax=axs[i // 2, i % 2],
   |

SearchedSpace.py:109:13: ERA001 Found commented-out code
    |
108 |         for ax in axs.flatten():
109 |             # ax.set_yscale('log')
    |             ^^^^^^^^^^^^^^^^^^^^^^ ERA001
110 |             ax.grid(False)
111 |             ax.set_ylabel("Density")
    |
    = help: Remove commented-out code

SearchedSpace.py:110:21: FBT003 Boolean positional value in function call
    |
108 |         for ax in axs.flatten():
109 |             # ax.set_yscale('log')
110 |             ax.grid(False)
    |                     ^^^^^ FBT003
111 |             ax.set_ylabel("Density")
112 |             ax.set_yticks([])
    |

SearchedSpace.py:113:13: ERA001 Found commented-out code
    |
111 |             ax.set_ylabel("Density")
112 |             ax.set_yticks([])
113 |             # ax.legend()
    |             ^^^^^^^^^^^^^ ERA001
114 |         plt.tight_layout()
115 |         return fig, axs
    |
    = help: Remove commented-out code

SearchedSpace.py:117:9: D102 Missing docstring in public method
    |
115 |         return fig, axs
116 | 
117 |     def get_all_possible_syntax(self):
    |         ^^^^^^^^^^^^^^^^^^^^^^^ D102
118 |         perm = product(
119 |             list(range(self.number_of_fragments)),
    |

SearchedSpace.py:130:26: A001 Variable `id` is shadowing a Python builtin
    |
128 |             if i[0] == 0:
129 |                 # check that the element is not higher than its position
130 |                 for pos, id in enumerate(i):
    |                          ^^ A001
131 |                     if id > pos:
132 |                         append = False
    |

SearchedSpace.py:135:25: ERA001 Found commented-out code
    |
133 |                         break
134 |                     if id != pos and i[id] == id:
135 |                         # print(id,i[id],pos,i[pos])
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
136 |                         append = True
137 |                     elif id == pos:
    |
    = help: Remove commented-out code

SearchedSpace.py:146:9: N802 Function name `generate_interactive_condition_V2` should be lowercase
    |
144 |         return possible_syntax
145 | 
146 |     def generate_interactive_condition_V2(self, df_total: pd.DataFrame,
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
147 |                                           properties_to_plot=None):
148 |         # function to generate an interactive prompt to select the condition
    |

SearchedSpace.py:146:9: C901 `generate_interactive_condition_V2` is too complex (21 > 10)
    |
144 |         return possible_syntax
145 | 
146 |     def generate_interactive_condition_V2(self, df_total: pd.DataFrame,
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ C901
147 |                                           properties_to_plot=None):
148 |         # function to generate an interactive prompt to select the condition
    |

SearchedSpace.py:146:9: PLR0915 Too many statements (116 > 50)
    |
144 |         return possible_syntax
145 | 
146 |     def generate_interactive_condition_V2(self, df_total: pd.DataFrame,
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0915
147 |                                           properties_to_plot=None):
148 |         # function to generate an interactive prompt to select the condition
    |

SearchedSpace.py:146:9: D102 Missing docstring in public method
    |
144 |         return possible_syntax
145 | 
146 |     def generate_interactive_condition_V2(self, df_total: pd.DataFrame,
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
147 |                                           properties_to_plot=None):
148 |         # function to generate an interactive prompt to select the condition
    |

SearchedSpace.py:216:26: ARG001 Unused function argument: `b`
    |
214 |         )
215 | 
216 |         def on_click_add(b) -> None:
    |                          ^ ARG001
217 |             add_condition(
218 |                 columns_dropdown.value,
    |

SearchedSpace.py:229:29: ARG001 Unused function argument: `b`
    |
227 |                 display_conditions[i].options = self.conditions_list[i]
228 | 
229 |         def on_click_remove(b) -> None:
    |                             ^ ARG001
230 |             remove_condition(
231 |                 columns_dropdown.value,
    |

SearchedSpace.py:236:13: ERA001 Found commented-out code
    |
234 |                 fragment_dropdown.value,
235 |             )
236 |             # self.redefine_search_space()
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
237 |             self.get_space_size()
238 |             number_of_elements_text.value = f"{self.space_size:.2e}"
    |
    = help: Remove commented-out code

SearchedSpace.py:243:28: ARG001 Unused function argument: `b`
    |
241 |                 display_conditions[i].options = self.conditions_list[i]
242 | 
243 |         def on_click_clear(b) -> None:
    |                            ^ ARG001
244 |             clear_condition(
245 |                 fragment_dropdown.value,
    |

SearchedSpace.py:260:42: ARG001 Unused function argument: `b`
    |
258 |         )
259 | 
260 |         def on_click_add_to_all_fragment(b) -> None:
    |                                          ^ ARG001
261 |             for i in range(self.number_of_fragments):
262 |                 add_condition(
    |

SearchedSpace.py:271:21: PLW2901 Outer `for` loop variable `i` overwritten by inner `for` loop target
    |
269 |                 number_of_elements_text.value = f"{self.space_size:.2e}"
270 | 
271 |                 for i in range(self.number_of_fragments):
    |                     ^ PLW2901
272 |                     display_conditions[i].options = self.conditions_list[i]
    |

SearchedSpace.py:279:9: N806 Variable `Vb` in function should be lowercase
    |
277 |             display="flex", flex_flow="row", align_items="flex-start"
278 |         )
279 |         Vb = VBox(
    |         ^^ N806
280 |             [
281 |                 columns_dropdown,
    |

SearchedSpace.py:320:9: N806 Variable `top5_All_text` in function should be lowercase
    |
318 |             df_total["target"].nlargest(n=top5_percent_length).min()
319 |         )
320 |         top5_All_text = widgets.Text(
    |         ^^^^^^^^^^^^^ N806
321 |             value=str(min_target_5percent),
322 |             description="min target to be anong the 5% highest:",
    |

SearchedSpace.py:333:29: ARG001 Unused function argument: `b`
    |
331 |         )
332 | 
333 |         def on_click_syntax(b) -> None:
    |                             ^ ARG001
334 |             self.syntax = syntax_dropdown.value
335 |             self.get_space_size()
    |

SearchedSpace.py:340:13: ERA001 Found commented-out code
    |
338 |             for i in range(self.number_of_fragments):
339 |                 display_conditions[i].options = self.conditions_list[i]
340 |             # number_of_elements_text.value = "{:.2e}".format(self.space_size)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
341 | 
342 |         syntax_button.on_click(on_click_syntax)
    |
    = help: Remove commented-out code

SearchedSpace.py:343:9: N806 Variable `Vb` in function should be lowercase
    |
342 |         syntax_button.on_click(on_click_syntax)
343 |         Vb = VBox(
    |         ^^ N806
344 |             [
345 |                 syntax_dropdown,
    |

SearchedSpace.py:365:9: N806 Variable `Vb` in function should be lowercase
    |
363 |             display_conditions[i].disabled = True
364 |         # change display of list in to a table
365 |         Vb = VBox(
    |         ^^ N806
366 |             display_conditions,
367 |             layout=vbox_layout,
    |

SearchedSpace.py:385:33: ARG001 Unused function argument: `b`
    |
383 |         ]
384 | 
385 |         def add_to_hist_compare(b) -> None:
    |                                 ^ ARG001
386 |             # self.redefine_search_space()
387 |             self.list_fragment = self.generate_list_fragment(
    |

SearchedSpace.py:386:13: ERA001 Found commented-out code
    |
385 |         def add_to_hist_compare(b) -> None:
386 |             # self.redefine_search_space()
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
387 |             self.list_fragment = self.generate_list_fragment(
388 |                 self.generation_type
    |
    = help: Remove commented-out code

SearchedSpace.py:427:23: ARG001 Unused function argument: `b`
    |
425 |             )
426 | 
427 |         def save_data(b) -> None:
    |                       ^ ARG001
428 |             import os
    |

SearchedSpace.py:431:16: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
    |
430 |             path_to_save = "data/search_space_properties.pkl"
431 |             if os.path.exists(path_to_save):
    |                ^^^^^^^^^^^^^^ PTH110
432 |                 df_search_space_properties = pd.read_pickle(path_to_save)
433 |                 df_search_space_properties_2 = pd.DataFrame.from_dict(
    |

SearchedSpace.py:432:46: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
    |
430 |             path_to_save = "data/search_space_properties.pkl"
431 |             if os.path.exists(path_to_save):
432 |                 df_search_space_properties = pd.read_pickle(path_to_save)
    |                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ S301
433 |                 df_search_space_properties_2 = pd.DataFrame.from_dict(
434 |                     search_space_properties
    |

__init__.py:1:1: D104 Missing docstring in public package
__init__.py:4:7: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
  |
3 | if sys.version_info[:2] >= (3, 8):
4 |     # TODO: Import directly (no need for conditional) when `python_requires = >= 3.8`
  |       ^^^^ TD002
5 |     from importlib.metadata import (
6 |         PackageNotFoundError,
  |

__init__.py:4:7: TD003 Missing issue link on the line following this TODO
  |
3 | if sys.version_info[:2] >= (3, 8):
4 |     # TODO: Import directly (no need for conditional) when `python_requires = >= 3.8`
  |       ^^^^ TD003
5 |     from importlib.metadata import (
6 |         PackageNotFoundError,
  |

__init__.py:4:7: FIX002 Line contains TODO, consider resolving the issue
  |
3 | if sys.version_info[:2] >= (3, 8):
4 |     # TODO: Import directly (no need for conditional) when `python_requires = >= 3.8`
  |       ^^^^ FIX002
5 |     from importlib.metadata import (
6 |         PackageNotFoundError,
  |

geom3d\dataloader.py:1:1: INP001 File `geom3d\dataloader.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\dataloader.py:1:1: D205 1 blank line required between summary line and description
  |
1 | / """script with the data loading functions
2 | | created by Mohammed Azzouzi
3 | | date: 2023-11-14.
4 | | """
  | |___^ D205
5 |   
6 |   import os
  |
  = help: Insert single blank line

geom3d\dataloader.py:20:5: D205 1 blank line required between summary line and description
   |
19 |   def load_data_df(config, df_oligomer, dataset_name="train"):
20 |       """Load the data from the dataframe and the database
   |  _____^
21 | |     Args:
22 | |         config: dict
23 | |             configuration file
24 | |         df_oligomer: pd.DataFrame
25 | |             dataframe of the oligomer dataset
26 | |         dataset_name: name added to the dataset
27 | |             dataframe of the precursors
28 | |     Returns:
29 | |         dataset: list
30 | |             list of the dataset.
31 | | 
32 | |     to do: add the option to load the dataset from a global dataset file
33 | |     """
   | |_______^ D205
34 |       if f"dataset_path_{dataset_name}" in config:
35 |           if os.path.exists(config[f"dataset_path_{dataset_name}"]):
   |
   = help: Insert single blank line

geom3d\dataloader.py:35:12: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   |
33 |     """
34 |     if f"dataset_path_{dataset_name}" in config:
35 |         if os.path.exists(config[f"dataset_path_{dataset_name}"]):
   |            ^^^^^^^^^^^^^^ PTH110
36 |             if "device" in config:
37 |                 dataset = torch.load(
   |

geom3d\dataloader.py:43:9: RET505 Unnecessary `else` after `return` statement
   |
41 |                 dataset = torch.load(config["dataset_path"])
42 |             return dataset
43 |         else:
   |         ^^^^ RET505
44 |             pass
   |
   = help: Remove unnecessary `else`

geom3d\dataloader.py:64:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   |
62 |     if config["save_dataset"]:
63 |         name = config["name"]
64 |         os.makedirs(name, exist_ok=True)
   |         ^^^^^^^^^^^ PTH103
65 |         torch.save(dataset, "training/" + name + f"/{len(dataset)}dataset.pt")
66 |     return dataset
   |

geom3d\dataloader.py:69:5: PLR0913 Too many arguments in function definition (6 > 5)
   |
69 | def generate_dataset(
   |     ^^^^^^^^^^^^^^^^ PLR0913
70 |     df_total,
71 |     db,
   |

geom3d\dataloader.py:69:5: D417 Missing argument descriptions in the docstring for `generate_dataset`: `db`, `model_name`, `number_of_molecules`, `radius`, `target_name`
   |
69 | def generate_dataset(
   |     ^^^^^^^^^^^^^^^^ D417
70 |     df_total,
71 |     db,
   |

geom3d\dataloader.py:94:22: NPY002 Replace legacy `np.random.choice` call with `np.random.Generator`
   |
92 |     if number_of_molecules > len(df_total):
93 |         number_of_molecules = len(df_total)
94 |     molecule_index = np.random.choice(
   |                      ^^^^^^^^^^^^^^^^ NPY002
95 |         len(df_total), number_of_molecules, replace=False
96 |     )
   |

geom3d\dataloader.py:99:9: ERA001 Found commented-out code
    |
 97 |     data_list = []
 98 |     for i in molecule_index:
 99 |         # try:
    |         ^^^^^^ ERA001
100 |         #     molecule = load_molecule(
101 |         #         df_total["InChIKey"][i], df_total["target"][i], db
    |
    = help: Remove commented-out code

geom3d\dataloader.py:100:9: ERA001 Found commented-out code
    |
 98 |     for i in molecule_index:
 99 |         # try:
100 |         #     molecule = load_molecule(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
101 |         #         df_total["InChIKey"][i], df_total["target"][i], db
102 |         #     )
    |
    = help: Remove commented-out code

geom3d\dataloader.py:101:9: ERA001 Found commented-out code
    |
 99 |         # try:
100 |         #     molecule = load_molecule(
101 |         #         df_total["InChIKey"][i], df_total["target"][i], db
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
102 |         #     )
103 |         #     data_list.append(molecule)
    |
    = help: Remove commented-out code

geom3d\dataloader.py:102:9: ERA001 Found commented-out code
    |
100 |         #     molecule = load_molecule(
101 |         #         df_total["InChIKey"][i], df_total["target"][i], db
102 |         #     )
    |         ^^^^^^^ ERA001
103 |         #     data_list.append(molecule)
104 |         # except KeyError:
    |
    = help: Remove commented-out code

geom3d\dataloader.py:103:9: ERA001 Found commented-out code
    |
101 |         #         df_total["InChIKey"][i], df_total["target"][i], db
102 |         #     )
103 |         #     data_list.append(molecule)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
104 |         # except KeyError:
105 |         #     print(f"No key found in the database for molecule at index {i}")
    |
    = help: Remove commented-out code

geom3d\dataloader.py:104:9: ERA001 Found commented-out code
    |
102 |         #     )
103 |         #     data_list.append(molecule)
104 |         # except KeyError:
    |         ^^^^^^^^^^^^^^^^^^ ERA001
105 |         #     print(f"No key found in the database for molecule at index {i}")
106 |         molecule = load_molecule(
    |
    = help: Remove commented-out code

geom3d\dataloader.py:105:9: ERA001 Found commented-out code
    |
103 |         #     data_list.append(molecule)
104 |         # except KeyError:
105 |         #     print(f"No key found in the database for molecule at index {i}")
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
106 |         molecule = load_molecule(
107 |             df_total["InChIKey"].iloc[i], df_total[target_name].iloc[i], db
    |
    = help: Remove commented-out code

geom3d\dataloader.py:121:5: D417 Missing argument descriptions in the docstring for `load_molecule`: `InChIKey`, `db`, `target`
    |
121 | def load_molecule(InChIKey, target, db):
    |     ^^^^^^^^^^^^^ D417
122 |     """Load a molecule from the database.
    |

geom3d\dataloader.py:121:19: N803 Argument name `InChIKey` should be lowercase
    |
121 | def load_molecule(InChIKey, target, db):
    |                   ^^^^^^^^ N803
122 |     """Load a molecule from the database.
    |

geom3d\dataloader.py:136:5: SIM105 Use `contextlib.suppress(KeyError)` instead of `try`-`except`-`pass`
    |
134 |       """
135 |       polymer = None
136 |       try:
    |  _____^
137 | |         polymer = db.get({"InChIKey": InChIKey})
138 | |         # Print the complete dictionary returned from the database
139 | |         # print("Database entry for InChIKey:", polymer)
140 | |     except KeyError:
141 | |         pass
    | |____________^ SIM105
142 |           # Handle the missing key case (e.g., return a default value or raise an exception)
    |
    = help: Replace with `contextlib.suppress(KeyError)`

geom3d\dataloader.py:139:9: ERA001 Found commented-out code
    |
137 |         polymer = db.get({"InChIKey": InChIKey})
138 |         # Print the complete dictionary returned from the database
139 |         # print("Database entry for InChIKey:", polymer)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
140 |     except KeyError:
141 |         pass
    |
    = help: Remove commented-out code

geom3d\dataloader.py:158:5: RET505 Unnecessary `else` after `return` statement
    |
156 |             x=atom_types, positions=positions, y=y, InChIKey=InChIKey,
157 |         )
158 |     else:
    |     ^^^^ RET505
159 |         return None
    |
    = help: Remove unnecessary `else`

geom3d\dataloader.py:163:5: D205 1 blank line required between summary line and description
    |
162 |   def load_frag_dataset_from_file(config, dataset_name="train"):
163 |       """Load the fragment dataset from the file
    |  _____^
164 | |     Args:
165 | |         config: dict
166 | |             configuration file
167 | |     Returns:
168 | |         dataset: list
169 | |             list of the dataset.
170 | |     """
    | |_______^ D205
171 |       if "device" in config:
172 |           dataset = torch.load(
    |
    = help: Insert single blank line

geom3d\dataloader.py:182:8: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
    |
180 |         )
181 | 
182 |     if os.path.exists(config["model_embedding_chkpt"]):
    |        ^^^^^^^^^^^^^^ PTH110
183 |         chkpt_path = config["model_embedding_chkpt"]
184 |         checkpoint = torch.load(chkpt_path, map_location=config["device"])
    |

geom3d\dataloader.py:194:5: RET505 Unnecessary `else` after `return` statement
    |
193 |         return dataset, pymodel
194 |     else:
    |     ^^^^ RET505
195 |         return None, None
    |
    = help: Remove unnecessary `else`

geom3d\dataloader.py:201:5: D205 1 blank line required between summary line and description
    |
199 |       config, df_total=None, dataset_opt=None, dataset_name="train"
200 |   ):
201 |       """Load the fragment dataset from the dataframe or the database
    |  _____^
202 | |     Args:
203 | |         config: dict
204 | |             configuration file
205 | |         df_total: pd.DataFrame
206 | |             dataframe of the oligomer dataset
207 | |         dataset_opt: list
208 | |             list of the dataset
209 | |     Returns:
210 | |         dataset: list
211 | |             list of the dataset
212 | |         pymodel: Pymodel
213 | |     the model.
214 | |     """
    | |_______^ D205
215 |       if "frag_dataset_path_" + dataset_name in config:
216 |           if os.path.exists(config["frag_dataset_path_" + dataset_name]):
    |
    = help: Insert single blank line

geom3d\dataloader.py:216:12: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
    |
214 |     """
215 |     if "frag_dataset_path_" + dataset_name in config:
216 |         if os.path.exists(config["frag_dataset_path_" + dataset_name]):
    |            ^^^^^^^^^^^^^^ PTH110
217 |             dataset, model = load_frag_dataset_from_file(config, dataset_name)
218 |             return dataset, model
    |

geom3d\dataloader.py:219:9: RET505 Unnecessary `else` after `return` statement
    |
217 |             dataset, model = load_frag_dataset_from_file(config, dataset_name)
218 |             return dataset, model
219 |         else:
    |         ^^^^ RET505
220 |             pass
221 |     if os.path.exists(config["dataset_path"]):
    |
    = help: Remove unnecessary `else`

geom3d\dataloader.py:221:8: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
    |
219 |         else:
220 |             pass
221 |     if os.path.exists(config["dataset_path"]):
    |        ^^^^^^^^^^^^^^ PTH110
222 |         if "device" in config:
223 |             dataset_opt = torch.load(
    |

geom3d\dataloader.py:242:8: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
    |
240 |     )
241 |     # check if model is in the path
242 |     if os.path.exists(config["model_embedding_chkpt"]):
    |        ^^^^^^^^^^^^^^ PTH110
243 |         chkpt_path = config["model_embedding_chkpt"]
244 |         checkpoint = torch.load(chkpt_path, map_location=config["device"])
    |

geom3d\dataloader.py:250:9: ERA001 Found commented-out code
    |
248 |         # Load the state dictionary
249 |         pymodel.load_state_dict(state_dict=checkpoint["state_dict"])
250 |         #pymodel.load_state_dict(state_dict=checkpoint["state_dict"])
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
251 |         pymodel.to(config["device"])
252 |         model = pymodel.molecule_3D_repr
    |
    = help: Remove commented-out code

geom3d\dataloader.py:269:5: ERA001 Found commented-out code
    |
267 |     )
268 |     # if config["save_dataset_frag"]:
269 |     #   name = config["name"] + "/transformer"
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
270 |     #  os.makedirs(name, exist_ok=True)
271 |     # torch.save(dataset, name + "/dataset_frag.pt")
    |
    = help: Remove commented-out code

geom3d\dataloader.py:270:5: ERA001 Found commented-out code
    |
268 |     # if config["save_dataset_frag"]:
269 |     #   name = config["name"] + "/transformer"
270 |     #  os.makedirs(name, exist_ok=True)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
271 |     # torch.save(dataset, name + "/dataset_frag.pt")
272 |     return dataset, pymodel
    |
    = help: Remove commented-out code

geom3d\dataloader.py:271:5: ERA001 Found commented-out code
    |
269 |     #   name = config["name"] + "/transformer"
270 |     #  os.makedirs(name, exist_ok=True)
271 |     # torch.save(dataset, name + "/dataset_frag.pt")
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
272 |     return dataset, pymodel
    |
    = help: Remove commented-out code

geom3d\dataloader.py:275:5: PLR0913 Too many arguments in function definition (7 > 5)
    |
275 | def generate_dataset_frag_pd(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
276 |     df_total,
277 |     model,
    |

geom3d\dataloader.py:284:5: D205 1 blank line required between summary line and description
    |
282 |       config=None,
283 |   ):
284 |       """Generate the fragment dataset from the dataframe
    |  _____^
285 | |     Args:
286 | |         df_total: pd.DataFrame
287 | |             dataframe of the oligomer dataset
288 | |         model: 3d rpr model
289 | |             torch model
290 | |         db: stk.ConstructedMoleculeMongoDb
291 | |             database of the molecules
292 | |         number_of_molecules: int
293 | |             number of molecules to generate
294 | |         number_of_fragement: int
295 | |             number of fragment
296 | |         device: str
297 | |             device to use
298 | |     Returns:
299 | |         data_list: list
300 | |             list of the dataset.
301 | |     """
    | |_______^ D205
302 |       if number_of_molecules > len(df_total):
303 |           number_of_molecules = len(df_total)
    |
    = help: Insert single blank line

geom3d\dataloader.py:305:22: NPY002 Replace legacy `np.random.choice` call with `np.random.Generator`
    |
303 |         number_of_molecules = len(df_total)
304 | 
305 |     molecule_index = np.random.choice(
    |                      ^^^^^^^^^^^^^^^^ NPY002
306 |         len(df_total), number_of_molecules, replace=False
307 |     )
    |

geom3d\dataloader.py:325:5: PLR0913 Too many arguments in function definition (7 > 5)
    |
325 | def generate_dataset_frag_dataset(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
326 |     dataset,
327 |     model,
    |

geom3d\dataloader.py:334:5: D205 1 blank line required between summary line and description
    |
332 |       config=None,
333 |   ):
334 |       """Generate the fragment dataset from the dataset
    |  _____^
335 | |     Args:
336 | |         dataset: list
337 | |             list of the dataset
338 | |         model: 3d rpr model
339 | |             torch model
340 | |         db: stk.ConstructedMoleculeMongoDb
341 | |             database of the molecules
342 | |         number_of_molecules: int
343 | |             number of molecules to generate
344 | |         number_of_fragement: int
345 | |             number of fragment
346 | |         device: str
347 | |             device to use
348 | |     Returns:
349 | |         data_list: list
350 | |             list of the dataset.
351 | |     """
    | |_______^ D205
352 |       data_list = []
353 |       if len(dataset) < number_of_molecules:
    |
    = help: Insert single blank line

geom3d\dataloader.py:355:22: NPY002 Replace legacy `np.random.choice` call with `np.random.Generator`
    |
353 |     if len(dataset) < number_of_molecules:
354 |         number_of_molecules = len(dataset)
355 |     molecule_index = np.random.choice(
    |                      ^^^^^^^^^^^^^^^^ NPY002
356 |         len(dataset), number_of_molecules, replace=False
357 |     )
    |

geom3d\dataloader.py:374:5: PLR0913 Too many arguments in function definition (7 > 5)
    |
374 | def fragment_based_encoding(
    |     ^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
375 |     InChIKey,
376 |     db_poly,
    |

geom3d\dataloader.py:375:5: N803 Argument name `InChIKey` should be lowercase
    |
374 | def fragment_based_encoding(
375 |     InChIKey,
    |     ^^^^^^^^ N803
376 |     db_poly,
377 |     model,
    |

geom3d\dataloader.py:383:5: D205 1 blank line required between summary line and description
    |
381 |       radius=0.1,
382 |   ):
383 |       """Fragment based encoding
    |  _____^
384 | |     Args:
385 | |         InChIKey: str
386 | |             InChIKey of the molecule
387 | |         db_poly: stk.ConstructedMoleculeMongoDb
388 | |             database of the molecules
389 | |         model: 3d rpr model
390 | |             torch model
391 | |         number_of_fragement: int
392 | |             number of fragment
393 | |         device: str
394 | |             device to use
395 | |     Returns:
396 | |         frags: list
397 | |             list of the fragments.
398 | |     """
    | |_______^ D205
399 |       if device is None:
400 |           device = "cuda" if torch.cuda.is_available() else torch.device("cpu")
    |
    = help: Insert single blank line

geom3d\dataloader.py:460:5: D205 1 blank line required between summary line and description
    |
458 |       frag_dataset, dataset, model, model_name
459 |   ):
460 |       """Update the fragment dataset
    |  _____^
461 | |     Args:
462 | |         frag_dataset: list
463 | |             list of the fragment dataset
464 | |         dataset: list
465 | |             list of the dataset
466 | |         model: torch model
467 | |             the model for the prediction
468 | |         model_name: str
469 | |             the name of the model
470 | |     Returns:
471 | |         frag_dataset: list
472 | |             list of the fragment dataset.
473 | |     """
    | |_______^ D205
474 |       dataset_dict = {data.InChIKey: data for data in dataset}
    |
    = help: Insert single blank line

geom3d\dataloader.py:499:14: ARG001 Unused function argument: `df`
    |
498 | def updata_dataset(
499 |     dataset, df, target_name
    |              ^^ ARG001
500 | ):
501 |     """Update the oligomer dataset
    |

geom3d\dataloader.py:499:18: ARG001 Unused function argument: `target_name`
    |
498 | def updata_dataset(
499 |     dataset, df, target_name
    |                  ^^^^^^^^^^^ ARG001
500 | ):
501 |     """Update the oligomer dataset
    |

geom3d\dataloader.py:501:5: D205 1 blank line required between summary line and description
    |
499 |       dataset, df, target_name
500 |   ):
501 |       """Update the oligomer dataset
    |  _____^
502 | |     Args:
503 | |         dataset: list
504 | |             list of the dataset
505 | |         model: torch model
506 | |             the model for the prediction
507 | |         model_name: str
508 | |             the name of the model
509 | |     Returns:
510 | |         frag_dataset: list
511 | |             list of the fragment dataset.
512 | |     """
    | |_______^ D205
513 |       for data in dataset:
514 |           data.y = None
    |
    = help: Insert single blank line

geom3d\dataloader.py:519:5: D205 1 blank line required between summary line and description
    |
518 |   def generate_dataset_and_dataloader(config):
519 |       """Generate the dataset and the dataloader
    |  _____^
520 | |     Args:
521 | |         config: dict
522 | |             configuration file
523 | |     Returns:
524 | |         train_loader: torch_geometric.loader.DataLoader
525 | |             dataloader for the training set
526 | |         val_loader: torch_geometric.loader.DataLoader
527 | |             dataloader for the validation set
528 | |         test_loader: torch_geometric.loader.DataLoader
529 | |             dataloader for the test set
530 | |         dataset_train: list
531 | |             list of the training dataset
532 | |         dataset_val: list
533 | |             list of the validation dataset
534 | |         dataset_test: list
535 | |             list of the test dataset.
536 | |     """
    | |_______^ D205
537 |   
538 |       def get_dataset_dataloader(config, df_name="train"):
    |
    = help: Insert single blank line

geom3d\dataloader.py:538:9: ANN202 Missing return type annotation for private function `get_dataset_dataloader`
    |
536 |     """
537 | 
538 |     def get_dataset_dataloader(config, df_name="train"):
    |         ^^^^^^^^^^^^^^^^^^^^^^ ANN202
539 |         df_precursors = pd.read_pickle(config["df_precursor"])
540 |         if f"dataset_path_{df_name}" in config:
    |
    = help: Add return type annotation

geom3d\dataloader.py:539:25: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
    |
538 |     def get_dataset_dataloader(config, df_name="train"):
539 |         df_precursors = pd.read_pickle(config["df_precursor"])
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ S301
540 |         if f"dataset_path_{df_name}" in config:
541 |             if os.path.exists(config["dataset_path" + f"_{df_name}"]):
    |

geom3d\dataloader.py:541:16: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
    |
539 |         df_precursors = pd.read_pickle(config["df_precursor"])
540 |         if f"dataset_path_{df_name}" in config:
541 |             if os.path.exists(config["dataset_path" + f"_{df_name}"]):
    |                ^^^^^^^^^^^^^^ PTH110
542 |                 if "device" in config:
543 |                     dataset = torch.load(
    |

geom3d\dataloader.py:553:13: RET505 Unnecessary `else` after `return` statement
    |
551 |                 data_loader = get_data_loader(dataset, config)
552 |                 return dataset, data_loader
553 |             else:
    |             ^^^^ RET505
554 |                 pass
555 |         df = pd.read_csv(config["running_dir"] + f"/df_{df_name}.csv")
    |
    = help: Remove unnecessary `else`

geom3d\dataloader.py:555:9: PD901 Avoid using the generic variable name `df` for DataFrames
    |
553 |             else:
554 |                 pass
555 |         df = pd.read_csv(config["running_dir"] + f"/df_{df_name}.csv")
    |         ^^ PD901
556 |         dataset = load_data_df(config, df, df_precursors)
557 |         data_loader = get_data_loader(dataset, config)
    |

geom3d\dataloader.py:577:5: D205 1 blank line required between summary line and description
    |
576 |   def get_data_loader(dataset, config):
577 |       """Get the dataloader
    |  _____^
578 | |     Args:
579 | |         dataset: list
580 | |             list of the dataset
581 | |         config: dict
582 | |             configuration file.
583 | | 
584 | |     Returns
585 | |     -------
586 | |         loader: torch_geometric.loader.DataLoader
587 | |             dataloader for the dataset
588 | | 
589 | |     """
    | |_______^ D205
590 |       # Set dataloaders
591 |       return DataLoader(
    |
    = help: Insert single blank line

geom3d\models\AWARE.py:1:1: N999 Invalid module name: 'AWARE'
geom3d\models\AWARE.py:1:1: D100 Missing docstring in public module
geom3d\models\AWARE.py:2:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | import torch
2 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
3 | from torch import nn
  |

geom3d\models\AWARE.py:6:7: D101 Missing docstring in public class
  |
6 | class AWARE(nn.Module):
  |       ^^^^^ D101
7 |     def __init__(self, emb_dim, r_prime, max_walk_len, num_layers, out_dim, use_bond=False):
8 |         super().__init__()
  |

geom3d\models\AWARE.py:7:9: PLR0913 Too many arguments in function definition (6 > 5)
  |
6 | class AWARE(nn.Module):
7 |     def __init__(self, emb_dim, r_prime, max_walk_len, num_layers, out_dim, use_bond=False):
  |         ^^^^^^^^ PLR0913
8 |         super().__init__()
9 |         self.r_prime = r_prime
  |

geom3d\models\AWARE.py:7:9: D107 Missing docstring in `__init__`
  |
6 | class AWARE(nn.Module):
7 |     def __init__(self, emb_dim, r_prime, max_walk_len, num_layers, out_dim, use_bond=False):
  |         ^^^^^^^^ D107
8 |         super().__init__()
9 |         self.r_prime = r_prime
  |

geom3d\models\AWARE.py:7:77: FBT002 Boolean default positional argument in function definition
  |
6 | class AWARE(nn.Module):
7 |     def __init__(self, emb_dim, r_prime, max_walk_len, num_layers, out_dim, use_bond=False):
  |                                                                             ^^^^^^^^ FBT002
8 |         super().__init__()
9 |         self.r_prime = r_prime
  |

geom3d\models\AWARE.py:40:9: D102 Missing docstring in public method
   |
38 |             )
39 | 
40 |     def forward(self, node_attribute_matrix, adjacent_matrix, adj_attr_matrix):
   |         ^^^^^^^ D102
41 |         F_1 = self.activation(self.Wv(node_attribute_matrix))  # (B, max_node, dim)
   |

geom3d\models\AWARE.py:41:9: N806 Variable `F_1` in function should be lowercase
   |
40 |     def forward(self, node_attribute_matrix, adjacent_matrix, adj_attr_matrix):
41 |         F_1 = self.activation(self.Wv(node_attribute_matrix))  # (B, max_node, dim)
   |         ^^^ N806
42 | 
43 |         F_n = F_1
   |

geom3d\models\AWARE.py:43:9: N806 Variable `F_n` in function should be lowercase
   |
41 |         F_1 = self.activation(self.Wv(node_attribute_matrix))  # (B, max_node, dim)
42 | 
43 |         F_n = F_1
   |         ^^^ N806
44 |         f_1 = torch.sum(self.activation(self.Wg(F_n)), dim=1)  # (B, dim)
45 |         f_T = [f_1]
   |

geom3d\models\AWARE.py:45:9: N806 Variable `f_T` in function should be lowercase
   |
43 |         F_n = F_1
44 |         f_1 = torch.sum(self.activation(self.Wg(F_n)), dim=1)  # (B, dim)
45 |         f_T = [f_1]
   |         ^^^ N806
46 | 
47 |         for _n in range(self.max_walk_len - 1):
   |

geom3d\models\AWARE.py:48:13: N806 Variable `S` in function should be lowercase
   |
47 |         for _n in range(self.max_walk_len - 1):
48 |             S = torch.bmm(self.Ww(F_n), torch.transpose(F_n, 1, 2))  # (B, max_node, max_node)
   |             ^ N806
49 |             masked_S = S.masked_fill(adjacent_matrix == 0, -1e8)
50 |             A_S = self.softmax(masked_S)  # (B, max_node, max_node)
   |

geom3d\models\AWARE.py:49:13: N806 Variable `masked_S` in function should be lowercase
   |
47 |         for _n in range(self.max_walk_len - 1):
48 |             S = torch.bmm(self.Ww(F_n), torch.transpose(F_n, 1, 2))  # (B, max_node, max_node)
49 |             masked_S = S.masked_fill(adjacent_matrix == 0, -1e8)
   |             ^^^^^^^^ N806
50 |             A_S = self.softmax(masked_S)  # (B, max_node, max_node)
51 |             if self.use_bond:
   |

geom3d\models\AWARE.py:50:13: N806 Variable `A_S` in function should be lowercase
   |
48 |             S = torch.bmm(self.Ww(F_n), torch.transpose(F_n, 1, 2))  # (B, max_node, max_node)
49 |             masked_S = S.masked_fill(adjacent_matrix == 0, -1e8)
50 |             A_S = self.softmax(masked_S)  # (B, max_node, max_node)
   |             ^^^ N806
51 |             if self.use_bond:
52 |                 bond_S = self.bond_mlp(adj_attr_matrix).squeeze(dim=3)  # (B, max_node, max_node)
   |

geom3d\models\AWARE.py:52:17: N806 Variable `bond_S` in function should be lowercase
   |
50 |             A_S = self.softmax(masked_S)  # (B, max_node, max_node)
51 |             if self.use_bond:
52 |                 bond_S = self.bond_mlp(adj_attr_matrix).squeeze(dim=3)  # (B, max_node, max_node)
   |                 ^^^^^^ N806
53 |                 A_S = A_S + bond_S
54 |             # Add self-loop
   |

geom3d\models\AWARE.py:53:17: N806 Variable `A_S` in function should be lowercase
   |
51 |             if self.use_bond:
52 |                 bond_S = self.bond_mlp(adj_attr_matrix).squeeze(dim=3)  # (B, max_node, max_node)
53 |                 A_S = A_S + bond_S
   |                 ^^^ N806
54 |             # Add self-loop
55 |             F_n = (F_n + torch.bmm(A_S, F_n)) * F_1  # (B, max_node, dim)
   |

geom3d\models\AWARE.py:55:13: N806 Variable `F_n` in function should be lowercase
   |
53 |                 A_S = A_S + bond_S
54 |             # Add self-loop
55 |             F_n = (F_n + torch.bmm(A_S, F_n)) * F_1  # (B, max_node, dim)
   |             ^^^ N806
56 |             f_n = torch.sum(self.activation(self.Wg(F_n)), dim=1)  # (B, dim)
57 |             f_T.append(f_n)
   |

geom3d\models\AWARE.py:58:9: N806 Variable `f_T` in function should be lowercase
   |
56 |             f_n = torch.sum(self.activation(self.Wg(F_n)), dim=1)  # (B, dim)
57 |             f_T.append(f_n)
58 |         f_T = F.normalize(torch.cat(f_T, dim=1))
   |         ^^^ N806
59 | 
60 |         return self.target_model(f_T)
   |

geom3d\models\Allegro\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\Allegro\__init__.py:3:1: PLE0604 Invalid object in `__all__`, must contain only strings
  |
1 | from . import _keys
2 | 
3 | __all__ = [_keys]
  | ^^^^^^^ PLE0604
  |

geom3d\models\Allegro\_keys.py:5:4: YTT203 `sys.version_info[1]` compared to integer (python4), compare `sys.version_info` to tuple
  |
3 | import sys
4 | 
5 | if sys.version_info[1] >= 8:
  |    ^^^^^^^^^^^^^^^^^^^ YTT203
6 |     from typing import Final
7 | else:
  |

geom3d\models\Allegro\_keys.py:5:27: PLR2004 Magic value used in comparison, consider replacing `8` with a constant variable
  |
3 | import sys
4 | 
5 | if sys.version_info[1] >= 8:
  |                           ^ PLR2004
6 |     from typing import Final
7 | else:
  |

geom3d\models\Allegro\model\Allegro.py:1:1: N999 Invalid module name: 'Allegro'
geom3d\models\Allegro\model\Allegro.py:1:1: D100 Missing docstring in public module
geom3d\models\Allegro\model\Allegro.py:25:5: N802 Function name `Allegro` should be lowercase
   |
25 | def Allegro(config, initialize: bool, dataset: Optional[AtomicDataset] = None):
   |     ^^^^^^^ N802
26 |     logging.debug("Building Allegro model...")
   |

geom3d\models\Allegro\model\Allegro.py:25:5: D103 Missing docstring in public function
   |
25 | def Allegro(config, initialize: bool, dataset: Optional[AtomicDataset] = None):
   |     ^^^^^^^ D103
26 |     logging.debug("Building Allegro model...")
   |

geom3d\models\Allegro\model\Allegro.py:25:21: FBT001 Boolean-typed positional argument in function definition
   |
25 | def Allegro(config, initialize: bool, dataset: Optional[AtomicDataset] = None):
   |                     ^^^^^^^^^^ FBT001
26 |     logging.debug("Building Allegro model...")
   |

geom3d\models\Allegro\model\Allegro.py:25:21: ARG001 Unused function argument: `initialize`
   |
25 | def Allegro(config, initialize: bool, dataset: Optional[AtomicDataset] = None):
   |                     ^^^^^^^^^^ ARG001
26 |     logging.debug("Building Allegro model...")
   |

geom3d\models\Allegro\model\Allegro.py:25:39: ARG001 Unused function argument: `dataset`
   |
25 | def Allegro(config, initialize: bool, dataset: Optional[AtomicDataset] = None):
   |                                       ^^^^^^^ ARG001
26 |     logging.debug("Building Allegro model...")
   |

geom3d\models\Allegro\model\Allegro.py:25:48: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
25 | def Allegro(config, initialize: bool, dataset: Optional[AtomicDataset] = None):
   |                                                ^^^^^^^^ FA100
26 |     logging.debug("Building Allegro model...")
   |

geom3d\models\Allegro\model\Allegro.py:30:5: ERA001 Found commented-out code
   |
28 |     # # Handle avg num neighbors auto
29 |     # builder_utils.add_avg_num_neighbors(
30 |     #     config=config, initialize=initialize, dataset=dataset
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
31 |     # )
   |
   = help: Remove commented-out code

geom3d\models\Allegro\model\Allegro.py:31:5: ERA001 Found commented-out code
   |
29 |     # builder_utils.add_avg_num_neighbors(
30 |     #     config=config, initialize=initialize, dataset=dataset
31 |     # )
   |     ^^^ ERA001
32 | 
33 |     # Handle simple irreps
   |
   = help: Remove commented-out code

geom3d\models\Allegro\model\Allegro.py:37:9: S101 Use of `assert` detected
   |
35 |         l_max = int(config["l_max"])
36 |         parity_setting = config["parity"]
37 |         assert parity_setting in ("o3_full", "o3_restricted", "so3")
   |         ^^^^^^ S101
38 |         irreps_edge_sh = repr(
39 |             o3.Irreps.spherical_harmonics(
   |

geom3d\models\Allegro\model\Allegro.py:45:9: S101 Use of `assert` detected
   |
43 |         nonscalars_include_parity = parity_setting == "o3_full"
44 |         # check consistant
45 |         assert config.get("irreps_edge_sh", irreps_edge_sh) == irreps_edge_sh
   |         ^^^^^^ S101
46 |         assert (
47 |             config.get("nonscalars_include_parity", nonscalars_include_parity)
   |

geom3d\models\Allegro\model\Allegro.py:46:9: S101 Use of `assert` detected
   |
44 |         # check consistant
45 |         assert config.get("irreps_edge_sh", irreps_edge_sh) == irreps_edge_sh
46 |         assert (
   |         ^^^^^^ S101
47 |             config.get("nonscalars_include_parity", nonscalars_include_parity)
48 |             == nonscalars_include_parity
   |

geom3d\models\Allegro\model\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\Allegro\model\__init__.py:3:1: PLE0604 Invalid object in `__all__`, must contain only strings
  |
1 | from .Allegro import Allegro
2 | 
3 | __all__ = [Allegro]
  | ^^^^^^^ PLE0604
  |

geom3d\models\Allegro\nn\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\Allegro\nn\__init__.py:6:1: PLE0604 Invalid object in `__all__`, must contain only strings
  |
4 | from ._norm_basis import NormalizedBasis
5 | 
6 | __all__ = [
  | ^^^^^^^ PLE0604
7 |     Allegro_Module,
8 |     EdgewiseEnergySum,
  |

geom3d\models\Allegro\nn\_allegro.py:21:7: N801 Class name `Allegro_Module` should use CapWords convention
   |
20 | @compile_mode("script")
21 | class Allegro_Module(GraphModuleMixin, torch.nn.Module):
   |       ^^^^^^^^^^^^^^ N801
22 |     # saved params
23 |     num_layers: int
   |

geom3d\models\Allegro\nn\_allegro.py:33:27: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
32 |     # internal values
33 |     _env_builder_w_index: List[int]
   |                           ^^^^ FA100
34 |     _env_builder_n_irreps: int
35 |     _input_pad: int
   |

geom3d\models\Allegro\nn\_allegro.py:37:9: C901 `__init__` is too complex (26 > 10)
   |
35 |     _input_pad: int
36 | 
37 |     def __init__(
   |         ^^^^^^^^ C901
38 |         self,
39 |         # required params
   |

geom3d\models\Allegro\nn\_allegro.py:37:9: PLR0913 Too many arguments in function definition (28 > 5)
   |
35 |     _input_pad: int
36 | 
37 |     def __init__(
   |         ^^^^^^^^ PLR0913
38 |         self,
39 |         # required params
   |

geom3d\models\Allegro\nn\_allegro.py:37:9: PLR0912 Too many branches (31 > 12)
   |
35 |     _input_pad: int
36 | 
37 |     def __init__(
   |         ^^^^^^^^ PLR0912
38 |         self,
39 |         # required params
   |

geom3d\models\Allegro\nn\_allegro.py:37:9: PLR0915 Too many statements (129 > 50)
   |
35 |     _input_pad: int
36 | 
37 |     def __init__(
   |         ^^^^^^^^ PLR0915
38 |         self,
39 |         # required params
   |

geom3d\models\Allegro\nn\_allegro.py:43:28: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
41 |         num_types: int,
42 |         r_max: float,
43 |         avg_num_neighbors: Optional[float] = None,
   |                            ^^^^^^^^ FA100
44 |         # cutoffs
45 |         r_start_cos_ratio: float = 0.8,
   |

geom3d\models\Allegro\nn\_allegro.py:46:9: N803 Argument name `PolynomialCutoff_p` should be lowercase
   |
44 |         # cutoffs
45 |         r_start_cos_ratio: float = 0.8,
46 |         PolynomialCutoff_p: float = 6,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^ N803
47 |         per_layer_cutoffs: Optional[List[float]] = None,
48 |         cutoff_type: str = "polynomial",
   |

geom3d\models\Allegro\nn\_allegro.py:47:28: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
45 |         r_start_cos_ratio: float = 0.8,
46 |         PolynomialCutoff_p: float = 6,
47 |         per_layer_cutoffs: Optional[List[float]] = None,
   |                            ^^^^^^^^ FA100
48 |         cutoff_type: str = "polynomial",
49 |         # general hyperparameters:
   |

geom3d\models\Allegro\nn\_allegro.py:47:37: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
45 |         r_start_cos_ratio: float = 0.8,
46 |         PolynomialCutoff_p: float = 6,
47 |         per_layer_cutoffs: Optional[List[float]] = None,
   |                                     ^^^^ FA100
48 |         cutoff_type: str = "polynomial",
49 |         # general hyperparameters:
   |

geom3d\models\Allegro\nn\_allegro.py:54:9: FBT001 Boolean-typed positional argument in function definition
   |
52 |         node_invariant_field: str = AtomicDataDict.NODE_ATTRS_KEY,
53 |         env_embed_multiplicity: int = 32,
54 |         embed_initial_edge: bool = True,
   |         ^^^^^^^^^^^^^^^^^^ FBT001
55 |         linear_after_env_embed: bool = False,
56 |         nonscalars_include_parity: bool = True,
   |

geom3d\models\Allegro\nn\_allegro.py:54:9: FBT002 Boolean default positional argument in function definition
   |
52 |         node_invariant_field: str = AtomicDataDict.NODE_ATTRS_KEY,
53 |         env_embed_multiplicity: int = 32,
54 |         embed_initial_edge: bool = True,
   |         ^^^^^^^^^^^^^^^^^^ FBT002
55 |         linear_after_env_embed: bool = False,
56 |         nonscalars_include_parity: bool = True,
   |

geom3d\models\Allegro\nn\_allegro.py:55:9: FBT001 Boolean-typed positional argument in function definition
   |
53 |         env_embed_multiplicity: int = 32,
54 |         embed_initial_edge: bool = True,
55 |         linear_after_env_embed: bool = False,
   |         ^^^^^^^^^^^^^^^^^^^^^^ FBT001
56 |         nonscalars_include_parity: bool = True,
57 |         # MLP parameters:
   |

geom3d\models\Allegro\nn\_allegro.py:55:9: FBT002 Boolean default positional argument in function definition
   |
53 |         env_embed_multiplicity: int = 32,
54 |         embed_initial_edge: bool = True,
55 |         linear_after_env_embed: bool = False,
   |         ^^^^^^^^^^^^^^^^^^^^^^ FBT002
56 |         nonscalars_include_parity: bool = True,
57 |         # MLP parameters:
   |

geom3d\models\Allegro\nn\_allegro.py:56:9: FBT001 Boolean-typed positional argument in function definition
   |
54 |         embed_initial_edge: bool = True,
55 |         linear_after_env_embed: bool = False,
56 |         nonscalars_include_parity: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^ FBT001
57 |         # MLP parameters:
58 |         two_body_latent=ScalarMLPFunction,
   |

geom3d\models\Allegro\nn\_allegro.py:56:9: FBT002 Boolean default positional argument in function definition
   |
54 |         embed_initial_edge: bool = True,
55 |         linear_after_env_embed: bool = False,
56 |         nonscalars_include_parity: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^ FBT002
57 |         # MLP parameters:
58 |         two_body_latent=ScalarMLPFunction,
   |

geom3d\models\Allegro\nn\_allegro.py:64:9: FBT001 Boolean-typed positional argument in function definition
   |
62 |         latent=ScalarMLPFunction,
63 |         latent_kwargs=None,
64 |         latent_resnet: bool = True,
   |         ^^^^^^^^^^^^^ FBT001
65 |         latent_resnet_update_ratios: Optional[List[float]] = None,
66 |         latent_resnet_update_ratios_learnable: bool = False,
   |

geom3d\models\Allegro\nn\_allegro.py:64:9: FBT002 Boolean default positional argument in function definition
   |
62 |         latent=ScalarMLPFunction,
63 |         latent_kwargs=None,
64 |         latent_resnet: bool = True,
   |         ^^^^^^^^^^^^^ FBT002
65 |         latent_resnet_update_ratios: Optional[List[float]] = None,
66 |         latent_resnet_update_ratios_learnable: bool = False,
   |

geom3d\models\Allegro\nn\_allegro.py:65:38: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
63 |         latent_kwargs=None,
64 |         latent_resnet: bool = True,
65 |         latent_resnet_update_ratios: Optional[List[float]] = None,
   |                                      ^^^^^^^^ FA100
66 |         latent_resnet_update_ratios_learnable: bool = False,
67 |         latent_out_field: Optional[str] = _keys.EDGE_FEATURES,
   |

geom3d\models\Allegro\nn\_allegro.py:65:47: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
63 |         latent_kwargs=None,
64 |         latent_resnet: bool = True,
65 |         latent_resnet_update_ratios: Optional[List[float]] = None,
   |                                               ^^^^ FA100
66 |         latent_resnet_update_ratios_learnable: bool = False,
67 |         latent_out_field: Optional[str] = _keys.EDGE_FEATURES,
   |

geom3d\models\Allegro\nn\_allegro.py:66:9: FBT001 Boolean-typed positional argument in function definition
   |
64 |         latent_resnet: bool = True,
65 |         latent_resnet_update_ratios: Optional[List[float]] = None,
66 |         latent_resnet_update_ratios_learnable: bool = False,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ FBT001
67 |         latent_out_field: Optional[str] = _keys.EDGE_FEATURES,
68 |         # Performance parameters:
   |

geom3d\models\Allegro\nn\_allegro.py:66:9: FBT002 Boolean default positional argument in function definition
   |
64 |         latent_resnet: bool = True,
65 |         latent_resnet_update_ratios: Optional[List[float]] = None,
66 |         latent_resnet_update_ratios_learnable: bool = False,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ FBT002
67 |         latent_out_field: Optional[str] = _keys.EDGE_FEATURES,
68 |         # Performance parameters:
   |

geom3d\models\Allegro\nn\_allegro.py:67:27: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
65 |         latent_resnet_update_ratios: Optional[List[float]] = None,
66 |         latent_resnet_update_ratios_learnable: bool = False,
67 |         latent_out_field: Optional[str] = _keys.EDGE_FEATURES,
   |                           ^^^^^^^^ FA100
68 |         # Performance parameters:
69 |         pad_to_alignment: int = 1,
   |

geom3d\models\Allegro\nn\_allegro.py:70:22: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
68 |         # Performance parameters:
69 |         pad_to_alignment: int = 1,
70 |         sparse_mode: Optional[str] = None,
   |                      ^^^^^^^^ FA100
71 |         # Other:
72 |         irreps_in=None,
   |

geom3d\models\Allegro\nn\_allegro.py:81:9: N806 Variable `SCALAR` in function should be lowercase
   |
79 |             two_body_latent_kwargs = {}
80 |         super().__init__()
81 |         SCALAR = o3.Irrep("0e")  # define for convinience
   |         ^^^^^^ N806
82 | 
83 |         # save parameters
   |

geom3d\models\Allegro\nn\_allegro.py:84:9: S101 Use of `assert` detected
   |
83 |         # save parameters
84 |         assert (
   |         ^^^^^^ S101
85 |             num_layers >= 1
86 |         )  # zero layers is "two body", but we don't need to support that fallback case
   |

geom3d\models\Allegro\nn\_allegro.py:98:9: S101 Use of `assert` detected
    |
 96 |         self.polynomial_cutoff_p = float(PolynomialCutoff_p)
 97 |         self.cutoff_type = cutoff_type
 98 |         assert cutoff_type in ("cosine", "polynomial")
    |         ^^^^^^ S101
 99 |         self.embed_initial_edge = embed_initial_edge
100 |         self.avg_num_neighbors = avg_num_neighbors
    |

geom3d\models\Allegro\nn\_allegro.py:119:15: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
117 |             "env_sum_normalizations",
118 |             # dividing by sqrt(N)
119 |             # TODO: this is only for hacking
    |               ^^^^ TD002
120 |             torch.ones_like(torch.as_tensor([1] * num_layers)),
121 |             # torch.as_tensor([avg_num_neighbors] * num_layers).rsqrt(),
    |

geom3d\models\Allegro\nn\_allegro.py:119:15: TD003 Missing issue link on the line following this TODO
    |
117 |             "env_sum_normalizations",
118 |             # dividing by sqrt(N)
119 |             # TODO: this is only for hacking
    |               ^^^^ TD003
120 |             torch.ones_like(torch.as_tensor([1] * num_layers)),
121 |             # torch.as_tensor([avg_num_neighbors] * num_layers).rsqrt(),
    |

geom3d\models\Allegro\nn\_allegro.py:119:15: FIX002 Line contains TODO, consider resolving the issue
    |
117 |             "env_sum_normalizations",
118 |             # dividing by sqrt(N)
119 |             # TODO: this is only for hacking
    |               ^^^^ FIX002
120 |             torch.ones_like(torch.as_tensor([1] * num_layers)),
121 |             # torch.as_tensor([avg_num_neighbors] * num_layers).rsqrt(),
    |

geom3d\models\Allegro\nn\_allegro.py:121:13: ERA001 Found commented-out code
    |
119 |             # TODO: this is only for hacking
120 |             torch.ones_like(torch.as_tensor([1] * num_layers)),
121 |             # torch.as_tensor([avg_num_neighbors] * num_layers).rsqrt(),
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
122 |         )
    |
    = help: Remove commented-out code

geom3d\models\Allegro\nn\_allegro.py:136:9: S101 Use of `assert` detected
    |
134 |         input_irreps = self.irreps_in[self.field]
135 |         # this is not inherant, but no reason to fix right now:
136 |         assert all(mul == 1 for mul, ir in input_irreps)
    |         ^^^^^^ S101
137 |         env_embed_irreps = o3.Irreps([(1, ir) for _, ir in input_irreps])
138 |         assert (
    |

geom3d\models\Allegro\nn\_allegro.py:138:9: S101 Use of `assert` detected
    |
136 |         assert all(mul == 1 for mul, ir in input_irreps)
137 |         env_embed_irreps = o3.Irreps([(1, ir) for _, ir in input_irreps])
138 |         assert (
    |         ^^^^^^ S101
139 |             env_embed_irreps[0].ir == SCALAR
140 |         ), "env_embed_irreps must start with scalars"
    |

geom3d\models\Allegro\nn\_allegro.py:162:22: B007 Loop control variable `mul` not used within loop body
    |
160 |                 # Add parity irreps
161 |                 ir_out = []
162 |                 for (mul, ir) in env_embed_irreps:
    |                      ^^^ B007
163 |                     if self.nonscalars_include_parity:
164 |                         # add both parity options
    |
    = help: Rename unused `mul` to `_mul`

geom3d\models\Allegro\nn\_allegro.py:208:9: S101 Use of `assert` detected
    |
206 |             out_irreps = new_arg_irreps
207 | 
208 |         assert len(new_tps_irreps) == len(tps_irreps)
    |         ^^^^^^ S101
209 |         tps_irreps = list(reversed(new_tps_irreps))
210 |         del new_tps_irreps
    |

geom3d\models\Allegro\nn\_allegro.py:212:9: S101 Use of `assert` detected
    |
210 |         del new_tps_irreps
211 | 
212 |         assert tps_irreps[-1].lmax == 0
    |         ^^^^^^ S101
213 | 
214 |         tps_irreps_in = tps_irreps[:-1]
    |

geom3d\models\Allegro\nn\_allegro.py:259:13: S101 Use of `assert` detected
    |
257 |             full_out_irreps = o3.Irreps(full_out_irreps)
258 |             self._n_scalar_outs.append(n_scalar_outs)
259 |             assert all(ir == SCALAR for _, ir in full_out_irreps[:n_scalar_outs])
    |             ^^^^^^ S101
260 |             tp = Contracter(
261 |                 irreps_in1=o3.Irreps(
    |

geom3d\models\Allegro\nn\_allegro.py:297:13: S101 Use of `assert` detected
    |
295 |             self.tps.append(tp)
296 |             # we extract the scalars from the first irrep of the tp
297 |             assert out_irreps[0].ir == SCALAR
    |             ^^^^^^ S101
298 | 
299 |             # Make env embed mlp
    |

geom3d\models\Allegro\nn\_allegro.py:381:13: S101 Use of `assert` detected
    |
379 |                 latent_resnet_update_ratios, dtype=torch.get_default_dtype()
380 |             )
381 |             assert latent_resnet_update_ratios.min() > 0.0
    |             ^^^^^^ S101
382 |             assert latent_resnet_update_ratios.min() < 1.0
383 |             latent_resnet_update_params = torch.special.logit(
    |

geom3d\models\Allegro\nn\_allegro.py:382:13: S101 Use of `assert` detected
    |
380 |             )
381 |             assert latent_resnet_update_ratios.min() > 0.0
382 |             assert latent_resnet_update_ratios.min() < 1.0
    |             ^^^^^^ S101
383 |             latent_resnet_update_params = torch.special.logit(
384 |                 latent_resnet_update_ratios
    |

geom3d\models\Allegro\nn\_allegro.py:388:9: S101 Use of `assert` detected
    |
386 |             # The sigmoid is mostly saturated at ±6, keep it in a reasonable range
387 |             latent_resnet_update_params.clamp_(-6.0, 6.0)
388 |         assert latent_resnet_update_params.shape == (
    |         ^^^^^^ S101
389 |             num_layers,
390 |         ), f"There must be {num_layers} layer resnet update ratios (layer0:layer1, layer1:layer2)"
    |

geom3d\models\Allegro\nn\_allegro.py:404:9: S101 Use of `assert` detected
    |
402 |             per_layer_cutoffs = torch.full((num_layers + 1,), r_max)
403 |         self.register_buffer("per_layer_cutoffs", torch.as_tensor(per_layer_cutoffs))
404 |         assert torch.all(self.per_layer_cutoffs <= r_max)
    |         ^^^^^^ S101
405 |         assert self.per_layer_cutoffs.shape == (
406 |             num_layers + 1,
    |

geom3d\models\Allegro\nn\_allegro.py:405:9: S101 Use of `assert` detected
    |
403 |         self.register_buffer("per_layer_cutoffs", torch.as_tensor(per_layer_cutoffs))
404 |         assert torch.all(self.per_layer_cutoffs <= r_max)
405 |         assert self.per_layer_cutoffs.shape == (
    |         ^^^^^^ S101
406 |             num_layers + 1,
407 |         ), "Must be one per-layer cutoff for layer 0 and every layer for a total of {num_layers} cutoffs (the first applies to the two body latent, which is 'layer 0')"
    |

geom3d\models\Allegro\nn\_allegro.py:408:9: S101 Use of `assert` detected
    |
406 |             num_layers + 1,
407 |         ), "Must be one per-layer cutoff for layer 0 and every layer for a total of {num_layers} cutoffs (the first applies to the two body latent, which is 'layer 0')"
408 |         assert (
    |         ^^^^^^ S101
409 |             self.per_layer_cutoffs[1:] <= self.per_layer_cutoffs[:-1]
410 |         ).all(), "Per-layer cutoffs must be equal or decreasing"
    |

geom3d\models\Allegro\nn\_allegro.py:411:9: S101 Use of `assert` detected
    |
409 |             self.per_layer_cutoffs[1:] <= self.per_layer_cutoffs[:-1]
410 |         ).all(), "Per-layer cutoffs must be equal or decreasing"
411 |         assert (
    |         ^^^^^^ S101
412 |             self.per_layer_cutoffs.min() > 0
413 |         ), "Per-layer cutoffs must be >0. To remove higher layers entirely, lower `num_layers`."
    |

geom3d\models\Allegro\nn\_allegro.py:425:9: PLR0912 Too many branches (13 > 12)
    |
423 |         )
424 | 
425 |     def forward(self, data: AtomicDataDict.Type) -> AtomicDataDict.Type:
    |         ^^^^^^^ PLR0912
426 |         """Evaluate.
    |

geom3d\models\Allegro\nn\_allegro.py:425:9: PLR0915 Too many statements (74 > 50)
    |
423 |         )
424 | 
425 |     def forward(self, data: AtomicDataDict.Type) -> AtomicDataDict.Type:
    |         ^^^^^^^ PLR0915
426 |         """Evaluate.
    |

geom3d\models\Allegro\nn\_allegro.py:571:51: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
569 |                 dim=0,
570 |             )
571 |             if self.env_sum_normalizations.ndim < 2:
    |                                                   ^ PLR2004
572 |                 # it's a scalar per layer
573 |                 norm_const = self.env_sum_normalizations[layer_index]
    |

geom3d\models\Allegro\nn\_edgewise.py:14:14: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
12 |     """Like ``NequIP.nn.AtomwiseReduce``, but accumulating per-edge data into per-atom data."""
13 | 
14 |     _factor: Optional[float]
   |              ^^^^^^^^ FA100
15 | 
16 |     def __init__(
   |

geom3d\models\Allegro\nn\_edgewise.py:16:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
14 |     _factor: Optional[float]
15 | 
16 |     def __init__(
   |         ^^^^^^^^ PLR0913
17 |         self,
18 |         field: str,
   |

geom3d\models\Allegro\nn\_edgewise.py:19:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
17 |         self,
18 |         field: str,
19 |         out_field: Optional[str] = None,
   |                    ^^^^^^^^ FA100
20 |         normalize_edge_reduce: bool = True,
21 |         avg_num_neighbors: Optional[float] = None,
   |

geom3d\models\Allegro\nn\_edgewise.py:20:9: FBT001 Boolean-typed positional argument in function definition
   |
18 |         field: str,
19 |         out_field: Optional[str] = None,
20 |         normalize_edge_reduce: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^ FBT001
21 |         avg_num_neighbors: Optional[float] = None,
22 |         reduce="sum",
   |

geom3d\models\Allegro\nn\_edgewise.py:20:9: FBT002 Boolean default positional argument in function definition
   |
18 |         field: str,
19 |         out_field: Optional[str] = None,
20 |         normalize_edge_reduce: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^ FBT002
21 |         avg_num_neighbors: Optional[float] = None,
22 |         reduce="sum",
   |

geom3d\models\Allegro\nn\_edgewise.py:20:9: ARG002 Unused method argument: `normalize_edge_reduce`
   |
18 |         field: str,
19 |         out_field: Optional[str] = None,
20 |         normalize_edge_reduce: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^ ARG002
21 |         avg_num_neighbors: Optional[float] = None,
22 |         reduce="sum",
   |

geom3d\models\Allegro\nn\_edgewise.py:21:9: ARG002 Unused method argument: `avg_num_neighbors`
   |
19 |         out_field: Optional[str] = None,
20 |         normalize_edge_reduce: bool = True,
21 |         avg_num_neighbors: Optional[float] = None,
   |         ^^^^^^^^^^^^^^^^^ ARG002
22 |         reduce="sum",
23 |         irreps_in=None,
   |

geom3d\models\Allegro\nn\_edgewise.py:21:28: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
19 |         out_field: Optional[str] = None,
20 |         normalize_edge_reduce: bool = True,
21 |         avg_num_neighbors: Optional[float] = None,
   |                            ^^^^^^^^ FA100
22 |         reduce="sum",
23 |         irreps_in=None,
   |

geom3d\models\Allegro\nn\_edgewise.py:29:9: S101 Use of `assert` detected
   |
27 |             irreps_in = {}
28 |         super().__init__()
29 |         assert reduce in ("sum", "mean", "min", "max")
   |         ^^^^^^ S101
30 |         self.reduce = reduce
31 |         self.field = field
   |

geom3d\models\Allegro\nn\_edgewise.py:40:11: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
38 |         )
39 |         self._factor = None
40 |         # TODO: will clean-up later
   |           ^^^^ TD002
41 |         # if normalize_edge_reduce and avg_num_neighbors is not None:
42 |         #     self._factor = 1.0 / math.sqrt(avg_num_neighbors)
   |

geom3d\models\Allegro\nn\_edgewise.py:40:11: TD003 Missing issue link on the line following this TODO
   |
38 |         )
39 |         self._factor = None
40 |         # TODO: will clean-up later
   |           ^^^^ TD003
41 |         # if normalize_edge_reduce and avg_num_neighbors is not None:
42 |         #     self._factor = 1.0 / math.sqrt(avg_num_neighbors)
   |

geom3d\models\Allegro\nn\_edgewise.py:40:11: FIX002 Line contains TODO, consider resolving the issue
   |
38 |         )
39 |         self._factor = None
40 |         # TODO: will clean-up later
   |           ^^^^ FIX002
41 |         # if normalize_edge_reduce and avg_num_neighbors is not None:
42 |         #     self._factor = 1.0 / math.sqrt(avg_num_neighbors)
   |

geom3d\models\Allegro\nn\_edgewise.py:42:9: ERA001 Found commented-out code
   |
40 |         # TODO: will clean-up later
41 |         # if normalize_edge_reduce and avg_num_neighbors is not None:
42 |         #     self._factor = 1.0 / math.sqrt(avg_num_neighbors)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
43 |         self._factor = 1
   |
   = help: Remove commented-out code

geom3d\models\Allegro\nn\_edgewise.py:57:17: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
55 |         )
56 | 
57 |         factor: Optional[float] = self._factor  # torchscript hack for typing
   |                 ^^^^^^^^ FA100
58 |         if factor is not None:
59 |             out = out * factor
   |

geom3d\models\Allegro\nn\_edgewise.py:72:14: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
70 |     """
71 | 
72 |     _factor: Optional[float]
   |              ^^^^^^^^ FA100
73 | 
74 |     def __init__(
   |

geom3d\models\Allegro\nn\_edgewise.py:77:9: ARG002 Unused method argument: `avg_num_neighbors`
   |
75 |         self,
76 |         num_types: int,
77 |         avg_num_neighbors: Optional[float] = None,
   |         ^^^^^^^^^^^^^^^^^ ARG002
78 |         normalize_edge_energy_sum: bool = True,
79 |         per_edge_species_scale: bool = False,
   |

geom3d\models\Allegro\nn\_edgewise.py:77:28: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
75 |         self,
76 |         num_types: int,
77 |         avg_num_neighbors: Optional[float] = None,
   |                            ^^^^^^^^ FA100
78 |         normalize_edge_energy_sum: bool = True,
79 |         per_edge_species_scale: bool = False,
   |

geom3d\models\Allegro\nn\_edgewise.py:78:9: FBT001 Boolean-typed positional argument in function definition
   |
76 |         num_types: int,
77 |         avg_num_neighbors: Optional[float] = None,
78 |         normalize_edge_energy_sum: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^ FBT001
79 |         per_edge_species_scale: bool = False,
80 |         irreps_in=None,
   |

geom3d\models\Allegro\nn\_edgewise.py:78:9: FBT002 Boolean default positional argument in function definition
   |
76 |         num_types: int,
77 |         avg_num_neighbors: Optional[float] = None,
78 |         normalize_edge_energy_sum: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^ FBT002
79 |         per_edge_species_scale: bool = False,
80 |         irreps_in=None,
   |

geom3d\models\Allegro\nn\_edgewise.py:78:9: ARG002 Unused method argument: `normalize_edge_energy_sum`
   |
76 |         num_types: int,
77 |         avg_num_neighbors: Optional[float] = None,
78 |         normalize_edge_energy_sum: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^ ARG002
79 |         per_edge_species_scale: bool = False,
80 |         irreps_in=None,
   |

geom3d\models\Allegro\nn\_edgewise.py:79:9: FBT001 Boolean-typed positional argument in function definition
   |
77 |         avg_num_neighbors: Optional[float] = None,
78 |         normalize_edge_energy_sum: bool = True,
79 |         per_edge_species_scale: bool = False,
   |         ^^^^^^^^^^^^^^^^^^^^^^ FBT001
80 |         irreps_in=None,
81 |     ):
   |

geom3d\models\Allegro\nn\_edgewise.py:79:9: FBT002 Boolean default positional argument in function definition
   |
77 |         avg_num_neighbors: Optional[float] = None,
78 |         normalize_edge_energy_sum: bool = True,
79 |         per_edge_species_scale: bool = False,
   |         ^^^^^^^^^^^^^^^^^^^^^^ FBT002
80 |         irreps_in=None,
81 |     ):
   |

geom3d\models\Allegro\nn\_edgewise.py:93:11: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
92 |         self._factor = None
93 |         # TODO: will clean-up later
   |           ^^^^ TD002
94 |         # if normalize_edge_energy_sum and avg_num_neighbors is not None:
95 |         #     self._factor = 1.0 / math.sqrt(avg_num_neighbors)
   |

geom3d\models\Allegro\nn\_edgewise.py:93:11: TD003 Missing issue link on the line following this TODO
   |
92 |         self._factor = None
93 |         # TODO: will clean-up later
   |           ^^^^ TD003
94 |         # if normalize_edge_energy_sum and avg_num_neighbors is not None:
95 |         #     self._factor = 1.0 / math.sqrt(avg_num_neighbors)
   |

geom3d\models\Allegro\nn\_edgewise.py:93:11: FIX002 Line contains TODO, consider resolving the issue
   |
92 |         self._factor = None
93 |         # TODO: will clean-up later
   |           ^^^^ FIX002
94 |         # if normalize_edge_energy_sum and avg_num_neighbors is not None:
95 |         #     self._factor = 1.0 / math.sqrt(avg_num_neighbors)
   |

geom3d\models\Allegro\nn\_edgewise.py:95:9: ERA001 Found commented-out code
   |
93 |         # TODO: will clean-up later
94 |         # if normalize_edge_energy_sum and avg_num_neighbors is not None:
95 |         #     self._factor = 1.0 / math.sqrt(avg_num_neighbors)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
96 |         self._factor = 1
   |
   = help: Remove commented-out code

geom3d\models\Allegro\nn\_edgewise.py:119:17: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
118 |         atom_eng = scatter(edge_eng, edge_center, dim=0, dim_size=len(species))
119 |         factor: Optional[float] = self._factor  # torchscript hack for typing
    |                 ^^^^^^^^ FA100
120 |         if factor is not None:
121 |             atom_eng = atom_eng * factor
    |

geom3d\models\Allegro\nn\_fc.py:22:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
20 |     out_field: str
21 | 
22 |     def __init__(
   |         ^^^^^^^^ PLR0913
23 |         self,
24 |         mlp_latent_dimensions: List[int],
   |

geom3d\models\Allegro\nn\_fc.py:24:32: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
22 |     def __init__(
23 |         self,
24 |         mlp_latent_dimensions: List[int],
   |                                ^^^^ FA100
25 |         mlp_output_dimension: Optional[int],
26 |         mlp_nonlinearity: Optional[str] = "silu",
   |

geom3d\models\Allegro\nn\_fc.py:25:31: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
23 |         self,
24 |         mlp_latent_dimensions: List[int],
25 |         mlp_output_dimension: Optional[int],
   |                               ^^^^^^^^ FA100
26 |         mlp_nonlinearity: Optional[str] = "silu",
27 |         mlp_initialization: str = "uniform",
   |

geom3d\models\Allegro\nn\_fc.py:26:27: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
24 |         mlp_latent_dimensions: List[int],
25 |         mlp_output_dimension: Optional[int],
26 |         mlp_nonlinearity: Optional[str] = "silu",
   |                           ^^^^^^^^ FA100
27 |         mlp_initialization: str = "uniform",
28 |         mlp_dropout_p: float = 0.0,
   |

geom3d\models\Allegro\nn\_fc.py:29:9: FBT001 Boolean-typed positional argument in function definition
   |
27 |         mlp_initialization: str = "uniform",
28 |         mlp_dropout_p: float = 0.0,
29 |         mlp_batchnorm: bool = False,
   |         ^^^^^^^^^^^^^ FBT001
30 |         field: str = AtomicDataDict.NODE_FEATURES_KEY,
31 |         out_field: Optional[str] = None,
   |

geom3d\models\Allegro\nn\_fc.py:29:9: FBT002 Boolean default positional argument in function definition
   |
27 |         mlp_initialization: str = "uniform",
28 |         mlp_dropout_p: float = 0.0,
29 |         mlp_batchnorm: bool = False,
   |         ^^^^^^^^^^^^^ FBT002
30 |         field: str = AtomicDataDict.NODE_FEATURES_KEY,
31 |         out_field: Optional[str] = None,
   |

geom3d\models\Allegro\nn\_fc.py:31:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
29 |         mlp_batchnorm: bool = False,
30 |         field: str = AtomicDataDict.NODE_FEATURES_KEY,
31 |         out_field: Optional[str] = None,
   |                    ^^^^^^^^ FA100
32 |         irreps_in=None,
33 |     ):
   |

geom3d\models\Allegro\nn\_fc.py:41:9: S101 Use of `assert` detected
   |
39 |             required_irreps_in=[self.field],
40 |         )
41 |         assert len(self.irreps_in[self.field]) == 1
   |         ^^^^^^ S101
42 |         assert self.irreps_in[self.field][0].ir == (0, 1)  # scalars
43 |         in_dim = self.irreps_in[self.field][0].mul
   |

geom3d\models\Allegro\nn\_fc.py:42:9: S101 Use of `assert` detected
   |
40 |         )
41 |         assert len(self.irreps_in[self.field]) == 1
42 |         assert self.irreps_in[self.field][0].ir == (0, 1)  # scalars
   |         ^^^^^^ S101
43 |         in_dim = self.irreps_in[self.field][0].mul
44 |         self._module = ScalarMLPFunction(
   |

geom3d\models\Allegro\nn\_fc.py:68:9: C901 `__init__` is too complex (12 > 10)
   |
66 |     out_features: int
67 | 
68 |     def __init__(
   |         ^^^^^^^^ C901
69 |         self,
70 |         mlp_input_dimension: Optional[int],
   |

geom3d\models\Allegro\nn\_fc.py:68:9: PLR0913 Too many arguments in function definition (7 > 5)
   |
66 |     out_features: int
67 | 
68 |     def __init__(
   |         ^^^^^^^^ PLR0913
69 |         self,
70 |         mlp_input_dimension: Optional[int],
   |

geom3d\models\Allegro\nn\_fc.py:70:30: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
68 |     def __init__(
69 |         self,
70 |         mlp_input_dimension: Optional[int],
   |                              ^^^^^^^^ FA100
71 |         mlp_latent_dimensions: List[int],
72 |         mlp_output_dimension: Optional[int],
   |

geom3d\models\Allegro\nn\_fc.py:71:32: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
69 |         self,
70 |         mlp_input_dimension: Optional[int],
71 |         mlp_latent_dimensions: List[int],
   |                                ^^^^ FA100
72 |         mlp_output_dimension: Optional[int],
73 |         mlp_nonlinearity: Optional[str] = "silu",
   |

geom3d\models\Allegro\nn\_fc.py:72:31: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
70 |         mlp_input_dimension: Optional[int],
71 |         mlp_latent_dimensions: List[int],
72 |         mlp_output_dimension: Optional[int],
   |                               ^^^^^^^^ FA100
73 |         mlp_nonlinearity: Optional[str] = "silu",
74 |         mlp_initialization: str = "normal",
   |

geom3d\models\Allegro\nn\_fc.py:73:27: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
71 |         mlp_latent_dimensions: List[int],
72 |         mlp_output_dimension: Optional[int],
73 |         mlp_nonlinearity: Optional[str] = "silu",
   |                           ^^^^^^^^ FA100
74 |         mlp_initialization: str = "normal",
75 |         mlp_dropout_p: float = 0.0,
   |

geom3d\models\Allegro\nn\_fc.py:76:9: FBT001 Boolean-typed positional argument in function definition
   |
74 |         mlp_initialization: str = "normal",
75 |         mlp_dropout_p: float = 0.0,
76 |         mlp_batchnorm: bool = False,
   |         ^^^^^^^^^^^^^ FBT001
77 |     ):
78 |         super().__init__()
   |

geom3d\models\Allegro\nn\_fc.py:76:9: FBT002 Boolean default positional argument in function definition
   |
74 |         mlp_initialization: str = "normal",
75 |         mlp_dropout_p: float = 0.0,
76 |         mlp_batchnorm: bool = False,
   |         ^^^^^^^^^^^^^ FBT002
77 |     ):
78 |         super().__init__()
   |

geom3d\models\Allegro\nn\_fc.py:94:9: S101 Use of `assert` detected
   |
92 |             + ([mlp_output_dimension] if mlp_output_dimension is not None else [])
93 |         )
94 |         assert len(dimensions) >= 2  # Must have input and output dim
   |         ^^^^^^ S101
95 |         num_layers = len(dimensions) - 1
   |

geom3d\models\Allegro\nn\_fc.py:94:35: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   |
92 |             + ([mlp_output_dimension] if mlp_output_dimension is not None else [])
93 |         )
94 |         assert len(dimensions) >= 2  # Must have input and output dim
   |                                   ^ PLR2004
95 |         num_layers = len(dimensions) - 1
   |

geom3d\models\Allegro\nn\_fc.py:105:13: N802 Function name `Proxy` should be lowercase
    |
103 |         tracer = fx.proxy.GraphAppendingTracer(graph)
104 | 
105 |         def Proxy(n):
    |             ^^^^^ N802
106 |             return fx.Proxy(n, tracer=tracer)
    |

geom3d\models\Allegro\nn\_fc.py:105:13: ANN202 Missing return type annotation for private function `Proxy`
    |
103 |         tracer = fx.proxy.GraphAppendingTracer(graph)
104 | 
105 |         def Proxy(n):
    |             ^^^^^ ANN202
106 |             return fx.Proxy(n, tracer=tracer)
    |
    = help: Add return type annotation

geom3d\models\Allegro\nn\_fc.py:163:13: SLF001 Private member accessed: `_dropout`
    |
161 |         if mlp_dropout_p > 0:
162 |             # with normal dropout everything blows up
163 |             base._dropout = torch.nn.AlphaDropout(p=mlp_dropout_p)
    |             ^^^^^^^^^^^^^ SLF001
164 | 
165 |         self._codegen_register({"_forward": fx.GraphModule(base, graph)})
    |

geom3d\models\Allegro\nn\_fc.py:167:9: ANN202 Missing return type annotation for private function `forward`
    |
165 |         self._codegen_register({"_forward": fx.GraphModule(base, graph)})
166 | 
167 |     def forward(self, x):
    |         ^^^^^^^ ANN202
168 |         return self._forward(x)
    |
    = help: Add return type annotation

geom3d\models\Allegro\nn\_norm_basis.py:22:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
20 |     num_basis: int
21 | 
22 |     def __init__(
   |         ^^^^^^^^ PLR0913
23 |         self,
24 |         r_max: float,
   |

geom3d\models\Allegro\nn\_norm_basis.py:27:32: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
25 |         r_min: float = 0.0,
26 |         original_basis=BesselBasis,
27 |         original_basis_kwargs: Optional[dict] = None,
   |                                ^^^^^^^^ FA100
28 |         n: int = 4000,
29 |         norm_basis_mean_shift: bool = True,
   |

geom3d\models\Allegro\nn\_norm_basis.py:29:9: FBT001 Boolean-typed positional argument in function definition
   |
27 |         original_basis_kwargs: Optional[dict] = None,
28 |         n: int = 4000,
29 |         norm_basis_mean_shift: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^ FBT001
30 |     ):
31 |         if original_basis_kwargs is None:
   |

geom3d\models\Allegro\nn\_norm_basis.py:29:9: FBT002 Boolean default positional argument in function definition
   |
27 |         original_basis_kwargs: Optional[dict] = None,
28 |         n: int = 4000,
29 |         norm_basis_mean_shift: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^ FBT002
30 |     ):
31 |         if original_basis_kwargs is None:
   |

geom3d\models\Allegro\nn\_norm_basis.py:37:9: S101 Use of `assert` detected
   |
35 |         self.r_min = r_min
36 |         self.r_max = r_max
37 |         assert self.r_min >= 0.0
   |         ^^^^^^ S101
38 |         assert self.r_max > r_min
39 |         self.n = n
   |

geom3d\models\Allegro\nn\_norm_basis.py:38:9: S101 Use of `assert` detected
   |
36 |         self.r_max = r_max
37 |         assert self.r_min >= 0.0
38 |         assert self.r_max > r_min
   |         ^^^^^^ S101
39 |         self.n = n
   |

geom3d\models\Allegro\nn\_norm_basis.py:48:13: S101 Use of `assert` detected
   |
46 |             rs = torch.linspace(r_min, r_max, n + 1)[1:]
47 |             bs = self.basis(rs)
48 |             assert bs.ndim == 2
   |             ^^^^^^ S101
49 |             assert len(bs) == n
50 |             if norm_basis_mean_shift:
   |

geom3d\models\Allegro\nn\_norm_basis.py:48:31: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   |
46 |             rs = torch.linspace(r_min, r_max, n + 1)[1:]
47 |             bs = self.basis(rs)
48 |             assert bs.ndim == 2
   |                               ^ PLR2004
49 |             assert len(bs) == n
50 |             if norm_basis_mean_shift:
   |

geom3d\models\Allegro\nn\_norm_basis.py:49:13: S101 Use of `assert` detected
   |
47 |             bs = self.basis(rs)
48 |             assert bs.ndim == 2
49 |             assert len(bs) == n
   |             ^^^^^^ S101
50 |             if norm_basis_mean_shift:
51 |                 basis_std, basis_mean = torch.std_mean(bs, dim=0)
   |

geom3d\models\Allegro\nn\_strided\__init__.py:5:1: PLE0604 Invalid object in `__all__`, must contain only strings
  |
3 | from ._linear import Linear
4 | 
5 | __all__ = [Contracter, MakeWeightedChannels, Linear]
  | ^^^^^^^ PLE0604
  |

geom3d\models\Allegro\nn\_strided\_channels.py:22:9: S101 Use of `assert` detected
   |
20 |     ):
21 |         super().__init__()
22 |         assert all(mul == 1 for mul, ir in irreps_in)
   |         ^^^^^^ S101
23 |         assert multiplicity_out >= 1
24 |         # Each edgewise output multiplicity is a per-irrep weighted sum over the input
   |

geom3d\models\Allegro\nn\_strided\_channels.py:23:9: S101 Use of `assert` detected
   |
21 |         super().__init__()
22 |         assert all(mul == 1 for mul, ir in irreps_in)
23 |         assert multiplicity_out >= 1
   |         ^^^^^^ S101
24 |         # Each edgewise output multiplicity is a per-irrep weighted sum over the input
25 |         # So we need to apply the weight for the ith irrep to all DOF in that irrep
   |

geom3d\models\Allegro\nn\_strided\_channels.py:40:9: ANN202 Missing return type annotation for private function `forward`
   |
38 |         self.weight_numel = len(irreps_in) * multiplicity_out
39 | 
40 |     def forward(self, edge_attr, weights):
   |         ^^^^^^^ ANN202
41 |         # weights are [z, u, i]
42 |         # edge_attr are [z, i]
   |
   = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_contract.py:16:5: C901 `codegen_strided_tensor_product_forward` is too complex (25 > 10)
   |
16 | def codegen_strided_tensor_product_forward(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ C901
17 |     irreps_in1: o3.Irreps,
18 |     in1_var: List[float],
   |

geom3d\models\Allegro\nn\_strided\_contract.py:16:5: PLR0913 Too many arguments in function definition (12 > 5)
   |
16 | def codegen_strided_tensor_product_forward(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
17 |     irreps_in1: o3.Irreps,
18 |     in1_var: List[float],
   |

geom3d\models\Allegro\nn\_strided\_contract.py:16:5: PLR0912 Too many branches (28 > 12)
   |
16 | def codegen_strided_tensor_product_forward(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0912
17 |     irreps_in1: o3.Irreps,
18 |     in1_var: List[float],
   |

geom3d\models\Allegro\nn\_strided\_contract.py:16:5: PLR0915 Too many statements (113 > 50)
   |
16 | def codegen_strided_tensor_product_forward(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0915
17 |     irreps_in1: o3.Irreps,
18 |     in1_var: List[float],
   |

geom3d\models\Allegro\nn\_strided\_contract.py:18:14: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
16 | def codegen_strided_tensor_product_forward(
17 |     irreps_in1: o3.Irreps,
18 |     in1_var: List[float],
   |              ^^^^ FA100
19 |     irreps_in2: o3.Irreps,
20 |     in2_var: List[float],
   |

geom3d\models\Allegro\nn\_strided\_contract.py:20:14: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
18 |     in1_var: List[float],
19 |     irreps_in2: o3.Irreps,
20 |     in2_var: List[float],
   |              ^^^^ FA100
21 |     irreps_out: o3.Irreps,
22 |     out_var: List[float],
   |

geom3d\models\Allegro\nn\_strided\_contract.py:22:14: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
20 |     in2_var: List[float],
21 |     irreps_out: o3.Irreps,
22 |     out_var: List[float],
   |              ^^^^ FA100
23 |     instructions: List[Instruction],
24 |     normalization: str = "component",
   |

geom3d\models\Allegro\nn\_strided\_contract.py:23:19: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
21 |     irreps_out: o3.Irreps,
22 |     out_var: List[float],
23 |     instructions: List[Instruction],
   |                   ^^^^ FA100
24 |     normalization: str = "component",
25 |     shared_weights: bool = False,
   |

geom3d\models\Allegro\nn\_strided\_contract.py:25:5: FBT001 Boolean-typed positional argument in function definition
   |
23 |     instructions: List[Instruction],
24 |     normalization: str = "component",
25 |     shared_weights: bool = False,
   |     ^^^^^^^^^^^^^^ FBT001
26 |     specialized_code: bool = True,
27 |     sparse_mode: Optional[str] = None,
   |

geom3d\models\Allegro\nn\_strided\_contract.py:25:5: FBT002 Boolean default positional argument in function definition
   |
23 |     instructions: List[Instruction],
24 |     normalization: str = "component",
25 |     shared_weights: bool = False,
   |     ^^^^^^^^^^^^^^ FBT002
26 |     specialized_code: bool = True,
27 |     sparse_mode: Optional[str] = None,
   |

geom3d\models\Allegro\nn\_strided\_contract.py:26:5: FBT001 Boolean-typed positional argument in function definition
   |
24 |     normalization: str = "component",
25 |     shared_weights: bool = False,
26 |     specialized_code: bool = True,
   |     ^^^^^^^^^^^^^^^^ FBT001
27 |     sparse_mode: Optional[str] = None,
28 |     pad_to_alignment: int = 1,
   |

geom3d\models\Allegro\nn\_strided\_contract.py:26:5: FBT002 Boolean default positional argument in function definition
   |
24 |     normalization: str = "component",
25 |     shared_weights: bool = False,
26 |     specialized_code: bool = True,
   |     ^^^^^^^^^^^^^^^^ FBT002
27 |     sparse_mode: Optional[str] = None,
28 |     pad_to_alignment: int = 1,
   |

geom3d\models\Allegro\nn\_strided\_contract.py:27:18: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
25 |     shared_weights: bool = False,
26 |     specialized_code: bool = True,
27 |     sparse_mode: Optional[str] = None,
   |                  ^^^^^^^^ FA100
28 |     pad_to_alignment: int = 1,
29 | ) -> Optional[fx.GraphModule]:
   |

geom3d\models\Allegro\nn\_strided\_contract.py:29:6: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
27 |     sparse_mode: Optional[str] = None,
28 |     pad_to_alignment: int = 1,
29 | ) -> Optional[fx.GraphModule]:
   |      ^^^^^^^^ FA100
30 |     """Returns None if strided doesn't make sense for this TP."""
31 |     # TODO padding
   |

geom3d\models\Allegro\nn\_strided\_contract.py:30:5: D401 First line of docstring should be in imperative mood: "Returns None if strided doesn't make sense for this TP."
   |
28 |     pad_to_alignment: int = 1,
29 | ) -> Optional[fx.GraphModule]:
30 |     """Returns None if strided doesn't make sense for this TP."""
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
31 |     # TODO padding
32 |     # Check if irreps can be strided
   |

geom3d\models\Allegro\nn\_strided\_contract.py:31:7: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
29 | ) -> Optional[fx.GraphModule]:
30 |     """Returns None if strided doesn't make sense for this TP."""
31 |     # TODO padding
   |       ^^^^ TD002
32 |     # Check if irreps can be strided
33 |     try:
   |

geom3d\models\Allegro\nn\_strided\_contract.py:31:7: TD004 Missing colon in TODO
   |
29 | ) -> Optional[fx.GraphModule]:
30 |     """Returns None if strided doesn't make sense for this TP."""
31 |     # TODO padding
   |       ^^^^ TD004
32 |     # Check if irreps can be strided
33 |     try:
   |

geom3d\models\Allegro\nn\_strided\_contract.py:31:7: TD003 Missing issue link on the line following this TODO
   |
29 | ) -> Optional[fx.GraphModule]:
30 |     """Returns None if strided doesn't make sense for this TP."""
31 |     # TODO padding
   |       ^^^^ TD003
32 |     # Check if irreps can be strided
33 |     try:
   |

geom3d\models\Allegro\nn\_strided\_contract.py:31:7: FIX002 Line contains TODO, consider resolving the issue
   |
29 | ) -> Optional[fx.GraphModule]:
30 |     """Returns None if strided doesn't make sense for this TP."""
31 |     # TODO padding
   |       ^^^^ FIX002
32 |     # Check if irreps can be strided
33 |     try:
   |

geom3d\models\Allegro\nn\_strided\_contract.py:42:5: S101 Use of `assert` detected
   |
41 |     # check the instructions
42 |     assert specialized_code
   |     ^^^^^^ S101
43 | 
44 |     connection_mode = instructions[0].connection_mode
   |

geom3d\models\Allegro\nn\_strided\_contract.py:52:9: S101 Use of `assert` detected
   |
50 |         return None
51 |     if not has_weight:
52 |         assert connection_mode == "uuu"  # for now
   |         ^^^^^^ S101
53 | 
54 |     # TODO: sort insturctions?
   |

geom3d\models\Allegro\nn\_strided\_contract.py:54:7: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
52 |         assert connection_mode == "uuu"  # for now
53 | 
54 |     # TODO: sort insturctions?
   |       ^^^^ TD002
55 | 
56 |     # Make the big w3j
   |

geom3d\models\Allegro\nn\_strided\_contract.py:54:7: TD003 Missing issue link on the line following this TODO
   |
52 |         assert connection_mode == "uuu"  # for now
53 | 
54 |     # TODO: sort insturctions?
   |       ^^^^ TD003
55 | 
56 |     # Make the big w3j
   |

geom3d\models\Allegro\nn\_strided\_contract.py:54:7: FIX002 Line contains TODO, consider resolving the issue
   |
52 |         assert connection_mode == "uuu"  # for now
53 | 
54 |     # TODO: sort insturctions?
   |       ^^^^ FIX002
55 | 
56 |     # Make the big w3j
   |

geom3d\models\Allegro\nn\_strided\_contract.py:65:9: S101 Use of `assert` detected
   |
63 |         mul_ir_out = layout_out.base_irreps[ins.i_out]
64 | 
65 |         assert mul_ir_in1.ir.p * mul_ir_in2.ir.p == mul_ir_out.ir.p
   |         ^^^^^^ S101
66 |         assert (
67 |             abs(mul_ir_in1.ir.l - mul_ir_in2.ir.l)
   |

geom3d\models\Allegro\nn\_strided\_contract.py:66:9: S101 Use of `assert` detected
   |
65 |         assert mul_ir_in1.ir.p * mul_ir_in2.ir.p == mul_ir_out.ir.p
66 |         assert (
   |         ^^^^^^ S101
67 |             abs(mul_ir_in1.ir.l - mul_ir_in2.ir.l)
68 |             <= mul_ir_out.ir.l
   |

geom3d\models\Allegro\nn\_strided\_contract.py:82:11: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
81 |         # Normalize the path through its w3j entries
82 |         # TODO: path_weight
   |           ^^^^ TD002
83 |         # TODO: in and out var
84 |         if normalization == "component":
   |

geom3d\models\Allegro\nn\_strided\_contract.py:82:11: TD003 Missing issue link on the line following this TODO
   |
81 |         # Normalize the path through its w3j entries
82 |         # TODO: path_weight
   |           ^^^^ TD003
83 |         # TODO: in and out var
84 |         if normalization == "component":
   |

geom3d\models\Allegro\nn\_strided\_contract.py:82:11: FIX002 Line contains TODO, consider resolving the issue
   |
81 |         # Normalize the path through its w3j entries
82 |         # TODO: path_weight
   |           ^^^^ FIX002
83 |         # TODO: in and out var
84 |         if normalization == "component":
   |

geom3d\models\Allegro\nn\_strided\_contract.py:83:11: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
81 |         # Normalize the path through its w3j entries
82 |         # TODO: path_weight
83 |         # TODO: in and out var
   |           ^^^^ TD002
84 |         if normalization == "component":
85 |             w3j_norm_term = 2 * mul_ir_out.ir.l + 1
   |

geom3d\models\Allegro\nn\_strided\_contract.py:83:11: TD003 Missing issue link on the line following this TODO
   |
81 |         # Normalize the path through its w3j entries
82 |         # TODO: path_weight
83 |         # TODO: in and out var
   |           ^^^^ TD003
84 |         if normalization == "component":
85 |             w3j_norm_term = 2 * mul_ir_out.ir.l + 1
   |

geom3d\models\Allegro\nn\_strided\_contract.py:83:11: FIX002 Line contains TODO, consider resolving the issue
   |
81 |         # Normalize the path through its w3j entries
82 |         # TODO: path_weight
83 |         # TODO: in and out var
   |           ^^^^ FIX002
84 |         if normalization == "component":
85 |             w3j_norm_term = 2 * mul_ir_out.ir.l + 1
   |

geom3d\models\Allegro\nn\_strided\_contract.py:165:7: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
163 |         )
164 | 
165 |     # TODO: support use of sparse w3j
    |       ^^^^ TD002
166 |     if sparse_mode is None:
167 |         # in dense, must shape it for einsum:
    |

geom3d\models\Allegro\nn\_strided\_contract.py:165:7: TD003 Missing issue link on the line following this TODO
    |
163 |         )
164 | 
165 |     # TODO: support use of sparse w3j
    |       ^^^^ TD003
166 |     if sparse_mode is None:
167 |         # in dense, must shape it for einsum:
    |

geom3d\models\Allegro\nn\_strided\_contract.py:165:7: FIX002 Line contains TODO, consider resolving the issue
    |
163 |         )
164 | 
165 |     # TODO: support use of sparse w3j
    |       ^^^^ FIX002
166 |     if sparse_mode is None:
167 |         # in dense, must shape it for einsum:
    |

geom3d\models\Allegro\nn\_strided\_contract.py:218:9: N802 Function name `Proxy` should be lowercase
    |
216 |     tracer = fx.proxy.GraphAppendingTracer(graph_out)
217 | 
218 |     def Proxy(n):
    |         ^^^^^ N802
219 |         return fx.Proxy(n, tracer=tracer)
    |

geom3d\models\Allegro\nn\_strided\_contract.py:218:9: ANN202 Missing return type annotation for private function `Proxy`
    |
216 |     tracer = fx.proxy.GraphAppendingTracer(graph_out)
217 | 
218 |     def Proxy(n):
    |         ^^^^^ ANN202
219 |         return fx.Proxy(n, tracer=tracer)
    |
    = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_contract.py:311:9: SLF001 Private member accessed: `_w3j_mm`
    |
309 |     constants_root.register_buffer("_big_w3j", w3j)
310 |     if sparse_mode is not None:
311 |         constants_root._w3j_mm = ExplicitGradSpmm(w3j)
    |         ^^^^^^^^^^^^^^^^^^^^^^ SLF001
312 |     graphmod_out = fx.GraphModule(constants_root, graph_out, class_name="tp_forward")
    |

geom3d\models\Allegro\nn\_strided\_contract.py:328:11: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
326 |         # for more details.
327 |         #
328 |         # TODO: consider the impact maximum intermediate result size on this logic
    |           ^^^^ TD002
329 |         #         \- this is the `memory_limit` option in opt_einsum
330 |         # TODO: allow user to choose opt_einsum parameters?
    |

geom3d\models\Allegro\nn\_strided\_contract.py:328:11: TD003 Missing issue link on the line following this TODO
    |
326 |         # for more details.
327 |         #
328 |         # TODO: consider the impact maximum intermediate result size on this logic
    |           ^^^^ TD003
329 |         #         \- this is the `memory_limit` option in opt_einsum
330 |         # TODO: allow user to choose opt_einsum parameters?
    |

geom3d\models\Allegro\nn\_strided\_contract.py:328:11: FIX002 Line contains TODO, consider resolving the issue
    |
326 |         # for more details.
327 |         #
328 |         # TODO: consider the impact maximum intermediate result size on this logic
    |           ^^^^ FIX002
329 |         #         \- this is the `memory_limit` option in opt_einsum
330 |         # TODO: allow user to choose opt_einsum parameters?
    |

geom3d\models\Allegro\nn\_strided\_contract.py:330:11: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
328 |         # TODO: consider the impact maximum intermediate result size on this logic
329 |         #         \- this is the `memory_limit` option in opt_einsum
330 |         # TODO: allow user to choose opt_einsum parameters?
    |           ^^^^ TD002
331 |         #
332 |         # We use float32 and zeros to save memory and time, since opt_einsum_fx looks only at traced shapes, not values or dtypes.
    |

geom3d\models\Allegro\nn\_strided\_contract.py:330:11: TD003 Missing issue link on the line following this TODO
    |
328 |         # TODO: consider the impact maximum intermediate result size on this logic
329 |         #         \- this is the `memory_limit` option in opt_einsum
330 |         # TODO: allow user to choose opt_einsum parameters?
    |           ^^^^ TD003
331 |         #
332 |         # We use float32 and zeros to save memory and time, since opt_einsum_fx looks only at traced shapes, not values or dtypes.
    |

geom3d\models\Allegro\nn\_strided\_contract.py:330:11: FIX002 Line contains TODO, consider resolving the issue
    |
328 |         # TODO: consider the impact maximum intermediate result size on this logic
329 |         #         \- this is the `memory_limit` option in opt_einsum
330 |         # TODO: allow user to choose opt_einsum parameters?
    |           ^^^^ FIX002
331 |         #
332 |         # We use float32 and zeros to save memory and time, since opt_einsum_fx looks only at traced shapes, not values or dtypes.
    |

geom3d\models\Allegro\nn\_strided\_contract.py:345:5: SLF001 Private member accessed: `_dim_in1`
    |
344 |     graphmod_out.weight_shape = weight_shape
345 |     graphmod_out._dim_in1 = layout_in1.base_dim
    |     ^^^^^^^^^^^^^^^^^^^^^ SLF001
346 |     graphmod_out._dim_in2 = layout_in2.base_dim
347 |     graphmod_out._dim_out = layout_out.base_dim
    |

geom3d\models\Allegro\nn\_strided\_contract.py:346:5: SLF001 Private member accessed: `_dim_in2`
    |
344 |     graphmod_out.weight_shape = weight_shape
345 |     graphmod_out._dim_in1 = layout_in1.base_dim
346 |     graphmod_out._dim_in2 = layout_in2.base_dim
    |     ^^^^^^^^^^^^^^^^^^^^^ SLF001
347 |     graphmod_out._dim_out = layout_out.base_dim
348 |     graphmod_out._mul_out = layout_out.mul
    |

geom3d\models\Allegro\nn\_strided\_contract.py:347:5: SLF001 Private member accessed: `_dim_out`
    |
345 |     graphmod_out._dim_in1 = layout_in1.base_dim
346 |     graphmod_out._dim_in2 = layout_in2.base_dim
347 |     graphmod_out._dim_out = layout_out.base_dim
    |     ^^^^^^^^^^^^^^^^^^^^^ SLF001
348 |     graphmod_out._mul_out = layout_out.mul
349 |     graphmod_out.weight_numel = abs(prod(weight_shape))
    |

geom3d\models\Allegro\nn\_strided\_contract.py:348:5: SLF001 Private member accessed: `_mul_out`
    |
346 |     graphmod_out._dim_in2 = layout_in2.base_dim
347 |     graphmod_out._dim_out = layout_out.base_dim
348 |     graphmod_out._mul_out = layout_out.mul
    |     ^^^^^^^^^^^^^^^^^^^^^ SLF001
349 |     graphmod_out.weight_numel = abs(prod(weight_shape))
    |

geom3d\models\Allegro\nn\_strided\_contract.py:354:5: N802 Function name `Contracter` should be lowercase
    |
354 | def Contracter(
    |     ^^^^^^^^^^ N802
355 |     irreps_in1,
356 |     irreps_in2,
    |

geom3d\models\Allegro\nn\_strided\_contract.py:354:5: PLR0913 Too many arguments in function definition (9 > 5)
    |
354 | def Contracter(
    |     ^^^^^^^^^^ PLR0913
355 |     irreps_in1,
356 |     irreps_in2,
    |

geom3d\models\Allegro\nn\_strided\_contract.py:354:5: ANN202 Missing return type annotation for private function `Contracter`
    |
354 | def Contracter(
    |     ^^^^^^^^^^ ANN202
355 |     irreps_in1,
356 |     irreps_in2,
    |
    = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_contract.py:358:19: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
356 |     irreps_in2,
357 |     irreps_out,
358 |     instructions: List[Tuple[int, int, int]],
    |                   ^^^^ FA100
359 |     has_weight: bool,
360 |     connection_mode: str,
    |

geom3d\models\Allegro\nn\_strided\_contract.py:358:24: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
    |
356 |     irreps_in2,
357 |     irreps_out,
358 |     instructions: List[Tuple[int, int, int]],
    |                        ^^^^^ FA100
359 |     has_weight: bool,
360 |     connection_mode: str,
    |

geom3d\models\Allegro\nn\_strided\_contract.py:359:5: FBT001 Boolean-typed positional argument in function definition
    |
357 |     irreps_out,
358 |     instructions: List[Tuple[int, int, int]],
359 |     has_weight: bool,
    |     ^^^^^^^^^^ FBT001
360 |     connection_mode: str,
361 |     pad_to_alignment: int = 1,
    |

geom3d\models\Allegro\nn\_strided\_contract.py:362:5: FBT001 Boolean-typed positional argument in function definition
    |
360 |     connection_mode: str,
361 |     pad_to_alignment: int = 1,
362 |     shared_weights: bool = False,
    |     ^^^^^^^^^^^^^^ FBT001
363 |     sparse_mode: Optional[str] = None,
364 | ):
    |

geom3d\models\Allegro\nn\_strided\_contract.py:362:5: FBT002 Boolean default positional argument in function definition
    |
360 |     connection_mode: str,
361 |     pad_to_alignment: int = 1,
362 |     shared_weights: bool = False,
    |     ^^^^^^^^^^^^^^ FBT002
363 |     sparse_mode: Optional[str] = None,
364 | ):
    |

geom3d\models\Allegro\nn\_strided\_contract.py:363:18: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
361 |     pad_to_alignment: int = 1,
362 |     shared_weights: bool = False,
363 |     sparse_mode: Optional[str] = None,
    |                  ^^^^^^^^ FA100
364 | ):
365 |     irreps_in1 = o3.Irreps(irreps_in1)
    |

geom3d\models\Allegro\nn\_strided\_contract.py:366:5: S101 Use of `assert` detected
    |
364 | ):
365 |     irreps_in1 = o3.Irreps(irreps_in1)
366 |     assert all(mul == irreps_in1[0].mul for mul, ir in irreps_in1)
    |     ^^^^^^ S101
367 |     irreps_in2 = o3.Irreps(irreps_in2)
368 |     assert all(mul == irreps_in2[0].mul for mul, ir in irreps_in2)
    |

geom3d\models\Allegro\nn\_strided\_contract.py:368:5: S101 Use of `assert` detected
    |
366 |     assert all(mul == irreps_in1[0].mul for mul, ir in irreps_in1)
367 |     irreps_in2 = o3.Irreps(irreps_in2)
368 |     assert all(mul == irreps_in2[0].mul for mul, ir in irreps_in2)
    |     ^^^^^^ S101
369 |     irreps_out = o3.Irreps(irreps_out)
370 |     assert all(mul == irreps_out[0].mul for mul, ir in irreps_out)
    |

geom3d\models\Allegro\nn\_strided\_contract.py:370:5: S101 Use of `assert` detected
    |
368 |     assert all(mul == irreps_in2[0].mul for mul, ir in irreps_in2)
369 |     irreps_out = o3.Irreps(irreps_out)
370 |     assert all(mul == irreps_out[0].mul for mul, ir in irreps_out)
    |     ^^^^^^ S101
371 | 
372 |     mod = codegen_strided_tensor_product_forward(
    |

geom3d\models\Allegro\nn\_strided\_layout.py:27:9: S101 Use of `assert` detected
   |
25 |         self.base_irreps = Irreps([(1, ir) for _, ir in irreps])
26 |         self.mul = self.irreps[0].mul if len(irreps) > 0 else 0
27 |         assert self.irreps.dim == self.base_irreps.dim * self.mul
   |         ^^^^^^ S101
28 |         self.pad_to_multiple = pad_to_multiple
29 |         assert self.pad_to_multiple in (1, 2, 4, 8)
   |

geom3d\models\Allegro\nn\_strided\_layout.py:29:9: S101 Use of `assert` detected
   |
27 |         assert self.irreps.dim == self.base_irreps.dim * self.mul
28 |         self.pad_to_multiple = pad_to_multiple
29 |         assert self.pad_to_multiple in (1, 2, 4, 8)
   |         ^^^^^^ S101
30 | 
31 |         self.base_dim = int(
   |

geom3d\models\Allegro\nn\_strided\_layout.py:57:9: S101 Use of `assert` detected
   |
56 |         # They should be inverses:
57 |         assert torch.all(
   |         ^^^^^^ S101
58 |             self.indexes_to_strided[self.indexes_to_catted]
59 |             == torch.arange(self.irreps.dim)
   |

geom3d\models\Allegro\nn\_strided\_linear.py:20:5: C901 `codegen_strided_linear` is too complex (13 > 10)
   |
20 | def codegen_strided_linear(
   |     ^^^^^^^^^^^^^^^^^^^^^^ C901
21 |     irreps_in: o3.Irreps,
22 |     irreps_out: o3.Irreps,
   |

geom3d\models\Allegro\nn\_strided\_linear.py:20:5: PLR0913 Too many arguments in function definition (7 > 5)
   |
20 | def codegen_strided_linear(
   |     ^^^^^^^^^^^^^^^^^^^^^^ PLR0913
21 |     irreps_in: o3.Irreps,
22 |     irreps_out: o3.Irreps,
   |

geom3d\models\Allegro\nn\_strided\_linear.py:20:5: PLR0912 Too many branches (13 > 12)
   |
20 | def codegen_strided_linear(
   |     ^^^^^^^^^^^^^^^^^^^^^^ PLR0912
21 |     irreps_in: o3.Irreps,
22 |     irreps_out: o3.Irreps,
   |

geom3d\models\Allegro\nn\_strided\_linear.py:20:5: PLR0915 Too many statements (61 > 50)
   |
20 | def codegen_strided_linear(
   |     ^^^^^^^^^^^^^^^^^^^^^^ PLR0915
21 |     irreps_in: o3.Irreps,
22 |     irreps_out: o3.Irreps,
   |

geom3d\models\Allegro\nn\_strided\_linear.py:23:19: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
21 |     irreps_in: o3.Irreps,
22 |     irreps_out: o3.Irreps,
23 |     instructions: List[Instruction],
   |                   ^^^^ FA100
24 |     normalization: str = "component",
25 |     internal_weights: bool = False,
   |

geom3d\models\Allegro\nn\_strided\_linear.py:25:5: FBT001 Boolean-typed positional argument in function definition
   |
23 |     instructions: List[Instruction],
24 |     normalization: str = "component",
25 |     internal_weights: bool = False,
   |     ^^^^^^^^^^^^^^^^ FBT001
26 |     shared_weights: bool = False,
27 |     pad_to_alignment: int = 1,
   |

geom3d\models\Allegro\nn\_strided\_linear.py:25:5: FBT002 Boolean default positional argument in function definition
   |
23 |     instructions: List[Instruction],
24 |     normalization: str = "component",
25 |     internal_weights: bool = False,
   |     ^^^^^^^^^^^^^^^^ FBT002
26 |     shared_weights: bool = False,
27 |     pad_to_alignment: int = 1,
   |

geom3d\models\Allegro\nn\_strided\_linear.py:26:5: FBT001 Boolean-typed positional argument in function definition
   |
24 |     normalization: str = "component",
25 |     internal_weights: bool = False,
26 |     shared_weights: bool = False,
   |     ^^^^^^^^^^^^^^ FBT001
27 |     pad_to_alignment: int = 1,
28 | ) -> Optional[fx.GraphModule]:
   |

geom3d\models\Allegro\nn\_strided\_linear.py:26:5: FBT002 Boolean default positional argument in function definition
   |
24 |     normalization: str = "component",
25 |     internal_weights: bool = False,
26 |     shared_weights: bool = False,
   |     ^^^^^^^^^^^^^^ FBT002
27 |     pad_to_alignment: int = 1,
28 | ) -> Optional[fx.GraphModule]:
   |

geom3d\models\Allegro\nn\_strided\_linear.py:28:6: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
26 |     shared_weights: bool = False,
27 |     pad_to_alignment: int = 1,
28 | ) -> Optional[fx.GraphModule]:
   |      ^^^^^^^^ FA100
29 |     """Returns None if strided doesn't make sense for this TP."""
30 |     # Check if irreps can be strided
   |

geom3d\models\Allegro\nn\_strided\_linear.py:29:5: D401 First line of docstring should be in imperative mood: "Returns None if strided doesn't make sense for this TP."
   |
27 |     pad_to_alignment: int = 1,
28 | ) -> Optional[fx.GraphModule]:
29 |     """Returns None if strided doesn't make sense for this TP."""
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
30 |     # Check if irreps can be strided
31 |     try:
   |

geom3d\models\Allegro\nn\_strided\_linear.py:38:5: S101 Use of `assert` detected
   |
36 |         return None
37 | 
38 |     assert normalization == "component"
   |     ^^^^^^ S101
39 | 
40 |     if internal_weights:
   |

geom3d\models\Allegro\nn\_strided\_linear.py:41:9: S101 Use of `assert` detected
   |
40 |     if internal_weights:
41 |         assert shared_weights
   |         ^^^^^^ S101
42 | 
43 |     # group instructions by output
   |

geom3d\models\Allegro\nn\_strided\_linear.py:44:21: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
43 |     # group instructions by output
44 |     ins_per_output: List[List[Instruction]] = [
   |                     ^^^^ FA100
45 |         [ins for ins in instructions if ins.i_out == i]
46 |         for i in range(len(layout_out.base_irreps))
   |

geom3d\models\Allegro\nn\_strided\_linear.py:44:26: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
43 |     # group instructions by output
44 |     ins_per_output: List[List[Instruction]] = [
   |                          ^^^^ FA100
45 |         [ins for ins in instructions if ins.i_out == i]
46 |         for i in range(len(layout_out.base_irreps))
   |

geom3d\models\Allegro\nn\_strided\_linear.py:48:28: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
46 |         for i in range(len(layout_out.base_irreps))
47 |     ]
48 |     ins_group_irrep_slice: List[Tuple[int, int]] = []
   |                            ^^^^ FA100
49 |     # check that each output is a mix of sequential irreps
50 |     for ins_group in ins_per_output:
   |

geom3d\models\Allegro\nn\_strided\_linear.py:48:33: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
   |
46 |         for i in range(len(layout_out.base_irreps))
47 |     ]
48 |     ins_group_irrep_slice: List[Tuple[int, int]] = []
   |                                 ^^^^^ FA100
49 |     # check that each output is a mix of sequential irreps
50 |     for ins_group in ins_per_output:
   |

geom3d\models\Allegro\nn\_strided\_linear.py:57:9: S101 Use of `assert` detected
   |
55 |         ins_group_irrep_slice.append((min(i_ins), max(i_ins)))
56 |         min_i_in, max_i_in = ins_group_irrep_slice[-1]
57 |         assert i_ins == set(range(min_i_in, 1 + max_i_in))
   |         ^^^^^^ S101
58 |         assert all(
59 |             layout_in.base_irreps[min_i_in] == layout_in.base_irreps[i]
   |

geom3d\models\Allegro\nn\_strided\_linear.py:58:9: S101 Use of `assert` detected
   |
56 |         min_i_in, max_i_in = ins_group_irrep_slice[-1]
57 |         assert i_ins == set(range(min_i_in, 1 + max_i_in))
58 |         assert all(
   |         ^^^^^^ S101
59 |             layout_in.base_irreps[min_i_in] == layout_in.base_irreps[i]
60 |             for i in range(min_i_in, max_i_in + 1)
   |

geom3d\models\Allegro\nn\_strided\_linear.py:62:9: S101 Use of `assert` detected
   |
60 |             for i in range(min_i_in, max_i_in + 1)
61 |         ), "All mixed irreps must be the same"
62 |         assert all(ins.i_out == ins_group[0].i_out for ins in ins_group)
   |         ^^^^^^ S101
63 | 
64 |     # TODO: split bad groups into multiple groups
   |

geom3d\models\Allegro\nn\_strided\_linear.py:64:7: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
62 |         assert all(ins.i_out == ins_group[0].i_out for ins in ins_group)
63 | 
64 |     # TODO: split bad groups into multiple groups
   |       ^^^^ TD002
65 | 
66 |     # generate actual code
   |

geom3d\models\Allegro\nn\_strided\_linear.py:64:7: TD003 Missing issue link on the line following this TODO
   |
62 |         assert all(ins.i_out == ins_group[0].i_out for ins in ins_group)
63 | 
64 |     # TODO: split bad groups into multiple groups
   |       ^^^^ TD003
65 | 
66 |     # generate actual code
   |

geom3d\models\Allegro\nn\_strided\_linear.py:64:7: FIX002 Line contains TODO, consider resolving the issue
   |
62 |         assert all(ins.i_out == ins_group[0].i_out for ins in ins_group)
63 | 
64 |     # TODO: split bad groups into multiple groups
   |       ^^^^ FIX002
65 | 
66 |     # generate actual code
   |

geom3d\models\Allegro\nn\_strided\_linear.py:70:9: N802 Function name `Proxy` should be lowercase
   |
68 |     tracer = fx.proxy.GraphAppendingTracer(graph_out)
69 | 
70 |     def Proxy(n):
   |         ^^^^^ N802
71 |         return fx.Proxy(n, tracer=tracer)
   |

geom3d\models\Allegro\nn\_strided\_linear.py:70:9: ANN202 Missing return type annotation for private function `Proxy`
   |
68 |     tracer = fx.proxy.GraphAppendingTracer(graph_out)
69 | 
70 |     def Proxy(n):
   |         ^^^^^ ANN202
71 |         return fx.Proxy(n, tracer=tracer)
   |
   = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_linear.py:179:11: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
177 |         # for more details.
178 |         #
179 |         # TODO: consider the impact maximum intermediate result size on this logic
    |           ^^^^ TD002
180 |         #         \- this is the `memory_limit` option in opt_einsum
181 |         # TODO: allow user to choose opt_einsum parameters?
    |

geom3d\models\Allegro\nn\_strided\_linear.py:179:11: TD003 Missing issue link on the line following this TODO
    |
177 |         # for more details.
178 |         #
179 |         # TODO: consider the impact maximum intermediate result size on this logic
    |           ^^^^ TD003
180 |         #         \- this is the `memory_limit` option in opt_einsum
181 |         # TODO: allow user to choose opt_einsum parameters?
    |

geom3d\models\Allegro\nn\_strided\_linear.py:179:11: FIX002 Line contains TODO, consider resolving the issue
    |
177 |         # for more details.
178 |         #
179 |         # TODO: consider the impact maximum intermediate result size on this logic
    |           ^^^^ FIX002
180 |         #         \- this is the `memory_limit` option in opt_einsum
181 |         # TODO: allow user to choose opt_einsum parameters?
    |

geom3d\models\Allegro\nn\_strided\_linear.py:181:11: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
179 |         # TODO: consider the impact maximum intermediate result size on this logic
180 |         #         \- this is the `memory_limit` option in opt_einsum
181 |         # TODO: allow user to choose opt_einsum parameters?
    |           ^^^^ TD002
182 |         #
183 |         # We use float32 and zeros to save memory and time, since opt_einsum_fx looks only at traced shapes, not values or dtypes.
    |

geom3d\models\Allegro\nn\_strided\_linear.py:181:11: TD003 Missing issue link on the line following this TODO
    |
179 |         # TODO: consider the impact maximum intermediate result size on this logic
180 |         #         \- this is the `memory_limit` option in opt_einsum
181 |         # TODO: allow user to choose opt_einsum parameters?
    |           ^^^^ TD003
182 |         #
183 |         # We use float32 and zeros to save memory and time, since opt_einsum_fx looks only at traced shapes, not values or dtypes.
    |

geom3d\models\Allegro\nn\_strided\_linear.py:181:11: FIX002 Line contains TODO, consider resolving the issue
    |
179 |         # TODO: consider the impact maximum intermediate result size on this logic
180 |         #         \- this is the `memory_limit` option in opt_einsum
181 |         # TODO: allow user to choose opt_einsum parameters?
    |           ^^^^ FIX002
182 |         #
183 |         # We use float32 and zeros to save memory and time, since opt_einsum_fx looks only at traced shapes, not values or dtypes.
    |

geom3d\models\Allegro\nn\_strided\_linear.py:197:5: N802 Function name `Linear` should be lowercase
    |
197 | def Linear(
    |     ^^^^^^ N802
198 |     irreps_in,
199 |     irreps_out,
    |

geom3d\models\Allegro\nn\_strided\_linear.py:197:5: PLR0913 Too many arguments in function definition (6 > 5)
    |
197 | def Linear(
    |     ^^^^^^ PLR0913
198 |     irreps_in,
199 |     irreps_out,
    |

geom3d\models\Allegro\nn\_strided\_linear.py:197:5: ANN202 Missing return type annotation for private function `Linear`
    |
197 | def Linear(
    |     ^^^^^^ ANN202
198 |     irreps_in,
199 |     irreps_out,
    |
    = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_linear.py:200:21: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
198 |     irreps_in,
199 |     irreps_out,
200 |     shared_weights: Optional[bool] = None,
    |                     ^^^^^^^^ FA100
201 |     internal_weights: bool = False,
202 |     instructions: Optional[List[Tuple[int, int]]] = None,
    |

geom3d\models\Allegro\nn\_strided\_linear.py:201:5: FBT001 Boolean-typed positional argument in function definition
    |
199 |     irreps_out,
200 |     shared_weights: Optional[bool] = None,
201 |     internal_weights: bool = False,
    |     ^^^^^^^^^^^^^^^^ FBT001
202 |     instructions: Optional[List[Tuple[int, int]]] = None,
203 |     pad_to_alignment: int = 1,
    |

geom3d\models\Allegro\nn\_strided\_linear.py:201:5: FBT002 Boolean default positional argument in function definition
    |
199 |     irreps_out,
200 |     shared_weights: Optional[bool] = None,
201 |     internal_weights: bool = False,
    |     ^^^^^^^^^^^^^^^^ FBT002
202 |     instructions: Optional[List[Tuple[int, int]]] = None,
203 |     pad_to_alignment: int = 1,
    |

geom3d\models\Allegro\nn\_strided\_linear.py:202:19: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
200 |     shared_weights: Optional[bool] = None,
201 |     internal_weights: bool = False,
202 |     instructions: Optional[List[Tuple[int, int]]] = None,
    |                   ^^^^^^^^ FA100
203 |     pad_to_alignment: int = 1,
204 | ):
    |

geom3d\models\Allegro\nn\_strided\_linear.py:202:28: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
200 |     shared_weights: Optional[bool] = None,
201 |     internal_weights: bool = False,
202 |     instructions: Optional[List[Tuple[int, int]]] = None,
    |                            ^^^^ FA100
203 |     pad_to_alignment: int = 1,
204 | ):
    |

geom3d\models\Allegro\nn\_strided\_linear.py:202:33: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
    |
200 |     shared_weights: Optional[bool] = None,
201 |     internal_weights: bool = False,
202 |     instructions: Optional[List[Tuple[int, int]]] = None,
    |                                 ^^^^^ FA100
203 |     pad_to_alignment: int = 1,
204 | ):
    |

geom3d\models\Allegro\nn\_strided\_spmm.py:15:13: ANN205 Missing return type annotation for staticmethod `forward`
   |
13 |     class _ExplicitGradSpmm(torch.autograd.Function):
14 |         @staticmethod
15 |         def forward(ctx, sparse, a):
   |             ^^^^^^^ ANN205
16 |             ctx.save_for_backward(sparse)
17 |             return torch.mm(sparse, a)
   |
   = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_spmm.py:20:13: ANN205 Missing return type annotation for staticmethod `backward`
   |
19 |         @staticmethod
20 |         def backward(ctx, grad_output):
   |             ^^^^^^^^ ANN205
21 |             (sparse,) = ctx.saved_tensors
22 |             return None, torch.mm(sparse.t(), grad_output)
   |
   = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_spmm.py:24:7: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
22 |             return None, torch.mm(sparse.t(), grad_output)
23 | 
24 |     # TODO: support csr with similar method; wait for 1.10 probably
   |       ^^^^ TD002
25 |     @torch.jit.script
26 |     def _remake_sparse_coo(i, v, shape: Tuple[int, int]):
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:24:7: TD003 Missing issue link on the line following this TODO
   |
22 |             return None, torch.mm(sparse.t(), grad_output)
23 | 
24 |     # TODO: support csr with similar method; wait for 1.10 probably
   |       ^^^^ TD003
25 |     @torch.jit.script
26 |     def _remake_sparse_coo(i, v, shape: Tuple[int, int]):
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:24:7: FIX002 Line contains TODO, consider resolving the issue
   |
22 |             return None, torch.mm(sparse.t(), grad_output)
23 | 
24 |     # TODO: support csr with similar method; wait for 1.10 probably
   |       ^^^^ FIX002
25 |     @torch.jit.script
26 |     def _remake_sparse_coo(i, v, shape: Tuple[int, int]):
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:26:9: ANN202 Missing return type annotation for private function `_remake_sparse_coo`
   |
24 |     # TODO: support csr with similar method; wait for 1.10 probably
25 |     @torch.jit.script
26 |     def _remake_sparse_coo(i, v, shape: Tuple[int, int]):
   |         ^^^^^^^^^^^^^^^^^^ ANN202
27 |         out = torch.sparse_coo_tensor(
28 |             indices=i, values=v, size=shape, device=v.device, dtype=v.dtype
   |
   = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_spmm.py:26:41: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
   |
24 |     # TODO: support csr with similar method; wait for 1.10 probably
25 |     @torch.jit.script
26 |     def _remake_sparse_coo(i, v, shape: Tuple[int, int]):
   |                                         ^^^^^ FA100
27 |         out = torch.sparse_coo_tensor(
28 |             indices=i, values=v, size=shape, device=v.device, dtype=v.dtype
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:32:25: FBT003 Boolean positional value in function call
   |
30 |         # mark it as coalesced, cause it is from when we build it in
31 |         # ExplicitGradSpmm's __init__
32 |         out._coalesced_(True)  # undocumented, AFAIK
   |                         ^^^^ FBT003
33 |         assert out.is_coalesced()
34 |         return out
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:33:9: S101 Use of `assert` detected
   |
31 |         # ExplicitGradSpmm's __init__
32 |         out._coalesced_(True)  # undocumented, AFAIK
33 |         assert out.is_coalesced()
   |         ^^^^^^ S101
34 |         return out
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:38:16: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
   |
36 |     @compile_mode("trace")
37 |     class ExplicitGradSpmmCOO(torch.nn.Module):
38 |         shape: Tuple[int, int]
   |                ^^^^^ FA100
39 | 
40 |         def __init__(self, mat: torch.Tensor):
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:42:13: S101 Use of `assert` detected
   |
40 |         def __init__(self, mat: torch.Tensor):
41 |             super().__init__()
42 |             assert mat.is_sparse
   |             ^^^^^^ S101
43 |             assert mat.ndim == 2
44 |             mat = mat.coalesce()
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:43:13: S101 Use of `assert` detected
   |
41 |             super().__init__()
42 |             assert mat.is_sparse
43 |             assert mat.ndim == 2
   |             ^^^^^^ S101
44 |             mat = mat.coalesce()
45 |             # To workaround https://github.com/pytorch/pytorch/issues/63987,
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:43:32: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   |
41 |             super().__init__()
42 |             assert mat.is_sparse
43 |             assert mat.ndim == 2
   |                                ^ PLR2004
44 |             mat = mat.coalesce()
45 |             # To workaround https://github.com/pytorch/pytorch/issues/63987,
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:51:13: ANN202 Missing return type annotation for private function `forward`
   |
49 |             self.shape = tuple(mat.shape)
50 | 
51 |         def forward(self, x):
   |             ^^^^^^^ ANN202
52 |             # TODO: support csr
53 |             sp = _remake_sparse_coo(self._i, self._v, self.shape)
   |
   = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_spmm.py:52:15: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
51 |         def forward(self, x):
52 |             # TODO: support csr
   |               ^^^^ TD002
53 |             sp = _remake_sparse_coo(self._i, self._v, self.shape)
54 |             if self.training:
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:52:15: TD003 Missing issue link on the line following this TODO
   |
51 |         def forward(self, x):
52 |             # TODO: support csr
   |               ^^^^ TD003
53 |             sp = _remake_sparse_coo(self._i, self._v, self.shape)
54 |             if self.training:
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:52:15: FIX002 Line contains TODO, consider resolving the issue
   |
51 |         def forward(self, x):
52 |             # TODO: support csr
   |               ^^^^ FIX002
53 |             sp = _remake_sparse_coo(self._i, self._v, self.shape)
54 |             if self.training:
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:63:13: ANN202 Missing return type annotation for private function `_make_tracing_inputs`
   |
61 |             return tmp
62 | 
63 |         def _make_tracing_inputs(self, n: int):
   |             ^^^^^^^^^^^^^^^^^^^^ ANN202
64 |             return [
65 |                 {
   |
   = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_spmm.py:81:53: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
   |
80 |         @torch.jit.script
81 |         def _remake_sparse_csr(crow, col, v, shape: Tuple[int, int]) -> torch.Tensor:
   |                                                     ^^^^^ FA100
82 |             return torch.sparse_csr_tensor(
83 |                 crow_indices=crow,
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:94:20: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
   |
92 |         @compile_mode("trace")
93 |         class ExplicitGradSpmmCSR(torch.nn.Module):
94 |             shape: Tuple[int, int]
   |                    ^^^^^ FA100
95 | 
96 |             def __init__(self, mat: torch.Tensor):
   |

geom3d\models\Allegro\nn\_strided\_spmm.py:98:17: S101 Use of `assert` detected
    |
 96 |             def __init__(self, mat: torch.Tensor):
 97 |                 super().__init__()
 98 |                 assert mat.is_sparse_csr
    |                 ^^^^^^ S101
 99 |                 assert mat.ndim == 2
100 |                 # To workaround https://github.com/pytorch/pytorch/issues/63987,
    |

geom3d\models\Allegro\nn\_strided\_spmm.py:99:17: S101 Use of `assert` detected
    |
 97 |                 super().__init__()
 98 |                 assert mat.is_sparse_csr
 99 |                 assert mat.ndim == 2
    |                 ^^^^^^ S101
100 |                 # To workaround https://github.com/pytorch/pytorch/issues/63987,
101 |                 # save indices and values explicitly
    |

geom3d\models\Allegro\nn\_strided\_spmm.py:99:36: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
 97 |                 super().__init__()
 98 |                 assert mat.is_sparse_csr
 99 |                 assert mat.ndim == 2
    |                                    ^ PLR2004
100 |                 # To workaround https://github.com/pytorch/pytorch/issues/63987,
101 |                 # save indices and values explicitly
    |

geom3d\models\Allegro\nn\_strided\_spmm.py:107:17: ANN202 Missing return type annotation for private function `forward`
    |
105 |                 self.shape = tuple(mat.shape)
106 | 
107 |             def forward(self, x):
    |                 ^^^^^^^ ANN202
108 |                 # TODO: support csr
109 |                 sp = _remake_sparse_csr(self._crow, self._col, self._v, self.shape)
    |
    = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_spmm.py:108:19: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
107 |             def forward(self, x):
108 |                 # TODO: support csr
    |                   ^^^^ TD002
109 |                 sp = _remake_sparse_csr(self._crow, self._col, self._v, self.shape)
110 |                 if self.training:
    |

geom3d\models\Allegro\nn\_strided\_spmm.py:108:19: TD003 Missing issue link on the line following this TODO
    |
107 |             def forward(self, x):
108 |                 # TODO: support csr
    |                   ^^^^ TD003
109 |                 sp = _remake_sparse_csr(self._crow, self._col, self._v, self.shape)
110 |                 if self.training:
    |

geom3d\models\Allegro\nn\_strided\_spmm.py:108:19: FIX002 Line contains TODO, consider resolving the issue
    |
107 |             def forward(self, x):
108 |                 # TODO: support csr
    |                   ^^^^ FIX002
109 |                 sp = _remake_sparse_csr(self._crow, self._col, self._v, self.shape)
110 |                 if self.training:
    |

geom3d\models\Allegro\nn\_strided\_spmm.py:119:17: ANN202 Missing return type annotation for private function `_make_tracing_inputs`
    |
117 |                 return tmp
118 | 
119 |             def _make_tracing_inputs(self, n: int):
    |                 ^^^^^^^^^^^^^^^^^^^^ ANN202
120 |                 return [
121 |                     {
    |
    = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_spmm.py:134:9: N802 Function name `ExplicitGradSpmm` should be lowercase
    |
132 |                 ]
133 | 
134 |     def ExplicitGradSpmm(mat):
    |         ^^^^^^^^^^^^^^^^ N802
135 |         if mat.is_sparse:
136 |             return ExplicitGradSpmmCOO(mat)
    |

geom3d\models\Allegro\nn\_strided\_spmm.py:134:9: ANN202 Missing return type annotation for private function `ExplicitGradSpmm`
    |
132 |                 ]
133 | 
134 |     def ExplicitGradSpmm(mat):
    |         ^^^^^^^^^^^^^^^^ ANN202
135 |         if mat.is_sparse:
136 |             return ExplicitGradSpmmCOO(mat)
    |
    = help: Add return type annotation

geom3d\models\Allegro\nn\_strided\_spmm.py:137:9: RET505 Unnecessary `elif` after `return` statement
    |
135 |         if mat.is_sparse:
136 |             return ExplicitGradSpmmCOO(mat)
137 |         elif _TORCH_IS_GE_1_10 and mat.is_sparse_csr:
    |         ^^^^ RET505
138 |             return ExplicitGradSpmmCSR(mat)
139 |         else:
    |
    = help: Remove unnecessary `elif`

geom3d\models\Allegro\nn\_strided\_spmm.py:152:13: ANN202 Missing return type annotation for private function `forward`
    |
150 |             self.mat = SparseTensor.from_dense(mat.to_dense())
151 | 
152 |         def forward(self, x):
    |             ^^^^^^^ ANN202
153 |             return spmm_add(self.mat, x)
    |
    = help: Add return type annotation

geom3d\models\Allegro\nn\cutoffs.py:1:1: D100 Missing docstring in public module
geom3d\models\Allegro\nn\cutoffs.py:8:5: D401 First line of docstring should be in imperative mood: "A piecewise cosine cutoff starting the cosine decay at r_decay_factor*r_max."
   |
 6 |   @torch.jit.script
 7 |   def cosine_cutoff(x: torch.Tensor, r_max: torch.Tensor, r_start_cos_ratio: float = 0.8):
 8 |       """A piecewise cosine cutoff starting the cosine decay at r_decay_factor*r_max.
   |  _____^
 9 | | 
10 | |     Broadcasts over r_max.
11 | |     """
   | |_______^ D401
12 |       r_max, x = torch.broadcast_tensors(r_max.unsqueeze(-1), x.unsqueeze(0))
13 |       r_decay: torch.Tensor = r_start_cos_ratio * r_max
   |

geom3d\models\Allegro\nn\cutoffs.py:20:5: D417 Missing argument description in the docstring for `polynomial_cutoff`: `x`
   |
19 | @torch.jit.script
20 | def polynomial_cutoff(
   |     ^^^^^^^^^^^^^^^^^ D417
21 |     x: torch.Tensor, r_max: torch.Tensor, p: float = 6.0
22 | ) -> torch.Tensor:
   |

geom3d\models\Allegro\nn\cutoffs.py:34:5: S101 Use of `assert` detected
   |
33 |     """
34 |     assert p >= 2.0
   |     ^^^^^^ S101
35 |     r_max, x = torch.broadcast_tensors(r_max.unsqueeze(-1), x.unsqueeze(0))
36 |     x = x / r_max
   |

geom3d\models\Allegro\nn\cutoffs.py:34:17: PLR2004 Magic value used in comparison, consider replacing `2.0` with a constant variable
   |
33 |     """
34 |     assert p >= 2.0
   |                 ^^^ PLR2004
35 |     r_max, x = torch.broadcast_tensors(r_max.unsqueeze(-1), x.unsqueeze(0))
36 |     x = x / r_max
   |

geom3d\models\AutoEncoder.py:1:1: N999 Invalid module name: 'AutoEncoder'
geom3d\models\AutoEncoder.py:1:1: D100 Missing docstring in public module
geom3d\models\AutoEncoder.py:2:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | import torch
2 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
3 | from torch import nn
  |

geom3d\models\AutoEncoder.py:6:5: N802 Function name `L1_loss` should be lowercase
  |
6 | def L1_loss(p, z, average=True):
  |     ^^^^^^^ N802
7 |     loss = torch.abs(p-z)
8 |     loss = loss.sum(dim=1)
  |

geom3d\models\AutoEncoder.py:6:5: D103 Missing docstring in public function
  |
6 | def L1_loss(p, z, average=True):
  |     ^^^^^^^ D103
7 |     loss = torch.abs(p-z)
8 |     loss = loss.sum(dim=1)
  |

geom3d\models\AutoEncoder.py:6:19: FBT002 Boolean default positional argument in function definition
  |
6 | def L1_loss(p, z, average=True):
  |                   ^^^^^^^ FBT002
7 |     loss = torch.abs(p-z)
8 |     loss = loss.sum(dim=1)
  |

geom3d\models\AutoEncoder.py:14:5: N802 Function name `L2_loss` should be lowercase
   |
14 | def L2_loss(p, z, average=True):
   |     ^^^^^^^ N802
15 |     loss = (p-z)**2
16 |     loss = loss.sum(dim=1)
   |

geom3d\models\AutoEncoder.py:14:5: D103 Missing docstring in public function
   |
14 | def L2_loss(p, z, average=True):
   |     ^^^^^^^ D103
15 |     loss = (p-z)**2
16 |     loss = loss.sum(dim=1)
   |

geom3d\models\AutoEncoder.py:14:19: FBT002 Boolean default positional argument in function definition
   |
14 | def L2_loss(p, z, average=True):
   |                   ^^^^^^^ FBT002
15 |     loss = (p-z)**2
16 |     loss = loss.sum(dim=1)
   |

geom3d\models\AutoEncoder.py:22:5: D103 Missing docstring in public function
   |
22 | def cosine_similarity(p, z, average=True):
   |     ^^^^^^^^^^^^^^^^^ D103
23 |     p = F.normalize(p, p=2, dim=1)
24 |     z = F.normalize(z, p=2, dim=1)
   |

geom3d\models\AutoEncoder.py:22:29: FBT002 Boolean default positional argument in function definition
   |
22 | def cosine_similarity(p, z, average=True):
   |                             ^^^^^^^ FBT002
23 |     p = F.normalize(p, p=2, dim=1)
24 |     z = F.normalize(z, p=2, dim=1)
   |

geom3d\models\AutoEncoder.py:31:7: D101 Missing docstring in public class
   |
31 | class AutoEncoder(torch.nn.Module):
   |       ^^^^^^^^^^^ D101
32 |     def __init__(self, emb_dim, loss, detach_target, beta=1):
33 |         super().__init__()
   |

geom3d\models\AutoEncoder.py:32:9: D107 Missing docstring in `__init__`
   |
31 | class AutoEncoder(torch.nn.Module):
32 |     def __init__(self, emb_dim, loss, detach_target, beta=1):
   |         ^^^^^^^^ D107
33 |         super().__init__()
34 |         self.emb_dim = emb_dim
   |

geom3d\models\AutoEncoder.py:42:13: ERA001 Found commented-out code
   |
40 |         if loss == "l1":
41 |             self.criterion = nn.L1Loss()
42 |             # self.criterion = L1_loss
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
43 |         elif loss == "l2":
44 |             self.criterion = nn.MSELoss()
   |
   = help: Remove commented-out code

geom3d\models\AutoEncoder.py:45:13: ERA001 Found commented-out code
   |
43 |         elif loss == "l2":
44 |             self.criterion = nn.MSELoss()
45 |             # self.criterion = L2_loss
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
46 |         elif loss == "cosine":
47 |             self.criterion = cosine_similarity
   |
   = help: Remove commented-out code

geom3d\models\AutoEncoder.py:56:9: D102 Missing docstring in public method
   |
54 |         )
55 | 
56 |     def forward(self, x, y):
   |         ^^^^^^^ D102
57 |         if self.detach_target:
58 |             y = y.detach()
   |

geom3d\models\AutoEncoder.py:67:7: D101 Missing docstring in public class
   |
67 | class VariationalAutoEncoder(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^^^^^^^^ D101
68 |     def __init__(self, emb_dim, loss, detach_target, beta=1):
69 |         super().__init__()
   |

geom3d\models\AutoEncoder.py:68:9: D107 Missing docstring in `__init__`
   |
67 | class VariationalAutoEncoder(torch.nn.Module):
68 |     def __init__(self, emb_dim, loss, detach_target, beta=1):
   |         ^^^^^^^^ D107
69 |         super().__init__()
70 |         self.emb_dim = emb_dim
   |

geom3d\models\AutoEncoder.py:78:13: ERA001 Found commented-out code
   |
76 |         if loss == "l1":
77 |             self.criterion = nn.L1Loss()
78 |             # self.criterion = L1_loss
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
79 |         elif loss == "l2":
80 |             self.criterion = nn.MSELoss()
   |
   = help: Remove commented-out code

geom3d\models\AutoEncoder.py:81:13: ERA001 Found commented-out code
   |
79 |         elif loss == "l2":
80 |             self.criterion = nn.MSELoss()
81 |             # self.criterion = L2_loss
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
82 |         elif loss == "cosine":
83 |             self.criterion = cosine_similarity
   |
   = help: Remove commented-out code

geom3d\models\AutoEncoder.py:95:9: D102 Missing docstring in public method
   |
93 |         )
94 | 
95 |     def encode(self, x):
   |         ^^^^^^ D102
96 |         mu = self.fc_mu(x)
97 |         log_var = self.fc_var(x)
   |

geom3d\models\AutoEncoder.py:100:9: D102 Missing docstring in public method
    |
 98 |         return mu, log_var
 99 | 
100 |     def reparameterize(self, mu, log_var):
    |         ^^^^^^^^^^^^^^ D102
101 |         std = torch.exp(0.5 * log_var)
102 |         eps = torch.randn_like(std)
    |

geom3d\models\AutoEncoder.py:105:9: D102 Missing docstring in public method
    |
103 |         return mu + eps * std
104 | 
105 |     def forward(self, x, y):
    |         ^^^^^^^ D102
106 |         if self.detach_target:
107 |             y = y.detach()
    |

geom3d\models\BERT.py:1:1: N999 Invalid module name: 'BERT'
geom3d\models\BERT.py:1:1: D100 Missing docstring in public module
geom3d\models\BERT.py:6:7: D101 Missing docstring in public class
  |
6 | class BertForSequenceRegression(BertPreTrainedModel):
  |       ^^^^^^^^^^^^^^^^^^^^^^^^^ D101
7 |     def __init__(self, config):
8 |         super().__init__(config)
  |

geom3d\models\BERT.py:7:9: D107 Missing docstring in `__init__`
  |
6 | class BertForSequenceRegression(BertPreTrainedModel):
7 |     def __init__(self, config):
  |         ^^^^^^^^ D107
8 |         super().__init__(config)
9 |         self.bert = BertModel(config)
  |

geom3d\models\BERT.py:14:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
12 |         self.loss_fct = torch.nn.MSELoss()
13 | 
14 |     def forward(self,
   |         ^^^^^^^ PLR0913
15 |         input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None,
16 |         labels=None, output_attentions=None, output_hidden_states=None):
   |

geom3d\models\BERT.py:14:9: D102 Missing docstring in public method
   |
12 |         self.loss_fct = torch.nn.MSELoss()
13 | 
14 |     def forward(self,
   |         ^^^^^^^ D102
15 |         input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None,
16 |         labels=None, output_attentions=None, output_hidden_states=None):
   |

geom3d\models\BERT.py:33:9: RET505 Unnecessary `else` after `return` statement
   |
31 |         if labels is not None:
32 |             return self.loss_fct(outputs.view(-1), labels.view(-1))
33 |         else:
   |         ^^^^ RET505
34 |             return outputs
   |
   = help: Remove unnecessary `else`

geom3d\models\CDConv.py:1:1: N999 Invalid module name: 'CDConv'
geom3d\models\CDConv.py:1:1: D100 Missing docstring in public module
geom3d\models\CDConv.py:9:1: B018 Found useless expression. Either assign it to a variable or remove it.
   |
 7 | from torch import Tensor, nn
 8 | 
 9 | _max, scatter_min, scatter_mean, scatter_sum
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ B018
10 | from torch_geometric.nn import (
11 |     MLP,
   |

geom3d\models\CDConv.py:9:1: F821 Undefined name `_max`
   |
 7 | from torch import Tensor, nn
 8 | 
 9 | _max, scatter_min, scatter_mean, scatter_sum
   | ^^^^ F821
10 | from torch_geometric.nn import (
11 |     MLP,
   |

geom3d\models\CDConv.py:9:7: F821 Undefined name `scatter_min`
   |
 7 | from torch import Tensor, nn
 8 | 
 9 | _max, scatter_min, scatter_mean, scatter_sum
   |       ^^^^^^^^^^^ F821
10 | from torch_geometric.nn import (
11 |     MLP,
   |

geom3d\models\CDConv.py:9:20: F821 Undefined name `scatter_mean`
   |
 7 | from torch import Tensor, nn
 8 | 
 9 | _max, scatter_min, scatter_mean, scatter_sum
   |                    ^^^^^^^^^^^^ F821
10 | from torch_geometric.nn import (
11 |     MLP,
   |

geom3d\models\CDConv.py:9:34: F821 Undefined name `scatter_sum`
   |
 7 | from torch import Tensor, nn
 8 | 
 9 | _max, scatter_min, scatter_mean, scatter_sum
   |                                  ^^^^^^^^^^^ F821
10 | from torch_geometric.nn import (
11 |     MLP,
   |

geom3d\models\CDConv.py:10:1: E402 Module level import not at top of file
   |
 9 |   _max, scatter_min, scatter_mean, scatter_sum
10 | / from torch_geometric.nn import (
11 | |     MLP,
12 | |     global_mean_pool,
13 | |     radius,
14 | | )
   | |_^ E402
15 |   from torch_geometric.nn.conv import MessagePassing
16 |   from torch_geometric.typing import (
   |

geom3d\models\CDConv.py:15:1: E402 Module level import not at top of file
   |
13 |     radius,
14 | )
15 | from torch_geometric.nn.conv import MessagePassing
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
16 | from torch_geometric.typing import (
17 |     OptTensor,
   |

geom3d\models\CDConv.py:16:1: E402 Module level import not at top of file
   |
14 |   )
15 |   from torch_geometric.nn.conv import MessagePassing
16 | / from torch_geometric.typing import (
17 | |     OptTensor,
18 | |     SparseTensor,
19 | |     set_diag,
20 | | )
   | |_^ E402
21 |   from torch_geometric.utils import add_self_loops, remove_self_loops
   |

geom3d\models\CDConv.py:21:1: E402 Module level import not at top of file
   |
19 |     set_diag,
20 | )
21 | from torch_geometric.utils import add_self_loops, remove_self_loops
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
   |

geom3d\models\CDConv.py:24:5: D103 Missing docstring in public function
   |
24 | def kaiming_uniform(tensor, size):
   |     ^^^^^^^^^^^^^^^ D103
25 |     fan = 1
26 |     for i in range(1, len(size)):
   |

geom3d\models\CDConv.py:34:7: D101 Missing docstring in public class
   |
32 |         return tensor.uniform_(-bound, bound)
33 | 
34 | class WeightNet(nn.Module):
   |       ^^^^^^^^^ D101
35 |     def __init__(self, l: int, kernel_channels):
36 |         super().__init__()
   |

geom3d\models\CDConv.py:35:9: D107 Missing docstring in `__init__`
   |
34 | class WeightNet(nn.Module):
35 |     def __init__(self, l: int, kernel_channels):
   |         ^^^^^^^^ D107
36 |         super().__init__()
   |

geom3d\models\CDConv.py:35:24: E741 Ambiguous variable name: `l`
   |
34 | class WeightNet(nn.Module):
35 |     def __init__(self, l: int, kernel_channels):
   |                        ^ E741
36 |         super().__init__()
   |

geom3d\models\CDConv.py:54:9: D102 Missing docstring in public method
   |
52 |         self.relu = nn.LeakyReLU(0.2)
53 | 
54 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
55 |         for i, channels in enumerate(self.kernel_channels):
56 |             if i == 0:
   |

geom3d\models\CDConv.py:62:9: D102 Missing docstring in public method
   |
60 |             self.bs[i].data.fill_(0.0)
61 | 
62 |     def forward(self, input, idx):
   |         ^^^^^^^ D102
63 |         for i in range(len(self.kernel_channels)):
64 |             W = torch.index_select(self.Ws[i], 0, idx)
   |

geom3d\models\CDConv.py:62:23: A002 Argument `input` is shadowing a Python builtin
   |
60 |             self.bs[i].data.fill_(0.0)
61 | 
62 |     def forward(self, input, idx):
   |                       ^^^^^ A002
63 |         for i in range(len(self.kernel_channels)):
64 |             W = torch.index_select(self.Ws[i], 0, idx)
   |

geom3d\models\CDConv.py:64:13: N806 Variable `W` in function should be lowercase
   |
62 |     def forward(self, input, idx):
63 |         for i in range(len(self.kernel_channels)):
64 |             W = torch.index_select(self.Ws[i], 0, idx)
   |             ^ N806
65 |             b = torch.index_select(self.bs[i], 0, idx)
66 |             if i == 0:
   |

geom3d\models\CDConv.py:73:7: D101 Missing docstring in public class
   |
71 |         return weight
72 | 
73 | class CDConv(MessagePassing):
   |       ^^^^^^ D101
74 |     def __init__(self, r: float, l: float, kernel_channels, in_channels: int, out_channels: int, add_self_loops: bool = True, **kwargs):
75 |         kwargs.setdefault("aggr", "add")
   |

geom3d\models\CDConv.py:74:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
73 | class CDConv(MessagePassing):
74 |     def __init__(self, r: float, l: float, kernel_channels, in_channels: int, out_channels: int, add_self_loops: bool = True, **kwargs):
   |         ^^^^^^^^ PLR0913
75 |         kwargs.setdefault("aggr", "add")
76 |         super().__init__(**kwargs)
   |

geom3d\models\CDConv.py:74:9: D107 Missing docstring in `__init__`
   |
73 | class CDConv(MessagePassing):
74 |     def __init__(self, r: float, l: float, kernel_channels, in_channels: int, out_channels: int, add_self_loops: bool = True, **kwargs):
   |         ^^^^^^^^ D107
75 |         kwargs.setdefault("aggr", "add")
76 |         super().__init__(**kwargs)
   |

geom3d\models\CDConv.py:74:34: E741 Ambiguous variable name: `l`
   |
73 | class CDConv(MessagePassing):
74 |     def __init__(self, r: float, l: float, kernel_channels, in_channels: int, out_channels: int, add_self_loops: bool = True, **kwargs):
   |                                  ^ E741
75 |         kwargs.setdefault("aggr", "add")
76 |         super().__init__(**kwargs)
   |

geom3d\models\CDConv.py:74:98: FBT001 Boolean-typed positional argument in function definition
   |
73 | class CDConv(MessagePassing):
74 |     def __init__(self, r: float, l: float, kernel_channels, in_channels: int, out_channels: int, add_self_loops: bool = True, **kwargs):
   |                                                                                                  ^^^^^^^^^^^^^^ FBT001
75 |         kwargs.setdefault("aggr", "add")
76 |         super().__init__(**kwargs)
   |

geom3d\models\CDConv.py:74:98: FBT002 Boolean default positional argument in function definition
   |
73 | class CDConv(MessagePassing):
74 |     def __init__(self, r: float, l: float, kernel_channels, in_channels: int, out_channels: int, add_self_loops: bool = True, **kwargs):
   |                                                                                                  ^^^^^^^^^^^^^^ FBT002
75 |         kwargs.setdefault("aggr", "add")
76 |         super().__init__(**kwargs)
   |

geom3d\models\CDConv.py:74:127: ANN003 Missing type annotation for `**kwargs`
   |
73 | class CDConv(MessagePassing):
74 |     def __init__(self, r: float, l: float, kernel_channels, in_channels: int, out_channels: int, add_self_loops: bool = True, **kwargs):
   |                                                                                                                               ^^^^^^^^ ANN003
75 |         kwargs.setdefault("aggr", "add")
76 |         super().__init__(**kwargs)
   |

geom3d\models\CDConv.py:90:9: D102 Missing docstring in public method
   |
88 |         self.reset_parameters()
89 | 
90 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
91 |         self.WeightNet.reset_parameters()
92 |         kaiming_uniform(self.W.data, size=[self.kernel_channels * self.in_channels, self.out_channels])
   |

geom3d\models\CDConv.py:94:9: D102 Missing docstring in public method
   |
92 |         kaiming_uniform(self.W.data, size=[self.kernel_channels * self.in_channels, self.out_channels])
93 | 
94 |     def forward(self, x: OptTensor, pos: Tensor, seq: Tensor, ori: Tensor, batch: Tensor) -> Tensor:
   |         ^^^^^^^ D102
95 |         row, col = radius(pos, pos, self.r, batch, batch, max_num_neighbors=9999)
96 |         edge_index = torch.stack([col, row], dim=0)
   |

geom3d\models\CDConv.py:110:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
110 |     def message(self, x_j: Optional[Tensor], pos_i: Tensor, pos_j: Tensor, seq_i: Tensor, seq_j: Tensor, ori_i: Tensor, ori_j: Tensor) -> Tensor:
    |         ^^^^^^^ PLR0913
111 |         # orientation
112 |         pos = pos_j - pos_i
    |

geom3d\models\CDConv.py:110:9: D102 Missing docstring in public method
    |
110 |     def message(self, x_j: Optional[Tensor], pos_i: Tensor, pos_j: Tensor, seq_i: Tensor, seq_j: Tensor, ori_i: Tensor, ori_j: Tensor) -> Tensor:
    |         ^^^^^^^ D102
111 |         # orientation
112 |         pos = pos_j - pos_i
    |

geom3d\models\CDConv.py:110:28: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
110 |     def message(self, x_j: Optional[Tensor], pos_i: Tensor, pos_j: Tensor, seq_i: Tensor, seq_j: Tensor, ori_i: Tensor, ori_j: Tensor) -> Tensor:
    |                            ^^^^^^^^ FA100
111 |         # orientation
112 |         pos = pos_j - pos_i
    |

geom3d\models\CDConv.py:140:9: D105 Missing docstring in magic method
    |
140 |     def __repr__(self) -> str:
    |         ^^^^^^^^ D105
141 |         return (f"{self.__class__.__name__}(r={self.r}, "
142 |                 f"l={self.l},"
    |

geom3d\models\CDConv.py:147:7: D101 Missing docstring in public class
    |
145 |                 f"out_channels={self.out_channels})")
146 | 
147 | class MaxPooling(nn.Module):
    |       ^^^^^^^^^^ D101
148 |     def __init__(self):
149 |         super().__init__()
    |

geom3d\models\CDConv.py:148:9: D107 Missing docstring in `__init__`
    |
147 | class MaxPooling(nn.Module):
148 |     def __init__(self):
    |         ^^^^^^^^ D107
149 |         super().__init__()
    |

geom3d\models\CDConv.py:151:9: D102 Missing docstring in public method
    |
149 |         super().__init__()
150 | 
151 |     def forward(self, x, pos, seq, ori, batch):
    |         ^^^^^^^ D102
152 |         idx = torch.div(seq.squeeze(1), 2, rounding_mode="floor")
153 |         idx = torch.cat([idx, idx[-1].view((1,))])
    |

geom3d\models\CDConv.py:158:13: F821 Undefined name `scatter_max`
    |
156 |         idx = torch.cumsum(idx, dim=0) - idx
157 |         idx = idx.to(torch.int64)
158 |         x = scatter_max(src=x, index=idx, dim=0)[0]
    |             ^^^^^^^^^^^ F821
159 |         pos = scatter_mean(src=pos, index=idx, dim=0)
160 |         seq = scatter_max(src=torch.div(seq, 2, rounding_mode="floor"), index=idx, dim=0)[0]
    |

geom3d\models\CDConv.py:159:15: F821 Undefined name `scatter_mean`
    |
157 |         idx = idx.to(torch.int64)
158 |         x = scatter_max(src=x, index=idx, dim=0)[0]
159 |         pos = scatter_mean(src=pos, index=idx, dim=0)
    |               ^^^^^^^^^^^^ F821
160 |         seq = scatter_max(src=torch.div(seq, 2, rounding_mode="floor"), index=idx, dim=0)[0]
161 |         ori = scatter_mean(src=ori, index=idx, dim=0)
    |

geom3d\models\CDConv.py:160:15: F821 Undefined name `scatter_max`
    |
158 |         x = scatter_max(src=x, index=idx, dim=0)[0]
159 |         pos = scatter_mean(src=pos, index=idx, dim=0)
160 |         seq = scatter_max(src=torch.div(seq, 2, rounding_mode="floor"), index=idx, dim=0)[0]
    |               ^^^^^^^^^^^ F821
161 |         ori = scatter_mean(src=ori, index=idx, dim=0)
162 |         ori = torch.nn.functional.normalize(ori, 2, -1)
    |

geom3d\models\CDConv.py:161:15: F821 Undefined name `scatter_mean`
    |
159 |         pos = scatter_mean(src=pos, index=idx, dim=0)
160 |         seq = scatter_max(src=torch.div(seq, 2, rounding_mode="floor"), index=idx, dim=0)[0]
161 |         ori = scatter_mean(src=ori, index=idx, dim=0)
    |               ^^^^^^^^^^^^ F821
162 |         ori = torch.nn.functional.normalize(ori, 2, -1)
163 |         batch = scatter_max(src=batch, index=idx, dim=0)[0]
    |

geom3d\models\CDConv.py:163:17: F821 Undefined name `scatter_max`
    |
161 |         ori = scatter_mean(src=ori, index=idx, dim=0)
162 |         ori = torch.nn.functional.normalize(ori, 2, -1)
163 |         batch = scatter_max(src=batch, index=idx, dim=0)[0]
    |                 ^^^^^^^^^^^ F821
164 | 
165 |         return x, pos, seq, ori, batch
    |

geom3d\models\CDConv.py:167:7: D101 Missing docstring in public class
    |
165 |         return x, pos, seq, ori, batch
166 | 
167 | class AvgPooling(nn.Module):
    |       ^^^^^^^^^^ D101
168 |     def __init__(self):
169 |         super().__init__()
    |

geom3d\models\CDConv.py:168:9: D107 Missing docstring in `__init__`
    |
167 | class AvgPooling(nn.Module):
168 |     def __init__(self):
    |         ^^^^^^^^ D107
169 |         super().__init__()
    |

geom3d\models\CDConv.py:171:9: D102 Missing docstring in public method
    |
169 |         super().__init__()
170 | 
171 |     def forward(self, x, pos, seq, ori, batch):
    |         ^^^^^^^ D102
172 |         idx = torch.div(seq.squeeze(1), 2, rounding_mode="floor")
173 |         idx = torch.cat([idx, idx[-1].view((1,))])
    |

geom3d\models\CDConv.py:178:13: F821 Undefined name `scatter_mean`
    |
176 |         idx = torch.cumsum(idx, dim=0) - idx
177 |         idx = idx.to(torch.int64)
178 |         x = scatter_mean(src=x, index=idx, dim=0)
    |             ^^^^^^^^^^^^ F821
179 |         pos = scatter_mean(src=pos, index=idx, dim=0)
180 |         seq = scatter_max(src=torch.div(seq, 2, rounding_mode="floor"), index=idx, dim=0)[0]
    |

geom3d\models\CDConv.py:179:15: F821 Undefined name `scatter_mean`
    |
177 |         idx = idx.to(torch.int64)
178 |         x = scatter_mean(src=x, index=idx, dim=0)
179 |         pos = scatter_mean(src=pos, index=idx, dim=0)
    |               ^^^^^^^^^^^^ F821
180 |         seq = scatter_max(src=torch.div(seq, 2, rounding_mode="floor"), index=idx, dim=0)[0]
181 |         ori = scatter_mean(src=ori, index=idx, dim=0)
    |

geom3d\models\CDConv.py:180:15: F821 Undefined name `scatter_max`
    |
178 |         x = scatter_mean(src=x, index=idx, dim=0)
179 |         pos = scatter_mean(src=pos, index=idx, dim=0)
180 |         seq = scatter_max(src=torch.div(seq, 2, rounding_mode="floor"), index=idx, dim=0)[0]
    |               ^^^^^^^^^^^ F821
181 |         ori = scatter_mean(src=ori, index=idx, dim=0)
182 |         ori = torch.nn.functional.normalize(ori, 2, -1)
    |

geom3d\models\CDConv.py:181:15: F821 Undefined name `scatter_mean`
    |
179 |         pos = scatter_mean(src=pos, index=idx, dim=0)
180 |         seq = scatter_max(src=torch.div(seq, 2, rounding_mode="floor"), index=idx, dim=0)[0]
181 |         ori = scatter_mean(src=ori, index=idx, dim=0)
    |               ^^^^^^^^^^^^ F821
182 |         ori = torch.nn.functional.normalize(ori, 2, -1)
183 |         batch = scatter_max(src=batch, index=idx, dim=0)[0]
    |

geom3d\models\CDConv.py:183:17: F821 Undefined name `scatter_max`
    |
181 |         ori = scatter_mean(src=ori, index=idx, dim=0)
182 |         ori = torch.nn.functional.normalize(ori, 2, -1)
183 |         batch = scatter_max(src=batch, index=idx, dim=0)[0]
    |                 ^^^^^^^^^^^ F821
184 | 
185 |         return x, pos, seq, ori, batch
    |

geom3d\models\CDConv.py:188:7: D101 Missing docstring in public class
    |
188 | class Linear(nn.Module):
    |       ^^^^^^ D101
189 |     def __init__(self,
190 |                  in_channels: int,
    |

geom3d\models\CDConv.py:189:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
188 | class Linear(nn.Module):
189 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
190 |                  in_channels: int,
191 |                  out_channels: int,
    |

geom3d\models\CDConv.py:189:9: D107 Missing docstring in `__init__`
    |
188 | class Linear(nn.Module):
189 |     def __init__(self,
    |         ^^^^^^^^ D107
190 |                  in_channels: int,
191 |                  out_channels: int,
    |

geom3d\models\CDConv.py:192:18: FBT001 Boolean-typed positional argument in function definition
    |
190 |                  in_channels: int,
191 |                  out_channels: int,
192 |                  batch_norm: bool = True,
    |                  ^^^^^^^^^^ FBT001
193 |                  dropout: float = 0.0,
194 |                  bias: bool = False,
    |

geom3d\models\CDConv.py:192:18: FBT002 Boolean default positional argument in function definition
    |
190 |                  in_channels: int,
191 |                  out_channels: int,
192 |                  batch_norm: bool = True,
    |                  ^^^^^^^^^^ FBT002
193 |                  dropout: float = 0.0,
194 |                  bias: bool = False,
    |

geom3d\models\CDConv.py:194:18: FBT001 Boolean-typed positional argument in function definition
    |
192 |                  batch_norm: bool = True,
193 |                  dropout: float = 0.0,
194 |                  bias: bool = False,
    |                  ^^^^ FBT001
195 |                  leakyrelu_negative_slope: float = 0.1,
196 |                  momentum: float = 0.2) -> nn.Module:
    |

geom3d\models\CDConv.py:194:18: FBT002 Boolean default positional argument in function definition
    |
192 |                  batch_norm: bool = True,
193 |                  dropout: float = 0.0,
194 |                  bias: bool = False,
    |                  ^^^^ FBT002
195 |                  leakyrelu_negative_slope: float = 0.1,
196 |                  momentum: float = 0.2) -> nn.Module:
    |

geom3d\models\CDConv.py:207:9: D102 Missing docstring in public method
    |
205 |         self.module = nn.Sequential(*module)
206 | 
207 |     def forward(self, x):
    |         ^^^^^^^ D102
208 |         return self.module(x)
    |

geom3d\models\CDConv.py:210:7: D101 Missing docstring in public class
    |
208 |         return self.module(x)
209 | 
210 | class MLP(nn.Module):
    |       ^^^ D101
211 |     def __init__(self,
212 |                  in_channels: int,
    |

geom3d\models\CDConv.py:210:7: F811 Redefinition of unused `MLP` from line 11
    |
208 |         return self.module(x)
209 | 
210 | class MLP(nn.Module):
    |       ^^^ F811
211 |     def __init__(self,
212 |                  in_channels: int,
    |
    = help: Remove definition: `MLP`

geom3d\models\CDConv.py:211:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
210 | class MLP(nn.Module):
211 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
212 |                  in_channels: int,
213 |                  mid_channels: int,
    |

geom3d\models\CDConv.py:211:9: D107 Missing docstring in `__init__`
    |
210 | class MLP(nn.Module):
211 |     def __init__(self,
    |         ^^^^^^^^ D107
212 |                  in_channels: int,
213 |                  mid_channels: int,
    |

geom3d\models\CDConv.py:215:18: FBT001 Boolean-typed positional argument in function definition
    |
213 |                  mid_channels: int,
214 |                  out_channels: int,
215 |                  batch_norm: bool,
    |                  ^^^^^^^^^^ FBT001
216 |                  dropout: float = 0.0,
217 |                  bias: bool = True,
    |

geom3d\models\CDConv.py:217:18: FBT001 Boolean-typed positional argument in function definition
    |
215 |                  batch_norm: bool,
216 |                  dropout: float = 0.0,
217 |                  bias: bool = True,
    |                  ^^^^ FBT001
218 |                  leakyrelu_negative_slope: float = 0.2,
219 |                  momentum: float = 0.2) -> nn.Module:
    |

geom3d\models\CDConv.py:217:18: FBT002 Boolean default positional argument in function definition
    |
215 |                  batch_norm: bool,
216 |                  dropout: float = 0.0,
217 |                  bias: bool = True,
    |                  ^^^^ FBT002
218 |                  leakyrelu_negative_slope: float = 0.2,
219 |                  momentum: float = 0.2) -> nn.Module:
    |

geom3d\models\CDConv.py:244:9: D102 Missing docstring in public method
    |
242 |         self.module = nn.Sequential(*module)
243 | 
244 |     def forward(self, input):
    |         ^^^^^^^ D102
245 |         return self.module(input)
    |

geom3d\models\CDConv.py:244:23: A002 Argument `input` is shadowing a Python builtin
    |
242 |         self.module = nn.Sequential(*module)
243 | 
244 |     def forward(self, input):
    |                       ^^^^^ A002
245 |         return self.module(input)
    |

geom3d\models\CDConv.py:247:7: D101 Missing docstring in public class
    |
245 |         return self.module(input)
246 | 
247 | class BasicBlock(nn.Module):
    |       ^^^^^^^^^^ D101
248 |     def __init__(self,
249 |                  r: float,
    |

geom3d\models\CDConv.py:248:9: PLR0913 Too many arguments in function definition (11 > 5)
    |
247 | class BasicBlock(nn.Module):
248 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
249 |                  r: float,
250 |                  l: float,
    |

geom3d\models\CDConv.py:248:9: D107 Missing docstring in `__init__`
    |
247 | class BasicBlock(nn.Module):
248 |     def __init__(self,
    |         ^^^^^^^^ D107
249 |                  r: float,
250 |                  l: float,
    |

geom3d\models\CDConv.py:250:18: E741 Ambiguous variable name: `l`
    |
248 |     def __init__(self,
249 |                  r: float,
250 |                  l: float,
    |                  ^ E741
251 |                  kernel_channels,
252 |                  in_channels: int,
    |

geom3d\models\CDConv.py:255:18: FBT001 Boolean-typed positional argument in function definition
    |
253 |                  out_channels: int,
254 |                  base_width: float = 16.0,
255 |                  batch_norm: bool = True,
    |                  ^^^^^^^^^^ FBT001
256 |                  dropout: float = 0.0,
257 |                  bias: bool = False,
    |

geom3d\models\CDConv.py:255:18: FBT002 Boolean default positional argument in function definition
    |
253 |                  out_channels: int,
254 |                  base_width: float = 16.0,
255 |                  batch_norm: bool = True,
    |                  ^^^^^^^^^^ FBT002
256 |                  dropout: float = 0.0,
257 |                  bias: bool = False,
    |

geom3d\models\CDConv.py:257:18: FBT001 Boolean-typed positional argument in function definition
    |
255 |                  batch_norm: bool = True,
256 |                  dropout: float = 0.0,
257 |                  bias: bool = False,
    |                  ^^^^ FBT001
258 |                  leakyrelu_negative_slope: float = 0.1,
259 |                  momentum: float = 0.2) -> nn.Module:
    |

geom3d\models\CDConv.py:257:18: FBT002 Boolean default positional argument in function definition
    |
255 |                  batch_norm: bool = True,
256 |                  dropout: float = 0.0,
257 |                  bias: bool = False,
    |                  ^^^^ FBT002
258 |                  leakyrelu_negative_slope: float = 0.1,
259 |                  momentum: float = 0.2) -> nn.Module:
    |

geom3d\models\CDConv.py:292:9: D102 Missing docstring in public method
    |
290 |                              momentum=momentum)
291 | 
292 |     def forward(self, x, pos, seq, ori, batch):
    |         ^^^^^^^ D102
293 |         identity = self.identity(x)
294 |         x = self.input(x)
    |

geom3d\models\CDConv.py:298:7: D101 Missing docstring in public class
    |
296 |         return self.output(x) + identity
297 | 
298 | class CDConv(nn.Module):
    |       ^^^^^^ D101
299 |     def __init__(self,
300 |                  geometric_radii: List[float],
    |

geom3d\models\CDConv.py:298:7: F811 Redefinition of unused `CDConv` from line 73
    |
296 |         return self.output(x) + identity
297 | 
298 | class CDConv(nn.Module):
    |       ^^^^^^ F811
299 |     def __init__(self,
300 |                  geometric_radii: List[float],
    |
    = help: Remove definition: `CDConv`

geom3d\models\CDConv.py:299:9: PLR0913 Too many arguments in function definition (10 > 5)
    |
298 | class CDConv(nn.Module):
299 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
300 |                  geometric_radii: List[float],
301 |                  sequential_kernel_size: float,
    |

geom3d\models\CDConv.py:299:9: D107 Missing docstring in `__init__`
    |
298 | class CDConv(nn.Module):
299 |     def __init__(self,
    |         ^^^^^^^^ D107
300 |                  geometric_radii: List[float],
301 |                  sequential_kernel_size: float,
    |

geom3d\models\CDConv.py:300:35: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
298 | class CDConv(nn.Module):
299 |     def __init__(self,
300 |                  geometric_radii: List[float],
    |                                   ^^^^ FA100
301 |                  sequential_kernel_size: float,
302 |                  kernel_channels: List[int],
    |

geom3d\models\CDConv.py:302:35: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
300 |                  geometric_radii: List[float],
301 |                  sequential_kernel_size: float,
302 |                  kernel_channels: List[int],
    |                                   ^^^^ FA100
303 |                  channels: List[int],
304 |                  base_width: float = 16.0,
    |

geom3d\models\CDConv.py:303:28: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
301 |                  sequential_kernel_size: float,
302 |                  kernel_channels: List[int],
303 |                  channels: List[int],
    |                            ^^^^ FA100
304 |                  base_width: float = 16.0,
305 |                  embedding_dim: int = 16,
    |

geom3d\models\CDConv.py:306:18: FBT001 Boolean-typed positional argument in function definition
    |
304 |                  base_width: float = 16.0,
305 |                  embedding_dim: int = 16,
306 |                  batch_norm: bool = True,
    |                  ^^^^^^^^^^ FBT001
307 |                  dropout: float = 0.2,
308 |                  bias: bool = False,
    |

geom3d\models\CDConv.py:306:18: FBT002 Boolean default positional argument in function definition
    |
304 |                  base_width: float = 16.0,
305 |                  embedding_dim: int = 16,
306 |                  batch_norm: bool = True,
    |                  ^^^^^^^^^^ FBT002
307 |                  dropout: float = 0.2,
308 |                  bias: bool = False,
    |

geom3d\models\CDConv.py:308:18: FBT001 Boolean-typed positional argument in function definition
    |
306 |                  batch_norm: bool = True,
307 |                  dropout: float = 0.2,
308 |                  bias: bool = False,
    |                  ^^^^ FBT001
309 |                  num_classes: int = 1195) -> nn.Module:
    |

geom3d\models\CDConv.py:308:18: FBT002 Boolean default positional argument in function definition
    |
306 |                  batch_norm: bool = True,
307 |                  dropout: float = 0.2,
308 |                  bias: bool = False,
    |                  ^^^^ FBT002
309 |                  num_classes: int = 1195) -> nn.Module:
    |

geom3d\models\CDConv.py:313:9: S101 Use of `assert` detected
    |
311 |         super().__init__()
312 | 
313 |         assert (len(geometric_radii) == len(channels)), "Model: 'geometric_radii' and 'channels' should have the same number of elements!"
    |         ^^^^^^ S101
314 | 
315 |         self.embedding = torch.nn.Embedding(num_embeddings=21, embedding_dim=embedding_dim)
    |

geom3d\models\CDConv.py:320:16: F402 Import `radius` from line 13 shadowed by loop variable
    |
318 |         layers = []
319 |         in_channels = embedding_dim
320 |         for i, radius in enumerate(geometric_radii):
    |                ^^^^^^ F402
321 |             layers.append(BasicBlock(r = radius,
322 |                                      l = sequential_kernel_size,
    |

geom3d\models\CDConv.py:349:9: D102 Missing docstring in public method
    |
347 |                               dropout=dropout)
348 | 
349 |     def forward(self, data):
    |         ^^^^^^^ D102
350 |         x, pos, seq, ori, batch = (self.embedding(data.x), data.pos, data.seq, data.ori, data.batch)
    |

geom3d\models\CNN.py:1:1: N999 Invalid module name: 'CNN'
geom3d\models\CNN.py:1:1: F403 `from collections import *` used; unable to detect undefined names
  |
1 | from collections import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^ F403
2 | 
3 | from torch import nn
  |

geom3d\models\CNN.py:1:1: D100 Missing docstring in public module
geom3d\models\CNN.py:6:7: D101 Missing docstring in public class
  |
6 | class CNN(nn.Module):
  |       ^^^ D101
7 |     def __init__(
8 |         self, vocab_size, pad_size, hidden_size, num_tasks,
  |

geom3d\models\CNN.py:7:9: PLR0913 Too many arguments in function definition (7 > 5)
  |
6 | class CNN(nn.Module):
7 |     def __init__(
  |         ^^^^^^^^ PLR0913
8 |         self, vocab_size, pad_size, hidden_size, num_tasks,
9 |         out_channels=16, kernel_size=8, dropout=0.3,
  |

geom3d\models\CNN.py:7:9: D107 Missing docstring in `__init__`
  |
6 | class CNN(nn.Module):
7 |     def __init__(
  |         ^^^^^^^^ D107
8 |         self, vocab_size, pad_size, hidden_size, num_tasks,
9 |         out_channels=16, kernel_size=8, dropout=0.3,
  |

geom3d\models\CNN.py:37:9: D102 Missing docstring in public method
   |
35 |         )
36 | 
37 |     def forward(self, x):
   |         ^^^^^^^ D102
38 |         x = self.embedding(x)
39 |         repr = self.layer1(x)
   |

geom3d\models\CNN.py:39:9: A001 Variable `repr` is shadowing a Python builtin
   |
37 |     def forward(self, x):
38 |         x = self.embedding(x)
39 |         repr = self.layer1(x)
   |         ^^^^ A001
40 |         repr = repr.view(-1, self.out_channels * self.intermediate_dim)
41 |         repr = self.layer2(repr)
   |

geom3d\models\CNN.py:40:9: A001 Variable `repr` is shadowing a Python builtin
   |
38 |         x = self.embedding(x)
39 |         repr = self.layer1(x)
40 |         repr = repr.view(-1, self.out_channels * self.intermediate_dim)
   |         ^^^^ A001
41 |         repr = self.layer2(repr)
42 |         return self.pred_layer(repr)
   |

geom3d\models\CNN.py:41:9: A001 Variable `repr` is shadowing a Python builtin
   |
39 |         repr = self.layer1(x)
40 |         repr = repr.view(-1, self.out_channels * self.intermediate_dim)
41 |         repr = self.layer2(repr)
   |         ^^^^ A001
42 |         return self.pred_layer(repr)
   |

geom3d\models\ClofNet.py:1:1: N999 Invalid module name: 'ClofNet'
geom3d\models\ClofNet.py:1:1: D100 Missing docstring in public module
geom3d\models\ClofNet.py:6:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
5 | import torch
6 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
7 | from torch import Tensor, nn
8 | from torch.nn import Embedding, Linear
  |

geom3d\models\ClofNet.py:11:37: F811 Redefinition of unused `MessagePassing` from line 10
   |
 9 | from torch_cluster import radius_graph
10 | from torch_geometric.nn import MessagePassing
11 | from torch_geometric.nn.conv import MessagePassing
   |                                     ^^^^^^^^^^^^^^ F811
12 | from torch_geometric.nn.inits import glorot_orthogonal
13 | from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor
   |
   = help: Remove definition: `MessagePassing`

geom3d\models\ClofNet.py:20:18: N812 Lowercase `pi` imported as non-lowercase `PI`
   |
18 | except ImportError:
19 |     sym = None
20 | from math import pi as PI
   |                  ^^^^^^^^ N812
21 | 
22 | device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
   |

geom3d\models\ClofNet.py:25:7: N801 Class name `rbf_emb` should use CapWords convention
   |
25 | class rbf_emb(nn.Module):
   |       ^^^^^^^ N801
26 |     """modified: delete cutoff with r."""
   |

geom3d\models\ClofNet.py:28:9: D107 Missing docstring in `__init__`
   |
26 |     """modified: delete cutoff with r."""
27 | 
28 |     def __init__(self, num_rbf, rbound_upper, rbf_trainable=False, **kwargs):
   |         ^^^^^^^^ D107
29 |         super().__init__()
30 |         self.rbound_upper = rbound_upper
   |

geom3d\models\ClofNet.py:28:47: FBT002 Boolean default positional argument in function definition
   |
26 |     """modified: delete cutoff with r."""
27 | 
28 |     def __init__(self, num_rbf, rbound_upper, rbf_trainable=False, **kwargs):
   |                                               ^^^^^^^^^^^^^ FBT002
29 |         super().__init__()
30 |         self.rbound_upper = rbound_upper
   |

geom3d\models\ClofNet.py:28:68: ANN003 Missing type annotation for `**kwargs`
   |
26 |     """modified: delete cutoff with r."""
27 | 
28 |     def __init__(self, num_rbf, rbound_upper, rbf_trainable=False, **kwargs):
   |                                                                    ^^^^^^^^ ANN003
29 |         super().__init__()
30 |         self.rbound_upper = rbound_upper
   |

geom3d\models\ClofNet.py:28:70: ARG002 Unused method argument: `kwargs`
   |
26 |     """modified: delete cutoff with r."""
27 | 
28 |     def __init__(self, num_rbf, rbound_upper, rbf_trainable=False, **kwargs):
   |                                                                      ^^^^^^ ARG002
29 |         super().__init__()
30 |         self.rbound_upper = rbound_upper
   |

geom3d\models\ClofNet.py:39:9: ANN202 Missing return type annotation for private function `_initial_params`
   |
37 |         self.register_buffer("betas", betas)
38 | 
39 |     def _initial_params(self):
   |         ^^^^^^^^^^^^^^^ ANN202
40 |         start_value = torch.exp(torch.scalar_tensor(-self.rbound_upper))
41 |         end_value = torch.exp(torch.scalar_tensor(-self.rbound_lower))
   |
   = help: Add return type annotation

geom3d\models\ClofNet.py:47:9: D102 Missing docstring in public method
   |
45 |         return means, betas
46 | 
47 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
48 |         means, betas = self._initial_params()
49 |         self.means.data.copy_(means)
   |

geom3d\models\ClofNet.py:52:9: D102 Missing docstring in public method
   |
50 |         self.betas.data.copy_(betas)
51 | 
52 |     def forward(self, dist):
   |         ^^^^^^^ D102
53 |         dist=dist.unsqueeze(-1)
54 |         rbounds = 0.5 * \
   |

geom3d\models\ClofNet.py:62:7: N801 Class name `emb` should use CapWords convention
   |
62 | class emb(torch.nn.Module):
   |       ^^^ N801
63 |     def __init__(self, num_radial, cutoff, envelope_exponent):
64 |         super().__init__()
   |

geom3d\models\ClofNet.py:62:7: D101 Missing docstring in public class
   |
62 | class emb(torch.nn.Module):
   |       ^^^ D101
63 |     def __init__(self, num_radial, cutoff, envelope_exponent):
64 |         super().__init__()
   |

geom3d\models\ClofNet.py:63:9: D107 Missing docstring in `__init__`
   |
62 | class emb(torch.nn.Module):
63 |     def __init__(self, num_radial, cutoff, envelope_exponent):
   |         ^^^^^^^^ D107
64 |         super().__init__()
65 |         #self.dist_emb = dist_emb(num_radial, cutoff, envelope_exponent)
   |

geom3d\models\ClofNet.py:63:44: ARG002 Unused method argument: `envelope_exponent`
   |
62 | class emb(torch.nn.Module):
63 |     def __init__(self, num_radial, cutoff, envelope_exponent):
   |                                            ^^^^^^^^^^^^^^^^^ ARG002
64 |         super().__init__()
65 |         #self.dist_emb = dist_emb(num_radial, cutoff, envelope_exponent)
   |

geom3d\models\ClofNet.py:65:9: ERA001 Found commented-out code
   |
63 |     def __init__(self, num_radial, cutoff, envelope_exponent):
64 |         super().__init__()
65 |         #self.dist_emb = dist_emb(num_radial, cutoff, envelope_exponent)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
66 |         self.dist_emb = rbf_emb(num_radial, cutoff)
67 |         # self.first_emb = dist_emb2(num_radial2, cutoff, envelope_exponent)
   |
   = help: Remove commented-out code

geom3d\models\ClofNet.py:67:9: ERA001 Found commented-out code
   |
65 |         #self.dist_emb = dist_emb(num_radial, cutoff, envelope_exponent)
66 |         self.dist_emb = rbf_emb(num_radial, cutoff)
67 |         # self.first_emb = dist_emb2(num_radial2, cutoff, envelope_exponent)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
68 |         # self.second_emb = dist_emb2(num_radial2, cutoff, envelope_exponent)
69 |         # self.vertical_emb = dist_emb2(num_radial2, cutoff, envelope_exponent)
   |
   = help: Remove commented-out code

geom3d\models\ClofNet.py:68:9: ERA001 Found commented-out code
   |
66 |         self.dist_emb = rbf_emb(num_radial, cutoff)
67 |         # self.first_emb = dist_emb2(num_radial2, cutoff, envelope_exponent)
68 |         # self.second_emb = dist_emb2(num_radial2, cutoff, envelope_exponent)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
69 |         # self.vertical_emb = dist_emb2(num_radial2, cutoff, envelope_exponent)
70 |         self.reset_parameters()
   |
   = help: Remove commented-out code

geom3d\models\ClofNet.py:69:9: ERA001 Found commented-out code
   |
67 |         # self.first_emb = dist_emb2(num_radial2, cutoff, envelope_exponent)
68 |         # self.second_emb = dist_emb2(num_radial2, cutoff, envelope_exponent)
69 |         # self.vertical_emb = dist_emb2(num_radial2, cutoff, envelope_exponent)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
70 |         self.reset_parameters()
   |
   = help: Remove commented-out code

geom3d\models\ClofNet.py:72:9: D102 Missing docstring in public method
   |
70 |         self.reset_parameters()
71 | 
72 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
73 |         self.dist_emb.reset_parameters()
74 |         # self.first_emb.reset_parameters()
   |

geom3d\models\ClofNet.py:74:9: ERA001 Found commented-out code
   |
72 |     def reset_parameters(self):
73 |         self.dist_emb.reset_parameters()
74 |         # self.first_emb.reset_parameters()
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
75 |         # self.second_emb.reset_parameters()
76 |         # self.vertical_emb.reset_parameters()
   |
   = help: Remove commented-out code

geom3d\models\ClofNet.py:75:9: ERA001 Found commented-out code
   |
73 |         self.dist_emb.reset_parameters()
74 |         # self.first_emb.reset_parameters()
75 |         # self.second_emb.reset_parameters()
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
76 |         # self.vertical_emb.reset_parameters()
   |
   = help: Remove commented-out code

geom3d\models\ClofNet.py:76:9: ERA001 Found commented-out code
   |
74 |         # self.first_emb.reset_parameters()
75 |         # self.second_emb.reset_parameters()
76 |         # self.vertical_emb.reset_parameters()
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
77 | 
78 |     def forward(self, dist):
   |
   = help: Remove commented-out code

geom3d\models\ClofNet.py:78:9: D102 Missing docstring in public method
   |
76 |         # self.vertical_emb.reset_parameters()
77 | 
78 |     def forward(self, dist):
   |         ^^^^^^^ D102
79 |         return self.dist_emb(dist)
80 |         # first_emb = self.first_emb(first)
   |

geom3d\models\ClofNet.py:80:9: ERA001 Found commented-out code
   |
78 |     def forward(self, dist):
79 |         return self.dist_emb(dist)
80 |         # first_emb = self.first_emb(first)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
81 |         # second_emb = self.first_emb(second)
82 |         # vertical_emb = self.first_emb(vertical)
   |
   = help: Remove commented-out code

geom3d\models\ClofNet.py:81:9: ERA001 Found commented-out code
   |
79 |         return self.dist_emb(dist)
80 |         # first_emb = self.first_emb(first)
81 |         # second_emb = self.first_emb(second)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
82 |         # vertical_emb = self.first_emb(vertical)
   |
   = help: Remove commented-out code

geom3d\models\ClofNet.py:82:9: ERA001 Found commented-out code
   |
80 |         # first_emb = self.first_emb(first)
81 |         # second_emb = self.first_emb(second)
82 |         # vertical_emb = self.first_emb(vertical)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
   |
   = help: Remove commented-out code

geom3d\models\ClofNet.py:86:7: D101 Missing docstring in public class
   |
86 | class ResidualLayer(torch.nn.Module):
   |       ^^^^^^^^^^^^^ D101
87 |     def __init__(self, hidden_channels, act="swish"):
88 |         super().__init__()
   |

geom3d\models\ClofNet.py:87:9: D107 Missing docstring in `__init__`
   |
86 | class ResidualLayer(torch.nn.Module):
87 |     def __init__(self, hidden_channels, act="swish"):
   |         ^^^^^^^^ D107
88 |         super().__init__()
89 |         self.act = act
   |

geom3d\models\ClofNet.py:95:9: D102 Missing docstring in public method
   |
93 |         self.reset_parameters()
94 | 
95 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
96 |         glorot_orthogonal(self.lin1.weight, scale=2.0)
97 |         self.lin1.bias.data.fill_(0)
   |

geom3d\models\ClofNet.py:101:9: D102 Missing docstring in public method
    |
 99 |         self.lin2.bias.data.fill_(0)
100 | 
101 |     def forward(self, x):
    |         ^^^^^^^ D102
102 |         return x + self.act(self.lin2(self.act(self.lin1(x))))
    |

geom3d\models\ClofNet.py:105:7: N801 Class name `init` should use CapWords convention
    |
105 | class init(torch.nn.Module):
    |       ^^^^ N801
106 |     def __init__(self, num_radial, hidden_channels, act="swish", use_node_features=True):
107 |         super().__init__()
    |

geom3d\models\ClofNet.py:105:7: D101 Missing docstring in public class
    |
105 | class init(torch.nn.Module):
    |       ^^^^ D101
106 |     def __init__(self, num_radial, hidden_channels, act="swish", use_node_features=True):
107 |         super().__init__()
    |

geom3d\models\ClofNet.py:106:9: D107 Missing docstring in `__init__`
    |
105 | class init(torch.nn.Module):
106 |     def __init__(self, num_radial, hidden_channels, act="swish", use_node_features=True):
    |         ^^^^^^^^ D107
107 |         super().__init__()
108 |         self.act = act
    |

geom3d\models\ClofNet.py:106:66: FBT002 Boolean default positional argument in function definition
    |
105 | class init(torch.nn.Module):
106 |     def __init__(self, num_radial, hidden_channels, act="swish", use_node_features=True):
    |                                                                  ^^^^^^^^^^^^^^^^^ FBT002
107 |         super().__init__()
108 |         self.act = act
    |

geom3d\models\ClofNet.py:120:9: D102 Missing docstring in public method
    |
118 |         self.reset_parameters()
119 | 
120 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
121 |         if self.use_node_features:
122 |             self.emb.weight.data.uniform_(-sqrt(3), sqrt(3))
    |

geom3d\models\ClofNet.py:127:9: D102 Missing docstring in public method
    |
125 |         glorot_orthogonal(self.lin_rbf_1.weight, scale=2.0)
126 | 
127 |     def forward(self, x, emb, i, j):
    |         ^^^^^^^ D102
128 |         rbf, _, _, _ = emb
129 |         if self.use_node_features:
    |

geom3d\models\ClofNet.py:140:7: D101 Missing docstring in public class
    |
140 | class ClofNet(torch.nn.Module):
    |       ^^^^^^^ D101
141 |     def __init__(
142 |             self, energy_and_force=False, cutoff=5.0, num_layers=4,
    |

geom3d\models\ClofNet.py:141:9: PLR0913 Too many arguments in function definition (20 > 5)
    |
140 | class ClofNet(torch.nn.Module):
141 |     def __init__(
    |         ^^^^^^^^ PLR0913
142 |             self, energy_and_force=False, cutoff=5.0, num_layers=4,
143 |             hidden_channels=64, out_channels=1, int_emb_size=64,
    |

geom3d\models\ClofNet.py:141:9: D107 Missing docstring in `__init__`
    |
140 | class ClofNet(torch.nn.Module):
141 |     def __init__(
    |         ^^^^^^^^ D107
142 |             self, energy_and_force=False, cutoff=5.0, num_layers=4,
143 |             hidden_channels=64, out_channels=1, int_emb_size=64,
    |

geom3d\models\ClofNet.py:142:19: FBT002 Boolean default positional argument in function definition
    |
140 | class ClofNet(torch.nn.Module):
141 |     def __init__(
142 |             self, energy_and_force=False, cutoff=5.0, num_layers=4,
    |                   ^^^^^^^^^^^^^^^^ FBT002
143 |             hidden_channels=64, out_channels=1, int_emb_size=64,
144 |             basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256,
    |

geom3d\models\ClofNet.py:143:33: ARG002 Unused method argument: `out_channels`
    |
141 |     def __init__(
142 |             self, energy_and_force=False, cutoff=5.0, num_layers=4,
143 |             hidden_channels=64, out_channels=1, int_emb_size=64,
    |                                 ^^^^^^^^^^^^ ARG002
144 |             basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256,
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
    |

geom3d\models\ClofNet.py:143:49: ARG002 Unused method argument: `int_emb_size`
    |
141 |     def __init__(
142 |             self, energy_and_force=False, cutoff=5.0, num_layers=4,
143 |             hidden_channels=64, out_channels=1, int_emb_size=64,
    |                                                 ^^^^^^^^^^^^ ARG002
144 |             basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256,
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
    |

geom3d\models\ClofNet.py:144:13: ARG002 Unused method argument: `basis_emb_size_dist`
    |
142 |             self, energy_and_force=False, cutoff=5.0, num_layers=4,
143 |             hidden_channels=64, out_channels=1, int_emb_size=64,
144 |             basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256,
    |             ^^^^^^^^^^^^^^^^^^^ ARG002
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
146 |             num_before_skip=1, num_after_skip=2, num_output_layers=3, heads=1,
    |

geom3d\models\ClofNet.py:144:36: ARG002 Unused method argument: `basis_emb_size_angle`
    |
142 |             self, energy_and_force=False, cutoff=5.0, num_layers=4,
143 |             hidden_channels=64, out_channels=1, int_emb_size=64,
144 |             basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256,
    |                                    ^^^^^^^^^^^^^^^^^^^^ ARG002
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
146 |             num_before_skip=1, num_after_skip=2, num_output_layers=3, heads=1,
    |

geom3d\models\ClofNet.py:144:60: ARG002 Unused method argument: `basis_emb_size_torsion`
    |
142 |             self, energy_and_force=False, cutoff=5.0, num_layers=4,
143 |             hidden_channels=64, out_channels=1, int_emb_size=64,
144 |             basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256,
    |                                                            ^^^^^^^^^^^^^^^^^^^^^^ ARG002
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
146 |             num_before_skip=1, num_after_skip=2, num_output_layers=3, heads=1,
    |

geom3d\models\ClofNet.py:144:86: ARG002 Unused method argument: `out_emb_channels`
    |
142 |             self, energy_and_force=False, cutoff=5.0, num_layers=4,
143 |             hidden_channels=64, out_channels=1, int_emb_size=64,
144 |             basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256,
    |                                                                                      ^^^^^^^^^^^^^^^^ ARG002
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
146 |             num_before_skip=1, num_after_skip=2, num_output_layers=3, heads=1,
    |

geom3d\models\ClofNet.py:145:28: ARG002 Unused method argument: `num_radial2`
    |
143 |             hidden_channels=64, out_channels=1, int_emb_size=64,
144 |             basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256,
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
    |                            ^^^^^^^^^^^ ARG002
146 |             num_before_skip=1, num_after_skip=2, num_output_layers=3, heads=1,
147 |             act="swish", output_init="GlorotOrthogonal", use_node_features=True, **kwargs):
    |

geom3d\models\ClofNet.py:146:13: ARG002 Unused method argument: `num_before_skip`
    |
144 |             basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256,
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
146 |             num_before_skip=1, num_after_skip=2, num_output_layers=3, heads=1,
    |             ^^^^^^^^^^^^^^^ ARG002
147 |             act="swish", output_init="GlorotOrthogonal", use_node_features=True, **kwargs):
148 |         super().__init__()
    |

geom3d\models\ClofNet.py:146:32: ARG002 Unused method argument: `num_after_skip`
    |
144 |             basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256,
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
146 |             num_before_skip=1, num_after_skip=2, num_output_layers=3, heads=1,
    |                                ^^^^^^^^^^^^^^ ARG002
147 |             act="swish", output_init="GlorotOrthogonal", use_node_features=True, **kwargs):
148 |         super().__init__()
    |

geom3d\models\ClofNet.py:146:50: ARG002 Unused method argument: `num_output_layers`
    |
144 |             basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256,
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
146 |             num_before_skip=1, num_after_skip=2, num_output_layers=3, heads=1,
    |                                                  ^^^^^^^^^^^^^^^^^ ARG002
147 |             act="swish", output_init="GlorotOrthogonal", use_node_features=True, **kwargs):
148 |         super().__init__()
    |

geom3d\models\ClofNet.py:147:26: ARG002 Unused method argument: `output_init`
    |
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
146 |             num_before_skip=1, num_after_skip=2, num_output_layers=3, heads=1,
147 |             act="swish", output_init="GlorotOrthogonal", use_node_features=True, **kwargs):
    |                          ^^^^^^^^^^^ ARG002
148 |         super().__init__()
149 |         self.hidden_channels = hidden_channels
    |

geom3d\models\ClofNet.py:147:58: FBT002 Boolean default positional argument in function definition
    |
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
146 |             num_before_skip=1, num_after_skip=2, num_output_layers=3, heads=1,
147 |             act="swish", output_init="GlorotOrthogonal", use_node_features=True, **kwargs):
    |                                                          ^^^^^^^^^^^^^^^^^ FBT002
148 |         super().__init__()
149 |         self.hidden_channels = hidden_channels
    |

geom3d\models\ClofNet.py:147:82: ANN003 Missing type annotation for `**kwargs`
    |
145 |             num_radial=12, num_radial2=80, envelope_exponent=5,
146 |             num_before_skip=1, num_after_skip=2, num_output_layers=3, heads=1,
147 |             act="swish", output_init="GlorotOrthogonal", use_node_features=True, **kwargs):
    |                                                                                  ^^^^^^^^ ANN003
148 |         super().__init__()
149 |         self.hidden_channels = hidden_channels
    |

geom3d\models\ClofNet.py:157:9: ERA001 Found commented-out code
    |
155 |         self.init_e = init(num_radial, hidden_channels, act, use_node_features=use_node_features)
156 |         self.heads = heads
157 |         # self.emb = emb(num_spherical, num_radial, self.cutoff, envelope_exponent)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
158 |         self.emblin = Embedding(95, hidden_channels)
159 |         self.emblinfinal = Embedding(95, 1)
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:167:13: ERA001 Found commented-out code
    |
165 |         self.lin1 = nn.Sequential(
166 |             nn.Linear(num_radial, hidden_channels),
167 |             #nn.LayerNorm(hidden_channels, elementwise_affine=False),
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
168 |             nn.SiLU(inplace=True),
169 |             nn.Linear(hidden_channels, hidden_channels))
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:170:9: ERA001 Found commented-out code
    |
168 |             nn.SiLU(inplace=True),
169 |             nn.Linear(hidden_channels, hidden_channels))
170 |         # self.lin1 = Linear(hidden_channels, hidden_channels)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
171 |         self.lin2 = nn.Sequential(
172 |             nn.Linear(num_radial, hidden_channels),
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:173:13: ERA001 Found commented-out code
    |
171 |         self.lin2 = nn.Sequential(
172 |             nn.Linear(num_radial, hidden_channels),
173 |             #nn.LayerNorm(hidden_channels, elementwise_affine=False),
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
174 |             nn.SiLU(inplace=True),
175 |             nn.Linear(hidden_channels, hidden_channels))
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:178:13: ERA001 Found commented-out code
    |
176 |         self.lin3 = nn.Sequential(
177 |             nn.Linear(3, hidden_channels//2),
178 |             #nn.LayerNorm(hidden_channels//4, elementwise_affine=False),
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
179 |             nn.SiLU(inplace=True),
180 |             nn.Linear(hidden_channels//2, 32))
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:183:13: ERA001 Found commented-out code
    |
181 |         self.lin4 = nn.Sequential(
182 |             nn.Linear(3, hidden_channels // 4),
183 |             #nn.LayerNorm(hidden_channels // 4, elementwise_affine=False),
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
184 |             nn.SiLU(inplace=True),
185 |             nn.Linear(hidden_channels // 4, 3))
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:206:9: D102 Missing docstring in public method
    |
204 |         self.reset_parameters()
205 | 
206 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
207 |         self.emb.reset_parameters()
208 |         self.freq1.data = torch.arange(0, self.freq1.numel()).float().mul_(pi)
    |

geom3d\models\ClofNet.py:210:9: D102 Missing docstring in public method
    |
208 |         self.freq1.data = torch.arange(0, self.freq1.numel()).float().mul_(pi)
209 | 
210 |     def global_add_pool(self: Tensor, batch: Optional[Tensor],
    |         ^^^^^^^^^^^^^^^ D102
211 |                         size: Optional[int] = None) -> Tensor:
    |

geom3d\models\ClofNet.py:210:46: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
208 |         self.freq1.data = torch.arange(0, self.freq1.numel()).float().mul_(pi)
209 | 
210 |     def global_add_pool(self: Tensor, batch: Optional[Tensor],
    |                                              ^^^^^^^^ FA100
211 |                         size: Optional[int] = None) -> Tensor:
    |

geom3d\models\ClofNet.py:211:31: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
210 |     def global_add_pool(self: Tensor, batch: Optional[Tensor],
211 |                         size: Optional[int] = None) -> Tensor:
    |                               ^^^^^^^^ FA100
212 | 
213 |         if batch is None:
    |

geom3d\models\ClofNet.py:214:59: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
213 |         if batch is None:
214 |             return self.sum(dim=-2, keepdim=self.dim() == 2)
    |                                                           ^ PLR2004
215 |         size = int(batch.max().item() + 1) if size is None else size
216 |         return scatter(self, batch, dim=-2, dim_size=size, reduce="add")
    |

geom3d\models\ClofNet.py:218:9: D102 Missing docstring in public method
    |
216 |         return scatter(self, batch, dim=-2, dim_size=size, reduce="add")
217 | 
218 |     def forward(self, z, pos, batch):
    |         ^^^^^^^ D102
219 |         if self.energy_and_force:
220 |             pos.requires_grad_()
    |

geom3d\models\ClofNet.py:237:9: ERA001 Found commented-out code
    |
235 |         coord_vertical = torch.cross(coord_diff, coord_cross)
236 |         frame = torch.cat((coord_diff.unsqueeze(-1), coord_cross.unsqueeze(-1), coord_vertical.unsqueeze(-1)), dim=-1)
237 |         # dist, first, second, vertical, i, j, idx_kj, idx_ji = self.xyz_to_dat(pos, edge_index, num_nodes)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
238 |         emb = self.emb(dist)
239 |         f = self.lin1(emb)
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:246:9: ERA001 Found commented-out code
    |
244 |         f = rbounds.unsqueeze(-1) * f
245 |         g=f
246 |         # g = self.lin2(emb)
    |         ^^^^^^^^^^^^^^^^^^^^ ERA001
247 |         # s, ea, ev, ef = self.mol2graph(z, pos)
248 |         # mask = self.ef_proj(ef) * ea.unsqueeze(-1)
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:247:9: ERA001 Found commented-out code
    |
245 |         g=f
246 |         # g = self.lin2(emb)
247 |         # s, ea, ev, ef = self.mol2graph(z, pos)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
248 |         # mask = self.ef_proj(ef) * ea.unsqueeze(-1)
249 |         s = self.neighbor_emb(z, z_emb, edge_index, f)
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:248:9: ERA001 Found commented-out code
    |
246 |         # g = self.lin2(emb)
247 |         # s, ea, ev, ef = self.mol2graph(z, pos)
248 |         # mask = self.ef_proj(ef) * ea.unsqueeze(-1)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
249 |         s = self.neighbor_emb(z, z_emb, edge_index, f)
250 |         #NE = self.s2v(s, frame, edge_index, g)
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:250:9: ERA001 Found commented-out code
    |
248 |         # mask = self.ef_proj(ef) * ea.unsqueeze(-1)
249 |         s = self.neighbor_emb(z, z_emb, edge_index, f)
250 |         #NE = self.s2v(s, frame, edge_index, g)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
251 |         NE1 = self.s2v(s, coord_diff.unsqueeze(-1), edge_index, f)
252 |         scalrization1 = torch.sum(NE1[i].unsqueeze(2) * frame.unsqueeze(-1), dim=1)
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:251:9: N806 Variable `NE1` in function should be lowercase
    |
249 |         s = self.neighbor_emb(z, z_emb, edge_index, f)
250 |         #NE = self.s2v(s, frame, edge_index, g)
251 |         NE1 = self.s2v(s, coord_diff.unsqueeze(-1), edge_index, f)
    |         ^^^ N806
252 |         scalrization1 = torch.sum(NE1[i].unsqueeze(2) * frame.unsqueeze(-1), dim=1)
253 |         scalrization2 = torch.sum(NE1[j].unsqueeze(2) * frame.unsqueeze(-1), dim=1)
    |

geom3d\models\ClofNet.py:255:9: ERA001 Found commented-out code
    |
253 |         scalrization2 = torch.sum(NE1[j].unsqueeze(2) * frame.unsqueeze(-1), dim=1)
254 |         scalrization1[:, 1, :] = torch.abs(scalrization1[:, 1, :].clone())
255 |         # scalrization1[:, 2, :] = torch.abs(scalrization1[:, 2, :])
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
256 |         scalrization2[:, 1, :] = torch.abs(scalrization2[:, 1, :].clone())
257 |         # calculate scalarization of(k - j)
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:258:9: ERA001 Found commented-out code
    |
256 |         scalrization2[:, 1, :] = torch.abs(scalrization2[:, 1, :].clone())
257 |         # calculate scalarization of(k - j)
258 |         # scalar1 = torch.sum(NE*a.unsqueeze(-1), dim=1)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
259 |         # scalar2 = torch.sum(NE * b.unsqueeze(-1), dim=1)
260 |         #lin3,lin4 maps vector to multiple frequencies
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:259:9: ERA001 Found commented-out code
    |
257 |         # calculate scalarization of(k - j)
258 |         # scalar1 = torch.sum(NE*a.unsqueeze(-1), dim=1)
259 |         # scalar2 = torch.sum(NE * b.unsqueeze(-1), dim=1)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
260 |         #lin3,lin4 maps vector to multiple frequencies
261 |         scalar3 = (self.lin3(torch.permute(scalrization1, (0,2,1)))+ torch.permute(scalrization1, (0,2,1))[:,:,0].unsqueeze(2))
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:263:9: ERA001 Found commented-out code
    |
261 |         scalar3 = (self.lin3(torch.permute(scalrization1, (0,2,1)))+ torch.permute(scalrization1, (0,2,1))[:,:,0].unsqueeze(2))
262 |         scalar4 = (self.lin3(torch.permute(scalrization2, (0,2,1)))+ torch.permute(scalrization2, (0,2,1))[:,:,0].unsqueeze(2))
263 |         #(E,hidden)
    |         ^^^^^^^^^^^ ERA001
264 |         scalar3 = torch.einsum("ijk,ik->ij", [scalar3, frequency])
265 |         #scalar3 = torch.matmul(scalar3,frequency)
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:265:9: ERA001 Found commented-out code
    |
263 |         #(E,hidden)
264 |         scalar3 = torch.einsum("ijk,ik->ij", [scalar3, frequency])
265 |         #scalar3 = torch.matmul(scalar3,frequency)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
266 |         scalar4 = torch.einsum("ijk,ik->ij", [scalar4, frequency])
267 |         scalar5 = (self.lin4(torch.permute(scalrization1, (0, 2, 1))) + torch.permute(scalrization1, (0, 2, 1))).permute((0, 2, 1))
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:270:9: N806 Variable `Aij` in function should be lowercase
    |
268 |         scalar6 = (self.lin4(torch.permute(scalrization2, (0, 2, 1))) + torch.permute(scalrization2, (0, 2, 1))).permute((0, 2, 1))
269 | 
270 |         Aij = torch.sum(self.q_proj(scalar5) * self.k_proj(scalar6), dim=1)
    |         ^^^ N806
271 |         #ev_decay
272 |         edgeweight = torch.cat((scalar3,scalar4, Aij), dim=-1) * rbounds.unsqueeze(-1)
    |

geom3d\models\ClofNet.py:281:9: PLW0127 Self-assignment of variable `edgefeature`
    |
279 |         edgefeature[:, 1, :] = torch.abs(edgefeature[:, 1, :].clone())
280 |         edgefeature = torch.einsum("ijk,ik->ij", [edgefeature, frequency])* rbounds.unsqueeze(-1)
281 |         edgefeature = edgefeature #+ edgefeature1
    |         ^^^^^^^^^^^ PLW0127
282 |         z_emb = self.interaction1(z_emb, edge_index, edge_attr=edgefeature, edgeweight=edgeweight)
283 |         i = 0
    |

geom3d\models\ClofNet.py:293:7: D101 Missing docstring in public class
    |
293 | class NeighborEmb(MessagePassing):
    |       ^^^^^^^^^^^ D101
294 | 
295 |     def __init__(self, hid_dim: int, **kwargs):  # ln_emb: bool, **kwargs):
    |

geom3d\models\ClofNet.py:295:9: D107 Missing docstring in `__init__`
    |
293 | class NeighborEmb(MessagePassing):
294 | 
295 |     def __init__(self, hid_dim: int, **kwargs):  # ln_emb: bool, **kwargs):
    |         ^^^^^^^^ D107
296 |         super().__init__(aggr="add")
297 |         self.embedding = nn.Embedding(95, hid_dim)
    |

geom3d\models\ClofNet.py:295:38: ANN003 Missing type annotation for `**kwargs`
    |
293 | class NeighborEmb(MessagePassing):
294 | 
295 |     def __init__(self, hid_dim: int, **kwargs):  # ln_emb: bool, **kwargs):
    |                                      ^^^^^^^^ ANN003
296 |         super().__init__(aggr="add")
297 |         self.embedding = nn.Embedding(95, hid_dim)
    |

geom3d\models\ClofNet.py:295:40: ARG002 Unused method argument: `kwargs`
    |
293 | class NeighborEmb(MessagePassing):
294 | 
295 |     def __init__(self, hid_dim: int, **kwargs):  # ln_emb: bool, **kwargs):
    |                                        ^^^^^^ ARG002
296 |         super().__init__(aggr="add")
297 |         self.embedding = nn.Embedding(95, hid_dim)
    |

geom3d\models\ClofNet.py:298:9: ERA001 Found commented-out code
    |
296 |         super().__init__(aggr="add")
297 |         self.embedding = nn.Embedding(95, hid_dim)
298 |         # self.conv = CFConv()
    |         ^^^^^^^^^^^^^^^^^^^^^^ ERA001
299 |         self.hid_dim = hid_dim
300 |         self.ln_emb = nn.LayerNorm(hid_dim,
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:303:9: D102 Missing docstring in public method
    |
301 |                                    elementwise_affine=False)  # kwargs['ln_learnable']) #if ln_emb else nn.Identity()
302 | 
303 |     def forward(self, z, s, edge_index, embs):
    |         ^^^^^^^ D102
304 |         s_neighbors = self.ln_emb(self.embedding(z))
305 |         s_neighbors = self.propagate(edge_index, x=s_neighbors, norm=embs)
    |

geom3d\models\ClofNet.py:307:9: ERA001 Found commented-out code
    |
305 |         s_neighbors = self.propagate(edge_index, x=s_neighbors, norm=embs)
306 | 
307 |         # s_neighbors = self.conv(s_neighbors, mask)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
308 |         return s + s_neighbors
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:310:9: D102 Missing docstring in public method
    |
308 |         return s + s_neighbors
309 | 
310 |     def message(self, x_j, norm):
    |         ^^^^^^^ D102
311 |         return norm.view(-1, self.hid_dim) * x_j
    |

geom3d\models\ClofNet.py:314:7: D101 Missing docstring in public class
    |
314 | class CFConvS2V(MessagePassing):
    |       ^^^^^^^^^ D101
315 | 
316 |     def __init__(self, hid_dim: int, **kwargs):  # ln_s2v: bool,
    |

geom3d\models\ClofNet.py:316:9: D107 Missing docstring in `__init__`
    |
314 | class CFConvS2V(MessagePassing):
315 | 
316 |     def __init__(self, hid_dim: int, **kwargs):  # ln_s2v: bool,
    |         ^^^^^^^^ D107
317 |         # lin1_tailact: bool, nolin1: bool=False, **kwargs):
318 |         super().__init__(aggr="add")
    |

geom3d\models\ClofNet.py:316:38: ANN003 Missing type annotation for `**kwargs`
    |
314 | class CFConvS2V(MessagePassing):
315 | 
316 |     def __init__(self, hid_dim: int, **kwargs):  # ln_s2v: bool,
    |                                      ^^^^^^^^ ANN003
317 |         # lin1_tailact: bool, nolin1: bool=False, **kwargs):
318 |         super().__init__(aggr="add")
    |

geom3d\models\ClofNet.py:316:40: ARG002 Unused method argument: `kwargs`
    |
314 | class CFConvS2V(MessagePassing):
315 | 
316 |     def __init__(self, hid_dim: int, **kwargs):  # ln_s2v: bool,
    |                                        ^^^^^^ ARG002
317 |         # lin1_tailact: bool, nolin1: bool=False, **kwargs):
318 |         super().__init__(aggr="add")
    |

geom3d\models\ClofNet.py:319:9: ERA001 Found commented-out code
    |
317 |         # lin1_tailact: bool, nolin1: bool=False, **kwargs):
318 |         super().__init__(aggr="add")
319 |         # super().__init__()
    |         ^^^^^^^^^^^^^^^^^^^^ ERA001
320 |         self.hid_dim = hid_dim
321 |         self.lin1 = nn.Sequential(  # nn.Identity() if nolin1 else nn.Sequential(
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:327:9: ERA001 Found commented-out code
    |
325 |         # if ln_s2v else nn.Identity(),
326 |         # kwargs["act"] if lin1_tailact else nn.Identity())
327 |         #self.lin2 = nn.Linear(3, hid_dim)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
328 | 
329 |     def forward(self, s, v, edge_index, emb):
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:330:9: D205 1 blank line required between summary line and description
    |
329 |       def forward(self, s, v, edge_index, emb):
330 |           """S (B, N, hid_dim)
    |  _________^
331 | |         v (B, N, 3, hid_dim)
332 | |         ea (B, N, N)
333 | |         ef (B, N, N, ef_dim)
334 | |         ev (B, N, N, 3)
335 | |         v (BN, 3, 1)
336 | |         emb (BN, hid_dim).
337 | |         """
    | |___________^ D205
338 |           s = self.lin1(s)
339 |           #v = self.lin2(v)
    |
    = help: Insert single blank line

geom3d\models\ClofNet.py:339:9: ERA001 Found commented-out code
    |
337 |         """
338 |         s = self.lin1(s)
339 |         #v = self.lin2(v)
    |         ^^^^^^^^^^^^^^^^^ ERA001
340 |         # sv = s*v
341 |         emb = emb.unsqueeze(1) * v
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:340:9: ERA001 Found commented-out code
    |
338 |         s = self.lin1(s)
339 |         #v = self.lin2(v)
340 |         # sv = s*v
    |         ^^^^^^^^^^ ERA001
341 |         emb = emb.unsqueeze(1) * v
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:343:9: ERA001 Found commented-out code
    |
341 |         emb = emb.unsqueeze(1) * v
342 | 
343 |         # s= s.view(-1, 1, self.hid_dim)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
344 |         v = self.propagate(edge_index, x=s, norm=emb)
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:346:9: ERA001 Found commented-out code
    |
344 |         v = self.propagate(edge_index, x=s, norm=emb)
345 | 
346 |         # s_neighbors = self.conv(s_neighbors, mask)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
347 |         return v.view(-1, 3, self.hid_dim)
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:349:9: D102 Missing docstring in public method
    |
347 |         return v.view(-1, 3, self.hid_dim)
348 | 
349 |     def message(self, x_j, norm):
    |         ^^^^^^^ D102
350 |         x_j = x_j.unsqueeze(1)
351 |         a = norm.view(-1, 3, self.hid_dim) * x_j
    |

geom3d\models\ClofNet.py:356:5: D419 Docstring is empty
    |
355 |   class TransformerConv(MessagePassing):
356 |       r"""
    |  _____^
357 | | 
358 | | 
359 | |     """
    | |_______^ D419
360 |       _alpha: OptTensor
    |

geom3d\models\ClofNet.py:362:9: PLR0913 Too many arguments in function definition (9 > 5)
    |
360 |     _alpha: OptTensor
361 | 
362 |     def __init__(
    |         ^^^^^^^^ PLR0913
363 |             self,
364 |             in_channels: Union[int, Tuple[int, int]],
    |

geom3d\models\ClofNet.py:362:9: D107 Missing docstring in `__init__`
    |
360 |     _alpha: OptTensor
361 | 
362 |     def __init__(
    |         ^^^^^^^^ D107
363 |             self,
364 |             in_channels: Union[int, Tuple[int, int]],
    |

geom3d\models\ClofNet.py:364:26: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
    |
362 |     def __init__(
363 |             self,
364 |             in_channels: Union[int, Tuple[int, int]],
    |                          ^^^^^ FA100
365 |             out_channels: int,
366 |             heads: int = 2,
    |

geom3d\models\ClofNet.py:364:37: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
    |
362 |     def __init__(
363 |             self,
364 |             in_channels: Union[int, Tuple[int, int]],
    |                                     ^^^^^ FA100
365 |             out_channels: int,
366 |             heads: int = 2,
    |

geom3d\models\ClofNet.py:367:13: FBT001 Boolean-typed positional argument in function definition
    |
365 |             out_channels: int,
366 |             heads: int = 2,
367 |             concat: bool = True,
    |             ^^^^^^ FBT001
368 |             beta: bool = False,
369 |             dropout: float = 0.,
    |

geom3d\models\ClofNet.py:367:13: FBT002 Boolean default positional argument in function definition
    |
365 |             out_channels: int,
366 |             heads: int = 2,
367 |             concat: bool = True,
    |             ^^^^^^ FBT002
368 |             beta: bool = False,
369 |             dropout: float = 0.,
    |

geom3d\models\ClofNet.py:368:13: FBT001 Boolean-typed positional argument in function definition
    |
366 |             heads: int = 2,
367 |             concat: bool = True,
368 |             beta: bool = False,
    |             ^^^^ FBT001
369 |             dropout: float = 0.,
370 |             edge_dim: Optional[int] = None,
    |

geom3d\models\ClofNet.py:368:13: FBT002 Boolean default positional argument in function definition
    |
366 |             heads: int = 2,
367 |             concat: bool = True,
368 |             beta: bool = False,
    |             ^^^^ FBT002
369 |             dropout: float = 0.,
370 |             edge_dim: Optional[int] = None,
    |

geom3d\models\ClofNet.py:370:23: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
368 |             beta: bool = False,
369 |             dropout: float = 0.,
370 |             edge_dim: Optional[int] = None,
    |                       ^^^^^^^^ FA100
371 |             bias: bool = True,
372 |             root_weight: bool = True,
    |

geom3d\models\ClofNet.py:371:13: FBT001 Boolean-typed positional argument in function definition
    |
369 |             dropout: float = 0.,
370 |             edge_dim: Optional[int] = None,
371 |             bias: bool = True,
    |             ^^^^ FBT001
372 |             root_weight: bool = True,
373 |             **kwargs,
    |

geom3d\models\ClofNet.py:371:13: FBT002 Boolean default positional argument in function definition
    |
369 |             dropout: float = 0.,
370 |             edge_dim: Optional[int] = None,
371 |             bias: bool = True,
    |             ^^^^ FBT002
372 |             root_weight: bool = True,
373 |             **kwargs,
    |

geom3d\models\ClofNet.py:372:13: FBT001 Boolean-typed positional argument in function definition
    |
370 |             edge_dim: Optional[int] = None,
371 |             bias: bool = True,
372 |             root_weight: bool = True,
    |             ^^^^^^^^^^^ FBT001
373 |             **kwargs,
374 |     ):
    |

geom3d\models\ClofNet.py:372:13: FBT002 Boolean default positional argument in function definition
    |
370 |             edge_dim: Optional[int] = None,
371 |             bias: bool = True,
372 |             root_weight: bool = True,
    |             ^^^^^^^^^^^ FBT002
373 |             **kwargs,
374 |     ):
    |

geom3d\models\ClofNet.py:373:13: ANN003 Missing type annotation for `**kwargs`
    |
371 |             bias: bool = True,
372 |             root_weight: bool = True,
373 |             **kwargs,
    |             ^^^^^^^^ ANN003
374 |     ):
375 |         kwargs.setdefault("aggr", "add")
    |

geom3d\models\ClofNet.py:418:9: D102 Missing docstring in public method
    |
416 |         self.reset_parameters()
417 | 
418 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
419 |         self.lin_key.reset_parameters()
420 |         self.lin_query.reset_parameters()
    |

geom3d\models\ClofNet.py:428:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
426 |             self.lin_beta.reset_parameters()
427 | 
428 |     def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,
    |         ^^^^^^^ PLR0913
429 |                 edge_attr: OptTensor = None, edgeweight: OptTensor = None, emb: OptTensor = None, return_attention_weights=None):
    |

geom3d\models\ClofNet.py:428:9: D102 Missing docstring in public method
    |
426 |             self.lin_beta.reset_parameters()
427 | 
428 |     def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,
    |         ^^^^^^^ D102
429 |                 edge_attr: OptTensor = None, edgeweight: OptTensor = None, emb: OptTensor = None, return_attention_weights=None):
    |

geom3d\models\ClofNet.py:428:26: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
    |
426 |             self.lin_beta.reset_parameters()
427 | 
428 |     def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,
    |                          ^^^^^ FA100
429 |                 edge_attr: OptTensor = None, edgeweight: OptTensor = None, emb: OptTensor = None, return_attention_weights=None):
    |

geom3d\models\ClofNet.py:431:9: N806 Variable `H` in function should be lowercase
    |
429 |                 edge_attr: OptTensor = None, edgeweight: OptTensor = None, emb: OptTensor = None, return_attention_weights=None):
430 | 
431 |         H, C = self.heads, self.out_channels
    |         ^ N806
432 | 
433 |         if isinstance(x, Tensor):
    |

geom3d\models\ClofNet.py:431:12: N806 Variable `C` in function should be lowercase
    |
429 |                 edge_attr: OptTensor = None, edgeweight: OptTensor = None, emb: OptTensor = None, return_attention_weights=None):
430 | 
431 |         H, C = self.heads, self.out_channels
    |            ^ N806
432 | 
433 |         if isinstance(x, Tensor):
    |

geom3d\models\ClofNet.py:452:13: ERA001 Found commented-out code
    |
451 |         if self.root_weight:
452 |             #x_r = self.lin_skip(x[1])
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
453 |             x_r = x[1]
454 |             if self.lin_beta is not None:
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:462:13: S101 Use of `assert` detected
    |
461 |         if isinstance(return_attention_weights, bool):
462 |             assert alpha is not None
    |             ^^^^^^ S101
463 |             if isinstance(edge_index, Tensor):
464 |                 return out, (edge_index, alpha)
    |

geom3d\models\ClofNet.py:465:13: RET505 Unnecessary `elif` after `return` statement
    |
463 |             if isinstance(edge_index, Tensor):
464 |                 return out, (edge_index, alpha)
465 |             elif isinstance(edge_index, SparseTensor):
    |             ^^^^ RET505
466 |                 return out, edge_index.set_value(alpha, layout="coo")
467 |             return None
    |
    = help: Remove unnecessary `elif`

geom3d\models\ClofNet.py:468:9: RET505 Unnecessary `else` after `return` statement
    |
466 |                 return out, edge_index.set_value(alpha, layout="coo")
467 |             return None
468 |         else:
    |         ^^^^ RET505
469 |             return out
    |
    = help: Remove unnecessary `else`

geom3d\models\ClofNet.py:471:9: PLR0913 Too many arguments in function definition (9 > 5)
    |
469 |             return out
470 | 
471 |     def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,
    |         ^^^^^^^ PLR0913
472 |                 edge_attr: OptTensor, edgeweight: OptTensor, emb: OptTensor, index: Tensor, ptr: OptTensor,
473 |                 size_i: Optional[int]) -> Tensor:
    |

geom3d\models\ClofNet.py:471:9: D102 Missing docstring in public method
    |
469 |             return out
470 | 
471 |     def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,
    |         ^^^^^^^ D102
472 |                 edge_attr: OptTensor, edgeweight: OptTensor, emb: OptTensor, index: Tensor, ptr: OptTensor,
473 |                 size_i: Optional[int]) -> Tensor:
    |

geom3d\models\ClofNet.py:472:62: ARG002 Unused method argument: `emb`
    |
471 |     def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,
472 |                 edge_attr: OptTensor, edgeweight: OptTensor, emb: OptTensor, index: Tensor, ptr: OptTensor,
    |                                                              ^^^ ARG002
473 |                 size_i: Optional[int]) -> Tensor:
    |

geom3d\models\ClofNet.py:473:25: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
471 |     def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,
472 |                 edge_attr: OptTensor, edgeweight: OptTensor, emb: OptTensor, index: Tensor, ptr: OptTensor,
473 |                 size_i: Optional[int]) -> Tensor:
    |                         ^^^^^^^^ FA100
474 | 
475 |         if self.lin_edge is not None:
    |

geom3d\models\ClofNet.py:476:13: S101 Use of `assert` detected
    |
475 |         if self.lin_edge is not None:
476 |             assert edge_attr is not None
    |             ^^^^^^ S101
477 |             edge_attr = self.lin_edge(edge_attr).view(-1, self.heads,
478 |                                                       self.out_channels)
    |

geom3d\models\ClofNet.py:489:13: ERA001 Found commented-out code
    |
487 |         out *= edgeweight.unsqueeze(1)
488 |         if edge_attr is not None:
489 |             #out += emb* edge_attr
    |             ^^^^^^^^^^^^^^^^^^^^^^ ERA001
490 |             out += edgeweight.unsqueeze(1) * edge_attr
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:492:9: ERA001 Found commented-out code
    |
490 |             out += edgeweight.unsqueeze(1) * edge_attr
491 | 
492 |         #out *= alpha.view(-1, self.heads, 1)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
493 |         return out
    |
    = help: Remove commented-out code

geom3d\models\ClofNet.py:495:9: D105 Missing docstring in magic method
    |
493 |         return out
494 | 
495 |     def __repr__(self) -> str:
    |         ^^^^^^^^ D105
496 |         return (f"{self.__class__.__name__}({self.in_channels}, "
497 |                 f"{self.out_channels}, heads={self.heads})")
    |

geom3d\models\DMPNN.py:1:1: N999 Invalid module name: 'DMPNN'
geom3d\models\DMPNN.py:1:1: D205 1 blank line required between summary line and description
  |
1 | / """credit to https://github.com/chao1224/BioChemGNN_Dense/blob/master/src/models/DMPNN.py
2 | | credit to https://github.com/chao1224/BioChemGNN/blob/main/BioChemGNN/models/DMPNN.py.
3 | | """
  | |___^ D205
4 |   from collections import *
  |
  = help: Insert single blank line

geom3d\models\DMPNN.py:4:1: F403 `from collections import *` used; unable to detect undefined names
  |
2 | credit to https://github.com/chao1224/BioChemGNN/blob/main/BioChemGNN/models/DMPNN.py.
3 | """
4 | from collections import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^ F403
5 | 
6 | import torch
  |

geom3d\models\DMPNN.py:9:22: N812 Lowercase `functional` imported as non-lowercase `F`
   |
 7 | from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder
 8 | from torch import nn
 9 | from torch.nn import functional as F
   |                      ^^^^^^^^^^^^^^^ N812
10 | from torch_scatter import scatter_add
   |

geom3d\models\DMPNN.py:15:5: E741 Ambiguous variable name: `l`
   |
13 | def get_revert_edge_index(num_edge):
14 |     """Corresponding to this line: https://github.com/chao1224/3D_Benchmark_dev/blob/main/Geom3D/datasets/datasets_utils.py#L90-L92."""
15 |     l = []
   |     ^ E741
16 |     for i in range(int(num_edge / 2)):
17 |         l.extend([i*2+1, i*2])
   |

geom3d\models\DMPNN.py:21:7: D101 Missing docstring in public class
   |
21 | class DMPNN(nn.Module):
   |       ^^^^^ D101
22 |     def __init__(self, num_layer, emb_dim, JK="last", drop_ratio=0, gnn_type="gin"):
23 |         super().__init__()
   |

geom3d\models\DMPNN.py:22:9: D107 Missing docstring in `__init__`
   |
21 | class DMPNN(nn.Module):
22 |     def __init__(self, num_layer, emb_dim, JK="last", drop_ratio=0, gnn_type="gin"):
   |         ^^^^^^^^ D107
23 |         super().__init__()
24 |         self.num_layer = num_layer
   |

geom3d\models\DMPNN.py:22:44: N803 Argument name `JK` should be lowercase
   |
21 | class DMPNN(nn.Module):
22 |     def __init__(self, num_layer, emb_dim, JK="last", drop_ratio=0, gnn_type="gin"):
   |                                            ^^ N803
23 |         super().__init__()
24 |         self.num_layer = num_layer
   |

geom3d\models\DMPNN.py:22:69: ARG002 Unused method argument: `gnn_type`
   |
21 | class DMPNN(nn.Module):
22 |     def __init__(self, num_layer, emb_dim, JK="last", drop_ratio=0, gnn_type="gin"):
   |                                                                     ^^^^^^^^ ARG002
23 |         super().__init__()
24 |         self.num_layer = num_layer
   |

geom3d\models\DMPNN.py:28:29: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   |
26 |         self.JK = JK
27 | 
28 |         if self.num_layer < 2:
   |                             ^ PLR2004
29 |             msg = "Number of GNN layers must be greater than 1."
30 |             raise ValueError(msg)
   |

geom3d\models\DMPNN.py:44:9: D102 Missing docstring in public method
   |
42 |             self.batch_norms.append(nn.BatchNorm1d(emb_dim))
43 | 
44 |     def forward(self, *argv):
   |         ^^^^^^^ D102
45 |         if len(argv) == 3:
46 |             x, edge_index, edge_attr = argv[0], argv[1], argv[2]
   |

geom3d\models\DMPNN.py:44:23: ANN002 Missing type annotation for `*argv`
   |
42 |             self.batch_norms.append(nn.BatchNorm1d(emb_dim))
43 | 
44 |     def forward(self, *argv):
   |                       ^^^^^ ANN002
45 |         if len(argv) == 3:
46 |             x, edge_index, edge_attr = argv[0], argv[1], argv[2]
   |

geom3d\models\DMPNN.py:45:25: PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   |
44 |     def forward(self, *argv):
45 |         if len(argv) == 3:
   |                         ^ PLR2004
46 |             x, edge_index, edge_attr = argv[0], argv[1], argv[2]
47 |         elif len(argv) == 1:
   |

geom3d\models\DimeNet.py:1:1: N999 Invalid module name: 'DimeNet'
geom3d\models\DimeNet.py:1:1: D100 Missing docstring in public module
geom3d\models\DimeNet.py:1:18: N812 Lowercase `pi` imported as non-lowercase `PI`
  |
1 | from math import pi as PI
  |                  ^^^^^^^^ N812
2 | from math import sqrt
  |

geom3d\models\DimeNet.py:15:5: D103 Missing docstring in public function
   |
15 | def swish(x):
   |     ^^^^^ D103
16 |     return x * x.sigmoid()
   |

geom3d\models\DimeNet.py:19:5: D103 Missing docstring in public function
   |
19 | def glorot_orthogonal(tensor, scale):
   |     ^^^^^^^^^^^^^^^^^ D103
20 |     if tensor is not None:
21 |         torch.nn.init.orthogonal_(tensor.data)
   |

geom3d\models\DimeNet.py:26:7: D101 Missing docstring in public class
   |
26 | class Envelope(torch.nn.Module):
   |       ^^^^^^^^ D101
27 |     def __init__(self, exponent):
28 |         super().__init__()
   |

geom3d\models\DimeNet.py:27:9: D107 Missing docstring in `__init__`
   |
26 | class Envelope(torch.nn.Module):
27 |     def __init__(self, exponent):
   |         ^^^^^^^^ D107
28 |         super().__init__()
29 |         self.p = exponent + 1
   |

geom3d\models\DimeNet.py:34:9: D102 Missing docstring in public method
   |
32 |         self.c = -self.p * (self.p + 1) / 2
33 | 
34 |     def forward(self, x):
   |         ^^^^^^^ D102
35 |         p, a, b, c = self.p, self.a, self.b, self.c
36 |         x_pow_p0 = x.pow(p - 1)
   |

geom3d\models\DimeNet.py:42:7: D101 Missing docstring in public class
   |
42 | class BesselBasisLayer(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^^ D101
43 |     def __init__(self, num_radial, cutoff=5.0, envelope_exponent=5):
44 |         super().__init__()
   |

geom3d\models\DimeNet.py:43:9: D107 Missing docstring in `__init__`
   |
42 | class BesselBasisLayer(torch.nn.Module):
43 |     def __init__(self, num_radial, cutoff=5.0, envelope_exponent=5):
   |         ^^^^^^^^ D107
44 |         super().__init__()
45 |         self.cutoff = cutoff
   |

geom3d\models\DimeNet.py:52:9: D102 Missing docstring in public method
   |
50 |         self.reset_parameters()
51 | 
52 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
53 |         # added the with torch.no_grad() to avoid the warning
54 |         with torch.no_grad(): torch.arange(1, self.freq.numel() + 1, out=self.freq).mul_(PI)
   |

geom3d\models\DimeNet.py:54:29: E701 Multiple statements on one line (colon)
   |
52 |     def reset_parameters(self):
53 |         # added the with torch.no_grad() to avoid the warning
54 |         with torch.no_grad(): torch.arange(1, self.freq.numel() + 1, out=self.freq).mul_(PI)
   |                             ^ E701
55 | 
56 |     def forward(self, dist):
   |

geom3d\models\DimeNet.py:56:9: D102 Missing docstring in public method
   |
54 |         with torch.no_grad(): torch.arange(1, self.freq.numel() + 1, out=self.freq).mul_(PI)
55 | 
56 |     def forward(self, dist):
   |         ^^^^^^^ D102
57 |         dist = dist.unsqueeze(-1) / self.cutoff
58 |         return self.envelope(dist) * (self.freq * dist).sin()
   |

geom3d\models\DimeNet.py:61:7: D101 Missing docstring in public class
   |
61 | class SphericalBasisLayer(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^^^^^ D101
62 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
63 |         super().__init__()
   |

geom3d\models\DimeNet.py:62:9: D107 Missing docstring in `__init__`
   |
61 | class SphericalBasisLayer(torch.nn.Module):
62 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
   |         ^^^^^^^^ D107
63 |         super().__init__()
64 |         assert num_radial <= 64
   |

geom3d\models\DimeNet.py:64:9: S101 Use of `assert` detected
   |
62 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
63 |         super().__init__()
64 |         assert num_radial <= 64
   |         ^^^^^^ S101
65 |         self.num_spherical = num_spherical
66 |         self.num_radial = num_radial
   |

geom3d\models\DimeNet.py:64:30: PLR2004 Magic value used in comparison, consider replacing `64` with a constant variable
   |
62 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
63 |         super().__init__()
64 |         assert num_radial <= 64
   |                              ^^ PLR2004
65 |         self.num_spherical = num_spherical
66 |         self.num_radial = num_radial
   |

geom3d\models\DimeNet.py:80:71: B023 Function definition does not bind loop variable `sph1`
   |
78 |             if i == 0:
79 |                 sph1 = sym.lambdify([theta], sph_harm_forms[i][0], modules)(0)
80 |                 self.sph_funcs.append(lambda x: torch.zeros_like(x) + sph1)
   |                                                                       ^^^^ B023
81 |             else:
82 |                 sph = sym.lambdify([theta], sph_harm_forms[i][0], modules)
   |

geom3d\models\DimeNet.py:88:9: D102 Missing docstring in public method
   |
86 |                 self.bessel_funcs.append(bessel)
87 | 
88 |     def forward(self, dist, angle, idx_kj):
   |         ^^^^^^^ D102
89 |         dist = dist / self.cutoff
90 |         rbf = torch.stack([f(dist) for f in self.bessel_funcs], dim=1)
   |

geom3d\models\DimeNet.py:99:7: D101 Missing docstring in public class
    |
 99 | class EmbeddingBlock(torch.nn.Module):
    |       ^^^^^^^^^^^^^^ D101
100 |     def __init__(self, node_class, num_radial, hidden_channels, act=swish):
101 |         super().__init__()
    |

geom3d\models\DimeNet.py:100:9: D107 Missing docstring in `__init__`
    |
 99 | class EmbeddingBlock(torch.nn.Module):
100 |     def __init__(self, node_class, num_radial, hidden_channels, act=swish):
    |         ^^^^^^^^ D107
101 |         super().__init__()
102 |         self.act = act
    |

geom3d\models\DimeNet.py:110:9: D102 Missing docstring in public method
    |
108 |         self.reset_parameters()
109 | 
110 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
111 |         self.emb.weight.data.uniform_(-sqrt(3), sqrt(3))
112 |         self.lin_rbf.reset_parameters()
    |

geom3d\models\DimeNet.py:115:9: D102 Missing docstring in public method
    |
113 |         self.lin.reset_parameters()
114 | 
115 |     def forward(self, x, rbf, i, j):
    |         ^^^^^^^ D102
116 |         x = self.emb(x)
117 |         rbf = self.act(self.lin_rbf(rbf))
    |

geom3d\models\DimeNet.py:121:7: D101 Missing docstring in public class
    |
121 | class ResidualLayer(torch.nn.Module):
    |       ^^^^^^^^^^^^^ D101
122 |     def __init__(self, hidden_channels, act=swish):
123 |         super().__init__()
    |

geom3d\models\DimeNet.py:122:9: D107 Missing docstring in `__init__`
    |
121 | class ResidualLayer(torch.nn.Module):
122 |     def __init__(self, hidden_channels, act=swish):
    |         ^^^^^^^^ D107
123 |         super().__init__()
124 |         self.act = act
    |

geom3d\models\DimeNet.py:130:9: D102 Missing docstring in public method
    |
128 |         self.reset_parameters()
129 | 
130 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
131 |         glorot_orthogonal(self.lin1.weight, scale=2.0)
132 |         self.lin1.bias.data.fill_(0)
    |

geom3d\models\DimeNet.py:136:9: D102 Missing docstring in public method
    |
134 |         self.lin2.bias.data.fill_(0)
135 | 
136 |     def forward(self, x):
    |         ^^^^^^^ D102
137 |         return x + self.act(self.lin2(self.act(self.lin1(x))))
    |

geom3d\models\DimeNet.py:140:7: D101 Missing docstring in public class
    |
140 | class InteractionBlock(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^ D101
141 |     def __init__(
142 |         self,
    |

geom3d\models\DimeNet.py:141:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
140 | class InteractionBlock(torch.nn.Module):
141 |     def __init__(
    |         ^^^^^^^^ PLR0913
142 |         self,
143 |         hidden_channels,
    |

geom3d\models\DimeNet.py:141:9: D107 Missing docstring in `__init__`
    |
140 | class InteractionBlock(torch.nn.Module):
141 |     def __init__(
    |         ^^^^^^^^ D107
142 |         self,
143 |         hidden_channels,
    |

geom3d\models\DimeNet.py:175:9: D102 Missing docstring in public method
    |
173 |         self.reset_parameters()
174 | 
175 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
176 |         glorot_orthogonal(self.lin_rbf.weight, scale=2.0)
177 |         glorot_orthogonal(self.lin_sbf.weight, scale=2.0)
    |

geom3d\models\DimeNet.py:190:9: D102 Missing docstring in public method
    |
188 |             res_layer.reset_parameters()
189 | 
190 |     def forward(self, x, rbf, sbf, idx_kj, idx_ji):
    |         ^^^^^^^ D102
191 |         rbf = self.lin_rbf(rbf)
192 |         sbf = self.lin_sbf(sbf)
    |

geom3d\models\DimeNet.py:209:7: D101 Missing docstring in public class
    |
209 | class OutputBlock(torch.nn.Module):
    |       ^^^^^^^^^^^ D101
210 |     def __init__(
211 |         self, num_radial, hidden_channels, out_channels, num_layers, act=swish
    |

geom3d\models\DimeNet.py:210:9: D107 Missing docstring in `__init__`
    |
209 | class OutputBlock(torch.nn.Module):
210 |     def __init__(
    |         ^^^^^^^^ D107
211 |         self, num_radial, hidden_channels, out_channels, num_layers, act=swish
212 |     ):
    |

geom3d\models\DimeNet.py:224:9: D102 Missing docstring in public method
    |
222 |         self.reset_parameters()
223 | 
224 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
225 |         glorot_orthogonal(self.lin_rbf.weight, scale=2.0)
226 |         for lin in self.lins:
    |

geom3d\models\DimeNet.py:231:9: D102 Missing docstring in public method
    |
229 |         self.lin.weight.data.fill_(0)
230 | 
231 |     def forward(self, x, rbf, i, num_nodes=None):
    |         ^^^^^^^ D102
232 |         x = self.lin_rbf(rbf) * x
233 |         x = scatter(x, i, dim=0, dim_size=num_nodes)
    |

geom3d\models\DimeNet.py:240:5: D205 1 blank line required between summary line and description
    |
239 |   class DimeNet(nn.Module):
240 |       r"""The directional message passing neural network (DimeNet) from the
    |  _____^
241 | |     `"Directional Message Passing for Molecular Graphs"
242 | |     <https://arxiv.org/abs/2003.03123>`_ paper.
243 | |     DimeNet transforms messages based on the angle between them in a
244 | |     rotation-equivariant fashion.
245 | |     .. note::
246 | |         For an example of using a pretrained DimeNet variant, see
247 | |         `examples/qm9_pretrained_DimeNet.py
248 | |         <https://github.com/rusty1s/pytorch_geometric/blob/master/examples/
249 | |         qm9_pretrained_DimeNet.py>`_.
250 | | 
251 | |     Args:
252 | |     ----
253 | |         hidden_channels (int): Hidden embedding size.
254 | |         out_channels (int): Size of each output sample.
255 | |         num_blocks (int): Number of building blocks.
256 | |         num_bilinear (int): Size of the bilinear layer tensor.
257 | |         num_spherical (int): Number of spherical harmonics.
258 | |         num_radial (int): Number of radial basis functions.
259 | |         cutoff: (float, optional): Cutoff distance for interatomic
260 | |             interactions. (default: :obj:`5.0`)
261 | |         envelope_exponent (int, optional): Shape of the smooth cutoff.
262 | |             (default: :obj:`5`)
263 | |         num_before_skip: (int, optional): Number of residual layers in the
264 | |             interaction blocks before the skip connection. (default: :obj:`1`)
265 | |         num_after_skip: (int, optional): Number of residual layers in the
266 | |             interaction blocks after the skip connection. (default: :obj:`2`)
267 | |         num_output_layers: (int, optional): Number of linear layers for the
268 | |             output blocks. (default: :obj:`3`)
269 | |         act: (function, optional): The activation funtion.
270 | |             (default: :obj:`swish`)
271 | | 
272 | |     """
    | |_______^ D205
273 |   
274 |       def __init__(
    |
    = help: Insert single blank line

geom3d\models\DimeNet.py:274:9: PLR0913 Too many arguments in function definition (13 > 5)
    |
272 |     """
273 | 
274 |     def __init__(
    |         ^^^^^^^^ PLR0913
275 |         self,
276 |         node_class,
    |

geom3d\models\DimeNet.py:274:9: D107 Missing docstring in `__init__`
    |
272 |     """
273 | 
274 |     def __init__(
    |         ^^^^^^^^ D107
275 |         self,
276 |         node_class,
    |

geom3d\models\DimeNet.py:328:9: D102 Missing docstring in public method
    |
326 |         self.reset_parameters()
327 | 
328 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
329 |         self.rbf.reset_parameters()
330 |         self.emb.reset_parameters()
    |

geom3d\models\DimeNet.py:336:9: D102 Missing docstring in public method
    |
334 |             interaction.reset_parameters()
335 | 
336 |     def triplets(self, edge_index, num_nodes):
    |         ^^^^^^^^ D102
337 |         row, col = edge_index  # j->i
    |

geom3d\models\DimeNet.py:359:9: D102 Missing docstring in public method
    |
357 |         return col, row, idx_i, idx_j, idx_k, idx_kj, idx_ji
358 | 
359 |     def forward(self, z, pos, batch=None):
    |         ^^^^^^^ D102
360 |         edge_index = radius_graph(pos, r=self.cutoff, batch=batch)
    |

geom3d\models\DimeNet.py:381:9: N806 Variable `P` in function should be lowercase
    |
379 |         # Embedding block.
380 |         x = self.emb(z, rbf, i, j)
381 |         P = self.output_blocks[0](x, rbf, i, num_nodes=pos.size(0))
    |         ^ N806
382 | 
383 |         # Interaction blocks.
    |

geom3d\models\DimeNet.py:388:13: N806 Variable `P` in function should be lowercase
    |
386 |         ):
387 |             x = interaction_block(x, rbf, sbf, idx_kj, idx_ji)
388 |             P += output_block(x, rbf, i)
    |             ^ N806
389 | 
390 |         return P.sum(dim=0) if batch is None else scatter(P, batch, dim=0)
    |

geom3d\models\DimeNetPlusPlus.py:1:1: N999 Invalid module name: 'DimeNetPlusPlus'
geom3d\models\DimeNetPlusPlus.py:24:7: D101 Missing docstring in public class
   |
24 | class InteractionPPBlock(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^^^^ D101
25 |     def __init__(
26 |         self,
   |

geom3d\models\DimeNetPlusPlus.py:25:9: PLR0913 Too many arguments in function definition (8 > 5)
   |
24 | class InteractionPPBlock(torch.nn.Module):
25 |     def __init__(
   |         ^^^^^^^^ PLR0913
26 |         self,
27 |         hidden_channels,
   |

geom3d\models\DimeNetPlusPlus.py:25:9: D107 Missing docstring in `__init__`
   |
24 | class InteractionPPBlock(torch.nn.Module):
25 |     def __init__(
   |         ^^^^^^^^ D107
26 |         self,
27 |         hidden_channels,
   |

geom3d\models\DimeNetPlusPlus.py:66:9: D102 Missing docstring in public method
   |
64 |         self.reset_parameters()
65 | 
66 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
67 |         glorot_orthogonal(self.lin_rbf1.weight, scale=2.0)
68 |         glorot_orthogonal(self.lin_rbf2.weight, scale=2.0)
   |

geom3d\models\DimeNetPlusPlus.py:87:9: D102 Missing docstring in public method
   |
85 |             res_layer.reset_parameters()
86 | 
87 |     def forward(self, x, rbf, sbf, idx_kj, idx_ji):
   |         ^^^^^^^ D102
88 |         # Initial transformations.
89 |         x_ji = self.act(self.lin_ji(x))
   |

geom3d\models\DimeNetPlusPlus.py:119:7: D101 Missing docstring in public class
    |
119 | class OutputPPBlock(torch.nn.Module):
    |       ^^^^^^^^^^^^^ D101
120 |     def __init__(
121 |         self,
    |

geom3d\models\DimeNetPlusPlus.py:120:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
119 | class OutputPPBlock(torch.nn.Module):
120 |     def __init__(
    |         ^^^^^^^^ PLR0913
121 |         self,
122 |         num_radial,
    |

geom3d\models\DimeNetPlusPlus.py:120:9: D107 Missing docstring in `__init__`
    |
119 | class OutputPPBlock(torch.nn.Module):
120 |     def __init__(
    |         ^^^^^^^^ D107
121 |         self,
122 |         num_radial,
    |

geom3d\models\DimeNetPlusPlus.py:141:9: D102 Missing docstring in public method
    |
139 |         self.reset_parameters()
140 | 
141 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
142 |         glorot_orthogonal(self.lin_rbf.weight, scale=2.0)
143 |         glorot_orthogonal(self.lin_up.weight, scale=2.0)
    |

geom3d\models\DimeNetPlusPlus.py:149:9: D102 Missing docstring in public method
    |
147 |         self.lin.weight.data.fill_(0)
148 | 
149 |     def forward(self, x, rbf, i, num_nodes=None, extract_representation=False):
    |         ^^^^^^^ D102
150 |         x = self.lin_rbf(rbf) * x
151 |         x = scatter(x, i, dim=0, dim_size=num_nodes)
    |

geom3d\models\DimeNetPlusPlus.py:149:50: FBT002 Boolean default positional argument in function definition
    |
147 |         self.lin.weight.data.fill_(0)
148 | 
149 |     def forward(self, x, rbf, i, num_nodes=None, extract_representation=False):
    |                                                  ^^^^^^^^^^^^^^^^^^^^^^ FBT002
150 |         x = self.lin_rbf(rbf) * x
151 |         x = scatter(x, i, dim=0, dim_size=num_nodes)
    |

geom3d\models\DimeNetPlusPlus.py:157:9: RET505 Unnecessary `else` after `return` statement
    |
155 |         if extract_representation:
156 |             return x
157 |         else:
    |         ^^^^ RET505
158 |             return self.lin(x)
    |
    = help: Remove unnecessary `else`

geom3d\models\DimeNetPlusPlus.py:189:9: PLR0913 Too many arguments in function definition (16 > 5)
    |
187 |     """
188 | 
189 |     def __init__(
    |         ^^^^^^^^ PLR0913
190 |         self,
191 |         node_class,
    |

geom3d\models\DimeNetPlusPlus.py:189:9: D107 Missing docstring in `__init__`
    |
187 |     """
188 | 
189 |     def __init__(
    |         ^^^^^^^^ D107
190 |         self,
191 |         node_class,
    |

geom3d\models\DimeNetPlusPlus.py:254:9: D102 Missing docstring in public method
    |
252 |         self.reset_parameters()
253 | 
254 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
255 |         self.rbf.reset_parameters()
256 |         self.emb.reset_parameters()
    |

geom3d\models\DimeNetPlusPlus.py:262:9: D102 Missing docstring in public method
    |
260 |             interaction.reset_parameters()
261 | 
262 |     def triplets(self, edge_index, num_nodes):
    |         ^^^^^^^^ D102
263 |         row, col = edge_index  # j->i
    |

geom3d\models\DimeNetPlusPlus.py:285:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
283 |         return col, row, idx_i, idx_j, idx_k, idx_kj, idx_ji
284 | 
285 |     def forward(self, z, pos, batch, edge_index=None, extract_representation=False, return_latent=False):
    |         ^^^^^^^ PLR0913
286 |         if edge_index is None:
287 |             edge_index = radius_graph(pos, r=self.cutoff, batch=batch)
    |

geom3d\models\DimeNetPlusPlus.py:285:9: D102 Missing docstring in public method
    |
283 |         return col, row, idx_i, idx_j, idx_k, idx_kj, idx_ji
284 | 
285 |     def forward(self, z, pos, batch, edge_index=None, extract_representation=False, return_latent=False):
    |         ^^^^^^^ D102
286 |         if edge_index is None:
287 |             edge_index = radius_graph(pos, r=self.cutoff, batch=batch)
    |

geom3d\models\DimeNetPlusPlus.py:285:55: FBT002 Boolean default positional argument in function definition
    |
283 |         return col, row, idx_i, idx_j, idx_k, idx_kj, idx_ji
284 | 
285 |     def forward(self, z, pos, batch, edge_index=None, extract_representation=False, return_latent=False):
    |                                                       ^^^^^^^^^^^^^^^^^^^^^^ FBT002
286 |         if edge_index is None:
287 |             edge_index = radius_graph(pos, r=self.cutoff, batch=batch)
    |

geom3d\models\DimeNetPlusPlus.py:285:85: FBT002 Boolean default positional argument in function definition
    |
283 |         return col, row, idx_i, idx_j, idx_k, idx_kj, idx_ji
284 | 
285 |     def forward(self, z, pos, batch, edge_index=None, extract_representation=False, return_latent=False):
    |                                                                                     ^^^^^^^^^^^^^ FBT002
286 |         if edge_index is None:
287 |             edge_index = radius_graph(pos, r=self.cutoff, batch=batch)
    |

geom3d\models\DimeNetPlusPlus.py:310:9: N806 Variable `P` in function should be lowercase
    |
308 |         # Embedding block.
309 |         x = self.emb(z, rbf, i, j)
310 |         P = self.output_blocks[0](x, rbf, i, num_nodes=pos.size(0), extract_representation=extract_representation)
    |         ^ N806
311 | 
312 |         # Interaction blocks.
    |

geom3d\models\DimeNetPlusPlus.py:315:13: N806 Variable `P` in function should be lowercase
    |
313 |         for interaction_block, output_block in zip(self.interaction_blocks, self.output_blocks[1:]):
314 |             x = interaction_block(x, rbf, sbf, idx_kj, idx_ji)
315 |             P += output_block(x, rbf, i, num_nodes=pos.size(0), extract_representation=extract_representation)
    |             ^ N806
316 | 
317 |         # representation if extract_representation=True
    |

geom3d\models\DimeNetPlusPlus.py:319:9: N806 Variable `P` in function should be lowercase
    |
317 |         # representation if extract_representation=True
318 |         # energy if extract_representation=False
319 |         P /= (self.num_blocks + 1)
    |         ^ N806
320 |         out = P.sum(dim=0) if batch is None else scatter(P, batch, dim=0, reduce=self.readout)
    |

geom3d\models\DimeNetPlusPlus.py:326:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
324 |         return out
325 | 
326 |     def forward_with_gathered_index(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
327 |         self, gathered_z, pos, batch,
328 |         edge_index, periodic_index_mapping, gathered_batch,  # for periodic crystal modeling
    |

geom3d\models\DimeNetPlusPlus.py:326:9: D102 Missing docstring in public method
    |
324 |         return out
325 | 
326 |     def forward_with_gathered_index(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
327 |         self, gathered_z, pos, batch,
328 |         edge_index, periodic_index_mapping, gathered_batch,  # for periodic crystal modeling
    |

geom3d\models\DimeNetPlusPlus.py:327:32: ARG002 Unused method argument: `batch`
    |
326 |     def forward_with_gathered_index(
327 |         self, gathered_z, pos, batch,
    |                                ^^^^^ ARG002
328 |         edge_index, periodic_index_mapping, gathered_batch,  # for periodic crystal modeling
329 |         extract_representation=False, return_latent=False
    |

geom3d\models\DimeNetPlusPlus.py:329:9: FBT002 Boolean default positional argument in function definition
    |
327 |         self, gathered_z, pos, batch,
328 |         edge_index, periodic_index_mapping, gathered_batch,  # for periodic crystal modeling
329 |         extract_representation=False, return_latent=False
    |         ^^^^^^^^^^^^^^^^^^^^^^ FBT002
330 |     ):
331 |         j, i = edge_index
    |

geom3d\models\DimeNetPlusPlus.py:329:39: FBT002 Boolean default positional argument in function definition
    |
327 |         self, gathered_z, pos, batch,
328 |         edge_index, periodic_index_mapping, gathered_batch,  # for periodic crystal modeling
329 |         extract_representation=False, return_latent=False
    |                                       ^^^^^^^^^^^^^ FBT002
330 |     ):
331 |         j, i = edge_index
    |

geom3d\models\DimeNetPlusPlus.py:353:9: N806 Variable `P` in function should be lowercase
    |
351 |         gathered_j = periodic_index_mapping[j]
352 |         x = self.emb(gathered_z, rbf, gathered_i, gathered_j)  # for edge representation
353 |         P = self.output_blocks[0](x, rbf, gathered_i, num_nodes=gathered_z.size(0), extract_representation=extract_representation)
    |         ^ N806
354 | 
355 |         # Interaction blocks.
    |

geom3d\models\DimeNetPlusPlus.py:358:13: N806 Variable `P` in function should be lowercase
    |
356 |         for interaction_block, output_block in zip(self.interaction_blocks, self.output_blocks[1:]):
357 |             x = interaction_block(x, rbf, sbf, idx_kj, idx_ji)
358 |             P += output_block(x, rbf, gathered_i, num_nodes=gathered_z.size(0), extract_representation=extract_representation)
    |             ^ N806
359 | 
360 |         # representation if extract_representation=True
    |

geom3d\models\DimeNetPlusPlus.py:362:9: N806 Variable `P` in function should be lowercase
    |
360 |         # representation if extract_representation=True
361 |         # energy if extract_representation=False
362 |         P /= (self.num_blocks + 1)
    |         ^ N806
363 | 
364 |         out = scatter(P, gathered_batch, dim=0, reduce=self.readout)
    |

geom3d\models\DimeNet_utils.py:1:1: N999 Invalid module name: 'DimeNet_utils'
geom3d\models\DimeNet_utils.py:1:1: D100 Missing docstring in public module
geom3d\models\DimeNet_utils.py:7:5: N802 Function name `Jn` should be lowercase
  |
7 | def Jn(r, n):
  |     ^^ N802
8 |     return np.sqrt(np.pi / (2 * r)) * sp.jv(n + 0.5, r)
  |

geom3d\models\DimeNet_utils.py:7:5: D103 Missing docstring in public function
  |
7 | def Jn(r, n):
  |     ^^ D103
8 |     return np.sqrt(np.pi / (2 * r)) * sp.jv(n + 0.5, r)
  |

geom3d\models\DimeNet_utils.py:11:5: N802 Function name `Jn_zeros` should be lowercase
   |
11 | def Jn_zeros(n, k):
   |     ^^^^^^^^ N802
12 |     zerosj = np.zeros((n, k), dtype="float32")
13 |     zerosj[0] = np.arange(1, k + 1) * np.pi
   |

geom3d\models\DimeNet_utils.py:11:5: D103 Missing docstring in public function
   |
11 | def Jn_zeros(n, k):
   |     ^^^^^^^^ D103
12 |     zerosj = np.zeros((n, k), dtype="float32")
13 |     zerosj[0] = np.arange(1, k + 1) * np.pi
   |

geom3d\models\DimeNet_utils.py:26:5: D103 Missing docstring in public function
   |
26 | def spherical_bessel_formulas(n):
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ D103
27 |     x = sym.symbols("x")
   |

geom3d\models\DimeNet_utils.py:38:5: D103 Missing docstring in public function
   |
38 | def bessel_basis(n, k):
   |     ^^^^^^^^^^^^ D103
39 |     zeros = Jn_zeros(n, k)
40 |     normalizer = []
   |

geom3d\models\DimeNet_utils.py:63:5: D103 Missing docstring in public function
   |
63 | def sph_harm_prefactor(k, m):
   |     ^^^^^^^^^^^^^^^^^^ D103
64 |     return (
65 |         (2 * k + 1)
   |

geom3d\models\DimeNet_utils.py:71:5: D103 Missing docstring in public function
   |
71 | def associated_legendre_polynomials(k, zero_m_only=True):
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
72 |     z = sym.symbols("z")
73 |     P_l_m = [[0] * (j + 1) for j in range(k)]
   |

geom3d\models\DimeNet_utils.py:71:40: FBT002 Boolean default positional argument in function definition
   |
71 | def associated_legendre_polynomials(k, zero_m_only=True):
   |                                        ^^^^^^^^^^^ FBT002
72 |     z = sym.symbols("z")
73 |     P_l_m = [[0] * (j + 1) for j in range(k)]
   |

geom3d\models\DimeNet_utils.py:73:5: N806 Variable `P_l_m` in function should be lowercase
   |
71 | def associated_legendre_polynomials(k, zero_m_only=True):
72 |     z = sym.symbols("z")
73 |     P_l_m = [[0] * (j + 1) for j in range(k)]
   |     ^^^^^ N806
74 | 
75 |     P_l_m[0][0] = 1
   |

geom3d\models\DimeNet_utils.py:100:5: C901 `real_sph_harm` is too complex (16 > 10)
    |
100 | def real_sph_harm(k, zero_m_only=True, spherical_coordinates=True):
    |     ^^^^^^^^^^^^^ C901
101 |     if not zero_m_only:
102 |         S_m = [0]
    |

geom3d\models\DimeNet_utils.py:100:5: PLR0912 Too many branches (15 > 12)
    |
100 | def real_sph_harm(k, zero_m_only=True, spherical_coordinates=True):
    |     ^^^^^^^^^^^^^ PLR0912
101 |     if not zero_m_only:
102 |         S_m = [0]
    |

geom3d\models\DimeNet_utils.py:100:5: D103 Missing docstring in public function
    |
100 | def real_sph_harm(k, zero_m_only=True, spherical_coordinates=True):
    |     ^^^^^^^^^^^^^ D103
101 |     if not zero_m_only:
102 |         S_m = [0]
    |

geom3d\models\DimeNet_utils.py:100:22: FBT002 Boolean default positional argument in function definition
    |
100 | def real_sph_harm(k, zero_m_only=True, spherical_coordinates=True):
    |                      ^^^^^^^^^^^ FBT002
101 |     if not zero_m_only:
102 |         S_m = [0]
    |

geom3d\models\DimeNet_utils.py:100:40: FBT002 Boolean default positional argument in function definition
    |
100 | def real_sph_harm(k, zero_m_only=True, spherical_coordinates=True):
    |                                        ^^^^^^^^^^^^^^^^^^^^^ FBT002
101 |     if not zero_m_only:
102 |         S_m = [0]
    |

geom3d\models\DimeNet_utils.py:102:9: N806 Variable `S_m` in function should be lowercase
    |
100 | def real_sph_harm(k, zero_m_only=True, spherical_coordinates=True):
101 |     if not zero_m_only:
102 |         S_m = [0]
    |         ^^^ N806
103 |         C_m = [1]
104 |         for i in range(1, k):
    |

geom3d\models\DimeNet_utils.py:103:9: N806 Variable `C_m` in function should be lowercase
    |
101 |     if not zero_m_only:
102 |         S_m = [0]
103 |         C_m = [1]
    |         ^^^ N806
104 |         for i in range(1, k):
105 |             x = sym.symbols("x")
    |

geom3d\models\DimeNet_utils.py:107:13: N806 Variable `S_m` in function should be lowercase
    |
105 |             x = sym.symbols("x")
106 |             y = sym.symbols("y")
107 |             S_m += [x * S_m[i - 1] + y * C_m[i - 1]]
    |             ^^^ N806
108 |             C_m += [x * C_m[i - 1] - y * S_m[i - 1]]
    |

geom3d\models\DimeNet_utils.py:108:13: N806 Variable `C_m` in function should be lowercase
    |
106 |             y = sym.symbols("y")
107 |             S_m += [x * S_m[i - 1] + y * C_m[i - 1]]
108 |             C_m += [x * C_m[i - 1] - y * S_m[i - 1]]
    |             ^^^ N806
109 | 
110 |     P_l_m = associated_legendre_polynomials(k, zero_m_only)
    |

geom3d\models\DimeNet_utils.py:110:5: N806 Variable `P_l_m` in function should be lowercase
    |
108 |             C_m += [x * C_m[i - 1] - y * S_m[i - 1]]
109 | 
110 |     P_l_m = associated_legendre_polynomials(k, zero_m_only)
    |     ^^^^^ N806
111 |     if spherical_coordinates:
112 |         theta = sym.symbols("theta")
    |

geom3d\models\DimeNet_utils.py:116:20: E721 Use `is` and `is not` for type comparisons, or `isinstance()` for isinstance checks
    |
114 |         for i in range(len(P_l_m)):
115 |             for j in range(len(P_l_m[i])):
116 |                 if type(P_l_m[i][j]) != int:
    |                    ^^^^^^^^^^^^^^^^^^^^^^^^ E721
117 |                     P_l_m[i][j] = P_l_m[i][j].subs(z, sym.cos(theta))
118 |         if not zero_m_only:
    |

geom3d\models\DimeNet_utils.py:133:5: N806 Variable `Y_func_l_m` in function should be lowercase
    |
131 |                 )
132 | 
133 |     Y_func_l_m = [["0"] * (2 * j + 1) for j in range(k)]
    |     ^^^^^^^^^^ N806
134 |     for i in range(k):
135 |         Y_func_l_m[i][0] = sym.simplify(sph_harm_prefactor(i, 0) * P_l_m[i][0])
    |

geom3d\models\EGNN.py:1:1: N999 Invalid module name: 'EGNN'
geom3d\models\EGNN.py:1:1: D100 Missing docstring in public module
geom3d\models\EGNN.py:6:5: D401 First line of docstring should be in imperative mood: "Custom PyTorch op to replicate TensorFlow's `unsorted_segment_sum`."
  |
5 | def unsorted_segment_sum(data, segment_ids, num_segments):
6 |     """Custom PyTorch op to replicate TensorFlow's `unsorted_segment_sum`."""
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
7 |     result_shape = (num_segments, data.size(1))
8 |     result = data.new_full(result_shape, 0)  # Init empty result tensor.
  |

geom3d\models\EGNN.py:14:7: N801 Class name `E_GCL` should use CapWords convention
   |
14 | class E_GCL(nn.Module):
   |       ^^^^^ N801
15 |     def __init__(
16 |         self,
   |

geom3d\models\EGNN.py:14:7: D101 Missing docstring in public class
   |
14 | class E_GCL(nn.Module):
   |       ^^^^^ D101
15 |     def __init__(
16 |         self,
   |

geom3d\models\EGNN.py:15:9: PLR0913 Too many arguments in function definition (12 > 5)
   |
14 | class E_GCL(nn.Module):
15 |     def __init__(
   |         ^^^^^^^^ PLR0913
16 |         self,
17 |         input_nf,
   |

geom3d\models\EGNN.py:15:9: D107 Missing docstring in `__init__`
   |
14 | class E_GCL(nn.Module):
15 |     def __init__(
   |         ^^^^^^^^ D107
16 |         self,
17 |         input_nf,
   |

geom3d\models\EGNN.py:22:16: B008 Do not perform function call `nn.ReLU` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   |
20 |         edges_in_d=0,
21 |         nodes_attr_dim=0,
22 |         act_fn=nn.ReLU(),
   |                ^^^^^^^^^ B008
23 |         positions_weight=1.0,
24 |         recurrent=True,
   |

geom3d\models\EGNN.py:24:9: FBT002 Boolean default positional argument in function definition
   |
22 |         act_fn=nn.ReLU(),
23 |         positions_weight=1.0,
24 |         recurrent=True,
   |         ^^^^^^^^^ FBT002
25 |         attention=False,
26 |         clamp=False,
   |

geom3d\models\EGNN.py:25:9: FBT002 Boolean default positional argument in function definition
   |
23 |         positions_weight=1.0,
24 |         recurrent=True,
25 |         attention=False,
   |         ^^^^^^^^^ FBT002
26 |         clamp=False,
27 |         norm_diff=False,
   |

geom3d\models\EGNN.py:26:9: FBT002 Boolean default positional argument in function definition
   |
24 |         recurrent=True,
25 |         attention=False,
26 |         clamp=False,
   |         ^^^^^ FBT002
27 |         norm_diff=False,
28 |         tanh=False,
   |

geom3d\models\EGNN.py:27:9: FBT002 Boolean default positional argument in function definition
   |
25 |         attention=False,
26 |         clamp=False,
27 |         norm_diff=False,
   |         ^^^^^^^^^ FBT002
28 |         tanh=False,
29 |     ):
   |

geom3d\models\EGNN.py:28:9: FBT002 Boolean default positional argument in function definition
   |
26 |         clamp=False,
27 |         norm_diff=False,
28 |         tanh=False,
   |         ^^^^ FBT002
29 |     ):
   |

geom3d\models\EGNN.py:69:9: D102 Missing docstring in public method
   |
67 |             self.att_mlp = nn.Sequential(nn.Linear(hidden_nf, 1), nn.Sigmoid())
68 | 
69 |     def edge_model(self, source, target, radial, edge_attr):
   |         ^^^^^^^^^^ D102
70 |         if edge_attr is None:  # Unused.
71 |             out = torch.cat([source, target, radial], dim=1)
   |

geom3d\models\EGNN.py:80:9: D102 Missing docstring in public method
   |
78 |         return out
79 | 
80 |     def node_model(self, x, edge_index, edge_attr, node_attr):
   |         ^^^^^^^^^^ D102
81 |         row, col = edge_index
82 |         agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0))
   |

geom3d\models\EGNN.py:92:9: D102 Missing docstring in public method
   |
90 |         return out, agg
91 | 
92 |     def positions_model(self, positions, edge_index, positions_diff, edge_feat):
   |         ^^^^^^^^^^^^^^^ D102
93 |         row, col = edge_index
94 |         trans = positions_diff * self.positions_mlp(edge_feat)
   |

geom3d\models\EGNN.py:102:9: D102 Missing docstring in public method
    |
100 |         return positions
101 | 
102 |     def positions2radial(self, edge_index, positions):
    |         ^^^^^^^^^^^^^^^^ D102
103 |         row, col = edge_index
104 |         positions_diff = positions[row] - positions[col]
    |

geom3d\models\EGNN.py:114:9: D205 1 blank line required between summary line and description
    |
113 |       def forward(self, h, positions, edge_index, node_attr=None, edge_attr=None):
114 |           """h: (N, emb)
    |  _________^
115 | |         positions: (N, 3)
116 | |         edge_index: (2, M)
117 | |         node_attr: None or (N, node_input_dim), where node_input_dim=1
118 | |         edge_attr: None or (M, edge_input_dim).
119 | |         """
    | |___________^ D205
120 |           row, col = edge_index
121 |           radial, positions_diff = self.positions2radial(
    |
    = help: Insert single blank line

geom3d\models\EGNN.py:126:9: ERA001 Found commented-out code
    |
124 |         edge_feat = self.edge_model(h[row], h[col], radial, edge_attr)  # (M, n_emb)
125 | 
126 |         # positions = self.positions_model(positions, edge_index, positions_diff, edge_feat)  # (M, 3)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
127 |         h, agg = self.node_model(
128 |             h, edge_index, edge_feat, node_attr
    |
    = help: Remove commented-out code

geom3d\models\EGNN.py:133:9: D102 Missing docstring in public method
    |
133 |     def forward_with_gathered_index(self, h, positions, edge_index, node_attr, periodic_index_mapping):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
134 |         row, col = edge_index
135 |         radial, positions_diff = self.positions2radial(
    |

geom3d\models\EGNN.py:141:79: F821 Undefined name `edge_attr`
    |
139 |         gathered_row = periodic_index_mapping[row]
140 |         gathered_col = periodic_index_mapping[col]
141 |         edge_feat = self.edge_model(h[gathered_row], h[gathered_col], radial, edge_attr)  # (M, n_emb)
    |                                                                               ^^^^^^^^^ F821
142 | 
143 |         h, agg = self.node_model(
    |

geom3d\models\EGNN.py:146:30: F821 Undefined name `edge_attr`
    |
144 |             h, edge_index, edge_feat, node_attr
145 |         )  # (N, emb_dim), (N, emb_dim*2 + input_node_dim)
146 |         return h, positions, edge_attr
    |                              ^^^^^^^^^ F821
    |

geom3d\models\EGNN.py:150:7: D101 Missing docstring in public class
    |
150 | class EGNN(nn.Module):
    |       ^^^^ D101
151 |     def __init__(
152 |         self,
    |

geom3d\models\EGNN.py:151:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
150 | class EGNN(nn.Module):
151 |     def __init__(
    |         ^^^^^^^^ PLR0913
152 |         self,
153 |         in_node_nf,
    |

geom3d\models\EGNN.py:151:9: D107 Missing docstring in `__init__`
    |
150 | class EGNN(nn.Module):
151 |     def __init__(
    |         ^^^^^^^^ D107
152 |         self,
153 |         in_node_nf,
    |

geom3d\models\EGNN.py:156:16: B008 Do not perform function call `nn.SiLU` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
    |
154 |         in_edge_nf,
155 |         hidden_nf,
156 |         act_fn=nn.SiLU(),
    |                ^^^^^^^^^ B008
157 |         n_layers=4,
158 |         positions_weight=1.0,
    |

geom3d\models\EGNN.py:159:9: FBT002 Boolean default positional argument in function definition
    |
157 |         n_layers=4,
158 |         positions_weight=1.0,
159 |         attention=True,
    |         ^^^^^^^^^ FBT002
160 |         node_attr=True,
161 |     ):
    |

geom3d\models\EGNN.py:160:9: FBT002 Boolean default positional argument in function definition
    |
158 |         positions_weight=1.0,
159 |         attention=True,
160 |         node_attr=True,
    |         ^^^^^^^^^ FBT002
161 |     ):
162 |         super().__init__()
    |

geom3d\models\EGNN.py:192:9: D102 Missing docstring in public method
    |
192 |     def forward(self, x, positions, edge_index, edge_attr=None):
    |         ^^^^^^^ D102
193 |         h = self.embedding(x)
    |

geom3d\models\EGNN.py:207:9: D102 Missing docstring in public method
    |
205 |         return self.node_dec(h)
206 | 
207 |     def forward_with_gathered_index(self, gathered_x, positions, edge_index, periodic_index_mapping):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
208 |         h = self.embedding(gathered_x)
    |

geom3d\models\EGNN.py:215:13: ERA001 Found commented-out code
    |
213 |                     h, positions, edge_index, node_attr=gathered_x, periodic_index_mapping=periodic_index_mapping
214 |                 )
215 |             # else:
    |             ^^^^^^^ ERA001
216 |             #     h, _, _ = self._modules["gcl_%d" % i](
217 |             #         h, positions, edge_index, node_attr=None, edge_attr=edge_attr
    |
    = help: Remove commented-out code

geom3d\models\EGNN.py:216:13: ERA001 Found commented-out code
    |
214 |                 )
215 |             # else:
216 |             #     h, _, _ = self._modules["gcl_%d" % i](
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
217 |             #         h, positions, edge_index, node_attr=None, edge_attr=edge_attr
218 |             #     )
    |
    = help: Remove commented-out code

geom3d\models\EGNN.py:218:13: ERA001 Found commented-out code
    |
216 |             #     h, _, _ = self._modules["gcl_%d" % i](
217 |             #         h, positions, edge_index, node_attr=None, edge_attr=edge_attr
218 |             #     )
    |             ^^^^^^^ ERA001
219 | 
220 |         return self.node_dec(h)
    |
    = help: Remove commented-out code

geom3d\models\ENN.py:1:1: N999 Invalid module name: 'ENN'
geom3d\models\ENN.py:2:1: F403 `from collections import *` used; unable to detect undefined names
  |
1 | """credit to https://github.com/chao1224/BioChemGNN_Dense/blob/master/src/models/enn.py."""
2 | from collections import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^ F403
3 | 
4 | import torch
  |

geom3d\models\ENN.py:12:7: D101 Missing docstring in public class
   |
12 | class GraphSoftmax(nn.Module):
   |       ^^^^^^^^^^^^ D101
13 |     eps = 1e-10
   |

geom3d\models\ENN.py:15:9: D102 Missing docstring in public method
   |
13 |     eps = 1e-10
14 | 
15 |     def forward(self, batch, input):
   |         ^^^^^^^ D102
16 |         batch_size = torch.max(batch).item() + 1
17 |         x = input - scatter_max(input, batch, dim=0, dim_size=batch_size)[0][batch]
   |

geom3d\models\ENN.py:15:30: A002 Argument `input` is shadowing a Python builtin
   |
13 |     eps = 1e-10
14 | 
15 |     def forward(self, batch, input):
   |                              ^^^^^ A002
16 |         batch_size = torch.max(batch).item() + 1
17 |         x = input - scatter_max(input, batch, dim=0, dim_size=batch_size)[0][batch]
   |

geom3d\models\ENN.py:24:7: D101 Missing docstring in public class
   |
24 | class Set2Set(nn.Module):
   |       ^^^^^^^ D101
25 |     def __init__(self, input_dim, processing_steps, num_layers):
26 |         super().__init__()
   |

geom3d\models\ENN.py:25:9: D107 Missing docstring in `__init__`
   |
24 | class Set2Set(nn.Module):
25 |     def __init__(self, input_dim, processing_steps, num_layers):
   |         ^^^^^^^^ D107
26 |         super().__init__()
27 |         self.input_dim = input_dim
   |

geom3d\models\ENN.py:34:9: D102 Missing docstring in public method
   |
32 |         self.softmax = GraphSoftmax()
33 | 
34 |     def forward(self, x, batch):
   |         ^^^^^^^ D102
35 |         batch_size = torch.max(batch).item() + 1
   |

geom3d\models\ENN.py:53:7: N801 Class name `ENN_S2S` should use CapWords convention
   |
53 | class ENN_S2S(nn.Module):
   |       ^^^^^^^ N801
54 |     def __init__(
55 |             self, hidden_dim, gru_layer_num, enn_layer_num,
   |

geom3d\models\ENN.py:53:7: D101 Missing docstring in public class
   |
53 | class ENN_S2S(nn.Module):
   |       ^^^^^^^ D101
54 |     def __init__(
55 |             self, hidden_dim, gru_layer_num, enn_layer_num,
   |

geom3d\models\ENN.py:54:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
53 | class ENN_S2S(nn.Module):
54 |     def __init__(
   |         ^^^^^^^^ PLR0913
55 |             self, hidden_dim, gru_layer_num, enn_layer_num,
56 |             set2set_processing_steps, set2set_num_layers, output_dim
   |

geom3d\models\ENN.py:54:9: D107 Missing docstring in `__init__`
   |
53 | class ENN_S2S(nn.Module):
54 |     def __init__(
   |         ^^^^^^^^ D107
55 |             self, hidden_dim, gru_layer_num, enn_layer_num,
56 |             set2set_processing_steps, set2set_num_layers, output_dim
   |

geom3d\models\ENN.py:73:9: D102 Missing docstring in public method
   |
71 |         self.fc_layer = nn.Linear(self.hidden_dim*2, self.output_dim)
72 | 
73 |     def forward(self, data):
   |         ^^^^^^^ D102
74 |         x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr
75 |         batch = data.batch
   |

geom3d\models\Equiformer\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\Equiformer\__init__.py:2:5: F401 `.equiformer_type_0.EquiformerEnergy` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .equiformer_type_0 import (
2 |     EquiformerEnergy,
  |     ^^^^^^^^^^^^^^^^ F401
3 | )
  |
  = help: Use an explicit re-export: `EquiformerEnergy as EquiformerEnergy`

geom3d\models\Equiformer\__init__.py:15:41: F401 `.equiformer_type_0_periodic.EquiformerEnergyPeriodic` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
13 | # # Equiformer_nonlinear_bessel_l3_energy_force,
14 | # # Equiformer_nonlinear_bessel_l3_e3_energy_force,
15 | from .equiformer_type_0_periodic import EquiformerEnergyPeriodic
   |                                         ^^^^^^^^^^^^^^^^^^^^^^^^ F401
16 | 
17 | # Equiformer_l2,
   |
   = help: Use an explicit re-export: `EquiformerEnergyPeriodic as EquiformerEnergyPeriodic`

geom3d\models\Equiformer\__init__.py:24:5: F401 `.equiformer_type_01.EquiformerEnergyForce` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
22 | # Equiformer_nonlinear_bessel_l2_drop00,
23 | from .equiformer_type_01 import (
24 |     EquiformerEnergyForce,
   |     ^^^^^^^^^^^^^^^^^^^^^ F401
25 | )
   |
   = help: Use an explicit re-export: `EquiformerEnergyForce as EquiformerEnergyForce`

geom3d\models\Equiformer\drop.py:1:1: D205 1 blank line required between summary line and description
  |
1 | / """Add `extra_repr` into DropPath implemented by timm
2 | | for displaying more info.
3 | | """
  | |___^ D205
  |
  = help: Insert single blank line

geom3d\models\Equiformer\drop.py:7:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
6 | import torch
7 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
8 | from e3nn import o3
9 | from torch import nn
  |

geom3d\models\Equiformer\drop.py:12:41: FBT001 Boolean-typed positional argument in function definition
   |
12 | def drop_path(x, drop_prob: float = 0., training: bool = False):
   |                                         ^^^^^^^^ FBT001
13 |     """Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).
14 |     This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,
   |

geom3d\models\Equiformer\drop.py:12:41: FBT002 Boolean default positional argument in function definition
   |
12 | def drop_path(x, drop_prob: float = 0., training: bool = False):
   |                                         ^^^^^^^^ FBT002
13 |     """Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).
14 |     This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,
   |

geom3d\models\Equiformer\drop.py:13:5: D205 1 blank line required between summary line and description
   |
12 |   def drop_path(x, drop_prob: float = 0., training: bool = False):
13 |       """Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).
   |  _____^
14 | |     This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,
15 | |     the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...
16 | |     See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for
17 | |     changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use
18 | |     'survival rate' as the argument.
19 | |     """
   | |_______^ D205
20 |       if drop_prob == 0. or not training:
21 |           return x
   |
   = help: Insert single blank line

geom3d\models\Equiformer\drop.py:32:9: D107 Missing docstring in `__init__`
   |
30 |     """Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks)."""
31 | 
32 |     def __init__(self, drop_prob=None):
   |         ^^^^^^^^ D107
33 |         super().__init__()
34 |         self.drop_prob = drop_prob
   |

geom3d\models\Equiformer\drop.py:36:9: D102 Missing docstring in public method
   |
34 |         self.drop_prob = drop_prob
35 | 
36 |     def forward(self, x):
   |         ^^^^^^^ D102
37 |         return drop_path(x, self.drop_prob, self.training)
   |

geom3d\models\Equiformer\drop.py:39:9: D102 Missing docstring in public method
   |
37 |         return drop_path(x, self.drop_prob, self.training)
38 | 
39 |     def extra_repr(self):
   |         ^^^^^^^^^^ D102
40 |         return f"drop_prob={self.drop_prob}"
   |

geom3d\models\Equiformer\drop.py:46:9: D107 Missing docstring in `__init__`
   |
44 |     """Consider batch for graph data when dropping paths."""
45 | 
46 |     def __init__(self, drop_prob=None):
   |         ^^^^^^^^ D107
47 |         super().__init__()
48 |         self.drop_prob = drop_prob
   |

geom3d\models\Equiformer\drop.py:51:9: D102 Missing docstring in public method
   |
51 |     def forward(self, x, batch):
   |         ^^^^^^^ D102
52 |         batch_size = batch.max() + 1
53 |         shape = (batch_size,) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets
   |

geom3d\models\Equiformer\drop.py:59:9: D102 Missing docstring in public method
   |
59 |     def extra_repr(self):
   |         ^^^^^^^^^^ D102
60 |         return f"drop_prob={self.drop_prob}"
   |

geom3d\models\Equiformer\drop.py:64:7: D101 Missing docstring in public class
   |
64 | class EquivariantDropout(nn.Module):
   |       ^^^^^^^^^^^^^^^^^^ D101
65 |     def __init__(self, irreps, drop_prob):
66 |         super().__init__()
   |

geom3d\models\Equiformer\drop.py:65:9: D107 Missing docstring in `__init__`
   |
64 | class EquivariantDropout(nn.Module):
65 |     def __init__(self, irreps, drop_prob):
   |         ^^^^^^^^ D107
66 |         super().__init__()
67 |         self.irreps = irreps
   |

geom3d\models\Equiformer\drop.py:70:49: FBT003 Boolean positional value in function call
   |
68 |         self.num_irreps = irreps.num_irreps
69 |         self.drop_prob = drop_prob
70 |         self.drop = torch.nn.Dropout(drop_prob, True)
   |                                                 ^^^^ FBT003
71 |         self.mul = o3.ElementwiseTensorProduct(irreps,
72 |             o3.Irreps(f"{self.num_irreps}x0e"))
   |

geom3d\models\Equiformer\drop.py:75:9: D102 Missing docstring in public method
   |
75 |     def forward(self, x):
   |         ^^^^^^^ D102
76 |         if not self.training or self.drop_prob == 0.0:
77 |             return x
   |

geom3d\models\Equiformer\drop.py:84:7: D101 Missing docstring in public class
   |
84 | class EquivariantScalarsDropout(nn.Module):
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^ D101
85 |     def __init__(self, irreps, drop_prob):
86 |         super().__init__()
   |

geom3d\models\Equiformer\drop.py:85:9: D107 Missing docstring in `__init__`
   |
84 | class EquivariantScalarsDropout(nn.Module):
85 |     def __init__(self, irreps, drop_prob):
   |         ^^^^^^^^ D107
86 |         super().__init__()
87 |         self.irreps = irreps
   |

geom3d\models\Equiformer\drop.py:91:9: D102 Missing docstring in public method
   |
91 |     def forward(self, x):
   |         ^^^^^^^ D102
92 |         if not self.training or self.drop_prob == 0.0:
93 |             return x
   |

geom3d\models\Equiformer\drop.py:105:9: D102 Missing docstring in public method
    |
105 |     def extra_repr(self):
    |         ^^^^^^^^^^ D102
106 |         return f"irreps={self.irreps}, drop_prob={self.drop_prob}"
    |

geom3d\models\Equiformer\equiformer_type_0.py:1:1: D100 Missing docstring in public module
geom3d\models\Equiformer\equiformer_type_0.py:38:5: D103 Missing docstring in public function
   |
38 | def get_norm_layer(norm_type):
   |     ^^^^^^^^^^^^^^ D103
39 |     if norm_type == "graph":
40 |         return EquivariantGraphNorm
   |

geom3d\models\Equiformer\equiformer_type_0.py:41:5: RET505 Unnecessary `elif` after `return` statement
   |
39 |     if norm_type == "graph":
40 |         return EquivariantGraphNorm
41 |     elif norm_type == "instance":
   |     ^^^^ RET505
42 |         return EquivariantInstanceNorm
43 |     elif norm_type == "layer":
   |
   = help: Remove unnecessary `elif`

geom3d\models\Equiformer\equiformer_type_0.py:54:7: D101 Missing docstring in public class
   |
54 | class SmoothLeakyReLU(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^ D101
55 |     def __init__(self, negative_slope=0.2):
56 |         super().__init__()
   |

geom3d\models\Equiformer\equiformer_type_0.py:55:9: D107 Missing docstring in `__init__`
   |
54 | class SmoothLeakyReLU(torch.nn.Module):
55 |     def __init__(self, negative_slope=0.2):
   |         ^^^^^^^^ D107
56 |         super().__init__()
57 |         self.alpha = negative_slope
   |

geom3d\models\Equiformer\equiformer_type_0.py:60:9: D102 Missing docstring in public method
   |
60 |     def forward(self, x):
   |         ^^^^^^^ D102
61 |         x1 = ((1 + self.alpha) / 2) * x
62 |         x2 = ((1 - self.alpha) / 2) * x * (2 * torch.sigmoid(x) - 1)
   |

geom3d\models\Equiformer\equiformer_type_0.py:66:9: D102 Missing docstring in public method
   |
66 |     def extra_repr(self):
   |         ^^^^^^^^^^ D102
67 |         return f"negative_slope={self.alpha}"
   |

geom3d\models\Equiformer\equiformer_type_0.py:70:5: D103 Missing docstring in public function
   |
70 | def get_mul_0(irreps):
   |     ^^^^^^^^^ D103
71 |     mul_0 = 0
72 |     for mul, ir in irreps:
   |

geom3d\models\Equiformer\equiformer_type_0.py:78:7: D101 Missing docstring in public class
   |
78 | class FullyConnectedTensorProductRescaleNorm(FullyConnectedTensorProductRescale):
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
79 | 
80 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
   |

geom3d\models\Equiformer\equiformer_type_0.py:80:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
78 | class FullyConnectedTensorProductRescaleNorm(FullyConnectedTensorProductRescale):
79 | 
80 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
   |         ^^^^^^^^ PLR0913
81 |         bias=True, rescale=True,
82 |         internal_weights=None, shared_weights=None,
   |

geom3d\models\Equiformer\equiformer_type_0.py:80:9: D107 Missing docstring in `__init__`
   |
78 | class FullyConnectedTensorProductRescaleNorm(FullyConnectedTensorProductRescale):
79 | 
80 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
   |         ^^^^^^^^ D107
81 |         bias=True, rescale=True,
82 |         internal_weights=None, shared_weights=None,
   |

geom3d\models\Equiformer\equiformer_type_0.py:81:9: FBT002 Boolean default positional argument in function definition
   |
80 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
81 |         bias=True, rescale=True,
   |         ^^^^ FBT002
82 |         internal_weights=None, shared_weights=None,
83 |         normalization=None, norm_layer="graph"):
   |

geom3d\models\Equiformer\equiformer_type_0.py:81:20: FBT002 Boolean default positional argument in function definition
   |
80 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
81 |         bias=True, rescale=True,
   |                    ^^^^^^^ FBT002
82 |         internal_weights=None, shared_weights=None,
83 |         normalization=None, norm_layer="graph"):
   |

geom3d\models\Equiformer\equiformer_type_0.py:92:9: D102 Missing docstring in public method
   |
92 |     def forward(self, x, y, batch, weight=None):
   |         ^^^^^^^ D102
93 |         out = self.forward_tp_rescale_bias(x, y, weight)
94 |         return self.norm(out, batch=batch)
   |

geom3d\models\Equiformer\equiformer_type_0.py:97:7: D101 Missing docstring in public class
   |
97 | class FullyConnectedTensorProductRescaleNormSwishGate(FullyConnectedTensorProductRescaleNorm):
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
98 | 
99 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
   |

geom3d\models\Equiformer\equiformer_type_0.py:99:9: PLR0913 Too many arguments in function definition (9 > 5)
    |
 97 | class FullyConnectedTensorProductRescaleNormSwishGate(FullyConnectedTensorProductRescaleNorm):
 98 | 
 99 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
    |         ^^^^^^^^ PLR0913
100 |         bias=True, rescale=True,
101 |         internal_weights=None, shared_weights=None,
    |

geom3d\models\Equiformer\equiformer_type_0.py:99:9: D107 Missing docstring in `__init__`
    |
 97 | class FullyConnectedTensorProductRescaleNormSwishGate(FullyConnectedTensorProductRescaleNorm):
 98 | 
 99 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
    |         ^^^^^^^^ D107
100 |         bias=True, rescale=True,
101 |         internal_weights=None, shared_weights=None,
    |

geom3d\models\Equiformer\equiformer_type_0.py:100:9: FBT002 Boolean default positional argument in function definition
    |
 99 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
100 |         bias=True, rescale=True,
    |         ^^^^ FBT002
101 |         internal_weights=None, shared_weights=None,
102 |         normalization=None, norm_layer="graph"):
    |

geom3d\models\Equiformer\equiformer_type_0.py:100:20: FBT002 Boolean default positional argument in function definition
    |
 99 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
100 |         bias=True, rescale=True,
    |                    ^^^^^^^ FBT002
101 |         internal_weights=None, shared_weights=None,
102 |         normalization=None, norm_layer="graph"):
    |

geom3d\models\Equiformer\equiformer_type_0.py:120:9: D102 Missing docstring in public method
    |
120 |     def forward(self, x, y, batch, weight=None):
    |         ^^^^^^^ D102
121 |         out = self.forward_tp_rescale_bias(x, y, weight)
122 |         out = self.norm(out, batch=batch)
    |

geom3d\models\Equiformer\equiformer_type_0.py:126:7: D101 Missing docstring in public class
    |
126 | class FullyConnectedTensorProductRescaleSwishGate(FullyConnectedTensorProductRescale):
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
127 | 
128 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
    |

geom3d\models\Equiformer\equiformer_type_0.py:128:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
126 | class FullyConnectedTensorProductRescaleSwishGate(FullyConnectedTensorProductRescale):
127 | 
128 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
    |         ^^^^^^^^ PLR0913
129 |         bias=True, rescale=True,
130 |         internal_weights=None, shared_weights=None,
    |

geom3d\models\Equiformer\equiformer_type_0.py:128:9: D107 Missing docstring in `__init__`
    |
126 | class FullyConnectedTensorProductRescaleSwishGate(FullyConnectedTensorProductRescale):
127 | 
128 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
    |         ^^^^^^^^ D107
129 |         bias=True, rescale=True,
130 |         internal_weights=None, shared_weights=None,
    |

geom3d\models\Equiformer\equiformer_type_0.py:129:9: FBT002 Boolean default positional argument in function definition
    |
128 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
129 |         bias=True, rescale=True,
    |         ^^^^ FBT002
130 |         internal_weights=None, shared_weights=None,
131 |         normalization=None):
    |

geom3d\models\Equiformer\equiformer_type_0.py:129:20: FBT002 Boolean default positional argument in function definition
    |
128 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
129 |         bias=True, rescale=True,
    |                    ^^^^^^^ FBT002
130 |         internal_weights=None, shared_weights=None,
131 |         normalization=None):
    |

geom3d\models\Equiformer\equiformer_type_0.py:149:9: D102 Missing docstring in public method
    |
149 |     def forward(self, x, y, weight=None):
    |         ^^^^^^^ D102
150 |         out = self.forward_tp_rescale_bias(x, y, weight)
151 |         return self.gate(out)
    |

geom3d\models\Equiformer\equiformer_type_0.py:154:5: N802 Function name `DepthwiseTensorProduct` should be lowercase
    |
154 | def DepthwiseTensorProduct(irreps_node_input, irreps_edge_attr, irreps_node_output,
    |     ^^^^^^^^^^^^^^^^^^^^^^ N802
155 |     internal_weights=False, bias=True):
156 |     """The irreps of output is pre-determined.
    |

geom3d\models\Equiformer\equiformer_type_0.py:155:5: FBT002 Boolean default positional argument in function definition
    |
154 | def DepthwiseTensorProduct(irreps_node_input, irreps_edge_attr, irreps_node_output,
155 |     internal_weights=False, bias=True):
    |     ^^^^^^^^^^^^^^^^ FBT002
156 |     """The irreps of output is pre-determined.
157 |     `irreps_node_output` is used to get certain types of vectors.
    |

geom3d\models\Equiformer\equiformer_type_0.py:155:29: FBT002 Boolean default positional argument in function definition
    |
154 | def DepthwiseTensorProduct(irreps_node_input, irreps_edge_attr, irreps_node_output,
155 |     internal_weights=False, bias=True):
    |                             ^^^^ FBT002
156 |     """The irreps of output is pre-determined.
157 |     `irreps_node_output` is used to get certain types of vectors.
    |

geom3d\models\Equiformer\equiformer_type_0.py:156:5: D205 1 blank line required between summary line and description
    |
154 |   def DepthwiseTensorProduct(irreps_node_input, irreps_edge_attr, irreps_node_output,
155 |       internal_weights=False, bias=True):
156 |       """The irreps of output is pre-determined.
    |  _____^
157 | |     `irreps_node_output` is used to get certain types of vectors.
158 | |     """
    | |_______^ D205
159 |       irreps_output = []
160 |       instructions = []
    |
    = help: Insert single blank line

geom3d\models\Equiformer\equiformer_type_0.py:156:5: D401 First line of docstring should be in imperative mood: "The irreps of output is pre-determined."
    |
154 |   def DepthwiseTensorProduct(irreps_node_input, irreps_edge_attr, irreps_node_output,
155 |       internal_weights=False, bias=True):
156 |       """The irreps of output is pre-determined.
    |  _____^
157 | |     `irreps_node_output` is used to get certain types of vectors.
158 | |     """
    | |_______^ D401
159 |       irreps_output = []
160 |       instructions = []
    |

geom3d\models\Equiformer\equiformer_type_0.py:184:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
182 |     """Use separable FCTP for spatial convolution."""
183 | 
184 |     def __init__(self, irreps_node_input, irreps_edge_attr, irreps_node_output,
    |         ^^^^^^^^ PLR0913
185 |         fc_neurons, use_activation=False, norm_layer="graph",
186 |         internal_weights=False):
    |

geom3d\models\Equiformer\equiformer_type_0.py:184:9: D107 Missing docstring in `__init__`
    |
182 |     """Use separable FCTP for spatial convolution."""
183 | 
184 |     def __init__(self, irreps_node_input, irreps_edge_attr, irreps_node_output,
    |         ^^^^^^^^ D107
185 |         fc_neurons, use_activation=False, norm_layer="graph",
186 |         internal_weights=False):
    |

geom3d\models\Equiformer\equiformer_type_0.py:185:21: FBT002 Boolean default positional argument in function definition
    |
184 |     def __init__(self, irreps_node_input, irreps_edge_attr, irreps_node_output,
185 |         fc_neurons, use_activation=False, norm_layer="graph",
    |                     ^^^^^^^^^^^^^^ FBT002
186 |         internal_weights=False):
    |

geom3d\models\Equiformer\equiformer_type_0.py:186:9: FBT002 Boolean default positional argument in function definition
    |
184 |     def __init__(self, irreps_node_input, irreps_edge_attr, irreps_node_output,
185 |         fc_neurons, use_activation=False, norm_layer="graph",
186 |         internal_weights=False):
    |         ^^^^^^^^^^^^^^^^ FBT002
187 | 
188 |         super().__init__()
    |

geom3d\models\Equiformer\equiformer_type_0.py:200:18: A001 Variable `slice` is shadowing a Python builtin
    |
198 |         if fc_neurons is not None:
199 |             self.dtp_rad = RadialProfile([*fc_neurons, self.dtp.tp.weight_numel])
200 |             for (slice, slice_sqrt_k) in self.dtp.slices_sqrt_k.values():
    |                  ^^^^^ A001
201 |                 self.dtp_rad.net[-1].weight.data[slice, :] *= slice_sqrt_k
202 |                 self.dtp_rad.offset.data[slice] *= slice_sqrt_k
    |

geom3d\models\Equiformer\equiformer_type_0.py:228:72: ANN003 Missing type annotation for `**kwargs`
    |
228 |     def forward(self, node_input, edge_attr, edge_scalars, batch=None, **kwargs):
    |                                                                        ^^^^^^^^ ANN003
229 |         """Depthwise TP: `node_input` TP `edge_attr`, with TP parametrized by
230 |         self.dtp_rad(`edge_scalars`).
    |

geom3d\models\Equiformer\equiformer_type_0.py:228:74: ARG002 Unused method argument: `kwargs`
    |
228 |     def forward(self, node_input, edge_attr, edge_scalars, batch=None, **kwargs):
    |                                                                          ^^^^^^ ARG002
229 |         """Depthwise TP: `node_input` TP `edge_attr`, with TP parametrized by
230 |         self.dtp_rad(`edge_scalars`).
    |

geom3d\models\Equiformer\equiformer_type_0.py:229:9: D205 1 blank line required between summary line and description
    |
228 |       def forward(self, node_input, edge_attr, edge_scalars, batch=None, **kwargs):
229 |           """Depthwise TP: `node_input` TP `edge_attr`, with TP parametrized by
    |  _________^
230 | |         self.dtp_rad(`edge_scalars`).
231 | |         """
    | |___________^ D205
232 |           weight = None
233 |           if self.dtp_rad is not None and edge_scalars is not None:
    |
    = help: Insert single blank line

geom3d\models\Equiformer\equiformer_type_0.py:246:5: D205 1 blank line required between summary line and description
    |
244 |   @compile_mode("script")
245 |   class Vec2AttnHeads(torch.nn.Module):
246 |       """Reshape vectors of shape [N, irreps_mid] to vectors of shape
    |  _____^
247 | |     [N, num_heads, irreps_head].
248 | |     """
    | |_______^ D205
249 |   
250 |       def __init__(self, irreps_head, num_heads):
    |
    = help: Insert single blank line

geom3d\models\Equiformer\equiformer_type_0.py:250:9: D107 Missing docstring in `__init__`
    |
248 |     """
249 | 
250 |     def __init__(self, irreps_head, num_heads):
    |         ^^^^^^^^ D107
251 |         super().__init__()
252 |         self.num_heads = num_heads
    |

geom3d\models\Equiformer\equiformer_type_0.py:265:9: D102 Missing docstring in public method
    |
265 |     def forward(self, x):
    |         ^^^^^^^ D102
266 |         N, _ = x.shape
267 |         out = []
    |

geom3d\models\Equiformer\equiformer_type_0.py:266:9: N806 Variable `N` in function should be lowercase
    |
265 |     def forward(self, x):
266 |         N, _ = x.shape
    |         ^ N806
267 |         out = []
268 |         for _ir_idx, (start_idx, end_idx) in enumerate(self.mid_in_indices):
    |

geom3d\models\Equiformer\equiformer_type_0.py:275:9: D105 Missing docstring in magic method
    |
275 |     def __repr__(self):
    |         ^^^^^^^^ D105
276 |         return f"{self.__class__.__name__}(irreps_head={self.irreps_head}, num_heads={self.num_heads})"
    |

geom3d\models\Equiformer\equiformer_type_0.py:281:5: D205 1 blank line required between summary line and description
    |
279 |   @compile_mode("script")
280 |   class AttnHeads2Vec(torch.nn.Module):
281 |       """Convert vectors of shape [N, num_heads, irreps_head] into
    |  _____^
282 | |     vectors of shape [N, irreps_head * num_heads].
283 | |     """
    | |_______^ D205
284 |   
285 |       def __init__(self, irreps_head):
    |
    = help: Insert single blank line

geom3d\models\Equiformer\equiformer_type_0.py:285:9: D107 Missing docstring in `__init__`
    |
283 |     """
284 | 
285 |     def __init__(self, irreps_head):
    |         ^^^^^^^^ D107
286 |         super().__init__()
287 |         self.irreps_head = irreps_head
    |

geom3d\models\Equiformer\equiformer_type_0.py:295:9: D102 Missing docstring in public method
    |
295 |     def forward(self, x):
    |         ^^^^^^^ D102
296 |         N, _, _ = x.shape
297 |         out = []
    |

geom3d\models\Equiformer\equiformer_type_0.py:296:9: N806 Variable `N` in function should be lowercase
    |
295 |     def forward(self, x):
296 |         N, _, _ = x.shape
    |         ^ N806
297 |         out = []
298 |         for _ir_idx, (start_idx, end_idx) in enumerate(self.head_indices):
    |

geom3d\models\Equiformer\equiformer_type_0.py:305:9: D105 Missing docstring in magic method
    |
305 |     def __repr__(self):
    |         ^^^^^^^^ D105
306 |         return f"{self.__class__.__name__}(irreps_head={self.irreps_head})"
    |

geom3d\models\Equiformer\equiformer_type_0.py:309:7: D101 Missing docstring in public class
    |
309 | class ConcatIrrepsTensor(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^^^ D101
310 | 
311 |     def __init__(self, irreps_1, irreps_2):
    |

geom3d\models\Equiformer\equiformer_type_0.py:311:9: D107 Missing docstring in `__init__`
    |
309 | class ConcatIrrepsTensor(torch.nn.Module):
310 | 
311 |     def __init__(self, irreps_1, irreps_2):
    |         ^^^^^^^^ D107
312 |         super().__init__()
313 |         assert irreps_1 == irreps_1.simplify()
    |

geom3d\models\Equiformer\equiformer_type_0.py:313:9: S101 Use of `assert` detected
    |
311 |     def __init__(self, irreps_1, irreps_2):
312 |         super().__init__()
313 |         assert irreps_1 == irreps_1.simplify()
    |         ^^^^^^ S101
314 |         self.check_sorted(irreps_1)
315 |         assert irreps_2 == irreps_2.simplify()
    |

geom3d\models\Equiformer\equiformer_type_0.py:315:9: S101 Use of `assert` detected
    |
313 |         assert irreps_1 == irreps_1.simplify()
314 |         self.check_sorted(irreps_1)
315 |         assert irreps_2 == irreps_2.simplify()
    |         ^^^^^^ S101
316 |         self.check_sorted(irreps_2)
    |

geom3d\models\Equiformer\equiformer_type_0.py:347:9: D102 Missing docstring in public method
    |
347 |     def get_irreps_dim(self, irreps):
    |         ^^^^^^^^^^^^^^ D102
348 |         muls = []
349 |         for mul, ir in irreps:
    |

geom3d\models\Equiformer\equiformer_type_0.py:354:9: D102 Missing docstring in public method
    |
354 |     def check_sorted(self, irreps):
    |         ^^^^^^^^^^^^ D102
355 |         lmax = None
356 |         p = None
    |

geom3d\models\Equiformer\equiformer_type_0.py:363:17: S101 Use of `assert` detected
    |
361 |                 continue
362 |             if ir.l == lmax:
363 |                 assert p < ir.p, f"Parity order error: {irreps}"
    |                 ^^^^^^ S101
364 |             assert lmax <= ir.l
    |

geom3d\models\Equiformer\equiformer_type_0.py:364:13: S101 Use of `assert` detected
    |
362 |             if ir.l == lmax:
363 |                 assert p < ir.p, f"Parity order error: {irreps}"
364 |             assert lmax <= ir.l
    |             ^^^^^^ S101
    |

geom3d\models\Equiformer\equiformer_type_0.py:367:9: D102 Missing docstring in public method
    |
367 |     def get_ir_index(self, ir, irreps):
    |         ^^^^^^^^^^^^ D102
368 |         for index, (_, irrep) in enumerate(irreps):
369 |             if irrep == ir:
    |

geom3d\models\Equiformer\equiformer_type_0.py:374:9: D102 Missing docstring in public method
    |
374 |     def forward(self, feature_1, feature_2):
    |         ^^^^^^^ D102
375 | 
376 |         output = []
    |

geom3d\models\Equiformer\equiformer_type_0.py:386:9: D105 Missing docstring in magic method
    |
386 |     def __repr__(self):
    |         ^^^^^^^^ D105
387 |         return f"{self.__class__.__name__}(irreps_1={self.irreps_1}, irreps_2={self.irreps_2})"
    |

geom3d\models\Equiformer\equiformer_type_0.py:392:5: D205 1 blank line required between summary line and description
    |
390 |   @compile_mode("script")
391 |   class GraphAttention(torch.nn.Module):
392 |       """1. Message = Alpha * Value
    |  _____^
393 | |     2. Two Linear to merge src and dst -> Separable FCTP -> 0e + (0e+1e+...)
394 | |     3. 0e -> Activation -> Inner Product -> (Alpha)
395 | |     4. (0e+1e+...) -> (Value).
396 | |     """
    | |_______^ D205
397 |   
398 |       def __init__(self,
    |
    = help: Insert single blank line

geom3d\models\Equiformer\equiformer_type_0.py:398:9: PLR0913 Too many arguments in function definition (12 > 5)
    |
396 |     """
397 | 
398 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
399 |         irreps_node_input, irreps_node_attr,
400 |         irreps_edge_attr, irreps_node_output,
    |

geom3d\models\Equiformer\equiformer_type_0.py:398:9: D107 Missing docstring in `__init__`
    |
396 |     """
397 | 
398 |     def __init__(self,
    |         ^^^^^^^^ D107
399 |         irreps_node_input, irreps_node_attr,
400 |         irreps_edge_attr, irreps_node_output,
    |

geom3d\models\Equiformer\equiformer_type_0.py:403:9: FBT002 Boolean default positional argument in function definition
    |
401 |         fc_neurons,
402 |         irreps_head, num_heads, irreps_pre_attn=None,
403 |         rescale_degree=False, nonlinear_message=False,
    |         ^^^^^^^^^^^^^^ FBT002
404 |         alpha_drop=0.1, proj_drop=0.1):
    |

geom3d\models\Equiformer\equiformer_type_0.py:403:31: FBT002 Boolean default positional argument in function definition
    |
401 |         fc_neurons,
402 |         irreps_head, num_heads, irreps_pre_attn=None,
403 |         rescale_degree=False, nonlinear_message=False,
    |                               ^^^^^^^^^^^^^^^^^ FBT002
404 |         alpha_drop=0.1, proj_drop=0.1):
    |

geom3d\models\Equiformer\equiformer_type_0.py:470:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
470 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
    |         ^^^^^^^ PLR0913
471 |         batch, **kwargs):
    |

geom3d\models\Equiformer\equiformer_type_0.py:470:9: D102 Missing docstring in public method
    |
470 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
    |         ^^^^^^^ D102
471 |         batch, **kwargs):
    |

geom3d\models\Equiformer\equiformer_type_0.py:470:35: ARG002 Unused method argument: `node_attr`
    |
470 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
    |                                   ^^^^^^^^^ ARG002
471 |         batch, **kwargs):
    |

geom3d\models\Equiformer\equiformer_type_0.py:471:9: ARG002 Unused method argument: `batch`
    |
470 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
471 |         batch, **kwargs):
    |         ^^^^^ ARG002
472 | 
473 |         message_src = self.merge_src(node_input)
    |

geom3d\models\Equiformer\equiformer_type_0.py:471:16: ANN003 Missing type annotation for `**kwargs`
    |
470 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
471 |         batch, **kwargs):
    |                ^^^^^^^^ ANN003
472 | 
473 |         message_src = self.merge_src(node_input)
    |

geom3d\models\Equiformer\equiformer_type_0.py:471:18: ARG002 Unused method argument: `kwargs`
    |
470 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
471 |         batch, **kwargs):
    |                  ^^^^^^ ARG002
472 | 
473 |         message_src = self.merge_src(node_input)
    |

geom3d\models\Equiformer\equiformer_type_0.py:518:9: D102 Missing docstring in public method
    |
518 |     def extra_repr(self):
    |         ^^^^^^^^^^ D102
519 |         output_str = super().extra_repr()
520 |         return output_str + f"rescale_degree={self.rescale_degree}, "
    |

geom3d\models\Equiformer\equiformer_type_0.py:527:9: D107 Missing docstring in `__init__`
    |
525 |     """Use two (FCTP + Gate)."""
526 | 
527 |     def __init__(self,
    |         ^^^^^^^^ D107
528 |         irreps_node_input, irreps_node_attr,
529 |         irreps_node_output, irreps_mlp_mid=None,
    |

geom3d\models\Equiformer\equiformer_type_0.py:552:9: D102 Missing docstring in public method
    |
552 |     def forward(self, node_input, node_attr, **kwargs):
    |         ^^^^^^^ D102
553 |         node_output = self.fctp_1(node_input, node_attr)
554 |         node_output = self.fctp_2(node_output, node_attr)
    |

geom3d\models\Equiformer\equiformer_type_0.py:552:46: ANN003 Missing type annotation for `**kwargs`
    |
552 |     def forward(self, node_input, node_attr, **kwargs):
    |                                              ^^^^^^^^ ANN003
553 |         node_output = self.fctp_1(node_input, node_attr)
554 |         node_output = self.fctp_2(node_output, node_attr)
    |

geom3d\models\Equiformer\equiformer_type_0.py:552:48: ARG002 Unused method argument: `kwargs`
    |
552 |     def forward(self, node_input, node_attr, **kwargs):
    |                                                ^^^^^^ ARG002
553 |         node_output = self.fctp_1(node_input, node_attr)
554 |         node_output = self.fctp_2(node_output, node_attr)
    |

geom3d\models\Equiformer\equiformer_type_0.py:562:5: D205 1 blank line required between summary line and description
    |
560 |   @compile_mode("script")
561 |   class TransBlock(torch.nn.Module):
562 |       """1. Layer Norm 1 -> GraphAttention -> Layer Norm 2 -> FeedForwardNetwork
    |  _____^
563 | |     2. Use pre-norm architecture.
564 | |     """
    | |_______^ D205
565 |   
566 |       def __init__(self,
    |
    = help: Insert single blank line

geom3d\models\Equiformer\equiformer_type_0.py:566:9: PLR0913 Too many arguments in function definition (15 > 5)
    |
564 |     """
565 | 
566 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
567 |         irreps_node_input, irreps_node_attr,
568 |         irreps_edge_attr, irreps_node_output,
    |

geom3d\models\Equiformer\equiformer_type_0.py:566:9: D107 Missing docstring in `__init__`
    |
564 |     """
565 | 
566 |     def __init__(self,
    |         ^^^^^^^^ D107
567 |         irreps_node_input, irreps_node_attr,
568 |         irreps_edge_attr, irreps_node_output,
    |

geom3d\models\Equiformer\equiformer_type_0.py:571:9: FBT002 Boolean default positional argument in function definition
    |
569 |         fc_neurons,
570 |         irreps_head, num_heads, irreps_pre_attn=None,
571 |         rescale_degree=False, nonlinear_message=False,
    |         ^^^^^^^^^^^^^^ FBT002
572 |         alpha_drop=0.1, proj_drop=0.1,
573 |         drop_path_rate=0.0,
    |

geom3d\models\Equiformer\equiformer_type_0.py:571:31: FBT002 Boolean default positional argument in function definition
    |
569 |         fc_neurons,
570 |         irreps_head, num_heads, irreps_pre_attn=None,
571 |         rescale_degree=False, nonlinear_message=False,
    |                               ^^^^^^^^^^^^^^^^^ FBT002
572 |         alpha_drop=0.1, proj_drop=0.1,
573 |         drop_path_rate=0.0,
    |

geom3d\models\Equiformer\equiformer_type_0.py:624:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
624 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
    |         ^^^^^^^ PLR0913
625 |         batch, **kwargs):
    |

geom3d\models\Equiformer\equiformer_type_0.py:624:9: D102 Missing docstring in public method
    |
624 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
    |         ^^^^^^^ D102
625 |         batch, **kwargs):
    |

geom3d\models\Equiformer\equiformer_type_0.py:625:16: ANN003 Missing type annotation for `**kwargs`
    |
624 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
625 |         batch, **kwargs):
    |                ^^^^^^^^ ANN003
626 | 
627 |         node_output = node_input
    |

geom3d\models\Equiformer\equiformer_type_0.py:625:18: ARG002 Unused method argument: `kwargs`
    |
624 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
625 |         batch, **kwargs):
    |                  ^^^^^^ ARG002
626 | 
627 |         node_output = node_input
    |

geom3d\models\Equiformer\equiformer_type_0.py:630:9: ERA001 Found commented-out code
    |
628 |         node_features = node_input
629 |         node_features = self.norm_1(node_features, batch=batch)
630 |         #norm_1_output = node_features
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
631 |         node_features = self.ga(node_input=node_features,
632 |             node_attr=node_attr,
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_0.py:643:9: ERA001 Found commented-out code
    |
641 |         node_features = node_output
642 |         node_features = self.norm_2(node_features, batch=batch)
643 |         #node_features = self.concat_norm_output(norm_1_output, node_features)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
644 |         node_features = self.ffn(node_features, node_attr)
645 |         if self.ffn_shortcut is not None:
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_0.py:654:7: D101 Missing docstring in public class
    |
654 | class NodeEmbeddingNetwork(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^^^^^ D101
655 | 
656 |     def __init__(self, irreps_node_embedding, max_atom_type, bias=True):
    |

geom3d\models\Equiformer\equiformer_type_0.py:656:9: D107 Missing docstring in `__init__`
    |
654 | class NodeEmbeddingNetwork(torch.nn.Module):
655 | 
656 |     def __init__(self, irreps_node_embedding, max_atom_type, bias=True):
    |         ^^^^^^^^ D107
657 | 
658 |         super().__init__()
    |

geom3d\models\Equiformer\equiformer_type_0.py:656:62: FBT002 Boolean default positional argument in function definition
    |
654 | class NodeEmbeddingNetwork(torch.nn.Module):
655 | 
656 |     def __init__(self, irreps_node_embedding, max_atom_type, bias=True):
    |                                                              ^^^^ FBT002
657 | 
658 |         super().__init__()
    |

geom3d\models\Equiformer\equiformer_type_0.py:675:7: D101 Missing docstring in public class
    |
675 | class ScaledScatter(torch.nn.Module):
    |       ^^^^^^^^^^^^^ D101
676 |     def __init__(self, avg_aggregate_num):
677 |         super().__init__()
    |

geom3d\models\Equiformer\equiformer_type_0.py:676:9: D107 Missing docstring in `__init__`
    |
675 | class ScaledScatter(torch.nn.Module):
676 |     def __init__(self, avg_aggregate_num):
    |         ^^^^^^^^ D107
677 |         super().__init__()
678 |         self.avg_aggregate_num = avg_aggregate_num + 0.0
    |

geom3d\models\Equiformer\equiformer_type_0.py:681:9: D102 Missing docstring in public method
    |
681 |     def forward(self, x, index, **kwargs):
    |         ^^^^^^^ D102
682 |         out = scatter(x, index, **kwargs)
683 |         return out.div(self.avg_aggregate_num ** 0.5)
    |

geom3d\models\Equiformer\equiformer_type_0.py:681:33: ANN003 Missing type annotation for `**kwargs`
    |
681 |     def forward(self, x, index, **kwargs):
    |                                 ^^^^^^^^ ANN003
682 |         out = scatter(x, index, **kwargs)
683 |         return out.div(self.avg_aggregate_num ** 0.5)
    |

geom3d\models\Equiformer\equiformer_type_0.py:686:9: D102 Missing docstring in public method
    |
686 |     def extra_repr(self):
    |         ^^^^^^^^^^ D102
687 |         return f"avg_aggregate_num={self.avg_aggregate_num}"
    |

geom3d\models\Equiformer\equiformer_type_0.py:690:7: D101 Missing docstring in public class
    |
690 | class EdgeDegreeEmbeddingNetwork(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
691 |     def __init__(self, irreps_node_embedding, irreps_edge_attr, fc_neurons, avg_aggregate_num):
692 |         super().__init__()
    |

geom3d\models\Equiformer\equiformer_type_0.py:691:9: D107 Missing docstring in `__init__`
    |
690 | class EdgeDegreeEmbeddingNetwork(torch.nn.Module):
691 |     def __init__(self, irreps_node_embedding, irreps_edge_attr, fc_neurons, avg_aggregate_num):
    |         ^^^^^^^^ D107
692 |         super().__init__()
693 |         self.exp = LinearRS(o3.Irreps("1x0e"), irreps_node_embedding,
    |

geom3d\models\Equiformer\equiformer_type_0.py:699:14: A001 Variable `slice` is shadowing a Python builtin
    |
697 |             internal_weights=False, bias=False)
698 |         self.rad = RadialProfile([*fc_neurons, self.dw.tp.weight_numel])
699 |         for (slice, slice_sqrt_k) in self.dw.slices_sqrt_k.values():
    |              ^^^^^ A001
700 |             self.rad.net[-1].weight.data[slice, :] *= slice_sqrt_k
701 |             self.rad.offset.data[slice] *= slice_sqrt_k
    |

geom3d\models\Equiformer\equiformer_type_0.py:706:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
706 |     def forward(self, node_input, edge_attr, edge_scalars, edge_src, edge_dst, batch):
    |         ^^^^^^^ PLR0913
707 |         node_features = torch.ones_like(node_input.narrow(1, 0, 1))
708 |         node_features = self.exp(node_features)
    |

geom3d\models\Equiformer\equiformer_type_0.py:706:9: D102 Missing docstring in public method
    |
706 |     def forward(self, node_input, edge_attr, edge_scalars, edge_src, edge_dst, batch):
    |         ^^^^^^^ D102
707 |         node_features = torch.ones_like(node_input.narrow(1, 0, 1))
708 |         node_features = self.exp(node_features)
    |

geom3d\models\Equiformer\equiformer_type_0.py:706:80: ARG002 Unused method argument: `batch`
    |
706 |     def forward(self, node_input, edge_attr, edge_scalars, edge_src, edge_dst, batch):
    |                                                                                ^^^^^ ARG002
707 |         node_features = torch.ones_like(node_input.narrow(1, 0, 1))
708 |         node_features = self.exp(node_features)
    |

geom3d\models\Equiformer\equiformer_type_0.py:716:7: D101 Missing docstring in public class
    |
716 | class EquiformerEnergy(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^ D101
717 |     def __init__(self,
718 |         irreps_in="5x0e",
    |

geom3d\models\Equiformer\equiformer_type_0.py:717:9: PLR0913 Too many arguments in function definition (24 > 5)
    |
716 | class EquiformerEnergy(torch.nn.Module):
717 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
718 |         irreps_in="5x0e",
719 |         irreps_node_embedding="128x0e+64x1e+32x2e", node_class=119, num_layers=6,
    |

geom3d\models\Equiformer\equiformer_type_0.py:717:9: D107 Missing docstring in `__init__`
    |
716 | class EquiformerEnergy(torch.nn.Module):
717 |     def __init__(self,
    |         ^^^^^^^^ D107
718 |         irreps_in="5x0e",
719 |         irreps_node_embedding="128x0e+64x1e+32x2e", node_class=119, num_layers=6,
    |

geom3d\models\Equiformer\equiformer_type_0.py:725:9: FBT002 Boolean default positional argument in function definition
    |
723 |         irreps_feature="512x0e",
724 |         irreps_head="32x0e+16x1o+8x2e", num_heads=4, irreps_pre_attn=None,
725 |         rescale_degree=False, nonlinear_message=False,
    |         ^^^^^^^^^^^^^^ FBT002
726 |         irreps_mlp_mid="128x0e+64x1e+32x2e",
727 |         norm_layer="layer",
    |

geom3d\models\Equiformer\equiformer_type_0.py:725:31: FBT002 Boolean default positional argument in function definition
    |
723 |         irreps_feature="512x0e",
724 |         irreps_head="32x0e+16x1o+8x2e", num_heads=4, irreps_pre_attn=None,
725 |         rescale_degree=False, nonlinear_message=False,
    |                               ^^^^^^^^^^^^^^^^^ FBT002
726 |         irreps_mlp_mid="128x0e+64x1e+32x2e",
727 |         norm_layer="layer",
    |

geom3d\models\Equiformer\equiformer_type_0.py:743:9: ERA001 Found commented-out code
    |
741 |         self.drop_path_rate = drop_path_rate
742 |         self.norm_layer = norm_layer
743 |         # self.task_mean = mean
    |         ^^^^^^^^^^^^^^^^^^^^^^^ ERA001
744 |         # self.task_std = std
745 |         self.scale = scale
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_0.py:744:9: ERA001 Found commented-out code
    |
742 |         self.norm_layer = norm_layer
743 |         # self.task_mean = mean
744 |         # self.task_std = std
    |         ^^^^^^^^^^^^^^^^^^^^^ ERA001
745 |         self.scale = scale
746 |         self.register_buffer("atomref", atomref)
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_0.py:792:9: D102 Missing docstring in public method
    |
792 |     def build_blocks(self):
    |         ^^^^^^^^^^^^ D102
793 |         for i in range(self.num_layers):
794 |             if i != (self.num_layers - 1):
    |

geom3d\models\Equiformer\equiformer_type_0.py:826:9: D102 Missing docstring in public method
    |
825 |     @torch.jit.ignore
826 |     def no_weight_decay(self):
    |         ^^^^^^^^^^^^^^^ D102
827 |         no_wd_list = []
828 |         named_parameters_list = [name for name, _ in self.named_parameters()]
    |

geom3d\models\Equiformer\equiformer_type_0.py:835:21: S101 Use of `assert` detected
    |
833 |                         continue
834 |                     global_parameter_name = module_name + "." + parameter_name
835 |                     assert global_parameter_name in named_parameters_list
    |                     ^^^^^^ S101
836 |                     no_wd_list.append(global_parameter_name)
    |

geom3d\models\Equiformer\equiformer_type_0.py:841:9: D102 Missing docstring in public method
    |
841 |     def forward(self, pos, batch, node_atom, **kwargs) -> torch.Tensor:
    |         ^^^^^^^ D102
842 | 
843 |         edge_src, edge_dst = radius_graph(pos, r=self.max_radius, batch=batch,
    |

geom3d\models\Equiformer\equiformer_type_0.py:841:46: ANN003 Missing type annotation for `**kwargs`
    |
841 |     def forward(self, pos, batch, node_atom, **kwargs) -> torch.Tensor:
    |                                              ^^^^^^^^ ANN003
842 | 
843 |         edge_src, edge_dst = radius_graph(pos, r=self.max_radius, batch=batch,
    |

geom3d\models\Equiformer\equiformer_type_0.py:841:48: ARG002 Unused method argument: `kwargs`
    |
841 |     def forward(self, pos, batch, node_atom, **kwargs) -> torch.Tensor:
    |                                                ^^^^^^ ARG002
842 | 
843 |         edge_src, edge_dst = radius_graph(pos, r=self.max_radius, batch=batch,
    |

geom3d\models\Equiformer\equiformer_type_0.py:849:9: ERA001 Found commented-out code
    |
847 |             x=edge_vec, normalize=True, normalization="component")
848 | 
849 |         # node_atom = node_atom.new_tensor([-1, 0, -1, -1, -1, -1, 1, 2, 3, 4])[node_atom]
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
850 |         atom_embedding, atom_attr, atom_onehot = self.atom_embed(node_atom)
851 |         edge_length = edge_vec.norm(dim=1)
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_0.py:874:9: ERA001 Found commented-out code
    |
873 |         # if self.scale is not None:
874 |         #     outputs = self.scale * outputs
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_0.py:878:5: N802 Function name `Equiformer_l2` should be lowercase
    |
878 | def Equiformer_l2(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^ N802
879 |     return EquiformerEnergy(
880 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:878:5: D103 Missing docstring in public function
    |
878 | def Equiformer_l2(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^ D103
879 |     return EquiformerEnergy(
880 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:878:61: ANN003 Missing type annotation for `**kwargs`
    |
878 | def Equiformer_l2(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                             ^^^^^^^^ ANN003
879 |     return EquiformerEnergy(
880 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:878:63: ARG001 Unused function argument: `kwargs`
    |
878 | def Equiformer_l2(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                               ^^^^^^ ARG001
879 |     return EquiformerEnergy(
880 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:893:5: N802 Function name `Equiformer_nonlinear_l2` should be lowercase
    |
893 | def Equiformer_nonlinear_l2(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^ N802
894 |     return EquiformerEnergy(
895 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:893:5: D103 Missing docstring in public function
    |
893 | def Equiformer_nonlinear_l2(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^ D103
894 |     return EquiformerEnergy(
895 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:893:71: ANN003 Missing type annotation for `**kwargs`
    |
893 | def Equiformer_nonlinear_l2(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                       ^^^^^^^^ ANN003
894 |     return EquiformerEnergy(
895 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:893:73: ARG001 Unused function argument: `kwargs`
    |
893 | def Equiformer_nonlinear_l2(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                         ^^^^^^ ARG001
894 |     return EquiformerEnergy(
895 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:908:5: N802 Function name `Equiformer_nonlinear_l2_e3` should be lowercase
    |
908 | def Equiformer_nonlinear_l2_e3(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
909 |     return EquiformerEnergy(
910 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:908:5: D103 Missing docstring in public function
    |
908 | def Equiformer_nonlinear_l2_e3(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
909 |     return EquiformerEnergy(
910 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:908:74: ANN003 Missing type annotation for `**kwargs`
    |
908 | def Equiformer_nonlinear_l2_e3(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                          ^^^^^^^^ ANN003
909 |     return EquiformerEnergy(
910 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:908:76: ARG001 Unused function argument: `kwargs`
    |
908 | def Equiformer_nonlinear_l2_e3(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                            ^^^^^^ ARG001
909 |     return EquiformerEnergy(
910 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:924:5: N802 Function name `Equiformer_nonlinear_bessel_l2` should be lowercase
    |
923 | # Equiformer, L_max = 2, Bessel radial basis, dropout = 0.2
924 | def Equiformer_nonlinear_bessel_l2(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
925 |     return EquiformerEnergy(
926 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:924:5: D103 Missing docstring in public function
    |
923 | # Equiformer, L_max = 2, Bessel radial basis, dropout = 0.2
924 | def Equiformer_nonlinear_bessel_l2(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
925 |     return EquiformerEnergy(
926 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:924:78: ANN003 Missing type annotation for `**kwargs`
    |
923 | # Equiformer, L_max = 2, Bessel radial basis, dropout = 0.2
924 | def Equiformer_nonlinear_bessel_l2(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                              ^^^^^^^^ ANN003
925 |     return EquiformerEnergy(
926 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:924:80: ARG001 Unused function argument: `kwargs`
    |
923 | # Equiformer, L_max = 2, Bessel radial basis, dropout = 0.2
924 | def Equiformer_nonlinear_bessel_l2(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                ^^^^^^ ARG001
925 |     return EquiformerEnergy(
926 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:940:5: N802 Function name `Equiformer_nonlinear_bessel_l2_drop01` should be lowercase
    |
939 | # Equiformer, L_max = 2, Bessel radial basis, dropout = 0.1
940 | def Equiformer_nonlinear_bessel_l2_drop01(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
941 |     return EquiformerEnergy(
942 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:940:5: D103 Missing docstring in public function
    |
939 | # Equiformer, L_max = 2, Bessel radial basis, dropout = 0.1
940 | def Equiformer_nonlinear_bessel_l2_drop01(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
941 |     return EquiformerEnergy(
942 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:940:85: ANN003 Missing type annotation for `**kwargs`
    |
939 | # Equiformer, L_max = 2, Bessel radial basis, dropout = 0.1
940 | def Equiformer_nonlinear_bessel_l2_drop01(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                     ^^^^^^^^ ANN003
941 |     return EquiformerEnergy(
942 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:940:87: ARG001 Unused function argument: `kwargs`
    |
939 | # Equiformer, L_max = 2, Bessel radial basis, dropout = 0.1
940 | def Equiformer_nonlinear_bessel_l2_drop01(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                       ^^^^^^ ARG001
941 |     return EquiformerEnergy(
942 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:956:5: N802 Function name `Equiformer_nonlinear_bessel_l2_drop00` should be lowercase
    |
955 | # Equiformer, L_max = 2, Bessel radial basis, dropout = 0.0
956 | def Equiformer_nonlinear_bessel_l2_drop00(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
957 |     return EquiformerEnergy(
958 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:956:5: D103 Missing docstring in public function
    |
955 | # Equiformer, L_max = 2, Bessel radial basis, dropout = 0.0
956 | def Equiformer_nonlinear_bessel_l2_drop00(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
957 |     return EquiformerEnergy(
958 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:956:85: ANN003 Missing type annotation for `**kwargs`
    |
955 | # Equiformer, L_max = 2, Bessel radial basis, dropout = 0.0
956 | def Equiformer_nonlinear_bessel_l2_drop00(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                     ^^^^^^^^ ANN003
957 |     return EquiformerEnergy(
958 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0.py:956:87: ARG001 Unused function argument: `kwargs`
    |
955 | # Equiformer, L_max = 2, Bessel radial basis, dropout = 0.0
956 | def Equiformer_nonlinear_bessel_l2_drop00(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                       ^^^^^^ ARG001
957 |     return EquiformerEnergy(
958 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:1:1: D100 Missing docstring in public module
geom3d\models\Equiformer\equiformer_type_01.py:37:7: D101 Missing docstring in public class
   |
37 | class CosineCutoff(torch.nn.Module):
   |       ^^^^^^^^^^^^ D101
38 |     def __init__(self, cutoff_lower=0.0, cutoff_upper=5.0):
39 |         super().__init__()
   |

geom3d\models\Equiformer\equiformer_type_01.py:38:9: D107 Missing docstring in `__init__`
   |
37 | class CosineCutoff(torch.nn.Module):
38 |     def __init__(self, cutoff_lower=0.0, cutoff_upper=5.0):
   |         ^^^^^^^^ D107
39 |         super().__init__()
40 |         self.cutoff_lower = cutoff_lower
   |

geom3d\models\Equiformer\equiformer_type_01.py:43:9: D102 Missing docstring in public method
   |
41 |         self.cutoff_upper = cutoff_upper
42 | 
43 |     def forward(self, distances):
   |         ^^^^^^^ D102
44 |         if self.cutoff_lower > 0:
45 |             cutoffs = 0.5 * (
   |

geom3d\models\Equiformer\equiformer_type_01.py:60:9: RET505 Unnecessary `else` after `return` statement
   |
58 |             cutoffs = cutoffs * (distances < self.cutoff_upper).float()
59 |             return cutoffs * (distances > self.cutoff_lower).float()
60 |         else:
   |         ^^^^ RET505
61 |             cutoffs = 0.5 * (torch.cos(distances * math.pi / self.cutoff_upper) + 1.0)
62 |             # remove contributions beyond the cutoff radius
   |
   = help: Remove unnecessary `else`

geom3d\models\Equiformer\equiformer_type_01.py:67:7: D101 Missing docstring in public class
   |
66 | # https://github.com/torchmd/torchmd-net/blob/main/torchmdnet/models/utils.py#L111
67 | class ExpNormalSmearing(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^^^ D101
68 |     def __init__(self, cutoff_lower=0.0, cutoff_upper=5.0, num_rbf=50, trainable=False):
69 |         super().__init__()
   |

geom3d\models\Equiformer\equiformer_type_01.py:68:9: D107 Missing docstring in `__init__`
   |
66 | # https://github.com/torchmd/torchmd-net/blob/main/torchmdnet/models/utils.py#L111
67 | class ExpNormalSmearing(torch.nn.Module):
68 |     def __init__(self, cutoff_lower=0.0, cutoff_upper=5.0, num_rbf=50, trainable=False):
   |         ^^^^^^^^ D107
69 |         super().__init__()
70 |         self.cutoff_lower = cutoff_lower
   |

geom3d\models\Equiformer\equiformer_type_01.py:68:72: FBT002 Boolean default positional argument in function definition
   |
66 | # https://github.com/torchmd/torchmd-net/blob/main/torchmdnet/models/utils.py#L111
67 | class ExpNormalSmearing(torch.nn.Module):
68 |     def __init__(self, cutoff_lower=0.0, cutoff_upper=5.0, num_rbf=50, trainable=False):
   |                                                                        ^^^^^^^^^ FBT002
69 |         super().__init__()
70 |         self.cutoff_lower = cutoff_lower
   |

geom3d\models\Equiformer\equiformer_type_01.py:80:46: F821 Undefined name `nn`
   |
78 |         means, betas = self._initial_params()
79 |         if trainable:
80 |             self.register_parameter("means", nn.Parameter(means))
   |                                              ^^ F821
81 |             self.register_parameter("betas", nn.Parameter(betas))
82 |         else:
   |

geom3d\models\Equiformer\equiformer_type_01.py:81:46: F821 Undefined name `nn`
   |
79 |         if trainable:
80 |             self.register_parameter("means", nn.Parameter(means))
81 |             self.register_parameter("betas", nn.Parameter(betas))
   |                                              ^^ F821
82 |         else:
83 |             self.register_buffer("means", means)
   |

geom3d\models\Equiformer\equiformer_type_01.py:86:9: ANN202 Missing return type annotation for private function `_initial_params`
   |
84 |             self.register_buffer("betas", betas)
85 | 
86 |     def _initial_params(self):
   |         ^^^^^^^^^^^^^^^ ANN202
87 |         # initialize means and betas according to the default values in PhysNet
88 |         # https://pubs.acs.org/doi/10.1021/acs.jctc.9b00181
   |
   = help: Add return type annotation

geom3d\models\Equiformer\equiformer_type_01.py:98:9: D102 Missing docstring in public method
    |
 96 |         return means, betas
 97 | 
 98 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
 99 |         means, betas = self._initial_params()
100 |         self.means.data.copy_(means)
    |

geom3d\models\Equiformer\equiformer_type_01.py:103:9: D102 Missing docstring in public method
    |
101 |         self.betas.data.copy_(betas)
102 | 
103 |     def forward(self, dist):
    |         ^^^^^^^ D102
104 |         dist = dist.unsqueeze(-1)
105 |         return self.cutoff_fn(dist) * torch.exp(
    |

geom3d\models\Equiformer\equiformer_type_01.py:111:7: D101 Missing docstring in public class
    |
111 | class EquiformerEnergyForce(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^^^^^^ D101
112 |     def __init__(self,
113 |         irreps_in="64x0e",
    |

geom3d\models\Equiformer\equiformer_type_01.py:112:9: PLR0913 Too many arguments in function definition (23 > 5)
    |
111 | class EquiformerEnergyForce(torch.nn.Module):
112 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
113 |         irreps_in="64x0e",
114 |         irreps_node_embedding="128x0e+64x1e+32x2e", node_class=119, num_layers=6,
    |

geom3d\models\Equiformer\equiformer_type_01.py:112:9: D107 Missing docstring in `__init__`
    |
111 | class EquiformerEnergyForce(torch.nn.Module):
112 |     def __init__(self,
    |         ^^^^^^^^ D107
113 |         irreps_in="64x0e",
114 |         irreps_node_embedding="128x0e+64x1e+32x2e", node_class=119, num_layers=6,
    |

geom3d\models\Equiformer\equiformer_type_01.py:120:9: FBT002 Boolean default positional argument in function definition
    |
118 |         irreps_feature="512x0e",
119 |         irreps_head="32x0e+16x1o+8x2e", num_heads=4, irreps_pre_attn=None,
120 |         rescale_degree=False, nonlinear_message=False,
    |         ^^^^^^^^^^^^^^ FBT002
121 |         irreps_mlp_mid="128x0e+64x1e+32x2e",
122 |         use_attn_head=False,
    |

geom3d\models\Equiformer\equiformer_type_01.py:120:31: FBT002 Boolean default positional argument in function definition
    |
118 |         irreps_feature="512x0e",
119 |         irreps_head="32x0e+16x1o+8x2e", num_heads=4, irreps_pre_attn=None,
120 |         rescale_degree=False, nonlinear_message=False,
    |                               ^^^^^^^^^^^^^^^^^ FBT002
121 |         irreps_mlp_mid="128x0e+64x1e+32x2e",
122 |         use_attn_head=False,
    |

geom3d\models\Equiformer\equiformer_type_01.py:122:9: FBT002 Boolean default positional argument in function definition
    |
120 |         rescale_degree=False, nonlinear_message=False,
121 |         irreps_mlp_mid="128x0e+64x1e+32x2e",
122 |         use_attn_head=False,
    |         ^^^^^^^^^^^^^ FBT002
123 |         norm_layer="layer",
124 |         alpha_drop=0.2, proj_drop=0.0, out_drop=0.0,
    |

geom3d\models\Equiformer\equiformer_type_01.py:139:9: ERA001 Found commented-out code
    |
137 |         self.use_attn_head = use_attn_head
138 |         self.norm_layer = norm_layer
139 |         # self.task_mean = mean
    |         ^^^^^^^^^^^^^^^^^^^^^^^ ERA001
140 |         # self.task_std = std
141 |         # self.scale = scale
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_01.py:140:9: ERA001 Found commented-out code
    |
138 |         self.norm_layer = norm_layer
139 |         # self.task_mean = mean
140 |         # self.task_std = std
    |         ^^^^^^^^^^^^^^^^^^^^^ ERA001
141 |         # self.scale = scale
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_01.py:141:9: ERA001 Found commented-out code
    |
139 |         # self.task_mean = mean
140 |         # self.task_std = std
141 |         # self.scale = scale
    |         ^^^^^^^^^^^^^^^^^^^^ ERA001
142 | 
143 |         self.irreps_node_attr = o3.Irreps(irreps_node_attr)
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_01.py:204:9: D102 Missing docstring in public method
    |
204 |     def build_blocks(self):
    |         ^^^^^^^^^^^^ D102
205 |         for i in range(self.num_layers):
206 |             if i != (self.num_layers - 1):
    |

geom3d\models\Equiformer\equiformer_type_01.py:238:9: D102 Missing docstring in public method
    |
237 |     @torch.jit.ignore
238 |     def no_weight_decay(self):
    |         ^^^^^^^^^^^^^^^ D102
239 |         no_wd_list = []
240 |         named_parameters_list = [name for name, _ in self.named_parameters()]
    |

geom3d\models\Equiformer\equiformer_type_01.py:247:21: S101 Use of `assert` detected
    |
245 |                         continue
246 |                     global_parameter_name = module_name + "." + parameter_name
247 |                     assert global_parameter_name in named_parameters_list
    |                     ^^^^^^ S101
248 |                     no_wd_list.append(global_parameter_name)
    |

geom3d\models\Equiformer\equiformer_type_01.py:256:9: D102 Missing docstring in public method
    |
254 |     # https://github.com/Open-Catalyst-Project/ocp/blob/main/ocpmodels/models/spinconv.py#L186
255 |     @torch.enable_grad()
256 |     def forward(self, node_atom, pos, batch):
    |         ^^^^^^^ D102
257 | 
258 |         pos = pos.requires_grad_(True)
    |

geom3d\models\Equiformer\equiformer_type_01.py:258:34: FBT003 Boolean positional value in function call
    |
256 |     def forward(self, node_atom, pos, batch):
257 | 
258 |         pos = pos.requires_grad_(True)
    |                                  ^^^^ FBT003
259 | 
260 |         edge_src, edge_dst = radius_graph(pos, r=self.max_radius, batch=batch,
    |

geom3d\models\Equiformer\equiformer_type_01.py:293:9: ERA001 Found commented-out code
    |
292 |         # if self.scale is not None:
293 |         #     outputs = self.scale * outputs
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
294 | 
295 |         # # https://github.com/Open-Catalyst-Project/ocp/blob/main/ocpmodels/models/spinconv.py#L321-L328
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_01.py:296:9: ERA001 Found commented-out code
    |
295 |         # # https://github.com/Open-Catalyst-Project/ocp/blob/main/ocpmodels/models/spinconv.py#L321-L328
296 |         # forces = -1 * (
    |         ^^^^^^^^^^^^^^^^^ ERA001
297 |         #             torch.autograd.grad(
298 |         #                 energy,
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_01.py:300:9: ERA001 Found commented-out code
    |
298 |         #                 energy,
299 |         #                 pos,
300 |         #                 grad_outputs=torch.ones_like(energy),
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
301 |         #                 create_graph=True,
302 |         #             )[0]
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_01.py:301:9: ERA001 Found commented-out code
    |
299 |         #                 pos,
300 |         #                 grad_outputs=torch.ones_like(energy),
301 |         #                 create_graph=True,
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
302 |         #             )[0]
303 |         #         )
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_01.py:303:9: ERA001 Found commented-out code
    |
301 |         #                 create_graph=True,
302 |         #             )[0]
303 |         #         )
    |         ^^^^^^^^^^^ ERA001
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_01.py:306:5: N802 Function name `Equiformer_l2_energy_force` should be lowercase
    |
306 | def Equiformer_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
307 |     return EquiformerEnergyForce(
308 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:306:5: D103 Missing docstring in public function
    |
306 | def Equiformer_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
307 |     return EquiformerEnergyForce(
308 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:306:74: ANN003 Missing type annotation for `**kwargs`
    |
306 | def Equiformer_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                          ^^^^^^^^ ANN003
307 |     return EquiformerEnergyForce(
308 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:306:76: ARG001 Unused function argument: `kwargs`
    |
306 | def Equiformer_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                            ^^^^^^ ARG001
307 |     return EquiformerEnergyForce(
308 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:321:5: N802 Function name `Equiformer_nonlinear_l2_energy_force` should be lowercase
    |
321 | def Equiformer_nonlinear_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
322 |     return EquiformerEnergyForce(
323 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:321:5: D103 Missing docstring in public function
    |
321 | def Equiformer_nonlinear_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
322 |     return EquiformerEnergyForce(
323 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:321:84: ANN003 Missing type annotation for `**kwargs`
    |
321 | def Equiformer_nonlinear_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                    ^^^^^^^^ ANN003
322 |     return EquiformerEnergyForce(
323 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:321:86: ARG001 Unused function argument: `kwargs`
    |
321 | def Equiformer_nonlinear_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                      ^^^^^^ ARG001
322 |     return EquiformerEnergyForce(
323 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:336:5: N802 Function name `Equiformer_nonlinear_l2_e3_energy_force` should be lowercase
    |
336 | def Equiformer_nonlinear_l2_e3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
337 |     return EquiformerEnergyForce(
338 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:336:5: D103 Missing docstring in public function
    |
336 | def Equiformer_nonlinear_l2_e3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
337 |     return EquiformerEnergyForce(
338 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:336:87: ANN003 Missing type annotation for `**kwargs`
    |
336 | def Equiformer_nonlinear_l2_e3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                       ^^^^^^^^ ANN003
337 |     return EquiformerEnergyForce(
338 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:336:89: ARG001 Unused function argument: `kwargs`
    |
336 | def Equiformer_nonlinear_l2_e3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                         ^^^^^^ ARG001
337 |     return EquiformerEnergyForce(
338 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:351:5: N802 Function name `Equiformer_nonlinear_bessel_l2_energy_force` should be lowercase
    |
351 | def Equiformer_nonlinear_bessel_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
352 |     return EquiformerEnergyForce(
353 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:351:5: D103 Missing docstring in public function
    |
351 | def Equiformer_nonlinear_bessel_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
352 |     return EquiformerEnergyForce(
353 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:351:91: ANN003 Missing type annotation for `**kwargs`
    |
351 | def Equiformer_nonlinear_bessel_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                           ^^^^^^^^ ANN003
352 |     return EquiformerEnergyForce(
353 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:351:93: ARG001 Unused function argument: `kwargs`
    |
351 | def Equiformer_nonlinear_bessel_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                             ^^^^^^ ARG001
352 |     return EquiformerEnergyForce(
353 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:366:5: N802 Function name `Equiformer_nonlinear_exp_l2_energy_force` should be lowercase
    |
366 | def Equiformer_nonlinear_exp_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
367 |     return EquiformerEnergyForce(
368 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:366:5: D103 Missing docstring in public function
    |
366 | def Equiformer_nonlinear_exp_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
367 |     return EquiformerEnergyForce(
368 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:366:88: ANN003 Missing type annotation for `**kwargs`
    |
366 | def Equiformer_nonlinear_exp_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                        ^^^^^^^^ ANN003
367 |     return EquiformerEnergyForce(
368 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:366:90: ARG001 Unused function argument: `kwargs`
    |
366 | def Equiformer_nonlinear_exp_l2_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                          ^^^^^^ ARG001
367 |     return EquiformerEnergyForce(
368 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:381:5: N802 Function name `Equiformer_nonlinear_exp_l3_energy_force` should be lowercase
    |
381 | def Equiformer_nonlinear_exp_l3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
382 |     return EquiformerEnergyForce(
383 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:381:5: D103 Missing docstring in public function
    |
381 | def Equiformer_nonlinear_exp_l3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
382 |     return EquiformerEnergyForce(
383 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:381:88: ANN003 Missing type annotation for `**kwargs`
    |
381 | def Equiformer_nonlinear_exp_l3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                        ^^^^^^^^ ANN003
382 |     return EquiformerEnergyForce(
383 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:381:90: ARG001 Unused function argument: `kwargs`
    |
381 | def Equiformer_nonlinear_exp_l3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                          ^^^^^^ ARG001
382 |     return EquiformerEnergyForce(
383 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:396:5: N802 Function name `Equiformer_nonlinear_attn_exp_l3_energy_force` should be lowercase
    |
396 | def Equiformer_nonlinear_attn_exp_l3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
397 |     return EquiformerEnergyForce(
398 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:396:5: D103 Missing docstring in public function
    |
396 | def Equiformer_nonlinear_attn_exp_l3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
397 |     return EquiformerEnergyForce(
398 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:396:93: ANN003 Missing type annotation for `**kwargs`
    |
396 | def Equiformer_nonlinear_attn_exp_l3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                             ^^^^^^^^ ANN003
397 |     return EquiformerEnergyForce(
398 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:396:95: ARG001 Unused function argument: `kwargs`
    |
396 | def Equiformer_nonlinear_attn_exp_l3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                               ^^^^^^ ARG001
397 |     return EquiformerEnergyForce(
398 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:412:5: N802 Function name `Equiformer_nonlinear_exp_l3_e3_energy_force` should be lowercase
    |
412 | def Equiformer_nonlinear_exp_l3_e3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
413 |     return EquiformerEnergyForce(
414 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:412:5: D103 Missing docstring in public function
    |
412 | def Equiformer_nonlinear_exp_l3_e3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
413 |     return EquiformerEnergyForce(
414 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:412:91: ANN003 Missing type annotation for `**kwargs`
    |
412 | def Equiformer_nonlinear_exp_l3_e3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                           ^^^^^^^^ ANN003
413 |     return EquiformerEnergyForce(
414 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:412:93: ARG001 Unused function argument: `kwargs`
    |
412 | def Equiformer_nonlinear_exp_l3_e3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                             ^^^^^^ ARG001
413 |     return EquiformerEnergyForce(
414 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:427:5: N802 Function name `Equiformer_nonlinear_bessel_l3_energy_force` should be lowercase
    |
427 | def Equiformer_nonlinear_bessel_l3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
428 |     return EquiformerEnergyForce(
429 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:427:5: D103 Missing docstring in public function
    |
427 | def Equiformer_nonlinear_bessel_l3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
428 |     return EquiformerEnergyForce(
429 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:427:91: ANN003 Missing type annotation for `**kwargs`
    |
427 | def Equiformer_nonlinear_bessel_l3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                           ^^^^^^^^ ANN003
428 |     return EquiformerEnergyForce(
429 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:427:93: ARG001 Unused function argument: `kwargs`
    |
427 | def Equiformer_nonlinear_bessel_l3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                             ^^^^^^ ARG001
428 |     return EquiformerEnergyForce(
429 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:442:5: N802 Function name `Equiformer_nonlinear_bessel_l3_e3_energy_force` should be lowercase
    |
442 | def Equiformer_nonlinear_bessel_l3_e3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
443 |     return EquiformerEnergyForce(
444 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:442:5: D103 Missing docstring in public function
    |
442 | def Equiformer_nonlinear_bessel_l3_e3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
443 |     return EquiformerEnergyForce(
444 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:442:94: ANN003 Missing type annotation for `**kwargs`
    |
442 | def Equiformer_nonlinear_bessel_l3_e3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                              ^^^^^^^^ ANN003
443 |     return EquiformerEnergyForce(
444 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_01.py:442:96: ARG001 Unused function argument: `kwargs`
    |
442 | def Equiformer_nonlinear_bessel_l3_e3_energy_force(irreps_in, radius, num_basis, node_class, **kwargs):
    |                                                                                                ^^^^^^ ARG001
443 |     return EquiformerEnergyForce(
444 |         irreps_in=irreps_in,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:1:1: D100 Missing docstring in public module
geom3d\models\Equiformer\equiformer_type_0_periodic.py:37:5: D103 Missing docstring in public function
   |
37 | def get_norm_layer(norm_type):
   |     ^^^^^^^^^^^^^^ D103
38 |     if norm_type == "graph":
39 |         return EquivariantGraphNorm
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:40:5: RET505 Unnecessary `elif` after `return` statement
   |
38 |     if norm_type == "graph":
39 |         return EquivariantGraphNorm
40 |     elif norm_type == "instance":
   |     ^^^^ RET505
41 |         return EquivariantInstanceNorm
42 |     elif norm_type == "layer":
   |
   = help: Remove unnecessary `elif`

geom3d\models\Equiformer\equiformer_type_0_periodic.py:53:7: D101 Missing docstring in public class
   |
53 | class SmoothLeakyReLU(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^ D101
54 |     def __init__(self, negative_slope=0.2):
55 |         super().__init__()
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:54:9: D107 Missing docstring in `__init__`
   |
53 | class SmoothLeakyReLU(torch.nn.Module):
54 |     def __init__(self, negative_slope=0.2):
   |         ^^^^^^^^ D107
55 |         super().__init__()
56 |         self.alpha = negative_slope
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:59:9: D102 Missing docstring in public method
   |
59 |     def forward(self, x):
   |         ^^^^^^^ D102
60 |         x1 = ((1 + self.alpha) / 2) * x
61 |         x2 = ((1 - self.alpha) / 2) * x * (2 * torch.sigmoid(x) - 1)
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:65:9: D102 Missing docstring in public method
   |
65 |     def extra_repr(self):
   |         ^^^^^^^^^^ D102
66 |         return f"negative_slope={self.alpha}"
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:69:5: D103 Missing docstring in public function
   |
69 | def get_mul_0(irreps):
   |     ^^^^^^^^^ D103
70 |     mul_0 = 0
71 |     for mul, ir in irreps:
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:77:7: D101 Missing docstring in public class
   |
77 | class FullyConnectedTensorProductRescaleNorm(FullyConnectedTensorProductRescale):
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
78 | 
79 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:79:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
77 | class FullyConnectedTensorProductRescaleNorm(FullyConnectedTensorProductRescale):
78 | 
79 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
   |         ^^^^^^^^ PLR0913
80 |         bias=True, rescale=True,
81 |         internal_weights=None, shared_weights=None,
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:79:9: D107 Missing docstring in `__init__`
   |
77 | class FullyConnectedTensorProductRescaleNorm(FullyConnectedTensorProductRescale):
78 | 
79 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
   |         ^^^^^^^^ D107
80 |         bias=True, rescale=True,
81 |         internal_weights=None, shared_weights=None,
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:80:9: FBT002 Boolean default positional argument in function definition
   |
79 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
80 |         bias=True, rescale=True,
   |         ^^^^ FBT002
81 |         internal_weights=None, shared_weights=None,
82 |         normalization=None, norm_layer="graph"):
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:80:20: FBT002 Boolean default positional argument in function definition
   |
79 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
80 |         bias=True, rescale=True,
   |                    ^^^^^^^ FBT002
81 |         internal_weights=None, shared_weights=None,
82 |         normalization=None, norm_layer="graph"):
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:91:9: D102 Missing docstring in public method
   |
91 |     def forward(self, x, y, batch, weight=None):
   |         ^^^^^^^ D102
92 |         out = self.forward_tp_rescale_bias(x, y, weight)
93 |         return self.norm(out, batch=batch)
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:96:7: D101 Missing docstring in public class
   |
96 | class FullyConnectedTensorProductRescaleNormSwishGate(FullyConnectedTensorProductRescaleNorm):
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
97 | 
98 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
   |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:98:9: PLR0913 Too many arguments in function definition (9 > 5)
    |
 96 | class FullyConnectedTensorProductRescaleNormSwishGate(FullyConnectedTensorProductRescaleNorm):
 97 | 
 98 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
    |         ^^^^^^^^ PLR0913
 99 |         bias=True, rescale=True,
100 |         internal_weights=None, shared_weights=None,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:98:9: D107 Missing docstring in `__init__`
    |
 96 | class FullyConnectedTensorProductRescaleNormSwishGate(FullyConnectedTensorProductRescaleNorm):
 97 | 
 98 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
    |         ^^^^^^^^ D107
 99 |         bias=True, rescale=True,
100 |         internal_weights=None, shared_weights=None,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:99:9: FBT002 Boolean default positional argument in function definition
    |
 98 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
 99 |         bias=True, rescale=True,
    |         ^^^^ FBT002
100 |         internal_weights=None, shared_weights=None,
101 |         normalization=None, norm_layer="graph"):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:99:20: FBT002 Boolean default positional argument in function definition
    |
 98 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
 99 |         bias=True, rescale=True,
    |                    ^^^^^^^ FBT002
100 |         internal_weights=None, shared_weights=None,
101 |         normalization=None, norm_layer="graph"):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:119:9: D102 Missing docstring in public method
    |
119 |     def forward(self, x, y, batch, weight=None):
    |         ^^^^^^^ D102
120 |         out = self.forward_tp_rescale_bias(x, y, weight)
121 |         out = self.norm(out, batch=batch)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:125:7: D101 Missing docstring in public class
    |
125 | class FullyConnectedTensorProductRescaleSwishGate(FullyConnectedTensorProductRescale):
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
126 | 
127 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:127:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
125 | class FullyConnectedTensorProductRescaleSwishGate(FullyConnectedTensorProductRescale):
126 | 
127 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
    |         ^^^^^^^^ PLR0913
128 |         bias=True, rescale=True,
129 |         internal_weights=None, shared_weights=None,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:127:9: D107 Missing docstring in `__init__`
    |
125 | class FullyConnectedTensorProductRescaleSwishGate(FullyConnectedTensorProductRescale):
126 | 
127 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
    |         ^^^^^^^^ D107
128 |         bias=True, rescale=True,
129 |         internal_weights=None, shared_weights=None,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:128:9: FBT002 Boolean default positional argument in function definition
    |
127 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
128 |         bias=True, rescale=True,
    |         ^^^^ FBT002
129 |         internal_weights=None, shared_weights=None,
130 |         normalization=None):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:128:20: FBT002 Boolean default positional argument in function definition
    |
127 |     def __init__(self, irreps_in1, irreps_in2, irreps_out,
128 |         bias=True, rescale=True,
    |                    ^^^^^^^ FBT002
129 |         internal_weights=None, shared_weights=None,
130 |         normalization=None):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:148:9: D102 Missing docstring in public method
    |
148 |     def forward(self, x, y, weight=None):
    |         ^^^^^^^ D102
149 |         out = self.forward_tp_rescale_bias(x, y, weight)
150 |         return self.gate(out)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:153:5: N802 Function name `DepthwiseTensorProduct` should be lowercase
    |
153 | def DepthwiseTensorProduct(irreps_node_input, irreps_edge_attr, irreps_node_output,
    |     ^^^^^^^^^^^^^^^^^^^^^^ N802
154 |     internal_weights=False, bias=True):
155 |     """The irreps of output is pre-determined.
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:154:5: FBT002 Boolean default positional argument in function definition
    |
153 | def DepthwiseTensorProduct(irreps_node_input, irreps_edge_attr, irreps_node_output,
154 |     internal_weights=False, bias=True):
    |     ^^^^^^^^^^^^^^^^ FBT002
155 |     """The irreps of output is pre-determined.
156 |     `irreps_node_output` is used to get certain types of vectors.
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:154:29: FBT002 Boolean default positional argument in function definition
    |
153 | def DepthwiseTensorProduct(irreps_node_input, irreps_edge_attr, irreps_node_output,
154 |     internal_weights=False, bias=True):
    |                             ^^^^ FBT002
155 |     """The irreps of output is pre-determined.
156 |     `irreps_node_output` is used to get certain types of vectors.
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:155:5: D205 1 blank line required between summary line and description
    |
153 |   def DepthwiseTensorProduct(irreps_node_input, irreps_edge_attr, irreps_node_output,
154 |       internal_weights=False, bias=True):
155 |       """The irreps of output is pre-determined.
    |  _____^
156 | |     `irreps_node_output` is used to get certain types of vectors.
157 | |     """
    | |_______^ D205
158 |       irreps_output = []
159 |       instructions = []
    |
    = help: Insert single blank line

geom3d\models\Equiformer\equiformer_type_0_periodic.py:155:5: D401 First line of docstring should be in imperative mood: "The irreps of output is pre-determined."
    |
153 |   def DepthwiseTensorProduct(irreps_node_input, irreps_edge_attr, irreps_node_output,
154 |       internal_weights=False, bias=True):
155 |       """The irreps of output is pre-determined.
    |  _____^
156 | |     `irreps_node_output` is used to get certain types of vectors.
157 | |     """
    | |_______^ D401
158 |       irreps_output = []
159 |       instructions = []
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:183:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
181 |     """Use separable FCTP for spatial convolution."""
182 | 
183 |     def __init__(self, irreps_node_input, irreps_edge_attr, irreps_node_output,
    |         ^^^^^^^^ PLR0913
184 |         fc_neurons, use_activation=False, norm_layer="graph",
185 |         internal_weights=False):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:183:9: D107 Missing docstring in `__init__`
    |
181 |     """Use separable FCTP for spatial convolution."""
182 | 
183 |     def __init__(self, irreps_node_input, irreps_edge_attr, irreps_node_output,
    |         ^^^^^^^^ D107
184 |         fc_neurons, use_activation=False, norm_layer="graph",
185 |         internal_weights=False):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:184:21: FBT002 Boolean default positional argument in function definition
    |
183 |     def __init__(self, irreps_node_input, irreps_edge_attr, irreps_node_output,
184 |         fc_neurons, use_activation=False, norm_layer="graph",
    |                     ^^^^^^^^^^^^^^ FBT002
185 |         internal_weights=False):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:185:9: FBT002 Boolean default positional argument in function definition
    |
183 |     def __init__(self, irreps_node_input, irreps_edge_attr, irreps_node_output,
184 |         fc_neurons, use_activation=False, norm_layer="graph",
185 |         internal_weights=False):
    |         ^^^^^^^^^^^^^^^^ FBT002
186 | 
187 |         super().__init__()
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:199:18: A001 Variable `slice` is shadowing a Python builtin
    |
197 |         if fc_neurons is not None:
198 |             self.dtp_rad = RadialProfile([*fc_neurons, self.dtp.tp.weight_numel])
199 |             for (slice, slice_sqrt_k) in self.dtp.slices_sqrt_k.values():
    |                  ^^^^^ A001
200 |                 self.dtp_rad.net[-1].weight.data[slice, :] *= slice_sqrt_k
201 |                 self.dtp_rad.offset.data[slice] *= slice_sqrt_k
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:227:72: ANN003 Missing type annotation for `**kwargs`
    |
227 |     def forward(self, node_input, edge_attr, edge_scalars, batch=None, **kwargs):
    |                                                                        ^^^^^^^^ ANN003
228 |         """Depthwise TP: `node_input` TP `edge_attr`, with TP parametrized by
229 |         self.dtp_rad(`edge_scalars`).
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:227:74: ARG002 Unused method argument: `kwargs`
    |
227 |     def forward(self, node_input, edge_attr, edge_scalars, batch=None, **kwargs):
    |                                                                          ^^^^^^ ARG002
228 |         """Depthwise TP: `node_input` TP `edge_attr`, with TP parametrized by
229 |         self.dtp_rad(`edge_scalars`).
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:228:9: D205 1 blank line required between summary line and description
    |
227 |       def forward(self, node_input, edge_attr, edge_scalars, batch=None, **kwargs):
228 |           """Depthwise TP: `node_input` TP `edge_attr`, with TP parametrized by
    |  _________^
229 | |         self.dtp_rad(`edge_scalars`).
230 | |         """
    | |___________^ D205
231 |           weight = None
232 |           if self.dtp_rad is not None and edge_scalars is not None:
    |
    = help: Insert single blank line

geom3d\models\Equiformer\equiformer_type_0_periodic.py:245:5: D205 1 blank line required between summary line and description
    |
243 |   @compile_mode("script")
244 |   class Vec2AttnHeads(torch.nn.Module):
245 |       """Reshape vectors of shape [N, irreps_mid] to vectors of shape
    |  _____^
246 | |     [N, num_heads, irreps_head].
247 | |     """
    | |_______^ D205
248 |   
249 |       def __init__(self, irreps_head, num_heads):
    |
    = help: Insert single blank line

geom3d\models\Equiformer\equiformer_type_0_periodic.py:249:9: D107 Missing docstring in `__init__`
    |
247 |     """
248 | 
249 |     def __init__(self, irreps_head, num_heads):
    |         ^^^^^^^^ D107
250 |         super().__init__()
251 |         self.num_heads = num_heads
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:264:9: D102 Missing docstring in public method
    |
264 |     def forward(self, x):
    |         ^^^^^^^ D102
265 |         N, _ = x.shape
266 |         out = []
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:265:9: N806 Variable `N` in function should be lowercase
    |
264 |     def forward(self, x):
265 |         N, _ = x.shape
    |         ^ N806
266 |         out = []
267 |         for _ir_idx, (start_idx, end_idx) in enumerate(self.mid_in_indices):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:274:9: D105 Missing docstring in magic method
    |
274 |     def __repr__(self):
    |         ^^^^^^^^ D105
275 |         return f"{self.__class__.__name__}(irreps_head={self.irreps_head}, num_heads={self.num_heads})"
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:280:5: D205 1 blank line required between summary line and description
    |
278 |   @compile_mode("script")
279 |   class AttnHeads2Vec(torch.nn.Module):
280 |       """Convert vectors of shape [N, num_heads, irreps_head] into
    |  _____^
281 | |     vectors of shape [N, irreps_head * num_heads].
282 | |     """
    | |_______^ D205
283 |   
284 |       def __init__(self, irreps_head):
    |
    = help: Insert single blank line

geom3d\models\Equiformer\equiformer_type_0_periodic.py:284:9: D107 Missing docstring in `__init__`
    |
282 |     """
283 | 
284 |     def __init__(self, irreps_head):
    |         ^^^^^^^^ D107
285 |         super().__init__()
286 |         self.irreps_head = irreps_head
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:294:9: D102 Missing docstring in public method
    |
294 |     def forward(self, x):
    |         ^^^^^^^ D102
295 |         N, _, _ = x.shape
296 |         out = []
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:295:9: N806 Variable `N` in function should be lowercase
    |
294 |     def forward(self, x):
295 |         N, _, _ = x.shape
    |         ^ N806
296 |         out = []
297 |         for _ir_idx, (start_idx, end_idx) in enumerate(self.head_indices):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:304:9: D105 Missing docstring in magic method
    |
304 |     def __repr__(self):
    |         ^^^^^^^^ D105
305 |         return f"{self.__class__.__name__}(irreps_head={self.irreps_head})"
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:308:7: D101 Missing docstring in public class
    |
308 | class ConcatIrrepsTensor(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^^^ D101
309 | 
310 |     def __init__(self, irreps_1, irreps_2):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:310:9: D107 Missing docstring in `__init__`
    |
308 | class ConcatIrrepsTensor(torch.nn.Module):
309 | 
310 |     def __init__(self, irreps_1, irreps_2):
    |         ^^^^^^^^ D107
311 |         super().__init__()
312 |         assert irreps_1 == irreps_1.simplify()
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:312:9: S101 Use of `assert` detected
    |
310 |     def __init__(self, irreps_1, irreps_2):
311 |         super().__init__()
312 |         assert irreps_1 == irreps_1.simplify()
    |         ^^^^^^ S101
313 |         self.check_sorted(irreps_1)
314 |         assert irreps_2 == irreps_2.simplify()
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:314:9: S101 Use of `assert` detected
    |
312 |         assert irreps_1 == irreps_1.simplify()
313 |         self.check_sorted(irreps_1)
314 |         assert irreps_2 == irreps_2.simplify()
    |         ^^^^^^ S101
315 |         self.check_sorted(irreps_2)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:346:9: D102 Missing docstring in public method
    |
346 |     def get_irreps_dim(self, irreps):
    |         ^^^^^^^^^^^^^^ D102
347 |         muls = []
348 |         for mul, ir in irreps:
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:353:9: D102 Missing docstring in public method
    |
353 |     def check_sorted(self, irreps):
    |         ^^^^^^^^^^^^ D102
354 |         lmax = None
355 |         p = None
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:362:17: S101 Use of `assert` detected
    |
360 |                 continue
361 |             if ir.l == lmax:
362 |                 assert p < ir.p, f"Parity order error: {irreps}"
    |                 ^^^^^^ S101
363 |             assert lmax <= ir.l
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:363:13: S101 Use of `assert` detected
    |
361 |             if ir.l == lmax:
362 |                 assert p < ir.p, f"Parity order error: {irreps}"
363 |             assert lmax <= ir.l
    |             ^^^^^^ S101
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:366:9: D102 Missing docstring in public method
    |
366 |     def get_ir_index(self, ir, irreps):
    |         ^^^^^^^^^^^^ D102
367 |         for index, (_, irrep) in enumerate(irreps):
368 |             if irrep == ir:
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:373:9: D102 Missing docstring in public method
    |
373 |     def forward(self, feature_1, feature_2):
    |         ^^^^^^^ D102
374 | 
375 |         output = []
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:385:9: D105 Missing docstring in magic method
    |
385 |     def __repr__(self):
    |         ^^^^^^^^ D105
386 |         return f"{self.__class__.__name__}(irreps_1={self.irreps_1}, irreps_2={self.irreps_2})"
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:391:5: D205 1 blank line required between summary line and description
    |
389 |   @compile_mode("script")
390 |   class GraphAttention(torch.nn.Module):
391 |       """1. Message = Alpha * Value
    |  _____^
392 | |     2. Two Linear to merge src and dst -> Separable FCTP -> 0e + (0e+1e+...)
393 | |     3. 0e -> Activation -> Inner Product -> (Alpha)
394 | |     4. (0e+1e+...) -> (Value).
395 | |     """
    | |_______^ D205
396 |   
397 |       def __init__(self,
    |
    = help: Insert single blank line

geom3d\models\Equiformer\equiformer_type_0_periodic.py:397:9: PLR0913 Too many arguments in function definition (12 > 5)
    |
395 |     """
396 | 
397 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
398 |         irreps_node_input, irreps_node_attr,
399 |         irreps_edge_attr, irreps_node_output,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:397:9: D107 Missing docstring in `__init__`
    |
395 |     """
396 | 
397 |     def __init__(self,
    |         ^^^^^^^^ D107
398 |         irreps_node_input, irreps_node_attr,
399 |         irreps_edge_attr, irreps_node_output,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:402:9: FBT002 Boolean default positional argument in function definition
    |
400 |         fc_neurons,
401 |         irreps_head, num_heads, irreps_pre_attn=None,
402 |         rescale_degree=False, nonlinear_message=False,
    |         ^^^^^^^^^^^^^^ FBT002
403 |         alpha_drop=0.1, proj_drop=0.1):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:402:31: FBT002 Boolean default positional argument in function definition
    |
400 |         fc_neurons,
401 |         irreps_head, num_heads, irreps_pre_attn=None,
402 |         rescale_degree=False, nonlinear_message=False,
    |                               ^^^^^^^^^^^^^^^^^ FBT002
403 |         alpha_drop=0.1, proj_drop=0.1):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:469:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
469 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
    |         ^^^^^^^ PLR0913
470 |         batch, **kwargs):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:469:9: D102 Missing docstring in public method
    |
469 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
    |         ^^^^^^^ D102
470 |         batch, **kwargs):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:469:35: ARG002 Unused method argument: `node_attr`
    |
469 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
    |                                   ^^^^^^^^^ ARG002
470 |         batch, **kwargs):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:470:9: ARG002 Unused method argument: `batch`
    |
469 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
470 |         batch, **kwargs):
    |         ^^^^^ ARG002
471 | 
472 |         message_src = self.merge_src(node_input)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:470:16: ANN003 Missing type annotation for `**kwargs`
    |
469 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
470 |         batch, **kwargs):
    |                ^^^^^^^^ ANN003
471 | 
472 |         message_src = self.merge_src(node_input)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:470:18: ARG002 Unused method argument: `kwargs`
    |
469 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
470 |         batch, **kwargs):
    |                  ^^^^^^ ARG002
471 | 
472 |         message_src = self.merge_src(node_input)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:517:9: D102 Missing docstring in public method
    |
517 |     def extra_repr(self):
    |         ^^^^^^^^^^ D102
518 |         output_str = super().extra_repr()
519 |         return output_str + f"rescale_degree={self.rescale_degree}, "
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:526:9: D107 Missing docstring in `__init__`
    |
524 |     """Use two (FCTP + Gate)."""
525 | 
526 |     def __init__(self,
    |         ^^^^^^^^ D107
527 |         irreps_node_input, irreps_node_attr,
528 |         irreps_node_output, irreps_mlp_mid=None,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:551:9: D102 Missing docstring in public method
    |
551 |     def forward(self, node_input, node_attr, **kwargs):
    |         ^^^^^^^ D102
552 |         node_output = self.fctp_1(node_input, node_attr)
553 |         node_output = self.fctp_2(node_output, node_attr)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:551:46: ANN003 Missing type annotation for `**kwargs`
    |
551 |     def forward(self, node_input, node_attr, **kwargs):
    |                                              ^^^^^^^^ ANN003
552 |         node_output = self.fctp_1(node_input, node_attr)
553 |         node_output = self.fctp_2(node_output, node_attr)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:551:48: ARG002 Unused method argument: `kwargs`
    |
551 |     def forward(self, node_input, node_attr, **kwargs):
    |                                                ^^^^^^ ARG002
552 |         node_output = self.fctp_1(node_input, node_attr)
553 |         node_output = self.fctp_2(node_output, node_attr)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:561:5: D205 1 blank line required between summary line and description
    |
559 |   @compile_mode("script")
560 |   class TransBlock(torch.nn.Module):
561 |       """1. Layer Norm 1 -> GraphAttention -> Layer Norm 2 -> FeedForwardNetwork
    |  _____^
562 | |     2. Use pre-norm architecture.
563 | |     """
    | |_______^ D205
564 |   
565 |       def __init__(self,
    |
    = help: Insert single blank line

geom3d\models\Equiformer\equiformer_type_0_periodic.py:565:9: PLR0913 Too many arguments in function definition (15 > 5)
    |
563 |     """
564 | 
565 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
566 |         irreps_node_input, irreps_node_attr,
567 |         irreps_edge_attr, irreps_node_output,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:565:9: D107 Missing docstring in `__init__`
    |
563 |     """
564 | 
565 |     def __init__(self,
    |         ^^^^^^^^ D107
566 |         irreps_node_input, irreps_node_attr,
567 |         irreps_edge_attr, irreps_node_output,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:570:9: FBT002 Boolean default positional argument in function definition
    |
568 |         fc_neurons,
569 |         irreps_head, num_heads, irreps_pre_attn=None,
570 |         rescale_degree=False, nonlinear_message=False,
    |         ^^^^^^^^^^^^^^ FBT002
571 |         alpha_drop=0.1, proj_drop=0.1,
572 |         drop_path_rate=0.0,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:570:31: FBT002 Boolean default positional argument in function definition
    |
568 |         fc_neurons,
569 |         irreps_head, num_heads, irreps_pre_attn=None,
570 |         rescale_degree=False, nonlinear_message=False,
    |                               ^^^^^^^^^^^^^^^^^ FBT002
571 |         alpha_drop=0.1, proj_drop=0.1,
572 |         drop_path_rate=0.0,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:623:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
623 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
    |         ^^^^^^^ PLR0913
624 |         batch, **kwargs):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:623:9: D102 Missing docstring in public method
    |
623 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
    |         ^^^^^^^ D102
624 |         batch, **kwargs):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:624:16: ANN003 Missing type annotation for `**kwargs`
    |
623 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
624 |         batch, **kwargs):
    |                ^^^^^^^^ ANN003
625 | 
626 |         node_output = node_input
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:624:18: ARG002 Unused method argument: `kwargs`
    |
623 |     def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars,
624 |         batch, **kwargs):
    |                  ^^^^^^ ARG002
625 | 
626 |         node_output = node_input
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:629:9: ERA001 Found commented-out code
    |
627 |         node_features = node_input
628 |         node_features = self.norm_1(node_features, batch=batch)
629 |         #norm_1_output = node_features
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
630 |         node_features = self.ga(node_input=node_features,
631 |             node_attr=node_attr,
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_0_periodic.py:642:9: ERA001 Found commented-out code
    |
640 |         node_features = node_output
641 |         node_features = self.norm_2(node_features, batch=batch)
642 |         #node_features = self.concat_norm_output(norm_1_output, node_features)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
643 |         node_features = self.ffn(node_features, node_attr)
644 |         if self.ffn_shortcut is not None:
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_0_periodic.py:653:7: D101 Missing docstring in public class
    |
653 | class NodeEmbeddingNetwork(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^^^^^ D101
654 | 
655 |     def __init__(self, irreps_node_embedding, max_atom_type, bias=True):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:655:9: D107 Missing docstring in `__init__`
    |
653 | class NodeEmbeddingNetwork(torch.nn.Module):
654 | 
655 |     def __init__(self, irreps_node_embedding, max_atom_type, bias=True):
    |         ^^^^^^^^ D107
656 | 
657 |         super().__init__()
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:655:62: FBT002 Boolean default positional argument in function definition
    |
653 | class NodeEmbeddingNetwork(torch.nn.Module):
654 | 
655 |     def __init__(self, irreps_node_embedding, max_atom_type, bias=True):
    |                                                              ^^^^ FBT002
656 | 
657 |         super().__init__()
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:674:7: D101 Missing docstring in public class
    |
674 | class ScaledScatter(torch.nn.Module):
    |       ^^^^^^^^^^^^^ D101
675 |     def __init__(self, avg_aggregate_num):
676 |         super().__init__()
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:675:9: D107 Missing docstring in `__init__`
    |
674 | class ScaledScatter(torch.nn.Module):
675 |     def __init__(self, avg_aggregate_num):
    |         ^^^^^^^^ D107
676 |         super().__init__()
677 |         self.avg_aggregate_num = avg_aggregate_num + 0.0
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:680:9: D102 Missing docstring in public method
    |
680 |     def forward(self, x, index, **kwargs):
    |         ^^^^^^^ D102
681 |         out = scatter(x, index, reduce=REDUCE, **kwargs)
682 |         return out.div(self.avg_aggregate_num ** 0.5)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:680:33: ANN003 Missing type annotation for `**kwargs`
    |
680 |     def forward(self, x, index, **kwargs):
    |                                 ^^^^^^^^ ANN003
681 |         out = scatter(x, index, reduce=REDUCE, **kwargs)
682 |         return out.div(self.avg_aggregate_num ** 0.5)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:685:9: D102 Missing docstring in public method
    |
685 |     def extra_repr(self):
    |         ^^^^^^^^^^ D102
686 |         return f"avg_aggregate_num={self.avg_aggregate_num}"
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:689:7: D101 Missing docstring in public class
    |
689 | class EdgeDegreeEmbeddingNetwork(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
690 |     def __init__(self, irreps_node_embedding, irreps_edge_attr, fc_neurons, avg_aggregate_num):
691 |         super().__init__()
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:690:9: D107 Missing docstring in `__init__`
    |
689 | class EdgeDegreeEmbeddingNetwork(torch.nn.Module):
690 |     def __init__(self, irreps_node_embedding, irreps_edge_attr, fc_neurons, avg_aggregate_num):
    |         ^^^^^^^^ D107
691 |         super().__init__()
692 |         self.exp = LinearRS(o3.Irreps("1x0e"), irreps_node_embedding,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:698:14: A001 Variable `slice` is shadowing a Python builtin
    |
696 |             internal_weights=False, bias=False)
697 |         self.rad = RadialProfile([*fc_neurons, self.dw.tp.weight_numel])
698 |         for (slice, slice_sqrt_k) in self.dw.slices_sqrt_k.values():
    |              ^^^^^ A001
699 |             self.rad.net[-1].weight.data[slice, :] *= slice_sqrt_k
700 |             self.rad.offset.data[slice] *= slice_sqrt_k
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:705:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
705 |     def forward(self, node_input, edge_attr, edge_scalars, edge_src, edge_dst, batch):
    |         ^^^^^^^ PLR0913
706 |         node_features = torch.ones_like(node_input.narrow(1, 0, 1))
707 |         node_features = self.exp(node_features)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:705:9: D102 Missing docstring in public method
    |
705 |     def forward(self, node_input, edge_attr, edge_scalars, edge_src, edge_dst, batch):
    |         ^^^^^^^ D102
706 |         node_features = torch.ones_like(node_input.narrow(1, 0, 1))
707 |         node_features = self.exp(node_features)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:705:80: ARG002 Unused method argument: `batch`
    |
705 |     def forward(self, node_input, edge_attr, edge_scalars, edge_src, edge_dst, batch):
    |                                                                                ^^^^^ ARG002
706 |         node_features = torch.ones_like(node_input.narrow(1, 0, 1))
707 |         node_features = self.exp(node_features)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:715:7: D101 Missing docstring in public class
    |
715 | class EquiformerEnergyPeriodic(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^^^^^^^^^ D101
716 |     def __init__(self,
717 |         irreps_in="5x0e",
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:716:9: PLR0913 Too many arguments in function definition (24 > 5)
    |
715 | class EquiformerEnergyPeriodic(torch.nn.Module):
716 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
717 |         irreps_in="5x0e",
718 |         irreps_node_embedding="128x0e+64x1e+32x2e", node_class=119, num_layers=6,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:716:9: D107 Missing docstring in `__init__`
    |
715 | class EquiformerEnergyPeriodic(torch.nn.Module):
716 |     def __init__(self,
    |         ^^^^^^^^ D107
717 |         irreps_in="5x0e",
718 |         irreps_node_embedding="128x0e+64x1e+32x2e", node_class=119, num_layers=6,
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:724:9: FBT002 Boolean default positional argument in function definition
    |
722 |         irreps_feature="512x0e",
723 |         irreps_head="32x0e+16x1o+8x2e", num_heads=4, irreps_pre_attn=None,
724 |         rescale_degree=False, nonlinear_message=False,
    |         ^^^^^^^^^^^^^^ FBT002
725 |         irreps_mlp_mid="128x0e+64x1e+32x2e",
726 |         norm_layer="layer",
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:724:31: FBT002 Boolean default positional argument in function definition
    |
722 |         irreps_feature="512x0e",
723 |         irreps_head="32x0e+16x1o+8x2e", num_heads=4, irreps_pre_attn=None,
724 |         rescale_degree=False, nonlinear_message=False,
    |                               ^^^^^^^^^^^^^^^^^ FBT002
725 |         irreps_mlp_mid="128x0e+64x1e+32x2e",
726 |         norm_layer="layer",
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:742:9: ERA001 Found commented-out code
    |
740 |         self.drop_path_rate = drop_path_rate
741 |         self.norm_layer = norm_layer
742 |         # self.task_mean = mean
    |         ^^^^^^^^^^^^^^^^^^^^^^^ ERA001
743 |         # self.task_std = std
744 |         self.scale = scale
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_0_periodic.py:743:9: ERA001 Found commented-out code
    |
741 |         self.norm_layer = norm_layer
742 |         # self.task_mean = mean
743 |         # self.task_std = std
    |         ^^^^^^^^^^^^^^^^^^^^^ ERA001
744 |         self.scale = scale
745 |         self.register_buffer("atomref", atomref)
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\equiformer_type_0_periodic.py:791:9: D102 Missing docstring in public method
    |
791 |     def build_blocks(self):
    |         ^^^^^^^^^^^^ D102
792 |         for i in range(self.num_layers):
793 |             if i != (self.num_layers - 1):
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:825:9: D102 Missing docstring in public method
    |
824 |     @torch.jit.ignore
825 |     def no_weight_decay(self):
    |         ^^^^^^^^^^^^^^^ D102
826 |         no_wd_list = []
827 |         named_parameters_list = [name for name, _ in self.named_parameters()]
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:834:21: S101 Use of `assert` detected
    |
832 |                         continue
833 |                     global_parameter_name = module_name + "." + parameter_name
834 |                     assert global_parameter_name in named_parameters_list
    |                     ^^^^^^ S101
835 |                     no_wd_list.append(global_parameter_name)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:839:9: D102 Missing docstring in public method
    |
837 |         return set(no_wd_list)
838 | 
839 |     def forward(self, pos, batch, node_atom, edge_index, **kwargs) -> torch.Tensor:
    |         ^^^^^^^ D102
840 |         edge_src, edge_dst = edge_index
841 |         edge_vec = pos.index_select(0, edge_src) - pos.index_select(0, edge_dst)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:839:58: ANN003 Missing type annotation for `**kwargs`
    |
837 |         return set(no_wd_list)
838 | 
839 |     def forward(self, pos, batch, node_atom, edge_index, **kwargs) -> torch.Tensor:
    |                                                          ^^^^^^^^ ANN003
840 |         edge_src, edge_dst = edge_index
841 |         edge_vec = pos.index_select(0, edge_src) - pos.index_select(0, edge_dst)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:839:60: ARG002 Unused method argument: `kwargs`
    |
837 |         return set(no_wd_list)
838 | 
839 |     def forward(self, pos, batch, node_atom, edge_index, **kwargs) -> torch.Tensor:
    |                                                            ^^^^^^ ARG002
840 |         edge_src, edge_dst = edge_index
841 |         edge_vec = pos.index_select(0, edge_src) - pos.index_select(0, edge_dst)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:866:9: D102 Missing docstring in public method
    |
866 |     def forward_with_gathered_index(self, pos, batch, node_atom, edge_index, periodic_index_mapping, **kwargs) -> torch.Tensor:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
867 |         edge_src, edge_dst = edge_index
868 |         edge_vec = pos.index_select(0, edge_src) - pos.index_select(0, edge_dst)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:866:102: ANN003 Missing type annotation for `**kwargs`
    |
866 |     def forward_with_gathered_index(self, pos, batch, node_atom, edge_index, periodic_index_mapping, **kwargs) -> torch.Tensor:
    |                                                                                                      ^^^^^^^^ ANN003
867 |         edge_src, edge_dst = edge_index
868 |         edge_vec = pos.index_select(0, edge_src) - pos.index_select(0, edge_dst)
    |

geom3d\models\Equiformer\equiformer_type_0_periodic.py:866:104: ARG002 Unused method argument: `kwargs`
    |
866 |     def forward_with_gathered_index(self, pos, batch, node_atom, edge_index, periodic_index_mapping, **kwargs) -> torch.Tensor:
    |                                                                                                        ^^^^^^ ARG002
867 |         edge_src, edge_dst = edge_index
868 |         edge_vec = pos.index_select(0, edge_src) - pos.index_select(0, edge_dst)
    |

geom3d\models\Equiformer\expnorm_rbf.py:1:1: D100 Missing docstring in public module
geom3d\models\Equiformer\expnorm_rbf.py:6:7: D101 Missing docstring in public class
  |
6 | class CosineCutoff(torch.nn.Module):
  |       ^^^^^^^^^^^^ D101
7 |     def __init__(self, cutoff_lower=0.0, cutoff_upper=5.0):
8 |         super().__init__()
  |

geom3d\models\Equiformer\expnorm_rbf.py:7:9: D107 Missing docstring in `__init__`
  |
6 | class CosineCutoff(torch.nn.Module):
7 |     def __init__(self, cutoff_lower=0.0, cutoff_upper=5.0):
  |         ^^^^^^^^ D107
8 |         super().__init__()
9 |         self.cutoff_lower = cutoff_lower
  |

geom3d\models\Equiformer\expnorm_rbf.py:12:9: D102 Missing docstring in public method
   |
10 |         self.cutoff_upper = cutoff_upper
11 | 
12 |     def forward(self, distances):
   |         ^^^^^^^ D102
13 |         if self.cutoff_lower > 0:
14 |             cutoffs = 0.5 * (
   |

geom3d\models\Equiformer\expnorm_rbf.py:29:9: RET505 Unnecessary `else` after `return` statement
   |
27 |             cutoffs = cutoffs * (distances < self.cutoff_upper).float()
28 |             return cutoffs * (distances > self.cutoff_lower).float()
29 |         else:
   |         ^^^^ RET505
30 |             cutoffs = 0.5 * (torch.cos(distances * math.pi / self.cutoff_upper) + 1.0)
31 |             # remove contributions beyond the cutoff radius
   |
   = help: Remove unnecessary `else`

geom3d\models\Equiformer\expnorm_rbf.py:36:7: D101 Missing docstring in public class
   |
35 | # https://github.com/torchmd/torchmd-net/blob/main/torchmdnet/models/utils.py#L111
36 | class ExpNormalSmearing(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^^^ D101
37 |     def __init__(self, cutoff_lower=0.0, cutoff_upper=5.0, num_rbf=50, trainable=False):
38 |         super().__init__()
   |

geom3d\models\Equiformer\expnorm_rbf.py:37:9: D107 Missing docstring in `__init__`
   |
35 | # https://github.com/torchmd/torchmd-net/blob/main/torchmdnet/models/utils.py#L111
36 | class ExpNormalSmearing(torch.nn.Module):
37 |     def __init__(self, cutoff_lower=0.0, cutoff_upper=5.0, num_rbf=50, trainable=False):
   |         ^^^^^^^^ D107
38 |         super().__init__()
39 |         self.cutoff_lower = cutoff_lower
   |

geom3d\models\Equiformer\expnorm_rbf.py:37:72: FBT002 Boolean default positional argument in function definition
   |
35 | # https://github.com/torchmd/torchmd-net/blob/main/torchmdnet/models/utils.py#L111
36 | class ExpNormalSmearing(torch.nn.Module):
37 |     def __init__(self, cutoff_lower=0.0, cutoff_upper=5.0, num_rbf=50, trainable=False):
   |                                                                        ^^^^^^^^^ FBT002
38 |         super().__init__()
39 |         self.cutoff_lower = cutoff_lower
   |

geom3d\models\Equiformer\expnorm_rbf.py:49:46: F821 Undefined name `nn`
   |
47 |         means, betas = self._initial_params()
48 |         if trainable:
49 |             self.register_parameter("means", nn.Parameter(means))
   |                                              ^^ F821
50 |             self.register_parameter("betas", nn.Parameter(betas))
51 |         else:
   |

geom3d\models\Equiformer\expnorm_rbf.py:50:46: F821 Undefined name `nn`
   |
48 |         if trainable:
49 |             self.register_parameter("means", nn.Parameter(means))
50 |             self.register_parameter("betas", nn.Parameter(betas))
   |                                              ^^ F821
51 |         else:
52 |             self.register_buffer("means", means)
   |

geom3d\models\Equiformer\expnorm_rbf.py:55:9: ANN202 Missing return type annotation for private function `_initial_params`
   |
53 |             self.register_buffer("betas", betas)
54 | 
55 |     def _initial_params(self):
   |         ^^^^^^^^^^^^^^^ ANN202
56 |         # initialize means and betas according to the default values in PhysNet
57 |         # https://pubs.acs.org/doi/10.1021/acs.jctc.9b00181
   |
   = help: Add return type annotation

geom3d\models\Equiformer\expnorm_rbf.py:67:9: D102 Missing docstring in public method
   |
65 |         return means, betas
66 | 
67 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
68 |         means, betas = self._initial_params()
69 |         self.means.data.copy_(means)
   |

geom3d\models\Equiformer\expnorm_rbf.py:72:9: D102 Missing docstring in public method
   |
70 |         self.betas.data.copy_(betas)
71 | 
72 |     def forward(self, dist):
   |         ^^^^^^^ D102
73 |         dist = dist.unsqueeze(-1)
74 |         return self.cutoff_fn(dist) * torch.exp(
   |

geom3d\models\Equiformer\fast_activation.py:16:9: D107 Missing docstring in `__init__`
   |
14 |     """Directly apply activation when irreps is type-0."""
15 | 
16 |     def __init__(self, irreps_in, acts):
   |         ^^^^^^^^ D107
17 |         super().__init__()
18 |         irreps_in = o3.Irreps(irreps_in)
   |

geom3d\models\Equiformer\fast_activation.py:19:9: S101 Use of `assert` detected
   |
17 |         super().__init__()
18 |         irreps_in = o3.Irreps(irreps_in)
19 |         assert len(irreps_in) == len(acts), (irreps_in, acts)
   |         ^^^^^^ S101
20 | 
21 |         # normalize the second moment
   |

geom3d\models\Equiformer\fast_activation.py:36:44: PLR2004 Magic value used in comparison, consider replacing `1e-5` with a constant variable
   |
35 |                 a1, a2 = act(x), act(-x)
36 |                 if (a1 - a2).abs().max() < 1e-5:
   |                                            ^^^^ PLR2004
37 |                     p_act = 1
38 |                 elif (a1 + a2).abs().max() < 1e-5:
   |

geom3d\models\Equiformer\fast_activation.py:38:46: PLR2004 Magic value used in comparison, consider replacing `1e-5` with a constant variable
   |
36 |                 if (a1 - a2).abs().max() < 1e-5:
37 |                     p_act = 1
38 |                 elif (a1 + a2).abs().max() < 1e-5:
   |                                              ^^^^ PLR2004
39 |                     p_act = -1
40 |                 else:
   |

geom3d\models\Equiformer\fast_activation.py:55:9: S101 Use of `assert` detected
   |
53 |         self.irreps_out = o3.Irreps(irreps_out)
54 |         self.acts = torch.nn.ModuleList(acts)
55 |         assert len(self.irreps_in) == len(self.acts)
   |         ^^^^^^ S101
   |

geom3d\models\Equiformer\fast_activation.py:59:5: ERA001 Found commented-out code
   |
58 |     #def __repr__(self):
59 |     #    acts = "".join(["x" if a is not None else " " for a in self.acts])
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
60 |     #    return f"{self.__class__.__name__} [{self.acts}] ({self.irreps_in} -> {self.irreps_out})"
61 |     def extra_repr(self):
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\fast_activation.py:60:5: ERA001 Found commented-out code
   |
58 |     #def __repr__(self):
59 |     #    acts = "".join(["x" if a is not None else " " for a in self.acts])
60 |     #    return f"{self.__class__.__name__} [{self.acts}] ({self.irreps_in} -> {self.irreps_out})"
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
61 |     def extra_repr(self):
62 |         output_str = super().extra_repr()
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\fast_activation.py:61:9: D102 Missing docstring in public method
   |
59 |     #    acts = "".join(["x" if a is not None else " " for a in self.acts])
60 |     #    return f"{self.__class__.__name__} [{self.acts}] ({self.irreps_in} -> {self.irreps_out})"
61 |     def extra_repr(self):
   |         ^^^^^^^^^^ D102
62 |         output_str = super().extra_repr()
63 |         return output_str + f"{self.irreps_in} -> {self.irreps_out}, "
   |

geom3d\models\Equiformer\fast_activation.py:66:9: D102 Missing docstring in public method
   |
66 |     def forward(self, features, dim=-1):
   |         ^^^^^^^ D102
67 |         # directly apply activation without narrow
68 |         if len(self.acts) == 1:
   |

geom3d\models\Equiformer\fast_activation.py:82:9: RET505 Unnecessary `elif` after `return` statement
   |
80 |         if len(output) > 1:
81 |             return torch.cat(output, dim=dim)
82 |         elif len(output) == 1:
   |         ^^^^ RET505
83 |             return output[0]
84 |         else:
   |
   = help: Remove unnecessary `elif`

geom3d\models\Equiformer\fast_activation.py:90:5: D205 1 blank line required between summary line and description
   |
88 |   @compile_mode("script")
89 |   class Gate(torch.nn.Module):
90 |       """1. Use `narrow` to split tensor.
   |  _____^
91 | |     2. Use `Activation` in this file.
92 | |     """
   | |_______^ D205
93 |   
94 |       def __init__(self, irreps_scalars, act_scalars, irreps_gates, act_gates, irreps_gated):
   |
   = help: Insert single blank line

geom3d\models\Equiformer\fast_activation.py:94:9: D107 Missing docstring in `__init__`
   |
92 |     """
93 | 
94 |     def __init__(self, irreps_scalars, act_scalars, irreps_gates, act_gates, irreps_gated):
   |         ^^^^^^^^ D107
95 |         super().__init__()
96 |         irreps_scalars = o3.Irreps(irreps_scalars)
   |

geom3d\models\Equiformer\fast_activation.py:109:9: ERA001 Found commented-out code
    |
107 |             msg = f"There are {irreps_gated.num_irreps} irreps in irreps_gated, but a different number ({irreps_gates.num_irreps}) of gate scalars in irreps_gates"
108 |             raise ValueError(msg)
109 |         #assert len(irreps_scalars) == 1
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
110 |         #assert len(irreps_gates) == 1
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\fast_activation.py:110:9: ERA001 Found commented-out code
    |
108 |             raise ValueError(msg)
109 |         #assert len(irreps_scalars) == 1
110 |         #assert len(irreps_gates) == 1
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
111 | 
112 |         self.irreps_scalars = irreps_scalars
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\fast_activation.py:129:9: D105 Missing docstring in magic method
    |
129 |     def __repr__(self):
    |         ^^^^^^^^ D105
130 |         return f"{self.__class__.__name__} ({self.irreps_in} -> {self.irreps_out})"
    |

geom3d\models\Equiformer\fast_activation.py:133:9: D102 Missing docstring in public method
    |
133 |     def forward(self, features):
    |         ^^^^^^^ D102
134 |         scalars_dim = self.irreps_scalars.dim
135 |         gates_dim = self.irreps_gates.dim
    |

geom3d\models\Equiformer\fast_layer_norm.py:1:1: D100 Missing docstring in public module
geom3d\models\Equiformer\fast_layer_norm.py:2:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | import torch
2 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
3 | from e3nn.o3 import Irreps
4 | from torch import nn
  |

geom3d\models\Equiformer\fast_layer_norm.py:7:7: D101 Missing docstring in public class
  |
7 | class EquivariantLayerNormFast(nn.Module):
  |       ^^^^^^^^^^^^^^^^^^^^^^^^ D101
8 | 
9 |     def __init__(self, irreps, eps=1e-5, affine=True, normalization="component"):
  |

geom3d\models\Equiformer\fast_layer_norm.py:9:9: D107 Missing docstring in `__init__`
   |
 7 | class EquivariantLayerNormFast(nn.Module):
 8 | 
 9 |     def __init__(self, irreps, eps=1e-5, affine=True, normalization="component"):
   |         ^^^^^^^^ D107
10 |         super().__init__()
   |

geom3d\models\Equiformer\fast_layer_norm.py:9:42: FBT002 Boolean default positional argument in function definition
   |
 7 | class EquivariantLayerNormFast(nn.Module):
 8 | 
 9 |     def __init__(self, irreps, eps=1e-5, affine=True, normalization="component"):
   |                                          ^^^^^^ FBT002
10 |         super().__init__()
   |

geom3d\models\Equiformer\fast_layer_norm.py:26:9: S101 Use of `assert` detected
   |
24 |             self.register_parameter("affine_bias", None)
25 | 
26 |         assert normalization in ["norm", "component"], "normalization needs to be 'norm' or 'component'"
   |         ^^^^^^ S101
27 |         self.normalization = normalization
   |

geom3d\models\Equiformer\fast_layer_norm.py:30:9: D105 Missing docstring in magic method
   |
30 |     def __repr__(self):
   |         ^^^^^^^^ D105
31 |         return f"{self.__class__.__name__} ({self.irreps}, eps={self.eps})"
   |

geom3d\models\Equiformer\fast_layer_norm.py:34:35: ANN003 Missing type annotation for `**kwargs`
   |
34 |     def forward(self, node_input, **kwargs):
   |                                   ^^^^^^^^ ANN003
35 |         """Use torch layer norm for scalar features."""
36 |         dim = node_input.shape[-1]
   |

geom3d\models\Equiformer\fast_layer_norm.py:34:37: ARG002 Unused method argument: `kwargs`
   |
34 |     def forward(self, node_input, **kwargs):
   |                                     ^^^^^^ ARG002
35 |         """Use torch layer norm for scalar features."""
36 |         dim = node_input.shape[-1]
   |

geom3d\models\Equiformer\fast_layer_norm.py:78:9: S101 Use of `assert` detected
   |
76 |             fields.append(field.reshape(-1, mul * d))  # [batch * sample, mul * repr]
77 | 
78 |         assert ix == dim
   |         ^^^^^^ S101
79 | 
80 |         return torch.cat(fields, dim=-1)
   |

geom3d\models\Equiformer\gaussian_rbf.py:1:1: D100 Missing docstring in public module
geom3d\models\Equiformer\gaussian_rbf.py:5:5: D103 Missing docstring in public function
  |
4 | @torch.jit.script
5 | def gaussian(x, mean, std):
  |     ^^^^^^^^ D103
6 |     pi = 3.14159
7 |     a = (2*pi) ** 0.5
  |

geom3d\models\Equiformer\gaussian_rbf.py:12:7: D101 Missing docstring in public class
   |
11 | # From Graphormer
12 | class GaussianRadialBasisLayer(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^^^^^^^^^^ D101
13 |     def __init__(self, num_basis, cutoff):
14 |         super().__init__()
   |

geom3d\models\Equiformer\gaussian_rbf.py:13:9: D107 Missing docstring in `__init__`
   |
11 | # From Graphormer
12 | class GaussianRadialBasisLayer(torch.nn.Module):
13 |     def __init__(self, num_basis, cutoff):
   |         ^^^^^^^^ D107
14 |         super().__init__()
15 |         self.num_basis = num_basis
   |

geom3d\models\Equiformer\gaussian_rbf.py:32:9: D102 Missing docstring in public method
   |
32 |     def forward(self, dist, node_atom=None, edge_src=None, edge_dst=None):
   |         ^^^^^^^ D102
33 |         x = dist / self.cutoff
34 |         x = x.unsqueeze(-1)
   |

geom3d\models\Equiformer\gaussian_rbf.py:32:29: ARG002 Unused method argument: `node_atom`
   |
32 |     def forward(self, dist, node_atom=None, edge_src=None, edge_dst=None):
   |                             ^^^^^^^^^ ARG002
33 |         x = dist / self.cutoff
34 |         x = x.unsqueeze(-1)
   |

geom3d\models\Equiformer\gaussian_rbf.py:32:45: ARG002 Unused method argument: `edge_src`
   |
32 |     def forward(self, dist, node_atom=None, edge_src=None, edge_dst=None):
   |                                             ^^^^^^^^ ARG002
33 |         x = dist / self.cutoff
34 |         x = x.unsqueeze(-1)
   |

geom3d\models\Equiformer\gaussian_rbf.py:32:60: ARG002 Unused method argument: `edge_dst`
   |
32 |     def forward(self, dist, node_atom=None, edge_src=None, edge_dst=None):
   |                                                            ^^^^^^^^ ARG002
33 |         x = dist / self.cutoff
34 |         x = x.unsqueeze(-1)
   |

geom3d\models\Equiformer\gaussian_rbf.py:42:9: D102 Missing docstring in public method
   |
42 |     def extra_repr(self):
   |         ^^^^^^^^^^ D102
43 |         return f"mean_init_max={self.mean_init_max}, mean_init_min={self.mean_init_min}, std_init_max={self.std_init_max}, std_init_min={self.std_init_min}"
   |

geom3d\models\Equiformer\graph_norm.py:1:1: D100 Missing docstring in public module
geom3d\models\Equiformer\graph_norm.py:9:5: D205 1 blank line required between summary line and description
   |
 7 |   # From "Geometric and Physical Quantities improve E(3) Equivariant Message Passing"
 8 |   class EquivariantGraphNorm(nn.Module):
 9 |       """Instance normalization for orthonormal representations
   |  _____^
10 | |     It normalizes by the norm of the representations.
11 | |     Note that the norm is invariant only for orthonormal representations.
12 | |     Irreducible representations `wigner_D` are orthonormal.
13 | | 
14 | |     Parameters
15 | |     ----------
16 | |     irreps : `Irreps`
17 | |         representation
18 | |     eps : float
19 | |         avoid division by zero when we normalize by the variance
20 | |     affine : bool
21 | |         do we have weight and bias parameters
22 | |     reduce : {'mean', 'max'}
23 | |         method used to reduce
24 | | 
25 | |     """
   | |_______^ D205
26 |   
27 |       def __init__(self, irreps, eps=1e-5, affine=True, reduce="mean", normalization="component"):
   |
   = help: Insert single blank line

geom3d\models\Equiformer\graph_norm.py:27:9: D107 Missing docstring in `__init__`
   |
25 |     """
26 | 
27 |     def __init__(self, irreps, eps=1e-5, affine=True, reduce="mean", normalization="component"):
   |         ^^^^^^^^ D107
28 |         super().__init__()
   |

geom3d\models\Equiformer\graph_norm.py:27:42: FBT002 Boolean default positional argument in function definition
   |
25 |     """
26 | 
27 |     def __init__(self, irreps, eps=1e-5, affine=True, reduce="mean", normalization="component"):
   |                                          ^^^^^^ FBT002
28 |         super().__init__()
   |

geom3d\models\Equiformer\graph_norm.py:45:9: S101 Use of `assert` detected
   |
43 |             self.register_parameter("affine_bias", None)
44 | 
45 |         assert isinstance(reduce, str), "reduce should be passed as a string value"
   |         ^^^^^^ S101
46 |         assert reduce in ["mean", "max"], "reduce needs to be 'mean' or 'max'"
47 |         self.reduce = reduce
   |

geom3d\models\Equiformer\graph_norm.py:46:9: S101 Use of `assert` detected
   |
45 |         assert isinstance(reduce, str), "reduce should be passed as a string value"
46 |         assert reduce in ["mean", "max"], "reduce needs to be 'mean' or 'max'"
   |         ^^^^^^ S101
47 |         self.reduce = reduce
   |

geom3d\models\Equiformer\graph_norm.py:49:9: S101 Use of `assert` detected
   |
47 |         self.reduce = reduce
48 | 
49 |         assert normalization in ["norm", "component"], "normalization needs to be 'norm' or 'component'"
   |         ^^^^^^ S101
50 |         self.normalization = normalization
   |

geom3d\models\Equiformer\graph_norm.py:53:9: D105 Missing docstring in magic method
   |
53 |     def __repr__(self):
   |         ^^^^^^^^ D105
54 |         return f"{self.__class__.__name__} ({self.irreps}, eps={self.eps})"
   |

geom3d\models\Equiformer\graph_norm.py:58:9: D417 Missing argument descriptions in the docstring for `forward`: `**kwargs`, `batch`
   |
57 |     #@torch.autocast(device_type='cuda', enabled=False)
58 |     def forward(self, node_input, batch, **kwargs):
   |         ^^^^^^^ D417
59 |         """evaluate.
   |

geom3d\models\Equiformer\graph_norm.py:58:42: ANN003 Missing type annotation for `**kwargs`
   |
57 |     #@torch.autocast(device_type='cuda', enabled=False)
58 |     def forward(self, node_input, batch, **kwargs):
   |                                          ^^^^^^^^ ANN003
59 |         """evaluate.
   |

geom3d\models\Equiformer\graph_norm.py:58:44: ARG002 Unused method argument: `kwargs`
   |
57 |     #@torch.autocast(device_type='cuda', enabled=False)
58 |     def forward(self, node_input, batch, **kwargs):
   |                                            ^^^^^^ ARG002
59 |         """evaluate.
   |

geom3d\models\Equiformer\graph_norm.py:82:13: ERA001 Found commented-out code
   |
80 |         for mul, ir in self.irreps:  # mul is the multiplicity (number of copies) of some irrep type (ir)
81 |             d = ir.dim
82 |             #field = node_input[:, ix: ix + mul * d]  # [batch * sample, mul * repr]
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
83 |             field = node_input.narrow(1, ix, mul*d)
84 |             ix += mul * d
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\graph_norm.py:86:13: ERA001 Found commented-out code
   |
84 |             ix += mul * d
85 | 
86 |             # [batch * sample, mul, repr]
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
87 |             field = field.reshape(-1, mul, d)
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\graph_norm.py:142:7: D101 Missing docstring in public class
    |
142 | class EquivariantGraphNormV2(nn.Module):
    |       ^^^^^^^^^^^^^^^^^^^^^^ D101
143 | 
144 |     def __init__(self, irreps, eps=1e-5, affine=True, reduce="mean", normalization="component"):
    |

geom3d\models\Equiformer\graph_norm.py:144:9: D107 Missing docstring in `__init__`
    |
142 | class EquivariantGraphNormV2(nn.Module):
143 | 
144 |     def __init__(self, irreps, eps=1e-5, affine=True, reduce="mean", normalization="component"):
    |         ^^^^^^^^ D107
145 |         super().__init__()
    |

geom3d\models\Equiformer\graph_norm.py:144:42: FBT002 Boolean default positional argument in function definition
    |
142 | class EquivariantGraphNormV2(nn.Module):
143 | 
144 |     def __init__(self, irreps, eps=1e-5, affine=True, reduce="mean", normalization="component"):
    |                                          ^^^^^^ FBT002
145 |         super().__init__()
    |

geom3d\models\Equiformer\graph_norm.py:170:9: S101 Use of `assert` detected
    |
168 |             self.register_parameter("affine_bias", None)
169 | 
170 |         assert isinstance(reduce, str), "reduce should be passed as a string value"
    |         ^^^^^^ S101
171 |         assert reduce in ["mean", "max"], "reduce needs to be 'mean' or 'max'"
172 |         self.reduce = reduce
    |

geom3d\models\Equiformer\graph_norm.py:171:9: S101 Use of `assert` detected
    |
170 |         assert isinstance(reduce, str), "reduce should be passed as a string value"
171 |         assert reduce in ["mean", "max"], "reduce needs to be 'mean' or 'max'"
    |         ^^^^^^ S101
172 |         self.reduce = reduce
    |

geom3d\models\Equiformer\graph_norm.py:174:9: S101 Use of `assert` detected
    |
172 |         self.reduce = reduce
173 | 
174 |         assert normalization in ["norm", "component"], "normalization needs to be 'norm' or 'component'"
    |         ^^^^^^ S101
175 |         self.normalization = normalization
    |

geom3d\models\Equiformer\graph_norm.py:178:9: D105 Missing docstring in magic method
    |
178 |     def __repr__(self):
    |         ^^^^^^^^ D105
179 |         return f"{self.__class__.__name__} ({self.irreps}, eps={self.eps})"
    |

geom3d\models\Equiformer\graph_norm.py:183:9: D102 Missing docstring in public method
    |
182 |     #@torch.autocast(device_type='cuda', enabled=False)
183 |     def forward(self, node_input, batch, **kwargs):
    |         ^^^^^^^ D102
184 | 
185 |         dim = node_input.shape[-1]
    |

geom3d\models\Equiformer\graph_norm.py:183:42: ANN003 Missing type annotation for `**kwargs`
    |
182 |     #@torch.autocast(device_type='cuda', enabled=False)
183 |     def forward(self, node_input, batch, **kwargs):
    |                                          ^^^^^^^^ ANN003
184 | 
185 |         dim = node_input.shape[-1]
    |

geom3d\models\Equiformer\graph_norm.py:183:44: ARG002 Unused method argument: `kwargs`
    |
182 |     #@torch.autocast(device_type='cuda', enabled=False)
183 |     def forward(self, node_input, batch, **kwargs):
    |                                            ^^^^^^ ARG002
184 | 
185 |         dim = node_input.shape[-1]
    |

geom3d\models\Equiformer\graph_norm.py:200:13: ERA001 Found commented-out code
    |
198 |             field = field.reshape(-1, mul, d) # [batch * sample, mul, repr]
199 |             # centering
200 |             #field_mean = global_mean_pool(field, batch) # [batch, mul, repr]
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
201 |             field_mean = node_input_mean.narrow(1, ix, mul * d)
202 |             field_mean = field_mean.reshape(-1, mul, d)
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\instance_norm.py:1:1: D100 Missing docstring in public module
geom3d\models\Equiformer\instance_norm.py:9:5: D205 1 blank line required between summary line and description
   |
 7 |   # From "Geometric and Physical Quantities improve E(3) Equivariant Message Passing"
 8 |   class EquivariantInstanceNorm(nn.Module):
 9 |       """Instance normalization for orthonormal representations
   |  _____^
10 | |     It normalizes by the norm of the representations.
11 | |     Note that the norm is invariant only for orthonormal representations.
12 | |     Irreducible representations `wigner_D` are orthonormal.
13 | | 
14 | |     Parameters
15 | |     ----------
16 | |     irreps : `Irreps`
17 | |         representation
18 | |     eps : float
19 | |         avoid division by zero when we normalize by the variance
20 | |     affine : bool
21 | |         do we have weight and bias parameters
22 | |     reduce : {'mean', 'max'}
23 | |         method used to reduce
24 | | 
25 | |     """
   | |_______^ D205
26 |   
27 |       def __init__(self, irreps, eps=1e-5, affine=True, reduce="mean", normalization="component"):
   |
   = help: Insert single blank line

geom3d\models\Equiformer\instance_norm.py:27:9: D107 Missing docstring in `__init__`
   |
25 |     """
26 | 
27 |     def __init__(self, irreps, eps=1e-5, affine=True, reduce="mean", normalization="component"):
   |         ^^^^^^^^ D107
28 |         super().__init__()
   |

geom3d\models\Equiformer\instance_norm.py:27:42: FBT002 Boolean default positional argument in function definition
   |
25 |     """
26 | 
27 |     def __init__(self, irreps, eps=1e-5, affine=True, reduce="mean", normalization="component"):
   |                                          ^^^^^^ FBT002
28 |         super().__init__()
   |

geom3d\models\Equiformer\instance_norm.py:44:9: S101 Use of `assert` detected
   |
42 |             self.register_parameter("affine_bias", None)
43 | 
44 |         assert isinstance(reduce, str), "reduce should be passed as a string value"
   |         ^^^^^^ S101
45 |         assert reduce in ["mean", "max"], "reduce needs to be 'mean' or 'max'"
46 |         self.reduce = reduce
   |

geom3d\models\Equiformer\instance_norm.py:45:9: S101 Use of `assert` detected
   |
44 |         assert isinstance(reduce, str), "reduce should be passed as a string value"
45 |         assert reduce in ["mean", "max"], "reduce needs to be 'mean' or 'max'"
   |         ^^^^^^ S101
46 |         self.reduce = reduce
   |

geom3d\models\Equiformer\instance_norm.py:48:9: S101 Use of `assert` detected
   |
46 |         self.reduce = reduce
47 | 
48 |         assert normalization in ["norm", "component"], "normalization needs to be 'norm' or 'component'"
   |         ^^^^^^ S101
49 |         self.normalization = normalization
   |

geom3d\models\Equiformer\instance_norm.py:52:9: D105 Missing docstring in magic method
   |
52 |     def __repr__(self):
   |         ^^^^^^^^ D105
53 |         return f"{self.__class__.__name__} ({self.irreps}, eps={self.eps})"
   |

geom3d\models\Equiformer\instance_norm.py:57:9: D417 Missing argument descriptions in the docstring for `forward`: `**kwargs`, `batch`
   |
56 |     #@torch.autocast(device_type='cuda', enabled=False)
57 |     def forward(self, node_input, batch, **kwargs):
   |         ^^^^^^^ D417
58 |         """evaluate.
   |

geom3d\models\Equiformer\instance_norm.py:57:42: ANN003 Missing type annotation for `**kwargs`
   |
56 |     #@torch.autocast(device_type='cuda', enabled=False)
57 |     def forward(self, node_input, batch, **kwargs):
   |                                          ^^^^^^^^ ANN003
58 |         """evaluate.
   |

geom3d\models\Equiformer\instance_norm.py:57:44: ARG002 Unused method argument: `kwargs`
   |
56 |     #@torch.autocast(device_type='cuda', enabled=False)
57 |     def forward(self, node_input, batch, **kwargs):
   |                                            ^^^^^^ ARG002
58 |         """evaluate.
   |

geom3d\models\Equiformer\instance_norm.py:71:9: ERA001 Found commented-out code
   |
70 |         """
71 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
72 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
73 |         # node_input has shape [batch * nodes, dim], but with variable nr of nodes.
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\instance_norm.py:71:51: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
70 |         """
71 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
   |                                                   ^^^^ TD002
72 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
73 |         # node_input has shape [batch * nodes, dim], but with variable nr of nodes.
   |

geom3d\models\Equiformer\instance_norm.py:71:51: TD003 Missing issue link on the line following this TODO
   |
70 |         """
71 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
   |                                                   ^^^^ TD003
72 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
73 |         # node_input has shape [batch * nodes, dim], but with variable nr of nodes.
   |

geom3d\models\Equiformer\instance_norm.py:71:51: FIX002 Line contains TODO, consider resolving the issue
   |
70 |         """
71 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
   |                                                   ^^^^ FIX002
72 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
73 |         # node_input has shape [batch * nodes, dim], but with variable nr of nodes.
   |

geom3d\models\Equiformer\instance_norm.py:72:9: ERA001 Found commented-out code
   |
70 |         """
71 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
72 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
73 |         # node_input has shape [batch * nodes, dim], but with variable nr of nodes.
74 |         # the node_input batch slices this into separate graphs
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\instance_norm.py:84:13: ERA001 Found commented-out code
   |
82 |         for mul, ir in self.irreps:  # mul is the multiplicity (number of copies) of some irrep type (ir)
83 |             d = ir.dim
84 |             #field = node_input[:, ix: ix + mul * d]  # [batch * sample, mul * repr]
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
85 |             field = node_input.narrow(1, ix, mul*d)
86 |             ix += mul * d
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\instance_norm.py:88:13: ERA001 Found commented-out code
   |
86 |             ix += mul * d
87 | 
88 |             # [batch * sample, mul, repr]
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
89 |             field = field.reshape(-1, mul, d)
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\layer_norm.py:1:1: D100 Missing docstring in public module
geom3d\models\Equiformer\layer_norm.py:12:7: D101 Missing docstring in public class
   |
10 | #   https://github.com/e3nn/e3nn/blob/main/e3nn/nn/_batchnorm.py
11 | @compile_mode("unsupported")
12 | class EquivariantLayerNorm(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^^^^^^ D101
13 | 
14 |     NORM_CLAMP = 2 ** -24  # Minimum positive subnormal for FP16
   |

geom3d\models\Equiformer\layer_norm.py:16:9: D107 Missing docstring in `__init__`
   |
14 |     NORM_CLAMP = 2 ** -24  # Minimum positive subnormal for FP16
15 | 
16 |     def __init__(self, irreps_in, eps=1e-5):
   |         ^^^^^^^^ D107
17 |         super().__init__()
18 |         self.irreps_in = irreps_in
   |

geom3d\models\Equiformer\layer_norm.py:26:9: ERA001 Found commented-out code
   |
24 |         self.layer_norms = torch.nn.ModuleList(self.layer_norms)
25 | 
26 |         #self.relu = torch.nn.ReLU()
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\layer_norm.py:29:29: ANN003 Missing type annotation for `**kwargs`
   |
29 |     def forward(self, f_in, **kwargs):
   |                             ^^^^^^^^ ANN003
30 |         """Assume `f_in` is of shape [N, C]."""
31 |         f_out = []
   |

geom3d\models\Equiformer\layer_norm.py:29:31: ARG002 Unused method argument: `kwargs`
   |
29 |     def forward(self, f_in, **kwargs):
   |                               ^^^^^^ ARG002
30 |         """Assume `f_in` is of shape [N, C]."""
31 |         f_out = []
   |

geom3d\models\Equiformer\layer_norm.py:33:9: N806 Variable `N` in function should be lowercase
   |
31 |         f_out = []
32 |         channel_idx = 0
33 |         N = f_in.shape[0]
   |         ^ N806
34 |         for degree_idx, (mul, ir) in enumerate(self.irreps_in):
35 |             feat = f_in[:, channel_idx:(channel_idx+mul*ir.dim)]
   |

geom3d\models\Equiformer\layer_norm.py:41:13: ERA001 Found commented-out code
   |
40 |             #if not ir.is_scalar():
41 |             #    new_norm = self.relu(new_norm)
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
42 | 
43 |             norm = norm.reshape(N, mul, 1)
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\layer_norm.py:54:9: D105 Missing docstring in magic method
   |
54 |     def __repr__(self):
   |         ^^^^^^^^ D105
55 |         return f"{self.__class__.__name__}({self.irreps_in}, eps={self.eps})"
   |

geom3d\models\Equiformer\layer_norm.py:58:7: D101 Missing docstring in public class
   |
58 | class EquivariantLayerNormV2(nn.Module):
   |       ^^^^^^^^^^^^^^^^^^^^^^ D101
59 | 
60 |     def __init__(self, irreps, eps=1e-5, affine=True, normalization="component"):
   |

geom3d\models\Equiformer\layer_norm.py:60:9: D107 Missing docstring in `__init__`
   |
58 | class EquivariantLayerNormV2(nn.Module):
59 | 
60 |     def __init__(self, irreps, eps=1e-5, affine=True, normalization="component"):
   |         ^^^^^^^^ D107
61 |         super().__init__()
   |

geom3d\models\Equiformer\layer_norm.py:60:42: FBT002 Boolean default positional argument in function definition
   |
58 | class EquivariantLayerNormV2(nn.Module):
59 | 
60 |     def __init__(self, irreps, eps=1e-5, affine=True, normalization="component"):
   |                                          ^^^^^^ FBT002
61 |         super().__init__()
   |

geom3d\models\Equiformer\layer_norm.py:77:9: S101 Use of `assert` detected
   |
75 |             self.register_parameter("affine_bias", None)
76 | 
77 |         assert normalization in ["norm", "component"], "normalization needs to be 'norm' or 'component'"
   |         ^^^^^^ S101
78 |         self.normalization = normalization
   |

geom3d\models\Equiformer\layer_norm.py:81:9: D105 Missing docstring in magic method
   |
81 |     def __repr__(self):
   |         ^^^^^^^^ D105
82 |         return f"{self.__class__.__name__}({self.irreps}, eps={self.eps})"
   |

geom3d\models\Equiformer\layer_norm.py:86:9: D102 Missing docstring in public method
   |
85 |     @torch.cuda.amp.autocast(enabled=False)
86 |     def forward(self, node_input, **kwargs):
   |         ^^^^^^^ D102
87 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
88 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
   |

geom3d\models\Equiformer\layer_norm.py:86:35: ANN003 Missing type annotation for `**kwargs`
   |
85 |     @torch.cuda.amp.autocast(enabled=False)
86 |     def forward(self, node_input, **kwargs):
   |                                   ^^^^^^^^ ANN003
87 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
88 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
   |

geom3d\models\Equiformer\layer_norm.py:86:37: ARG002 Unused method argument: `kwargs`
   |
85 |     @torch.cuda.amp.autocast(enabled=False)
86 |     def forward(self, node_input, **kwargs):
   |                                     ^^^^^^ ARG002
87 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
88 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
   |

geom3d\models\Equiformer\layer_norm.py:87:9: ERA001 Found commented-out code
   |
85 |     @torch.cuda.amp.autocast(enabled=False)
86 |     def forward(self, node_input, **kwargs):
87 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
88 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
89 |         # node_input has shape [batch * nodes, dim], but with variable nr of nodes.
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\layer_norm.py:87:51: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
85 |     @torch.cuda.amp.autocast(enabled=False)
86 |     def forward(self, node_input, **kwargs):
87 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
   |                                                   ^^^^ TD002
88 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
89 |         # node_input has shape [batch * nodes, dim], but with variable nr of nodes.
   |

geom3d\models\Equiformer\layer_norm.py:87:51: TD003 Missing issue link on the line following this TODO
   |
85 |     @torch.cuda.amp.autocast(enabled=False)
86 |     def forward(self, node_input, **kwargs):
87 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
   |                                                   ^^^^ TD003
88 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
89 |         # node_input has shape [batch * nodes, dim], but with variable nr of nodes.
   |

geom3d\models\Equiformer\layer_norm.py:87:51: FIX002 Line contains TODO, consider resolving the issue
   |
85 |     @torch.cuda.amp.autocast(enabled=False)
86 |     def forward(self, node_input, **kwargs):
87 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
   |                                                   ^^^^ FIX002
88 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
89 |         # node_input has shape [batch * nodes, dim], but with variable nr of nodes.
   |

geom3d\models\Equiformer\layer_norm.py:88:9: ERA001 Found commented-out code
   |
86 |     def forward(self, node_input, **kwargs):
87 |         # batch, *size, dim = node_input.shape  # TODO: deal with batch
88 |         # node_input = node_input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
89 |         # node_input has shape [batch * nodes, dim], but with variable nr of nodes.
90 |         # the node_input batch slices this into separate graphs
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\layer_norm.py:100:13: ERA001 Found commented-out code
    |
 98 |         for mul, ir in self.irreps:  # mul is the multiplicity (number of copies) of some irrep type (ir)
 99 |             d = ir.dim
100 |             #field = node_input[:, ix: ix + mul * d]  # [batch * sample, mul * repr]
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
101 |             field = node_input.narrow(1, ix, mul*d)
102 |             ix += mul * d
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\layer_norm.py:104:13: ERA001 Found commented-out code
    |
102 |             ix += mul * d
103 | 
104 |             # [batch * sample, mul, repr]
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
105 |             field = field.reshape(-1, mul, d)
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\layer_norm.py:154:9: D107 Missing docstring in `__init__`
    |
152 |     """V2 + Centering for vectors of all degrees."""
153 | 
154 |     def __init__(self, irreps, eps=1e-5, affine=True, normalization="component"):
    |         ^^^^^^^^ D107
155 |         super().__init__()
    |

geom3d\models\Equiformer\layer_norm.py:154:42: FBT002 Boolean default positional argument in function definition
    |
152 |     """V2 + Centering for vectors of all degrees."""
153 | 
154 |     def __init__(self, irreps, eps=1e-5, affine=True, normalization="component"):
    |                                          ^^^^^^ FBT002
155 |         super().__init__()
    |

geom3d\models\Equiformer\layer_norm.py:171:9: S101 Use of `assert` detected
    |
169 |             self.register_parameter("affine_bias", None)
170 | 
171 |         assert normalization in ["norm", "component"], "normalization needs to be 'norm' or 'component'"
    |         ^^^^^^ S101
172 |         self.normalization = normalization
    |

geom3d\models\Equiformer\layer_norm.py:175:9: D105 Missing docstring in magic method
    |
175 |     def __repr__(self):
    |         ^^^^^^^^ D105
176 |         return f"{self.__class__.__name__} ({self.irreps}, eps={self.eps})"
    |

geom3d\models\Equiformer\layer_norm.py:180:9: D102 Missing docstring in public method
    |
179 |     #@torch.autocast(device_type='cuda', enabled=False)
180 |     def forward(self, node_input, **kwargs):
    |         ^^^^^^^ D102
181 | 
182 |         dim = node_input.shape[-1]
    |

geom3d\models\Equiformer\layer_norm.py:180:35: ANN003 Missing type annotation for `**kwargs`
    |
179 |     #@torch.autocast(device_type='cuda', enabled=False)
180 |     def forward(self, node_input, **kwargs):
    |                                   ^^^^^^^^ ANN003
181 | 
182 |         dim = node_input.shape[-1]
    |

geom3d\models\Equiformer\layer_norm.py:180:37: ARG002 Unused method argument: `kwargs`
    |
179 |     #@torch.autocast(device_type='cuda', enabled=False)
180 |     def forward(self, node_input, **kwargs):
    |                                     ^^^^^^ ARG002
181 | 
182 |         dim = node_input.shape[-1]
    |

geom3d\models\Equiformer\layer_norm.py:232:9: D107 Missing docstring in `__init__`
    |
230 |     """V3 + Learnable mean shift."""
231 | 
232 |     def __init__(self, irreps, eps=1e-5, affine=True, normalization="component"):
    |         ^^^^^^^^ D107
233 |         super().__init__()
    |

geom3d\models\Equiformer\layer_norm.py:232:42: FBT002 Boolean default positional argument in function definition
    |
230 |     """V3 + Learnable mean shift."""
231 | 
232 |     def __init__(self, irreps, eps=1e-5, affine=True, normalization="component"):
    |                                          ^^^^^^ FBT002
233 |         super().__init__()
    |

geom3d\models\Equiformer\layer_norm.py:258:9: S101 Use of `assert` detected
    |
256 |             self.register_parameter("affine_bias", None)
257 | 
258 |         assert normalization in ["norm", "component"], "normalization needs to be 'norm' or 'component'"
    |         ^^^^^^ S101
259 |         self.normalization = normalization
    |

geom3d\models\Equiformer\layer_norm.py:262:9: D105 Missing docstring in magic method
    |
262 |     def __repr__(self):
    |         ^^^^^^^^ D105
263 |         return f"{self.__class__.__name__} ({self.irreps}, eps={self.eps})"
    |

geom3d\models\Equiformer\layer_norm.py:267:9: D102 Missing docstring in public method
    |
266 |     #@torch.autocast(device_type='cuda', enabled=False)
267 |     def forward(self, node_input, **kwargs):
    |         ^^^^^^^ D102
268 | 
269 |         dim = node_input.shape[-1]
    |

geom3d\models\Equiformer\layer_norm.py:267:35: ANN003 Missing type annotation for `**kwargs`
    |
266 |     #@torch.autocast(device_type='cuda', enabled=False)
267 |     def forward(self, node_input, **kwargs):
    |                                   ^^^^^^^^ ANN003
268 | 
269 |         dim = node_input.shape[-1]
    |

geom3d\models\Equiformer\layer_norm.py:267:37: ARG002 Unused method argument: `kwargs`
    |
266 |     #@torch.autocast(device_type='cuda', enabled=False)
267 |     def forward(self, node_input, **kwargs):
    |                                     ^^^^^^ ARG002
268 | 
269 |         dim = node_input.shape[-1]
    |

geom3d\models\Equiformer\radial_basis.py:1:1: D100 Missing docstring in public module
geom3d\models\Equiformer\radial_basis.py:21:9: D107 Missing docstring in `__init__`
   |
19 |     """
20 | 
21 |     def __init__(self, exponent):
   |         ^^^^^^^^ D107
22 |         super().__init__()
23 |         assert exponent > 0
   |

geom3d\models\Equiformer\radial_basis.py:23:9: S101 Use of `assert` detected
   |
21 |     def __init__(self, exponent):
22 |         super().__init__()
23 |         assert exponent > 0
   |         ^^^^^^ S101
24 |         self.p = exponent
25 |         self.a = -(self.p + 1) * (self.p + 2) / 2
   |

geom3d\models\Equiformer\radial_basis.py:29:9: D102 Missing docstring in public method
   |
27 |         self.c = -self.p * (self.p + 1) / 2
28 | 
29 |     def forward(self, d_scaled):
   |         ^^^^^^^ D102
30 |         env_val = (
31 |             1
   |

geom3d\models\Equiformer\radial_basis.py:40:5: D205 1 blank line required between summary line and description
   |
39 |   class ExponentialEnvelope(torch.nn.Module):
40 |       """Exponential envelope function that ensures a smooth cutoff,
   |  _____^
41 | |     as proposed in Unke, Chmiela, Gastegger, Schütt, Sauceda, Müller 2021.
42 | |     SpookyNet: Learning Force Fields with Electronic Degrees of Freedom
43 | |     and Nonlocal Effects.
44 | |     """
   | |_______^ D205
45 |   
46 |       def __init__(self):
   |
   = help: Insert single blank line

geom3d\models\Equiformer\radial_basis.py:46:9: D107 Missing docstring in `__init__`
   |
44 |     """
45 | 
46 |     def __init__(self):
   |         ^^^^^^^^ D107
47 |         super().__init__()
   |

geom3d\models\Equiformer\radial_basis.py:49:9: D102 Missing docstring in public method
   |
47 |         super().__init__()
48 | 
49 |     def forward(self, d_scaled):
   |         ^^^^^^^ D102
50 |         env_val = torch.exp(
51 |             -(d_scaled ** 2) / ((1 - d_scaled) * (1 + d_scaled))
   |

geom3d\models\Equiformer\radial_basis.py:68:9: D107 Missing docstring in `__init__`
   |
66 |     """
67 | 
68 |     def __init__(
   |         ^^^^^^^^ D107
69 |         self,
70 |         num_radial: int,
   |

geom3d\models\Equiformer\radial_basis.py:85:9: D102 Missing docstring in public method
   |
83 |         )
84 | 
85 |     def forward(self, d_scaled):
   |         ^^^^^^^ D102
86 |         return (
87 |             self.norm_const
   |

geom3d\models\Equiformer\radial_basis.py:94:5: D205 1 blank line required between summary line and description
    |
 93 |   class BernsteinBasis(torch.nn.Module):
 94 |       """Bernstein polynomial basis,
    |  _____^
 95 | |     as proposed in Unke, Chmiela, Gastegger, Schütt, Sauceda, Müller 2021.
 96 | |     SpookyNet: Learning Force Fields with Electronic Degrees of Freedom
 97 | |     and Nonlocal Effects.
 98 | | 
 99 | |     Parameters
100 | |     ----------
101 | |     num_radial: int
102 | |         Controls maximum frequency.
103 | |     pregamma_initial: float
104 | |         Initial value of exponential coefficient gamma.
105 | |         Default: gamma = 0.5 * a_0**-1 = 0.94486,
106 | |         inverse softplus -> pregamma = log e**gamma - 1 = 0.45264
107 | | 
108 | |     """
    | |_______^ D205
109 |   
110 |       def __init__(
    |
    = help: Insert single blank line

geom3d\models\Equiformer\radial_basis.py:110:9: D107 Missing docstring in `__init__`
    |
108 |     """
109 | 
110 |     def __init__(
    |         ^^^^^^^^ D107
111 |         self,
112 |         num_radial: int,
    |

geom3d\models\Equiformer\radial_basis.py:134:9: D102 Missing docstring in public method
    |
132 |         self.register_buffer("exp2", exp2[None, :], persistent=False)
133 | 
134 |     def forward(self, d_scaled):
    |         ^^^^^^^ D102
135 |         gamma = self.softplus(self.pregamma)  # constrain to positive
136 |         exp_d = torch.exp(-gamma * d_scaled)[:, None]
    |

geom3d\models\Equiformer\radial_basis.py:143:5: D205 1 blank line required between summary line and description
    |
142 |   class RadialBasis(torch.nn.Module):
143 |       """Parameters
    |  _____^
144 | |     ----------
145 | |     num_radial: int
146 | |         Controls maximum frequency.
147 | |     cutoff: float
148 | |         Cutoff distance in Angstrom.
149 | |     rbf: dict = {"name": "gaussian"}
150 | |         Basis function and its hyperparameters.
151 | |     envelope: dict = {"name": "polynomial", "exponent": 5}
152 | |         Envelope function and its hyperparameters.
153 | | 
154 | |     """
    | |_______^ D205
155 |   
156 |       def __init__(
    |
    = help: Insert single blank line

geom3d\models\Equiformer\radial_basis.py:156:9: D107 Missing docstring in `__init__`
    |
154 |     """
155 | 
156 |     def __init__(
    |         ^^^^^^^^ D107
157 |         self,
158 |         num_radial: int,
    |

geom3d\models\Equiformer\radial_basis.py:160:14: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
158 |         num_radial: int,
159 |         cutoff: float,
160 |         rbf: Optional[dict] = None,
    |              ^^^^^^^^ FA100
161 |         envelope: Optional[dict] = None,
162 |     ):
    |

geom3d\models\Equiformer\radial_basis.py:161:19: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
159 |         cutoff: float,
160 |         rbf: Optional[dict] = None,
161 |         envelope: Optional[dict] = None,
    |                   ^^^^^^^^ FA100
162 |     ):
163 |         if envelope is None:
    |

geom3d\models\Equiformer\radial_basis.py:201:9: D102 Missing docstring in public method
    |
199 |             raise ValueError(msg)
200 | 
201 |     def forward(self, d):
    |         ^^^^^^^ D102
202 |         d_scaled = d * self.inv_cutoff
    |

geom3d\models\Equiformer\radial_func.py:1:1: D100 Missing docstring in public module
geom3d\models\Equiformer\radial_func.py:8:7: D101 Missing docstring in public class
   |
 8 | class RadialProfile(nn.Module):
   |       ^^^^^^^^^^^^^ D101
 9 |     def __init__(self, ch_list, use_layer_norm=True, use_offset=True):
10 |         super().__init__()
   |

geom3d\models\Equiformer\radial_func.py:9:9: D107 Missing docstring in `__init__`
   |
 8 | class RadialProfile(nn.Module):
 9 |     def __init__(self, ch_list, use_layer_norm=True, use_offset=True):
   |         ^^^^^^^^ D107
10 |         super().__init__()
11 |         modules = []
   |

geom3d\models\Equiformer\radial_func.py:9:33: FBT002 Boolean default positional argument in function definition
   |
 8 | class RadialProfile(nn.Module):
 9 |     def __init__(self, ch_list, use_layer_norm=True, use_offset=True):
   |                                 ^^^^^^^^^^^^^^ FBT002
10 |         super().__init__()
11 |         modules = []
   |

geom3d\models\Equiformer\radial_func.py:9:54: FBT002 Boolean default positional argument in function definition
   |
 8 | class RadialProfile(nn.Module):
 9 |     def __init__(self, ch_list, use_layer_norm=True, use_offset=True):
   |                                                      ^^^^^^^^^^ FBT002
10 |         super().__init__()
11 |         modules = []
   |

geom3d\models\Equiformer\radial_func.py:28:13: ERA001 Found commented-out code
   |
26 |             if use_layer_norm:
27 |                 modules.append(nn.LayerNorm(ch_list[i]))
28 |             #modules.append(nn.ReLU())
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
29 |             #modules.append(Activation(o3.Irreps('{}x0e'.format(ch_list[i])),
30 |             #    acts=[torch.nn.functional.silu]))
   |
   = help: Remove commented-out code

geom3d\models\Equiformer\radial_func.py:45:9: D102 Missing docstring in public method
   |
45 |     def forward(self, f_in):
   |         ^^^^^^^ D102
46 |         f_out = self.net(f_in)
47 |         if self.offset is not None:
   |

geom3d\models\Equiformer\tensor_product_rescale.py:11:7: D101 Missing docstring in public class
   |
11 | class TensorProductRescale(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^^^^^^ D101
12 |     def __init__(self,
13 |         irreps_in1, irreps_in2, irreps_out,
   |

geom3d\models\Equiformer\tensor_product_rescale.py:12:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
11 | class TensorProductRescale(torch.nn.Module):
12 |     def __init__(self,
   |         ^^^^^^^^ PLR0913
13 |         irreps_in1, irreps_in2, irreps_out,
14 |         instructions,
   |

geom3d\models\Equiformer\tensor_product_rescale.py:12:9: D107 Missing docstring in `__init__`
   |
11 | class TensorProductRescale(torch.nn.Module):
12 |     def __init__(self,
   |         ^^^^^^^^ D107
13 |         irreps_in1, irreps_in2, irreps_out,
14 |         instructions,
   |

geom3d\models\Equiformer\tensor_product_rescale.py:15:9: FBT002 Boolean default positional argument in function definition
   |
13 |         irreps_in1, irreps_in2, irreps_out,
14 |         instructions,
15 |         bias=True, rescale=True,
   |         ^^^^ FBT002
16 |         internal_weights=None, shared_weights=None,
17 |         normalization=None):
   |

geom3d\models\Equiformer\tensor_product_rescale.py:15:20: FBT002 Boolean default positional argument in function definition
   |
13 |         irreps_in1, irreps_in2, irreps_out,
14 |         instructions,
15 |         bias=True, rescale=True,
   |                    ^^^^^^^ FBT002
16 |         internal_weights=None, shared_weights=None,
17 |         normalization=None):
   |

geom3d\models\Equiformer\tensor_product_rescale.py:38:9: D102 Missing docstring in public method
   |
38 |     def calculate_fan_in(self, ins):
   |         ^^^^^^^^^^^^^^^^ D102
39 |         return {
40 |             "uvw": (self.irreps_in1[ins.i_in1].mul * self.irreps_in2[ins.i_in2].mul),
   |

geom3d\models\Equiformer\tensor_product_rescale.py:51:9: D102 Missing docstring in public method
   |
51 |     def init_rescale_bias(self) -> None:
   |         ^^^^^^^^^^^^^^^^^ D102
52 | 
53 |         irreps_out = self.irreps_out
   |

geom3d\models\Equiformer\tensor_product_rescale.py:107:21: ERA001 Found commented-out code
    |
105 |                         sqrt_k = 1 / slices_fan_in[slice_idx] ** 0.5
106 |                         weight.data.mul_(sqrt_k)
107 |                     #else:
    |                     ^^^^^^ ERA001
108 |                     #    sqrt_k = 1.
109 |                     #
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\tensor_product_rescale.py:108:21: ERA001 Found commented-out code
    |
106 |                         weight.data.mul_(sqrt_k)
107 |                     #else:
108 |                     #    sqrt_k = 1.
    |                     ^^^^^^^^^^^^^^^^ ERA001
109 |                     #
110 |                     #if self.rescale:
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\tensor_product_rescale.py:111:25: ERA001 Found commented-out code
    |
109 |                     #
110 |                     #if self.rescale:
111 |                         #weight.data.uniform_(-sqrt_k, sqrt_k)
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
112 |                     #    weight.data.mul_(sqrt_k)
113 |                     #self.slices_sqrt_k[slice_idx] = (self.irreps_out_slices[slice_idx], sqrt_k)
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\tensor_product_rescale.py:112:21: ERA001 Found commented-out code
    |
110 |                     #if self.rescale:
111 |                         #weight.data.uniform_(-sqrt_k, sqrt_k)
112 |                     #    weight.data.mul_(sqrt_k)
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
113 |                     #self.slices_sqrt_k[slice_idx] = (self.irreps_out_slices[slice_idx], sqrt_k)
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\tensor_product_rescale.py:113:21: ERA001 Found commented-out code
    |
111 |                         #weight.data.uniform_(-sqrt_k, sqrt_k)
112 |                     #    weight.data.mul_(sqrt_k)
113 |                     #self.slices_sqrt_k[slice_idx] = (self.irreps_out_slices[slice_idx], sqrt_k)
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
114 | 
115 |             # Initialize the biases
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\tensor_product_rescale.py:117:13: ERA001 Found commented-out code
    |
115 |             # Initialize the biases
116 |             #for (out_slice_idx, out_slice, out_bias) in zip(self.bias_slice_idx, self.bias_slices, self.bias):
117 |             #    sqrt_k = 1 / slices_fan_in[out_slice_idx] ** 0.5
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
118 |             #    out_bias.uniform_(-sqrt_k, sqrt_k)
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\tensor_product_rescale.py:118:13: ERA001 Found commented-out code
    |
116 |             #for (out_slice_idx, out_slice, out_bias) in zip(self.bias_slice_idx, self.bias_slices, self.bias):
117 |             #    sqrt_k = 1 / slices_fan_in[out_slice_idx] ** 0.5
118 |             #    out_bias.uniform_(-sqrt_k, sqrt_k)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\tensor_product_rescale.py:121:9: D102 Missing docstring in public method
    |
121 |     def forward_tp_rescale_bias(self, x, y, weight=None):
    |         ^^^^^^^^^^^^^^^^^^^^^^^ D102
122 | 
123 |         out = self.tp(x, y, weight)
    |

geom3d\models\Equiformer\tensor_product_rescale.py:127:9: ERA001 Found commented-out code
    |
125 |         #if self.rescale and self.tp.internal_weights:
126 |         #    for (slice, slice_sqrt_k) in self.slices_sqrt_k.values():
127 |         #        out[:, slice] /= slice_sqrt_k
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
128 |         if self.use_bias:
129 |             for (_, slice, bias) in zip(self.bias_slice_idx, self.bias_slices, self.bias):
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\tensor_product_rescale.py:129:21: A001 Variable `slice` is shadowing a Python builtin
    |
127 |         #        out[:, slice] /= slice_sqrt_k
128 |         if self.use_bias:
129 |             for (_, slice, bias) in zip(self.bias_slice_idx, self.bias_slices, self.bias):
    |                     ^^^^^ A001
130 |                 #out[:, slice] += bias
131 |                 out.narrow(1, slice.start, slice.stop - slice.start).add_(bias)
    |

geom3d\models\Equiformer\tensor_product_rescale.py:130:17: ERA001 Found commented-out code
    |
128 |         if self.use_bias:
129 |             for (_, slice, bias) in zip(self.bias_slice_idx, self.bias_slices, self.bias):
130 |                 #out[:, slice] += bias
    |                 ^^^^^^^^^^^^^^^^^^^^^^ ERA001
131 |                 out.narrow(1, slice.start, slice.stop - slice.start).add_(bias)
132 |         return out
    |
    = help: Remove commented-out code

geom3d\models\Equiformer\tensor_product_rescale.py:135:9: D102 Missing docstring in public method
    |
135 |     def forward(self, x, y, weight=None):
    |         ^^^^^^^ D102
136 |         return self.forward_tp_rescale_bias(x, y, weight)
    |

geom3d\models\Equiformer\tensor_product_rescale.py:139:7: D101 Missing docstring in public class
    |
139 | class FullyConnectedTensorProductRescale(TensorProductRescale):
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
140 |     def __init__(self,
141 |         irreps_in1, irreps_in2, irreps_out,
    |

geom3d\models\Equiformer\tensor_product_rescale.py:140:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
139 | class FullyConnectedTensorProductRescale(TensorProductRescale):
140 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
141 |         irreps_in1, irreps_in2, irreps_out,
142 |         bias=True, rescale=True,
    |

geom3d\models\Equiformer\tensor_product_rescale.py:140:9: D107 Missing docstring in `__init__`
    |
139 | class FullyConnectedTensorProductRescale(TensorProductRescale):
140 |     def __init__(self,
    |         ^^^^^^^^ D107
141 |         irreps_in1, irreps_in2, irreps_out,
142 |         bias=True, rescale=True,
    |

geom3d\models\Equiformer\tensor_product_rescale.py:142:9: FBT002 Boolean default positional argument in function definition
    |
140 |     def __init__(self,
141 |         irreps_in1, irreps_in2, irreps_out,
142 |         bias=True, rescale=True,
    |         ^^^^ FBT002
143 |         internal_weights=None, shared_weights=None,
144 |         normalization=None):
    |

geom3d\models\Equiformer\tensor_product_rescale.py:142:20: FBT002 Boolean default positional argument in function definition
    |
140 |     def __init__(self,
141 |         irreps_in1, irreps_in2, irreps_out,
142 |         bias=True, rescale=True,
    |                    ^^^^^^^ FBT002
143 |         internal_weights=None, shared_weights=None,
144 |         normalization=None):
    |

geom3d\models\Equiformer\tensor_product_rescale.py:160:7: D101 Missing docstring in public class
    |
160 | class LinearRS(FullyConnectedTensorProductRescale):
    |       ^^^^^^^^ D101
161 |     def __init__(self, irreps_in, irreps_out, bias=True, rescale=True):
162 |         super().__init__(irreps_in, o3.Irreps("1x0e"), irreps_out,
    |

geom3d\models\Equiformer\tensor_product_rescale.py:161:9: D107 Missing docstring in `__init__`
    |
160 | class LinearRS(FullyConnectedTensorProductRescale):
161 |     def __init__(self, irreps_in, irreps_out, bias=True, rescale=True):
    |         ^^^^^^^^ D107
162 |         super().__init__(irreps_in, o3.Irreps("1x0e"), irreps_out,
163 |             bias=bias, rescale=rescale, internal_weights=True,
    |

geom3d\models\Equiformer\tensor_product_rescale.py:161:47: FBT002 Boolean default positional argument in function definition
    |
160 | class LinearRS(FullyConnectedTensorProductRescale):
161 |     def __init__(self, irreps_in, irreps_out, bias=True, rescale=True):
    |                                               ^^^^ FBT002
162 |         super().__init__(irreps_in, o3.Irreps("1x0e"), irreps_out,
163 |             bias=bias, rescale=rescale, internal_weights=True,
    |

geom3d\models\Equiformer\tensor_product_rescale.py:161:58: FBT002 Boolean default positional argument in function definition
    |
160 | class LinearRS(FullyConnectedTensorProductRescale):
161 |     def __init__(self, irreps_in, irreps_out, bias=True, rescale=True):
    |                                                          ^^^^^^^ FBT002
162 |         super().__init__(irreps_in, o3.Irreps("1x0e"), irreps_out,
163 |             bias=bias, rescale=rescale, internal_weights=True,
    |

geom3d\models\Equiformer\tensor_product_rescale.py:166:9: D102 Missing docstring in public method
    |
164 |             shared_weights=True, normalization=None)
165 | 
166 |     def forward(self, x):
    |         ^^^^^^^ D102
167 |         y = torch.ones_like(x[:, 0:1])
168 |         return self.forward_tp_rescale_bias(x, y)
    |

geom3d\models\Equiformer\tensor_product_rescale.py:171:5: D103 Missing docstring in public function
    |
171 | def irreps2gate(irreps):
    |     ^^^^^^^^^^^ D103
172 |     irreps_scalars = []
173 |     irreps_gated = []
    |

geom3d\models\Equiformer\tensor_product_rescale.py:186:7: D101 Missing docstring in public class
    |
186 | class FullyConnectedTensorProductRescaleSwishGate(FullyConnectedTensorProductRescale):
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
187 |     def __init__(self,
188 |         irreps_in1, irreps_in2, irreps_out,
    |

geom3d\models\Equiformer\tensor_product_rescale.py:187:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
186 | class FullyConnectedTensorProductRescaleSwishGate(FullyConnectedTensorProductRescale):
187 |     def __init__(self,
    |         ^^^^^^^^ PLR0913
188 |         irreps_in1, irreps_in2, irreps_out,
189 |         bias=True, rescale=True,
    |

geom3d\models\Equiformer\tensor_product_rescale.py:187:9: D107 Missing docstring in `__init__`
    |
186 | class FullyConnectedTensorProductRescaleSwishGate(FullyConnectedTensorProductRescale):
187 |     def __init__(self,
    |         ^^^^^^^^ D107
188 |         irreps_in1, irreps_in2, irreps_out,
189 |         bias=True, rescale=True,
    |

geom3d\models\Equiformer\tensor_product_rescale.py:189:9: FBT002 Boolean default positional argument in function definition
    |
187 |     def __init__(self,
188 |         irreps_in1, irreps_in2, irreps_out,
189 |         bias=True, rescale=True,
    |         ^^^^ FBT002
190 |         internal_weights=None, shared_weights=None,
191 |         normalization=None):
    |

geom3d\models\Equiformer\tensor_product_rescale.py:189:20: FBT002 Boolean default positional argument in function definition
    |
187 |     def __init__(self,
188 |         irreps_in1, irreps_in2, irreps_out,
189 |         bias=True, rescale=True,
    |                    ^^^^^^^ FBT002
190 |         internal_weights=None, shared_weights=None,
191 |         normalization=None):
    |

geom3d\models\Equiformer\tensor_product_rescale.py:209:9: D102 Missing docstring in public method
    |
209 |     def forward(self, x, y, weight=None):
    |         ^^^^^^^ D102
210 |         out = self.forward_tp_rescale_bias(x, y, weight)
211 |         return self.gate(out)
    |

geom3d\models\Equiformer\tensor_product_rescale.py:214:5: D103 Missing docstring in public function
    |
214 | def sort_irreps_even_first(irreps):
    |     ^^^^^^^^^^^^^^^^^^^^^^ D103
215 |     Ret = collections.namedtuple("sort", ["irreps", "p", "inv"])
216 |     out = [(ir.l, -ir.p, i, mul) for i, (mul, ir) in enumerate(irreps)]
    |

geom3d\models\Equiformer\tensor_product_rescale.py:215:11: PYI024 Use `typing.NamedTuple` instead of `collections.namedtuple`
    |
214 | def sort_irreps_even_first(irreps):
215 |     Ret = collections.namedtuple("sort", ["irreps", "p", "inv"])
    |           ^^^^^^^^^^^^^^^^^^^^^^ PYI024
216 |     out = [(ir.l, -ir.p, i, mul) for i, (mul, ir) in enumerate(irreps)]
217 |     out = sorted(out)
    |
    = help: Replace with `typing.NamedTuple`

geom3d\models\Equiformer\tensor_product_rescale.py:220:44: E741 Ambiguous variable name: `l`
    |
218 |     inv = tuple(i for _, _, i, _ in out)
219 |     p = perm.inverse(inv)
220 |     irreps = o3.Irreps([(mul, (l, -p)) for l, p, _, mul in out])
    |                                            ^ E741
221 |     return Ret(irreps, p, inv)
    |

geom3d\models\GPS.py:1:1: N999 Invalid module name: 'GPS'
geom3d\models\GPS.py:1:1: D100 Missing docstring in public module
geom3d\models\GPS.py:2:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | import torch
2 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
3 | from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder
4 | from stk_search.geom3d.models.GPS_layer import GPSLayer
  |

geom3d\models\GPS.py:9:7: D101 Missing docstring in public class
   |
 9 | class SANGraphHead(nn.Module):
   |       ^^^^^^^^^^^^ D101
10 |     def __init__(self, dim_in, dim_out, L=2):
11 |         super().__init__()
   |

geom3d\models\GPS.py:10:9: D107 Missing docstring in `__init__`
   |
 9 | class SANGraphHead(nn.Module):
10 |     def __init__(self, dim_in, dim_out, L=2):
   |         ^^^^^^^^ D107
11 |         super().__init__()
12 |         self.pooling_fun = global_mean_pool
   |

geom3d\models\GPS.py:10:41: N803 Argument name `L` should be lowercase
   |
 9 | class SANGraphHead(nn.Module):
10 |     def __init__(self, dim_in, dim_out, L=2):
   |                                         ^ N803
11 |         super().__init__()
12 |         self.pooling_fun = global_mean_pool
   |

geom3d\models\GPS.py:13:9: N806 Variable `list_FC_layers` in function should be lowercase
   |
11 |         super().__init__()
12 |         self.pooling_fun = global_mean_pool
13 |         list_FC_layers = [
   |         ^^^^^^^^^^^^^^ N806
14 |             nn.Linear(dim_in // 2 ** l, dim_in // 2 ** (l + 1), bias=True)
15 |             for l in range(L)]
   |

geom3d\models\GPS.py:15:17: E741 Ambiguous variable name: `l`
   |
13 |         list_FC_layers = [
14 |             nn.Linear(dim_in // 2 ** l, dim_in // 2 ** (l + 1), bias=True)
15 |             for l in range(L)]
   |                 ^ E741
16 |         list_FC_layers.append(
17 |             nn.Linear(dim_in // 2 ** L, dim_out, bias=True))
   |

geom3d\models\GPS.py:21:9: ANN202 Missing return type annotation for private function `_apply_index`
   |
19 |         self.L = L
20 | 
21 |     def _apply_index(self, batch):
   |         ^^^^^^^^^^^^ ANN202
22 |         return batch.graph_feature, batch.y
   |
   = help: Add return type annotation

geom3d\models\GPS.py:24:9: D102 Missing docstring in public method
   |
22 |         return batch.graph_feature, batch.y
23 | 
24 |     def forward(self, batch):
   |         ^^^^^^^ D102
25 |         graph_emb = self.pooling_fun(batch.x, batch.batch)
26 |         for l in range(self.L):
   |

geom3d\models\GPS.py:26:13: E741 Ambiguous variable name: `l`
   |
24 |     def forward(self, batch):
25 |         graph_emb = self.pooling_fun(batch.x, batch.batch)
26 |         for l in range(self.L):
   |             ^ E741
27 |             graph_emb = self.FC_layers[l](graph_emb)
28 |             graph_emb = F.relu(graph_emb)
   |

geom3d\models\GPS.py:35:7: D101 Missing docstring in public class
   |
35 | class GPSModel(torch.nn.Module):
   |       ^^^^^^^^ D101
36 |     def __init__(
37 |         self, dim_in, num_tasks,
   |

geom3d\models\GPS.py:36:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
35 | class GPSModel(torch.nn.Module):
36 |     def __init__(
   |         ^^^^^^^^ PLR0913
37 |         self, dim_in, num_tasks,
38 |         gt_layers=5, gt_dim_hidden=300, gt_n_heads=4, gt_dropout=0, gt_attn_dropout=0.5,
   |

geom3d\models\GPS.py:36:9: D107 Missing docstring in `__init__`
   |
35 | class GPSModel(torch.nn.Module):
36 |     def __init__(
   |         ^^^^^^^^ D107
37 |         self, dim_in, num_tasks,
38 |         gt_layers=5, gt_dim_hidden=300, gt_n_heads=4, gt_dropout=0, gt_attn_dropout=0.5,
   |

geom3d\models\GPS.py:39:9: FBT002 Boolean default positional argument in function definition
   |
37 |         self, dim_in, num_tasks,
38 |         gt_layers=5, gt_dim_hidden=300, gt_n_heads=4, gt_dropout=0, gt_attn_dropout=0.5,
39 |         gt_layer_norm=False, gt_batch_norm=True
   |         ^^^^^^^^^^^^^ FBT002
40 |     ):
41 |         super().__init__()
   |

geom3d\models\GPS.py:39:30: FBT002 Boolean default positional argument in function definition
   |
37 |         self, dim_in, num_tasks,
38 |         gt_layers=5, gt_dim_hidden=300, gt_n_heads=4, gt_dropout=0, gt_attn_dropout=0.5,
39 |         gt_layer_norm=False, gt_batch_norm=True
   |                              ^^^^^^^^^^^^^ FBT002
40 |     ):
41 |         super().__init__()
   |

geom3d\models\GPS.py:50:13: PERF401 Use a list comprehension to create a transformed list
   |
48 |           layers = []
49 |           for _ in range(gt_layers):
50 |               layers.append(GPSLayer(
   |  _____________^
51 | |                 dim_h=gt_dim_hidden,
52 | |                 local_gnn_type=local_gnn_type,
53 | |                 global_model_type=global_model_type,
54 | |                 num_heads=gt_n_heads,
55 | |                 equivstable_pe=False,
56 | |                 dropout=gt_dropout,
57 | |                 attn_dropout=gt_attn_dropout,
58 | |                 layer_norm=gt_layer_norm,
59 | |                 batch_norm=gt_batch_norm,
60 | |             ))
   | |______________^ PERF401
61 |           self.layers = torch.nn.Sequential(*layers)
   |

geom3d\models\GPS.py:65:9: D102 Missing docstring in public method
   |
63 |         self.post_mp = SANGraphHead(dim_in=dim_in, dim_out=num_tasks)
64 | 
65 |     def forward(self, batch):
   |         ^^^^^^^ D102
66 |         batch.x = self.atom_encoder(batch.x)
67 |         batch.edge_attr = self.bond_encoder(batch.edge_attr)
   |

geom3d\models\GPS_layer.py:1:1: N999 Invalid module name: 'GPS_layer'
geom3d\models\GPS_layer.py:1:1: D100 Missing docstring in public module
geom3d\models\GPS_layer.py:2:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | import torch
2 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
3 | import torch_geometric.nn as pygnn
4 | from torch import nn
  |

geom3d\models\GPS_layer.py:11:7: D101 Missing docstring in public class
   |
 9 | Credit to https://github.com/rampasek/GraphGPS/blob/main/graphGPS/layer/GPS_layer.py
10 | """
11 | class GPSLayer(nn.Module):
   |       ^^^^^^^^ D101
12 |     def __init__(self, dim_h,
13 |                  local_gnn_type, global_model_type, num_heads,
   |

geom3d\models\GPS_layer.py:12:9: C901 `__init__` is too complex (11 > 10)
   |
10 | """
11 | class GPSLayer(nn.Module):
12 |     def __init__(self, dim_h,
   |         ^^^^^^^^ C901
13 |                  local_gnn_type, global_model_type, num_heads,
14 |                  equivstable_pe=False, dropout=0.0,
   |

geom3d\models\GPS_layer.py:12:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
10 | """
11 | class GPSLayer(nn.Module):
12 |     def __init__(self, dim_h,
   |         ^^^^^^^^ PLR0913
13 |                  local_gnn_type, global_model_type, num_heads,
14 |                  equivstable_pe=False, dropout=0.0,
   |

geom3d\models\GPS_layer.py:12:9: D107 Missing docstring in `__init__`
   |
10 | """
11 | class GPSLayer(nn.Module):
12 |     def __init__(self, dim_h,
   |         ^^^^^^^^ D107
13 |                  local_gnn_type, global_model_type, num_heads,
14 |                  equivstable_pe=False, dropout=0.0,
   |

geom3d\models\GPS_layer.py:14:18: FBT002 Boolean default positional argument in function definition
   |
12 |     def __init__(self, dim_h,
13 |                  local_gnn_type, global_model_type, num_heads,
14 |                  equivstable_pe=False, dropout=0.0,
   |                  ^^^^^^^^^^^^^^ FBT002
15 |                  attn_dropout=0.0, layer_norm=False, batch_norm=True):
16 |         super().__init__()
   |

geom3d\models\GPS_layer.py:15:36: FBT002 Boolean default positional argument in function definition
   |
13 |                  local_gnn_type, global_model_type, num_heads,
14 |                  equivstable_pe=False, dropout=0.0,
15 |                  attn_dropout=0.0, layer_norm=False, batch_norm=True):
   |                                    ^^^^^^^^^^ FBT002
16 |         super().__init__()
   |

geom3d\models\GPS_layer.py:15:54: FBT002 Boolean default positional argument in function definition
   |
13 |                  local_gnn_type, global_model_type, num_heads,
14 |                  equivstable_pe=False, dropout=0.0,
15 |                  attn_dropout=0.0, layer_norm=False, batch_norm=True):
   |                                                      ^^^^^^^^^^ FBT002
16 |         super().__init__()
   |

geom3d\models\GPS_layer.py:60:13: ERA001 Found commented-out code
   |
58 |         # Normalization for MPNN and Self-Attention representations.
59 |         if self.layer_norm:
60 |             # self.norm1_local = pygnn.norm.LayerNorm(dim_h)
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
61 |             # self.norm1_attn = pygnn.norm.LayerNorm(dim_h)
62 |             self.norm1_local = pygnn.norm.GraphNorm(dim_h)
   |
   = help: Remove commented-out code

geom3d\models\GPS_layer.py:61:13: ERA001 Found commented-out code
   |
59 |         if self.layer_norm:
60 |             # self.norm1_local = pygnn.norm.LayerNorm(dim_h)
61 |             # self.norm1_attn = pygnn.norm.LayerNorm(dim_h)
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
62 |             self.norm1_local = pygnn.norm.GraphNorm(dim_h)
63 |             self.norm1_attn = pygnn.norm.GraphNorm(dim_h)
   |
   = help: Remove commented-out code

geom3d\models\GPS_layer.py:64:13: ERA001 Found commented-out code
   |
62 |             self.norm1_local = pygnn.norm.GraphNorm(dim_h)
63 |             self.norm1_attn = pygnn.norm.GraphNorm(dim_h)
64 |             # self.norm1_local = pygnn.norm.InstanceNorm(dim_h)
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
65 |             # self.norm1_attn = pygnn.norm.InstanceNorm(dim_h)
66 |         if self.batch_norm:
   |
   = help: Remove commented-out code

geom3d\models\GPS_layer.py:65:13: ERA001 Found commented-out code
   |
63 |             self.norm1_attn = pygnn.norm.GraphNorm(dim_h)
64 |             # self.norm1_local = pygnn.norm.InstanceNorm(dim_h)
65 |             # self.norm1_attn = pygnn.norm.InstanceNorm(dim_h)
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
66 |         if self.batch_norm:
67 |             self.norm1_local = nn.BatchNorm1d(dim_h)
   |
   = help: Remove commented-out code

geom3d\models\GPS_layer.py:77:13: ERA001 Found commented-out code
   |
75 |         self.ff_linear2 = nn.Linear(dim_h * 2, dim_h)
76 |         if self.layer_norm:
77 |             # self.norm2 = pygnn.norm.LayerNorm(dim_h)
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
78 |             self.norm2 = pygnn.norm.GraphNorm(dim_h)
79 |             # self.norm2 = pygnn.norm.InstanceNorm(dim_h)
   |
   = help: Remove commented-out code

geom3d\models\GPS_layer.py:79:13: ERA001 Found commented-out code
   |
77 |             # self.norm2 = pygnn.norm.LayerNorm(dim_h)
78 |             self.norm2 = pygnn.norm.GraphNorm(dim_h)
79 |             # self.norm2 = pygnn.norm.InstanceNorm(dim_h)
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
80 |         if self.batch_norm:
81 |             self.norm2 = nn.BatchNorm1d(dim_h)
   |
   = help: Remove commented-out code

geom3d\models\GPS_layer.py:85:9: C901 `forward` is too complex (13 > 10)
   |
83 |         self.ff_dropout2 = nn.Dropout(dropout)
84 | 
85 |     def forward(self, batch):
   |         ^^^^^^^ C901
86 |         h = batch.x
87 |         h_in1 = h  # for first residual connection
   |

geom3d\models\GPS_layer.py:85:9: PLR0912 Too many branches (15 > 12)
   |
83 |         self.ff_dropout2 = nn.Dropout(dropout)
84 | 
85 |     def forward(self, batch):
   |         ^^^^^^^ PLR0912
86 |         h = batch.x
87 |         h_in1 = h  # for first residual connection
   |

geom3d\models\GPS_layer.py:85:9: D102 Missing docstring in public method
   |
83 |         self.ff_dropout2 = nn.Dropout(dropout)
84 | 
85 |     def forward(self, batch):
   |         ^^^^^^^ D102
86 |         h = batch.x
87 |         h_in1 = h  # for first residual connection
   |

geom3d\models\GPS_layer.py:138:9: ERA001 Found commented-out code
    |
137 |         # Combine local and global outputs.
138 |         # h = torch.cat(h_out_list, dim=-1)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
139 |         h = sum(h_out_list)
    |
    = help: Remove commented-out code

geom3d\models\GPS_layer.py:151:9: ANN202 Missing return type annotation for private function `_sa_block`
    |
149 |         return batch
150 | 
151 |     def _sa_block(self, x, attn_mask, key_padding_mask):
    |         ^^^^^^^^^ ANN202
152 |         """Self-attention block."""
153 |         return self.self_attn(x, x, x,
    |
    = help: Add return type annotation

geom3d\models\GPS_layer.py:158:9: ANN202 Missing return type annotation for private function `_ff_block`
    |
156 |                            need_weights=False)[0]
157 | 
158 |     def _ff_block(self, x):
    |         ^^^^^^^^^ ANN202
159 |         """Feed Forward block."""
160 |         x = self.ff_dropout1(self.activation(self.ff_linear1(x)))
    |
    = help: Add return type annotation

geom3d\models\GPS_layer.py:163:9: D102 Missing docstring in public method
    |
161 |         return self.ff_dropout2(self.ff_linear2(x))
162 | 
163 |     def extra_repr(self):
    |         ^^^^^^^^^^ D102
164 |         return f"summary: dim_h={self.dim_h}, " \
165 |             f"local_gnn_type={self.local_gnn_type}, " \
    |

geom3d\models\GPS_layer.py:164:16: ISC002 Implicitly concatenated string literals over multiple lines
    |
163 |       def extra_repr(self):
164 |           return f"summary: dim_h={self.dim_h}, " \
    |  ________________^
165 | |             f"local_gnn_type={self.local_gnn_type}, " \
    | |_____________________________________________________^ ISC002
166 |               f"global_model_type={self.global_model_type}, " \
167 |               f"heads={self.num_heads}"
    |

geom3d\models\GPS_layer.py:165:13: ISC002 Implicitly concatenated string literals over multiple lines
    |
163 |       def extra_repr(self):
164 |           return f"summary: dim_h={self.dim_h}, " \
165 |               f"local_gnn_type={self.local_gnn_type}, " \
    |  _____________^
166 | |             f"global_model_type={self.global_model_type}, " \
    | |___________________________________________________________^ ISC002
167 |               f"heads={self.num_heads}"
    |

geom3d\models\GPS_layer.py:166:13: ISC002 Implicitly concatenated string literals over multiple lines
    |
164 |           return f"summary: dim_h={self.dim_h}, " \
165 |               f"local_gnn_type={self.local_gnn_type}, " \
166 |               f"global_model_type={self.global_model_type}, " \
    |  _____________^
167 | |             f"heads={self.num_heads}"
    | |_____________________________________^ ISC002
    |

geom3d\models\GVP.py:1:1: N999 Invalid module name: 'GVP'
geom3d\models\GVP.py:1:1: D100 Missing docstring in public module
geom3d\models\GVP.py:6:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
5 | import torch
6 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
7 | import torch_scatter
8 | from torch import nn
  |

geom3d\models\GVP.py:12:15: ANN002 Missing type annotation for `*args`
   |
12 | def tuple_sum(*args):
   |               ^^^^^ ANN002
13 |     """Sums any number of tuples (s, V) elementwise."""
14 |     return tuple(map(sum, zip(*args)))
   |

geom3d\models\GVP.py:13:5: D401 First line of docstring should be in imperative mood: "Sums any number of tuples (s, V) elementwise."
   |
12 | def tuple_sum(*args):
13 |     """Sums any number of tuples (s, V) elementwise."""
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
14 |     return tuple(map(sum, zip(*args)))
   |

geom3d\models\GVP.py:16:15: ANN002 Missing type annotation for `*args`
   |
14 |     return tuple(map(sum, zip(*args)))
15 | 
16 | def tuple_cat(*args, dim=-1):
   |               ^^^^^ ANN002
17 |     """Concatenates any number of tuples (s, V) elementwise.
   |

geom3d\models\GVP.py:36:5: D401 First line of docstring should be in imperative mood: "Returns random tuples (s, V) drawn elementwise from a normal distribution."
   |
35 |   def randn(n, dims, device="cpu"):
36 |       """Returns random tuples (s, V) drawn elementwise from a normal distribution.
   |  _____^
37 | |     
38 | |     :param n: number of data points
39 | |     :param dims: tuple of dimensions (n_scalar, n_vector)
40 | |     
41 | |     :return: (s, V) with s.shape = (n, n_scalar) and
42 | |              V.shape = (n, n_vector, 3)
43 | |     """
   | |_______^ D401
44 |       return torch.randn(n, dims[0], device=device), \
45 |               torch.randn(n, dims[1], 3, device=device)
   |

geom3d\models\GVP.py:47:5: ANN202 Missing return type annotation for private function `_norm_no_nan`
   |
45 |             torch.randn(n, dims[1], 3, device=device)
46 | 
47 | def _norm_no_nan(x, axis=-1, keepdims=False, eps=1e-8, sqrt=True):
   |     ^^^^^^^^^^^^ ANN202
48 |     """L2 norm of tensor clamped above a minimum value `eps`.
   |
   = help: Add return type annotation

geom3d\models\GVP.py:47:30: FBT002 Boolean default positional argument in function definition
   |
45 |             torch.randn(n, dims[1], 3, device=device)
46 | 
47 | def _norm_no_nan(x, axis=-1, keepdims=False, eps=1e-8, sqrt=True):
   |                              ^^^^^^^^ FBT002
48 |     """L2 norm of tensor clamped above a minimum value `eps`.
   |

geom3d\models\GVP.py:47:56: FBT002 Boolean default positional argument in function definition
   |
45 |             torch.randn(n, dims[1], 3, device=device)
46 | 
47 | def _norm_no_nan(x, axis=-1, keepdims=False, eps=1e-8, sqrt=True):
   |                                                        ^^^^ FBT002
48 |     """L2 norm of tensor clamped above a minimum value `eps`.
   |

geom3d\models\GVP.py:55:5: ANN202 Missing return type annotation for private function `_split`
   |
53 |     return torch.sqrt(out) if sqrt else out
54 | 
55 | def _split(x, nv):
   |     ^^^^^^ ANN202
56 |     """Splits a merged representation of (s, V) back into a tuple.
57 |     Should be used only with `_merge(s, V)` and only if the tuple 
   |
   = help: Add return type annotation

geom3d\models\GVP.py:56:5: D205 1 blank line required between summary line and description
   |
55 |   def _split(x, nv):
56 |       """Splits a merged representation of (s, V) back into a tuple.
   |  _____^
57 | |     Should be used only with `_merge(s, V)` and only if the tuple 
58 | |     representation cannot be used.
59 | |     
60 | |     :param x: the `torch.Tensor` returned from `_merge`
61 | |     :param nv: the number of vector channels in the input to `_merge`
62 | |     """
   | |_______^ D205
63 |       v = torch.reshape(x[..., -3*nv:], x.shape[:-1] + (nv, 3))
64 |       s = x[..., :-3*nv]
   |
   = help: Insert single blank line

geom3d\models\GVP.py:56:5: D401 First line of docstring should be in imperative mood: "Splits a merged representation of (s, V) back into a tuple."
   |
55 |   def _split(x, nv):
56 |       """Splits a merged representation of (s, V) back into a tuple.
   |  _____^
57 | |     Should be used only with `_merge(s, V)` and only if the tuple 
58 | |     representation cannot be used.
59 | |     
60 | |     :param x: the `torch.Tensor` returned from `_merge`
61 | |     :param nv: the number of vector channels in the input to `_merge`
62 | |     """
   | |_______^ D401
63 |       v = torch.reshape(x[..., -3*nv:], x.shape[:-1] + (nv, 3))
64 |       s = x[..., :-3*nv]
   |

geom3d\models\GVP.py:67:5: ANN202 Missing return type annotation for private function `_merge`
   |
65 |     return s, v
66 | 
67 | def _merge(s, v):
   |     ^^^^^^ ANN202
68 |     """Merges a tuple (s, V) into a single `torch.Tensor`, where the
69 |     vector channels are flattened and appended to the scalar channels.
   |
   = help: Add return type annotation

geom3d\models\GVP.py:68:5: D205 1 blank line required between summary line and description
   |
67 |   def _merge(s, v):
68 |       """Merges a tuple (s, V) into a single `torch.Tensor`, where the
   |  _____^
69 | |     vector channels are flattened and appended to the scalar channels.
70 | |     Should be used only if the tuple representation cannot be used.
71 | |     Use `_split(x, nv)` to reverse.
72 | |     """
   | |_______^ D205
73 |       v = torch.reshape(v, v.shape[:-2] + (3*v.shape[-2],))
74 |       return torch.cat([s, v], -1)
   |
   = help: Insert single blank line

geom3d\models\GVP.py:68:5: D401 First line of docstring should be in imperative mood: "Merges a tuple (s, V) into a single `torch.Tensor`, where the"
   |
67 |   def _merge(s, v):
68 |       """Merges a tuple (s, V) into a single `torch.Tensor`, where the
   |  _____^
69 | |     vector channels are flattened and appended to the scalar channels.
70 | |     Should be used only if the tuple representation cannot be used.
71 | |     Use `_split(x, nv)` to reverse.
72 | |     """
   | |_______^ D401
73 |       v = torch.reshape(v, v.shape[:-2] + (3*v.shape[-2],))
74 |       return torch.cat([s, v], -1)
   |

geom3d\models\GVP.py:78:5: D205 1 blank line required between summary line and description
   |
77 |   class GVP(nn.Module):
78 |       """Geometric Vector Perceptron. See manuscript and README.md
   |  _____^
79 | |     for more details.
80 | |     
81 | |     :param in_dims: tuple (n_scalar, n_vector)
82 | |     :param out_dims: tuple (n_scalar, n_vector)
83 | |     :param h_dim: intermediate number of vector channels, optional
84 | |     :param activations: tuple of functions (scalar_act, vector_act)
85 | |     :param vector_gate: whether to use vector gating.
86 | |                         (vector_act will be used as sigma^+ in vector gating if `True`)
87 | |     """
   | |_______^ D205
88 |   
89 |       def __init__(self, in_dims, out_dims, h_dim=None,
   |
   = help: Insert single blank line

geom3d\models\GVP.py:89:9: D107 Missing docstring in `__init__`
   |
87 |     """
88 | 
89 |     def __init__(self, in_dims, out_dims, h_dim=None,
   |         ^^^^^^^^ D107
90 |                  activations=(F.relu, torch.sigmoid), vector_gate=False):
91 |         super().__init__()
   |

geom3d\models\GVP.py:90:55: FBT002 Boolean default positional argument in function definition
   |
89 |     def __init__(self, in_dims, out_dims, h_dim=None,
90 |                  activations=(F.relu, torch.sigmoid), vector_gate=False):
   |                                                       ^^^^^^^^^^^ FBT002
91 |         super().__init__()
92 |         self.si, self.vi = in_dims
   |

geom3d\models\GVP.py:101:36: E701 Multiple statements on one line (colon)
    |
 99 |             if self.vo:
100 |                 self.wv = nn.Linear(self.h_dim, self.vo, bias=False)
101 |                 if self.vector_gate: self.wsv = nn.Linear(self.so, self.vo)
    |                                    ^ E701
102 |         else:
103 |             self.ws = nn.Linear(self.si, self.so)
    |

geom3d\models\GVP.py:109:9: D205 1 blank line required between summary line and description
    |
108 |       def forward(self, x):
109 |           """:param x: tuple (s, V) of `torch.Tensor`,
    |  _________^
110 | |                   or (if vectors_in is 0), a single `torch.Tensor`
111 | |         :return: tuple (s, V) of `torch.Tensor`,
112 | |                  or (if vectors_out is 0), a single `torch.Tensor`
113 | |         """
    | |___________^ D205
114 |           if self.vi:
115 |               s, v = x
    |
    = help: Insert single blank line

geom3d\models\GVP.py:143:5: D205 1 blank line required between summary line and description
    |
142 |   class _VDropout(nn.Module):
143 |       """Vector channel dropout where the elements of each
    |  _____^
144 | |     vector channel are dropped together.
145 | |     """
    | |_______^ D205
146 |   
147 |       def __init__(self, drop_rate):
    |
    = help: Insert single blank line

geom3d\models\GVP.py:152:9: ANN202 Missing return type annotation for private function `forward`
    |
150 |         self.dummy_param = nn.Parameter(torch.empty(0))
151 | 
152 |     def forward(self, x):
    |         ^^^^^^^ ANN202
153 |         """:param x: `torch.Tensor` corresponding to vector channels"""
154 |         device = self.dummy_param.device
    |
    = help: Add return type annotation

geom3d\models\GVP.py:163:5: D205 1 blank line required between summary line and description
    |
162 |   class Dropout(nn.Module):
163 |       """Combined dropout for tuples (s, V).
    |  _____^
164 | |     Takes tuples (s, V) as input and as output.
165 | |     """
    | |_______^ D205
166 |   
167 |       def __init__(self, drop_rate):
    |
    = help: Insert single blank line

geom3d\models\GVP.py:167:9: D107 Missing docstring in `__init__`
    |
165 |     """
166 | 
167 |     def __init__(self, drop_rate):
    |         ^^^^^^^^ D107
168 |         super().__init__()
169 |         self.sdropout = nn.Dropout(drop_rate)
    |

geom3d\models\GVP.py:173:9: D205 1 blank line required between summary line and description
    |
172 |       def forward(self, x):
173 |           """:param x: tuple (s, V) of `torch.Tensor`,
    |  _________^
174 | |         or single `torch.Tensor` 
175 | |         (will be assumed to be scalar channels)
176 | |         """
    | |___________^ D205
177 |           if type(x) is torch.Tensor:
178 |               return self.sdropout(x)
    |
    = help: Insert single blank line

geom3d\models\GVP.py:183:5: D205 1 blank line required between summary line and description
    |
182 |   class LayerNorm(nn.Module):
183 |       """Combined LayerNorm for tuples (s, V).
    |  _____^
184 | |     Takes tuples (s, V) as input and as output.
185 | |     """
    | |_______^ D205
186 |   
187 |       def __init__(self, dims):
    |
    = help: Insert single blank line

geom3d\models\GVP.py:187:9: D107 Missing docstring in `__init__`
    |
185 |     """
186 | 
187 |     def __init__(self, dims):
    |         ^^^^^^^^ D107
188 |         super().__init__()
189 |         self.s, self.v = dims
    |

geom3d\models\GVP.py:193:9: D205 1 blank line required between summary line and description
    |
192 |       def forward(self, x):
193 |           """:param x: tuple (s, V) of `torch.Tensor`,
    |  _________^
194 | |         or single `torch.Tensor` 
195 | |         (will be assumed to be scalar channels)
196 | |         """
    | |___________^ D205
197 |           if not self.v:
198 |               return self.scalar_norm(x)
    |
    = help: Insert single blank line

geom3d\models\GVP.py:205:5: D205 1 blank line required between summary line and description
    |
204 |   class GVPConv(MessagePassing):
205 |       """Graph convolution / message passing with Geometric Vector Perceptrons.
    |  _____^
206 | |     Takes in a graph with node and edge embeddings,
207 | |     and returns new node embeddings.
208 | |     
209 | |     This does NOT do residual updates and pointwise feedforward layers
210 | |     ---see `GVPConvLayer`.
211 | |     
212 | |     :param in_dims: input node embedding dimensions (n_scalar, n_vector)
213 | |     :param out_dims: output node embedding dimensions (n_scalar, n_vector)
214 | |     :param edge_dims: input edge embedding dimensions (n_scalar, n_vector)
215 | |     :param n_layers: number of GVPs in the message function
216 | |     :param module_list: preconstructed message function, overrides n_layers
217 | |     :param aggr: should be "add" if some incoming edges are masked, as in
218 | |                  a masked autoregressive decoder architecture, otherwise "mean"
219 | |     :param activations: tuple of functions (scalar_act, vector_act) to use in GVPs
220 | |     :param vector_gate: whether to use vector gating.
221 | |                         (vector_act will be used as sigma^+ in vector gating if `True`)
222 | |     """
    | |_______^ D205
223 |   
224 |       def __init__(self, in_dims, out_dims, edge_dims,
    |
    = help: Insert single blank line

geom3d\models\GVP.py:224:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
222 |     """
223 | 
224 |     def __init__(self, in_dims, out_dims, edge_dims,
    |         ^^^^^^^^ PLR0913
225 |                  n_layers=3, module_list=None, aggr="mean",
226 |                  activations=(F.relu, torch.sigmoid), vector_gate=False):
    |

geom3d\models\GVP.py:224:9: D107 Missing docstring in `__init__`
    |
222 |     """
223 | 
224 |     def __init__(self, in_dims, out_dims, edge_dims,
    |         ^^^^^^^^ D107
225 |                  n_layers=3, module_list=None, aggr="mean",
226 |                  activations=(F.relu, torch.sigmoid), vector_gate=False):
    |

geom3d\models\GVP.py:226:55: FBT002 Boolean default positional argument in function definition
    |
224 |     def __init__(self, in_dims, out_dims, edge_dims,
225 |                  n_layers=3, module_list=None, aggr="mean",
226 |                  activations=(F.relu, torch.sigmoid), vector_gate=False):
    |                                                       ^^^^^^^^^^^ FBT002
227 |         super().__init__(aggr=aggr)
228 |         self.si, self.vi = in_dims
    |

geom3d\models\GVP.py:232:9: N806 Variable `GVP_` in function should be lowercase
    |
230 |         self.se, self.ve = edge_dims
231 | 
232 |         GVP_ = functools.partial(GVP,
    |         ^^^^ N806
233 |                 activations=activations, vector_gate=vector_gate)
    |

geom3d\models\GVP.py:252:9: D205 1 blank line required between summary line and description
    |
251 |       def forward(self, x, edge_index, edge_attr):
252 |           """:param x: tuple (s, V) of `torch.Tensor`
    |  _________^
253 | |         :param edge_index: array of shape [2, n_edges]
254 | |         :param edge_attr: tuple (s, V) of `torch.Tensor`
255 | |         """
    | |___________^ D205
256 |           x_s, x_v = x
257 |           message = self.propagate(edge_index,
    |
    = help: Insert single blank line

geom3d\models\GVP.py:262:9: D102 Missing docstring in public method
    |
260 |         return _split(message, self.vo)
261 | 
262 |     def message(self, s_i, v_i, s_j, v_j, edge_attr):
    |         ^^^^^^^ D102
263 |         v_j = v_j.view(v_j.shape[0], v_j.shape[1]//3, 3)
264 |         v_i = v_i.view(v_i.shape[0], v_i.shape[1]//3, 3)
    |

geom3d\models\GVP.py:271:5: D205 1 blank line required between summary line and description
    |
270 |   class GVPConvLayer(nn.Module):
271 |       """Full graph convolution / message passing layer with
    |  _____^
272 | |     Geometric Vector Perceptrons. Residually updates node embeddings with
273 | |     aggregated incoming messages, applies a pointwise feedforward 
274 | |     network to node embeddings, and returns updated node embeddings.
275 | |     
276 | |     To only compute the aggregated messages, see `GVPConv`.
277 | |     
278 | |     :param node_dims: node embedding dimensions (n_scalar, n_vector)
279 | |     :param edge_dims: input edge embedding dimensions (n_scalar, n_vector)
280 | |     :param n_message: number of GVPs to use in message function
281 | |     :param n_feedforward: number of GVPs to use in feedforward function
282 | |     :param drop_rate: drop probability in all dropout layers
283 | |     :param autoregressive: if `True`, this `GVPConvLayer` will be used
284 | |            with a different set of input node embeddings for messages
285 | |            where src >= dst
286 | |     :param activations: tuple of functions (scalar_act, vector_act) to use in GVPs
287 | |     :param vector_gate: whether to use vector gating.
288 | |                         (vector_act will be used as sigma^+ in vector gating if `True`)
289 | |     """
    | |_______^ D205
290 |   
291 |       def __init__(self, node_dims, edge_dims,
    |
    = help: Insert single blank line

geom3d\models\GVP.py:291:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
289 |     """
290 | 
291 |     def __init__(self, node_dims, edge_dims,
    |         ^^^^^^^^ PLR0913
292 |                  n_message=3, n_feedforward=2, drop_rate=.1,
293 |                  autoregressive=False,
    |

geom3d\models\GVP.py:291:9: D107 Missing docstring in `__init__`
    |
289 |     """
290 | 
291 |     def __init__(self, node_dims, edge_dims,
    |         ^^^^^^^^ D107
292 |                  n_message=3, n_feedforward=2, drop_rate=.1,
293 |                  autoregressive=False,
    |

geom3d\models\GVP.py:293:18: FBT002 Boolean default positional argument in function definition
    |
291 |     def __init__(self, node_dims, edge_dims,
292 |                  n_message=3, n_feedforward=2, drop_rate=.1,
293 |                  autoregressive=False,
    |                  ^^^^^^^^^^^^^^ FBT002
294 |                  activations=(F.relu, torch.sigmoid), vector_gate=False):
    |

geom3d\models\GVP.py:294:55: FBT002 Boolean default positional argument in function definition
    |
292 |                  n_message=3, n_feedforward=2, drop_rate=.1,
293 |                  autoregressive=False,
294 |                  activations=(F.relu, torch.sigmoid), vector_gate=False):
    |                                                       ^^^^^^^^^^^ FBT002
295 | 
296 |         super().__init__()
    |

geom3d\models\GVP.py:300:9: N806 Variable `GVP_` in function should be lowercase
    |
298 |                            aggr="add" if autoregressive else "mean",
299 |                            activations=activations, vector_gate=vector_gate)
300 |         GVP_ = functools.partial(GVP,
    |         ^^^^ N806
301 |                 activations=activations, vector_gate=vector_gate)
302 |         self.norm = nn.ModuleList([LayerNorm(node_dims) for _ in range(2)])
    |

geom3d\models\GVP.py:312:17: PERF401 Use a list comprehension to create a transformed list
    |
310 |             ff_func.append(GVP_(node_dims, hid_dims))
311 |             for _i in range(n_feedforward-2):
312 |                 ff_func.append(GVP_(hid_dims, hid_dims))
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PERF401
313 |             ff_func.append(GVP_(hid_dims, node_dims, activations=(None, None)))
314 |         self.ff_func = nn.Sequential(*ff_func)
    |

geom3d\models\GVP.py:318:9: D205 1 blank line required between summary line and description
    |
316 |       def forward(self, x, edge_index, edge_attr,
317 |                   autoregressive_x=None, node_mask=None):
318 |           """:param x: tuple (s, V) of `torch.Tensor`
    |  _________^
319 | |         :param edge_index: array of shape [2, n_edges]
320 | |         :param edge_attr: tuple (s, V) of `torch.Tensor`
321 | |         :param autoregressive_x: tuple (s, V) of `torch.Tensor`. 
322 | |                 If not `None`, will be used as src node embeddings
323 | |                 for forming messages where src >= dst. The corrent node 
324 | |                 embeddings `x` will still be the base of the update and the 
325 | |                 pointwise feedforward.
326 | |         :param node_mask: array of type `bool` to index into the first
327 | |                 dim of node embeddings (s, V). If not `None`, only
328 | |                 these nodes will be updated.
329 | |         """
    | |___________^ D205
330 |           if autoregressive_x is not None:
331 |               src, dst = edge_index
    |
    = help: Insert single blank line

geom3d\models\GVP.py:370:5: ANN202 Missing return type annotation for private function `_element_mapping`
    |
369 | _NUM_ATOM_TYPES = 9
370 | def _element_mapping(x):
    |     ^^^^^^^^^^^^^^^^ ANN202
371 |     return {"H": 0, "C": 1, "N": 2, "O": 3, "F": 4, "S": 5, "Cl": 6, "CL": 6, "P": 7}.get(x, 8)
372 | def _amino_acids(x):
    |
    = help: Add return type annotation

geom3d\models\GVP.py:372:5: ANN202 Missing return type annotation for private function `_amino_acids`
    |
370 | def _element_mapping(x):
371 |     return {"H": 0, "C": 1, "N": 2, "O": 3, "F": 4, "S": 5, "Cl": 6, "CL": 6, "P": 7}.get(x, 8)
372 | def _amino_acids(x):
    |     ^^^^^^^^^^^^ ANN202
373 |     return {"ALA": 0, "ARG": 1, "ASN": 2, "ASP": 3, "CYS": 4, "GLU": 5, "GLN": 6, "GLY": 7, "HIS": 8, "ILE": 9, "LEU": 10, "LYS": 11, "MET": 12, "PHE": 13, "PRO": 14, "SER": 15, "THR": 16, "TRP": 17, "TYR": 18, "VAL": 19}.get(x, 20)
374 | _DEFAULT_V_DIM = (100, 16)
    |
    = help: Add return type annotation

geom3d\models\GVP.py:378:7: N801 Class name `GVP_GNN` should use CapWords convention
    |
378 | class GVP_GNN(nn.Module):
    |       ^^^^^^^ N801
379 |     """A base 5-layer GVP-GNN for all ATOM3D tasks, using GVPs with
380 |     vector gating as described in the manuscript. Takes in atomic-level
    |

geom3d\models\GVP.py:379:5: D205 1 blank line required between summary line and description
    |
378 |   class GVP_GNN(nn.Module):
379 |       """A base 5-layer GVP-GNN for all ATOM3D tasks, using GVPs with
    |  _____^
380 | |     vector gating as described in the manuscript. Takes in atomic-level
381 | |     structure graphs of type `torch_geometric.data.Batch`
382 | |     and returns a single scalar.
383 | |     
384 | |     This class should not be used directly. Instead, please use the
385 | |     task-specific models which extend BaseModel. (Some of these classes
386 | |     may be aliases of BaseModel.)
387 | |     
388 | |     :param num_rbf: number of radial bases to use in the edge embedding
389 | |     """
    | |_______^ D205
390 |   
391 |       def __init__(self, num_rbf=16, out_channels=1195):
    |
    = help: Insert single blank line

geom3d\models\GVP.py:391:9: D107 Missing docstring in `__init__`
    |
389 |     """
390 | 
391 |     def __init__(self, num_rbf=16, out_channels=1195):
    |         ^^^^^^^^ D107
392 | 
393 |         super().__init__()
    |

geom3d\models\GVP.py:428:30: FBT002 Boolean default positional argument in function definition
    |
426 |         )
427 | 
428 |     def forward(self, batch, scatter_mean=True, dense=True):
    |                              ^^^^^^^^^^^^ FBT002
429 |         """Forward pass which can be adjusted based on task formulation.
    |

geom3d\models\GVP.py:428:49: FBT002 Boolean default positional argument in function definition
    |
426 |         )
427 | 
428 |     def forward(self, batch, scatter_mean=True, dense=True):
    |                                                 ^^^^^ FBT002
429 |         """Forward pass which can be adjusted based on task formulation.
    |

geom3d\models\GVP.py:438:9: N806 Variable `h_V` in function should be lowercase
    |
436 |                       to a single scalar; else, returns the embedding
437 |         """
438 |         h_V = self.embed(batch.atoms)
    |         ^^^ N806
439 |         h_E = (batch.edge_s, batch.edge_v)
440 |         h_V = self.W_v(h_V)
    |

geom3d\models\GVP.py:439:9: N806 Variable `h_E` in function should be lowercase
    |
437 |         """
438 |         h_V = self.embed(batch.atoms)
439 |         h_E = (batch.edge_s, batch.edge_v)
    |         ^^^ N806
440 |         h_V = self.W_v(h_V)
441 |         h_E = self.W_e(h_E)
    |

geom3d\models\GVP.py:440:9: N806 Variable `h_V` in function should be lowercase
    |
438 |         h_V = self.embed(batch.atoms)
439 |         h_E = (batch.edge_s, batch.edge_v)
440 |         h_V = self.W_v(h_V)
    |         ^^^ N806
441 |         h_E = self.W_e(h_E)
    |

geom3d\models\GVP.py:441:9: N806 Variable `h_E` in function should be lowercase
    |
439 |         h_E = (batch.edge_s, batch.edge_v)
440 |         h_V = self.W_v(h_V)
441 |         h_E = self.W_e(h_E)
    |         ^^^ N806
442 | 
443 |         batch_id = batch.batch
    |

geom3d\models\GVP.py:446:13: N806 Variable `h_V` in function should be lowercase
    |
445 |         for layer in self.layers:
446 |             h_V = layer(h_V, batch.edge_index, h_E)
    |             ^^^ N806
447 | 
448 |         out = self.W_out(h_V)
    |

geom3d\models\GVP.py:449:24: E701 Multiple statements on one line (colon)
    |
448 |         out = self.W_out(h_V)
449 |         if scatter_mean: out = torch_scatter.scatter_mean(out, batch_id, dim=0)
    |                        ^ E701
450 |         if dense: out = self.dense(out).squeeze(-1)
451 |         return out
    |

geom3d\models\GVP.py:450:17: E701 Multiple statements on one line (colon)
    |
448 |         out = self.W_out(h_V)
449 |         if scatter_mean: out = torch_scatter.scatter_mean(out, batch_id, dim=0)
450 |         if dense: out = self.dense(out).squeeze(-1)
    |                 ^ E701
451 |         return out
    |

geom3d\models\GearNet.py:1:1: N999 Invalid module name: 'GearNet'
geom3d\models\GearNet.py:1:1: D100 Missing docstring in public module
geom3d\models\GearNet.py:11:7: D101 Missing docstring in public class
   |
11 | class GearNet(nn.Module):
   |       ^^^^^^^ D101
12 |     def __init__(self, input_dim, hidden_dims, num_relation, edge_input_dim=None, num_angle_bin=None,
13 |                  short_cut=False, batch_norm=False, activation="relu", concat_hidden=False, readout="sum"):
   |

geom3d\models\GearNet.py:12:9: PLR0913 Too many arguments in function definition (10 > 5)
   |
11 | class GearNet(nn.Module):
12 |     def __init__(self, input_dim, hidden_dims, num_relation, edge_input_dim=None, num_angle_bin=None,
   |         ^^^^^^^^ PLR0913
13 |                  short_cut=False, batch_norm=False, activation="relu", concat_hidden=False, readout="sum"):
14 |         super().__init__()
   |

geom3d\models\GearNet.py:12:9: D107 Missing docstring in `__init__`
   |
11 | class GearNet(nn.Module):
12 |     def __init__(self, input_dim, hidden_dims, num_relation, edge_input_dim=None, num_angle_bin=None,
   |         ^^^^^^^^ D107
13 |                  short_cut=False, batch_norm=False, activation="relu", concat_hidden=False, readout="sum"):
14 |         super().__init__()
   |

geom3d\models\GearNet.py:13:18: FBT002 Boolean default positional argument in function definition
   |
11 | class GearNet(nn.Module):
12 |     def __init__(self, input_dim, hidden_dims, num_relation, edge_input_dim=None, num_angle_bin=None,
13 |                  short_cut=False, batch_norm=False, activation="relu", concat_hidden=False, readout="sum"):
   |                  ^^^^^^^^^ FBT002
14 |         super().__init__()
   |

geom3d\models\GearNet.py:13:35: FBT002 Boolean default positional argument in function definition
   |
11 | class GearNet(nn.Module):
12 |     def __init__(self, input_dim, hidden_dims, num_relation, edge_input_dim=None, num_angle_bin=None,
13 |                  short_cut=False, batch_norm=False, activation="relu", concat_hidden=False, readout="sum"):
   |                                   ^^^^^^^^^^ FBT002
14 |         super().__init__()
   |

geom3d\models\GearNet.py:13:72: FBT002 Boolean default positional argument in function definition
   |
11 | class GearNet(nn.Module):
12 |     def __init__(self, input_dim, hidden_dims, num_relation, edge_input_dim=None, num_angle_bin=None,
13 |                  short_cut=False, batch_norm=False, activation="relu", concat_hidden=False, readout="sum"):
   |                                                                        ^^^^^^^^^^^^^ FBT002
14 |         super().__init__()
   |

geom3d\models\GearNet.py:47:28: F821 Undefined name `scatter_mean`
   |
45 |             self.readout = scatter_add
46 |         elif readout == "mean":
47 |             self.readout = scatter_mean
   |                            ^^^^^^^^^^^^ F821
48 |         else:
49 |             msg = f"Unknown readout `{readout}`"
   |

geom3d\models\GearNet.py:52:9: D102 Missing docstring in public method
   |
50 |             raise ValueError(msg)
51 | 
52 |     def forward(self, graph, input, all_loss=None, metric=None):
   |         ^^^^^^^ D102
53 |         hiddens = []
54 |         layer_input = input
   |

geom3d\models\GearNet.py:52:30: A002 Argument `input` is shadowing a Python builtin
   |
50 |             raise ValueError(msg)
51 | 
52 |     def forward(self, graph, input, all_loss=None, metric=None):
   |                              ^^^^^ A002
53 |         hiddens = []
54 |         layer_input = input
   |

geom3d\models\GearNet.py:52:37: ARG002 Unused method argument: `all_loss`
   |
50 |             raise ValueError(msg)
51 | 
52 |     def forward(self, graph, input, all_loss=None, metric=None):
   |                                     ^^^^^^^^ ARG002
53 |         hiddens = []
54 |         layer_input = input
   |

geom3d\models\GearNet.py:52:52: ARG002 Unused method argument: `metric`
   |
50 |             raise ValueError(msg)
51 | 
52 |     def forward(self, graph, input, all_loss=None, metric=None):
   |                                                    ^^^^^^ ARG002
53 |         hiddens = []
54 |         layer_input = input
   |

geom3d\models\GearNet_layer.py:1:1: N999 Invalid module name: 'GearNet_layer'
geom3d\models\GearNet_layer.py:1:1: D100 Missing docstring in public module
geom3d\models\GearNet_layer.py:5:22: N812 Lowercase `functional` imported as non-lowercase `F`
  |
3 | import torch
4 | from torch import nn
5 | from torch.nn import functional as F
  |                      ^^^^^^^^^^^^^^^ N812
6 | from torch_geometric.data import Data
7 | from torch_scatter import scatter_add
  |

geom3d\models\GearNet_layer.py:10:7: D101 Missing docstring in public class
   |
10 | class MultiLayerPerceptron(nn.Module):
   |       ^^^^^^^^^^^^^^^^^^^^ D101
11 |     def __init__(self, input_dim, hidden_dims, short_cut=False, batch_norm=False, activation="relu", dropout=0):
12 |         super().__init__()
   |

geom3d\models\GearNet_layer.py:11:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
10 | class MultiLayerPerceptron(nn.Module):
11 |     def __init__(self, input_dim, hidden_dims, short_cut=False, batch_norm=False, activation="relu", dropout=0):
   |         ^^^^^^^^ PLR0913
12 |         super().__init__()
   |

geom3d\models\GearNet_layer.py:11:9: D107 Missing docstring in `__init__`
   |
10 | class MultiLayerPerceptron(nn.Module):
11 |     def __init__(self, input_dim, hidden_dims, short_cut=False, batch_norm=False, activation="relu", dropout=0):
   |         ^^^^^^^^ D107
12 |         super().__init__()
   |

geom3d\models\GearNet_layer.py:11:48: FBT002 Boolean default positional argument in function definition
   |
10 | class MultiLayerPerceptron(nn.Module):
11 |     def __init__(self, input_dim, hidden_dims, short_cut=False, batch_norm=False, activation="relu", dropout=0):
   |                                                ^^^^^^^^^ FBT002
12 |         super().__init__()
   |

geom3d\models\GearNet_layer.py:11:65: FBT002 Boolean default positional argument in function definition
   |
10 | class MultiLayerPerceptron(nn.Module):
11 |     def __init__(self, input_dim, hidden_dims, short_cut=False, batch_norm=False, activation="relu", dropout=0):
   |                                                                 ^^^^^^^^^^ FBT002
12 |         super().__init__()
   |

geom3d\models\GearNet_layer.py:14:40: F821 Undefined name `Sequence`
   |
12 |         super().__init__()
13 | 
14 |         if not isinstance(hidden_dims, Sequence):
   |                                        ^^^^^^^^ F821
15 |             hidden_dims = [hidden_dims]
16 |         self.dims = [input_dim, *hidden_dims]
   |

geom3d\models\GearNet_layer.py:38:9: D102 Missing docstring in public method
   |
36 |             self.batch_norms = None
37 | 
38 |     def forward(self, input):
   |         ^^^^^^^ D102
39 |         layer_input = input
   |

geom3d\models\GearNet_layer.py:38:23: A002 Argument `input` is shadowing a Python builtin
   |
36 |             self.batch_norms = None
37 | 
38 |     def forward(self, input):
   |                       ^^^^^ A002
39 |         layer_input = input
   |

geom3d\models\GearNet_layer.py:57:7: D101 Missing docstring in public class
   |
57 | class IEConvLayer(nn.Module):
   |       ^^^^^^^^^^^ D101
58 |     eps = 1e-6
   |

geom3d\models\GearNet_layer.py:60:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
58 |     eps = 1e-6
59 | 
60 |     def __init__(self, input_dim, hidden_dim, output_dim, edge_input_dim, kernel_hidden_dim=32,
   |         ^^^^^^^^ PLR0913
61 |                 dropout=0.05, dropout_before_conv=0.2, activation="relu", aggregate_func="sum"):
62 |         super().__init__()
   |

geom3d\models\GearNet_layer.py:60:9: D107 Missing docstring in `__init__`
   |
58 |     eps = 1e-6
59 | 
60 |     def __init__(self, input_dim, hidden_dim, output_dim, edge_input_dim, kernel_hidden_dim=32,
   |         ^^^^^^^^ D107
61 |                 dropout=0.05, dropout_before_conv=0.2, activation="relu", aggregate_func="sum"):
62 |         super().__init__()
   |

geom3d\models\GearNet_layer.py:87:9: D102 Missing docstring in public method
   |
85 |             self.activation = activation
86 | 
87 |     def message(self, graph, input, edge_input):
   |         ^^^^^^^ D102
88 |         node_in = graph.edge_list[:, 0]
89 |         message = self.linear1(input[node_in])
   |

geom3d\models\GearNet_layer.py:87:30: A002 Argument `input` is shadowing a Python builtin
   |
85 |             self.activation = activation
86 | 
87 |     def message(self, graph, input, edge_input):
   |                              ^^^^^ A002
88 |         node_in = graph.edge_list[:, 0]
89 |         message = self.linear1(input[node_in])
   |

geom3d\models\GearNet_layer.py:96:9: D102 Missing docstring in public method
   |
96 |     def aggregate(self, graph, message):
   |         ^^^^^^^^^ D102
97 |         node_in, node_out = graph.edge_list.t()[:2]
98 |         edge_weight = graph.edge_weight.unsqueeze(-1)
   |

geom3d\models\GearNet_layer.py:107:9: D102 Missing docstring in public method
    |
105 |         return update
106 | 
107 |     def combine(self, input, update):
    |         ^^^^^^^ D102
108 |         return self.linear2(update)
    |

geom3d\models\GearNet_layer.py:107:23: A002 Argument `input` is shadowing a Python builtin
    |
105 |         return update
106 | 
107 |     def combine(self, input, update):
    |                       ^^^^^ A002
108 |         return self.linear2(update)
    |

geom3d\models\GearNet_layer.py:107:23: ARG002 Unused method argument: `input`
    |
105 |         return update
106 | 
107 |     def combine(self, input, update):
    |                       ^^^^^ ARG002
108 |         return self.linear2(update)
    |

geom3d\models\GearNet_layer.py:110:9: D102 Missing docstring in public method
    |
108 |         return self.linear2(update)
109 | 
110 |     def forward(self, graph, input, edge_input):
    |         ^^^^^^^ D102
111 |         input = self.input_batch_norm(input)
112 |         layer_input = self.dropout(self.activation(input))
    |

geom3d\models\GearNet_layer.py:110:30: A002 Argument `input` is shadowing a Python builtin
    |
108 |         return self.linear2(update)
109 | 
110 |     def forward(self, graph, input, edge_input):
    |                              ^^^^^ A002
111 |         input = self.input_batch_norm(input)
112 |         layer_input = self.dropout(self.activation(input))
    |

geom3d\models\GearNet_layer.py:111:9: A001 Variable `input` is shadowing a Python builtin
    |
110 |     def forward(self, graph, input, edge_input):
111 |         input = self.input_batch_norm(input)
    |         ^^^^^ A001
112 |         layer_input = self.dropout(self.activation(input))
    |

geom3d\models\GearNet_layer.py:122:7: D101 Missing docstring in public class
    |
122 | class GeometricRelationalGraphConv(nn.Module):
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
123 |     eps = 1e-6
    |

geom3d\models\GearNet_layer.py:125:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
123 |     eps = 1e-6
124 | 
125 |     def __init__(self, input_dim, output_dim, num_relation, edge_input_dim=None,
    |         ^^^^^^^^ PLR0913
126 |                 batch_norm=False, activation="relu"):
127 |         super().__init__()
    |

geom3d\models\GearNet_layer.py:125:9: D107 Missing docstring in `__init__`
    |
123 |     eps = 1e-6
124 | 
125 |     def __init__(self, input_dim, output_dim, num_relation, edge_input_dim=None,
    |         ^^^^^^^^ D107
126 |                 batch_norm=False, activation="relu"):
127 |         super().__init__()
    |

geom3d\models\GearNet_layer.py:126:17: FBT002 Boolean default positional argument in function definition
    |
125 |     def __init__(self, input_dim, output_dim, num_relation, edge_input_dim=None,
126 |                 batch_norm=False, activation="relu"):
    |                 ^^^^^^^^^^ FBT002
127 |         super().__init__()
128 |         self.input_dim = input_dim
    |

geom3d\models\GearNet_layer.py:148:9: D102 Missing docstring in public method
    |
146 |             self.edge_linear = None
147 | 
148 |     def message(self, graph, input, edge_input=None):
    |         ^^^^^^^ D102
149 |         node_in = graph.edge_list[:, 0]
150 |         message = input[node_in]
    |

geom3d\models\GearNet_layer.py:148:30: A002 Argument `input` is shadowing a Python builtin
    |
146 |             self.edge_linear = None
147 | 
148 |     def message(self, graph, input, edge_input=None):
    |                              ^^^^^ A002
149 |         node_in = graph.edge_list[:, 0]
150 |         message = input[node_in]
    |

geom3d\models\GearNet_layer.py:154:13: S101 Use of `assert` detected
    |
152 |             message += self.edge_linear(graph.edge_feature.float())
153 |         if edge_input is not None:
154 |             assert edge_input.shape == message.shape
    |             ^^^^^^ S101
155 |             message += edge_input
156 |         return message
    |

geom3d\models\GearNet_layer.py:158:9: D102 Missing docstring in public method
    |
156 |         return message
157 | 
158 |     def aggregate(self, graph, message):
    |         ^^^^^^^^^ D102
159 |         assert graph.num_relation == self.num_relation
    |

geom3d\models\GearNet_layer.py:159:9: S101 Use of `assert` detected
    |
158 |     def aggregate(self, graph, message):
159 |         assert graph.num_relation == self.num_relation
    |         ^^^^^^ S101
160 | 
161 |         node_out = graph.edge_list[:, 1] * self.num_relation + graph.edge_list[:, 2]
    |

geom3d\models\GearNet_layer.py:167:9: D102 Missing docstring in public method
    |
167 |     def combine(self, input, update):
    |         ^^^^^^^ D102
168 |         output = self.linear(update)
169 |         if self.batch_norm:
    |

geom3d\models\GearNet_layer.py:167:23: A002 Argument `input` is shadowing a Python builtin
    |
167 |     def combine(self, input, update):
    |                       ^^^^^ A002
168 |         output = self.linear(update)
169 |         if self.batch_norm:
    |

geom3d\models\GearNet_layer.py:167:23: ARG002 Unused method argument: `input`
    |
167 |     def combine(self, input, update):
    |                       ^^^^^ ARG002
168 |         output = self.linear(update)
169 |         if self.batch_norm:
    |

geom3d\models\GearNet_layer.py:175:9: D102 Missing docstring in public method
    |
173 |         return output
174 | 
175 |     def forward(self, graph, input, edge_input=None):
    |         ^^^^^^^ D102
176 |         message = self.message(graph, input, edge_input)
177 |         update = self.aggregate(graph, message)
    |

geom3d\models\GearNet_layer.py:175:30: A002 Argument `input` is shadowing a Python builtin
    |
173 |         return output
174 | 
175 |     def forward(self, graph, input, edge_input=None):
    |                              ^^^^^ A002
176 |         message = self.message(graph, input, edge_input)
177 |         update = self.aggregate(graph, message)
    |

geom3d\models\GearNet_layer.py:181:7: D101 Missing docstring in public class
    |
181 | class SpatialLineGraph(nn.Module):
    |       ^^^^^^^^^^^^^^^^ D101
182 |     def __init__(self, num_angle_bin=8):
183 |         super().__init__()
    |

geom3d\models\GearNet_layer.py:182:9: D107 Missing docstring in `__init__`
    |
181 | class SpatialLineGraph(nn.Module):
182 |     def __init__(self, num_angle_bin=8):
    |         ^^^^^^^^ D107
183 |         super().__init__()
184 |         self.num_angle_bin = num_angle_bin
    |

geom3d\models\GearNet_layer.py:186:9: D417 Missing argument description in the docstring for `forward`: `graph`
    |
184 |         self.num_angle_bin = num_angle_bin
185 | 
186 |     def forward(self, graph):
    |         ^^^^^^^ D417
187 |         """Generate the spatial line graph of the input graph.
188 |         The edge types are decided by the angles between two adjacent edges in the input graph.
    |

geom3d\models\GearNet_layer.py:187:9: D205 1 blank line required between summary line and description
    |
186 |       def forward(self, graph):
187 |           """Generate the spatial line graph of the input graph.
    |  _________^
188 | |         The edge types are decided by the angles between two adjacent edges in the input graph.
189 | | 
190 | |         Parameters
191 | |         ----------
192 | |             graph (PackedGraph): :math:`n` graph(s)
193 | | 
194 | |         Returns
195 | |         -------
196 | |             graph (PackedGraph): the spatial line graph
197 | | 
198 | |         """
    | |___________^ D205
199 |           line_graph = construct_line_graph(graph)
200 |           node_in, node_out = graph.edge_list[:, :2].t()
    |
    = help: Insert single blank line

geom3d\models\GearNet_layer.py:220:5: ANN202 Missing return type annotation for private function `_get_offsets`
    |
220 | def _get_offsets(graph, num_nodes=None, num_edges=None, num_cum_nodes=None, num_cum_edges=None):
    |     ^^^^^^^^^^^^ ANN202
221 |     if num_nodes is None:
222 |         prepend = torch.tensor([0], device=graph.node_feature.device)
    |
    = help: Add return type annotation

geom3d\models\GearNet_layer.py:233:5: D205 1 blank line required between summary line and description
    |
232 |   def construct_line_graph(graph):
233 |       """Construct a packed line graph of this packed graph.
    |  _____^
234 | |     The node features of the line graphs are inherited from the edge features of the original graphs.
235 | | 
236 | |     In the line graph, each node corresponds to an edge in the original graph.
237 | |     For a pair of edges (a, b) and (b, c) that share the same intermediate node in the original graph,
238 | |     there is a directed edge (a, b) -> (b, c) in the line graph.
239 | | 
240 | |     Returns
241 | |     -------
242 | |         PackedGraph
243 | | 
244 | |     """
    | |_______^ D205
245 |       node_in, node_out = graph.edge_list.t()[:2]
246 |       edge_index = torch.arange(graph.num_edge, device=graph.node_feature.device)
    |
    = help: Insert single blank line

geom3d\models\GearNet_layer.py:254:5: A001 Variable `range` is shadowing a Python builtin
    |
252 |     size = degree_out * degree_in
253 |     starts = (size.cumsum(0) - size).repeat_interleave(size)
254 |     range = torch.arange(size.sum(), device=graph.node_feature.device)
    |     ^^^^^ A001
255 |     # each node u has degree_out[u] * degree_in[u] local edges
256 |     local_index = range - starts
    |

geom3d\models\GemNet\GemNet.py:1:1: N999 Invalid module name: 'GemNet'
geom3d\models\GemNet\GemNet.py:1:1: D100 Missing docstring in public module
geom3d\models\GemNet\GemNet.py:32:5: D205 1 blank line required between summary line and description
   |
31 |   class GemNet(torch.nn.Module):
32 |       """Parameters
   |  _____^
33 | |     ----------
34 | |         num_spherical: int
35 | |             Controls maximum frequency.
36 | |         num_radial: int
37 | |             Controls maximum frequency.
38 | |         num_blocks: int
39 | |             Number of building blocks to be stacked.
40 | |         emb_size_atom: int
41 | |             Embedding size of the atoms.
42 | |         emb_size_edge: int
43 | |             Embedding size of the edges.
44 | |         emb_size_trip: int
45 | |             (Down-projected) Embedding size in the triplet message passing block.
46 | |         emb_size_quad: int
47 | |             (Down-projected) Embedding size in the quadruplet message passing block.
48 | |         emb_size_rbf: int
49 | |             Embedding size of the radial basis transformation.
50 | |         emb_size_cbf: int
51 | |             Embedding size of the circular basis transformation (one angle).
52 | |         emb_size_sbf: int
53 | |             Embedding size of the spherical basis transformation (two angles).
54 | |         emb_size_bil_trip: int
55 | |             Embedding size of the edge embeddings in the triplet-based message passing block after the bilinear layer.
56 | |         emb_size_bil_quad: int
57 | |             Embedding size of the edge embeddings in the quadruplet-based message passing block after the bilinear layer.
58 | |         num_before_skip: int
59 | |             Number of residual blocks before the first skip connection.
60 | |         num_after_skip: int
61 | |             Number of residual blocks after the first skip connection.
62 | |         num_concat: int
63 | |             Number of residual blocks after the concatenation.
64 | |         num_atom: int
65 | |             Number of residual blocks in the atom embedding blocks.
66 | |         direct_forces: bool
67 | |             If True predict forces based on aggregation of interatomic directions.
68 | |             If False predict forces based on negative gradient of energy potential.
69 | |         triplets_only: bool
70 | |             If True use GemNet-T or GemNet-dT.No quadruplet based message passing.
71 | |         num_targets: int
72 | |             Number of prediction targets.
73 | |         cutoff: float
74 | |             Embedding cutoff for interactomic directions in Angstrom.
75 | |         int_cutoff: float
76 | |             Interaction cutoff for interactomic directions in Angstrom. No effect for GemNet-(d)T
77 | |         envelope_exponent: int
78 | |             Exponent of the envelope function. Determines the shape of the smooth cutoff.
79 | |         extensive: bool
80 | |             Whether the output should be extensive (proportional to the number of atoms)
81 | |         forces_coupled: bool
82 | |             No effect if direct_forces is False. If True enforce that |F_ac| = |F_ca|
83 | |         output_init: str
84 | |             Initialization method for the final dense layer.
85 | |         activation: str
86 | |             Name of the activation function.
87 | |         scale_file: str
88 | |             Path to the json file containing the scaling factors.
89 | | 
90 | |     """
   | |_______^ D205
91 |   
92 |       def __init__(
   |
   = help: Insert single blank line

geom3d\models\GemNet\GemNet.py:92:9: PLR0913 Too many arguments in function definition (29 > 5)
   |
90 |     """
91 | 
92 |     def __init__(
   |         ^^^^^^^^ PLR0913
93 |         self,
94 |         node_class: int,
   |

geom3d\models\GemNet\GemNet.py:92:9: D107 Missing docstring in `__init__`
   |
90 |     """
91 | 
92 |     def __init__(
   |         ^^^^^^^^ D107
93 |         self,
94 |         node_class: int,
   |

geom3d\models\GemNet\GemNet.py:111:9: FBT001 Boolean-typed positional argument in function definition
    |
109 |         num_concat: int,
110 |         num_atom: int,
111 |         triplets_only: bool,
    |         ^^^^^^^^^^^^^ FBT001
112 |         num_targets: int = 1,
113 |         direct_forces: bool = False,
    |

geom3d\models\GemNet\GemNet.py:113:9: FBT001 Boolean-typed positional argument in function definition
    |
111 |         triplets_only: bool,
112 |         num_targets: int = 1,
113 |         direct_forces: bool = False,
    |         ^^^^^^^^^^^^^ FBT001
114 |         cutoff: float = 5.0,
115 |         int_cutoff: float = 10.0,  # no effect for GemNet-(d)T
    |

geom3d\models\GemNet\GemNet.py:113:9: FBT002 Boolean default positional argument in function definition
    |
111 |         triplets_only: bool,
112 |         num_targets: int = 1,
113 |         direct_forces: bool = False,
    |         ^^^^^^^^^^^^^ FBT002
114 |         cutoff: float = 5.0,
115 |         int_cutoff: float = 10.0,  # no effect for GemNet-(d)T
    |

geom3d\models\GemNet\GemNet.py:117:9: FBT002 Boolean default positional argument in function definition
    |
115 |         int_cutoff: float = 10.0,  # no effect for GemNet-(d)T
116 |         envelope_exponent: int = 5,
117 |         extensive=True,
    |         ^^^^^^^^^ FBT002
118 |         forces_coupled: bool = False,
119 |         output_init="HeOrthogonal",
    |

geom3d\models\GemNet\GemNet.py:118:9: FBT001 Boolean-typed positional argument in function definition
    |
116 |         envelope_exponent: int = 5,
117 |         extensive=True,
118 |         forces_coupled: bool = False,
    |         ^^^^^^^^^^^^^^ FBT001
119 |         output_init="HeOrthogonal",
120 |         activation: str = "swish",
    |

geom3d\models\GemNet\GemNet.py:118:9: FBT002 Boolean default positional argument in function definition
    |
116 |         envelope_exponent: int = 5,
117 |         extensive=True,
118 |         forces_coupled: bool = False,
    |         ^^^^^^^^^^^^^^ FBT002
119 |         output_init="HeOrthogonal",
120 |         activation: str = "swish",
    |

geom3d\models\GemNet\GemNet.py:122:9: ARG002 Unused method argument: `name`
    |
120 |         activation: str = "swish",
121 |         scale_file=None,
122 |         name="GemNet",
    |         ^^^^ ARG002
123 |         **kwargs,
124 |         ):
    |

geom3d\models\GemNet\GemNet.py:123:9: ANN003 Missing type annotation for `**kwargs`
    |
121 |         scale_file=None,
122 |         name="GemNet",
123 |         **kwargs,
    |         ^^^^^^^^ ANN003
124 |         ):
125 |         super().__init__()
    |

geom3d\models\GemNet\GemNet.py:123:11: ARG002 Unused method argument: `kwargs`
    |
121 |         scale_file=None,
122 |         name="GemNet",
123 |         **kwargs,
    |           ^^^^^^ ARG002
124 |         ):
125 |         super().__init__()
    |

geom3d\models\GemNet\GemNet.py:126:9: S101 Use of `assert` detected
    |
124 |         ):
125 |         super().__init__()
126 |         assert num_blocks > 0
    |         ^^^^^^ S101
127 |         self.num_targets = num_targets
128 |         self.num_blocks = num_blocks
    |

geom3d\models\GemNet\GemNet.py:232:13: PERF401 Use a list comprehension to create a transformed list
    |
230 |           )  # GemNet-(d)Q or -(d)T
231 |           for i in range(num_blocks):
232 |               int_blocks.append(
    |  _____________^
233 | |                 interaction_block(
234 | |                     emb_size_atom=emb_size_atom,
235 | |                     emb_size_edge=emb_size_edge,
236 | |                     emb_size_trip=emb_size_trip,
237 | |                     emb_size_quad=emb_size_quad,
238 | |                     emb_size_rbf=emb_size_rbf,
239 | |                     emb_size_cbf=emb_size_cbf,
240 | |                     emb_size_sbf=emb_size_sbf,
241 | |                     emb_size_bil_trip=emb_size_bil_trip,
242 | |                     emb_size_bil_quad=emb_size_bil_quad,
243 | |                     num_before_skip=num_before_skip,
244 | |                     num_after_skip=num_after_skip,
245 | |                     num_concat=num_concat,
246 | |                     num_atom=num_atom,
247 | |                     activation=activation,
248 | |                     scale_file=scale_file,
249 | |                     name=f"IntBlock_{i+1}",
250 | |                 )
251 | |             )
    | |_____________^ PERF401
252 |   
253 |           for i in range(num_blocks + 1):
    |

geom3d\models\GemNet\GemNet.py:254:13: PERF401 Use a list comprehension to create a transformed list
    |
253 |           for i in range(num_blocks + 1):
254 |               out_blocks.append(
    |  _____________^
255 | |                 OutputBlock(
256 | |                     emb_size_atom=emb_size_atom,
257 | |                     emb_size_edge=emb_size_edge,
258 | |                     emb_size_rbf=emb_size_rbf,
259 | |                     nHidden=num_atom,
260 | |                     num_targets=num_targets,
261 | |                     activation=activation,
262 | |                     output_init=output_init,
263 | |                     direct_forces=direct_forces,
264 | |                     scale_file=scale_file,
265 | |                     name=f"OutBlock_{i}",
266 | |                 )
267 | |             )
    | |_____________^ PERF401
268 |   
269 |           self.out_blocks = torch.nn.ModuleList(out_blocks)
    |

geom3d\models\GemNet\GemNet.py:273:9: ANN205 Missing return type annotation for staticmethod `calculate_interatomic_vectors`
    |
272 |     @staticmethod
273 |     def calculate_interatomic_vectors(R, id_s, id_t):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ANN205
274 |         """Parameters
275 |         ----------
    |
    = help: Add return type annotation

geom3d\models\GemNet\GemNet.py:273:39: N803 Argument name `R` should be lowercase
    |
272 |     @staticmethod
273 |     def calculate_interatomic_vectors(R, id_s, id_t):
    |                                       ^ N803
274 |         """Parameters
275 |         ----------
    |

geom3d\models\GemNet\GemNet.py:274:9: D205 1 blank line required between summary line and description
    |
272 |       @staticmethod
273 |       def calculate_interatomic_vectors(R, id_s, id_t):
274 |           """Parameters
    |  _________^
275 | |         ----------
276 | |             R: Tensor, shape = (nAtoms,3)
277 | |                 Atom positions.
278 | |             id_s: Tensor, shape = (nEdges,)
279 | |                 Indices of the source atom of the edges.
280 | |             id_t: Tensor, shape = (nEdges,)
281 | |                 Indices of the target atom of the edges.
282 | | 
283 | |         Returns
284 | |         -------
285 | |             (D_st, V_st): tuple
286 | |                 D_st: Tensor, shape = (nEdges,)
287 | |                     Distance from atom t to s.
288 | |                 V_st: Tensor, shape = (nEdges,)
289 | |                     Unit direction from atom t to s.
290 | | 
291 | |         """
    | |___________^ D205
292 |           Rt = R[id_t]
293 |           Rs = R[id_s]
    |
    = help: Insert single blank line

geom3d\models\GemNet\GemNet.py:292:9: N806 Variable `Rt` in function should be lowercase
    |
291 |         """
292 |         Rt = R[id_t]
    |         ^^ N806
293 |         Rs = R[id_s]
294 |         V_st = Rt - Rs  # s -> t
    |

geom3d\models\GemNet\GemNet.py:293:9: N806 Variable `Rs` in function should be lowercase
    |
291 |         """
292 |         Rt = R[id_t]
293 |         Rs = R[id_s]
    |         ^^ N806
294 |         V_st = Rt - Rs  # s -> t
295 |         D_st = torch.sqrt(torch.sum(V_st ** 2, dim=1))
    |

geom3d\models\GemNet\GemNet.py:294:9: N806 Variable `V_st` in function should be lowercase
    |
292 |         Rt = R[id_t]
293 |         Rs = R[id_s]
294 |         V_st = Rt - Rs  # s -> t
    |         ^^^^ N806
295 |         D_st = torch.sqrt(torch.sum(V_st ** 2, dim=1))
296 |         V_st = V_st / D_st[..., None]
    |

geom3d\models\GemNet\GemNet.py:295:9: N806 Variable `D_st` in function should be lowercase
    |
293 |         Rs = R[id_s]
294 |         V_st = Rt - Rs  # s -> t
295 |         D_st = torch.sqrt(torch.sum(V_st ** 2, dim=1))
    |         ^^^^ N806
296 |         V_st = V_st / D_st[..., None]
297 |         return D_st, V_st
    |

geom3d\models\GemNet\GemNet.py:296:9: N806 Variable `V_st` in function should be lowercase
    |
294 |         V_st = Rt - Rs  # s -> t
295 |         D_st = torch.sqrt(torch.sum(V_st ** 2, dim=1))
296 |         V_st = V_st / D_st[..., None]
    |         ^^^^ N806
297 |         return D_st, V_st
    |

geom3d\models\GemNet\GemNet.py:300:9: ANN205 Missing return type annotation for staticmethod `calculate_neighbor_angles`
    |
299 |     @staticmethod
300 |     def calculate_neighbor_angles(R_ac, R_ab):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^ ANN205
301 |         """Calculate angles between atoms c <- a -> b.
    |
    = help: Add return type annotation

geom3d\models\GemNet\GemNet.py:300:9: D417 Missing argument descriptions in the docstring for `calculate_neighbor_angles`: `R_ab`, `R_ac`
    |
299 |     @staticmethod
300 |     def calculate_neighbor_angles(R_ac, R_ab):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^ D417
301 |         """Calculate angles between atoms c <- a -> b.
    |

geom3d\models\GemNet\GemNet.py:300:35: N803 Argument name `R_ac` should be lowercase
    |
299 |     @staticmethod
300 |     def calculate_neighbor_angles(R_ac, R_ab):
    |                                   ^^^^ N803
301 |         """Calculate angles between atoms c <- a -> b.
    |

geom3d\models\GemNet\GemNet.py:300:41: N803 Argument name `R_ab` should be lowercase
    |
299 |     @staticmethod
300 |     def calculate_neighbor_angles(R_ac, R_ab):
    |                                         ^^^^ N803
301 |         """Calculate angles between atoms c <- a -> b.
    |

geom3d\models\GemNet\GemNet.py:325:9: ANN205 Missing return type annotation for staticmethod `vector_rejection`
    |
324 |     @staticmethod
325 |     def vector_rejection(R_ab, P_n):
    |         ^^^^^^^^^^^^^^^^ ANN205
326 |         """Project the vector R_ab onto a plane with normal vector P_n.
    |
    = help: Add return type annotation

geom3d\models\GemNet\GemNet.py:325:9: D417 Missing argument descriptions in the docstring for `vector_rejection`: `P_n`, `R_ab`
    |
324 |     @staticmethod
325 |     def vector_rejection(R_ab, P_n):
    |         ^^^^^^^^^^^^^^^^ D417
326 |         """Project the vector R_ab onto a plane with normal vector P_n.
    |

geom3d\models\GemNet\GemNet.py:325:26: N803 Argument name `R_ab` should be lowercase
    |
324 |     @staticmethod
325 |     def vector_rejection(R_ab, P_n):
    |                          ^^^^ N803
326 |         """Project the vector R_ab onto a plane with normal vector P_n.
    |

geom3d\models\GemNet\GemNet.py:325:32: N803 Argument name `P_n` should be lowercase
    |
324 |     @staticmethod
325 |     def vector_rejection(R_ab, P_n):
    |                                ^^^ N803
326 |         """Project the vector R_ab onto a plane with normal vector P_n.
    |

geom3d\models\GemNet\GemNet.py:346:9: PLR0913 Too many arguments in function definition (11 > 5)
    |
345 |     @staticmethod
346 |     def calculate_angles(
    |         ^^^^^^^^^^^^^^^^ PLR0913
347 |         R,
348 |         id_c,
    |

geom3d\models\GemNet\GemNet.py:346:9: ANN205 Missing return type annotation for staticmethod `calculate_angles`
    |
345 |     @staticmethod
346 |     def calculate_angles(
    |         ^^^^^^^^^^^^^^^^ ANN205
347 |         R,
348 |         id_c,
    |
    = help: Add return type annotation

geom3d\models\GemNet\GemNet.py:346:9: D417 Missing argument descriptions in the docstring for `calculate_angles`: `R`, `id4_expand_abd`, `id4_expand_intm_ab`, `id4_expand_intm_db`, `id4_int_a`, `id4_int_b`, `id4_reduce_cab`, `id4_reduce_intm_ab`, `id4_reduce_intm_ca`, `id_a`, `id_c`
    |
345 |     @staticmethod
346 |     def calculate_angles(
    |         ^^^^^^^^^^^^^^^^ D417
347 |         R,
348 |         id_c,
    |

geom3d\models\GemNet\GemNet.py:347:9: N803 Argument name `R` should be lowercase
    |
345 |     @staticmethod
346 |     def calculate_angles(
347 |         R,
    |         ^ N803
348 |         id_c,
349 |         id_a,
    |

geom3d\models\GemNet\GemNet.py:397:9: N806 Variable `Ra` in function should be lowercase
    |
395 |         """
396 |         # ---------------------------------- a - b <- d ---------------------------------- #
397 |         Ra = R[id4_int_a[id4_expand_intm_ab]]  # a       (intmTriplets,3)
    |         ^^ N806
398 |         Rb = R[id4_int_b[id4_expand_intm_ab]]  # b       (intmTriplets,3)
399 |         # Rb = R[id_a[id4_expand_intm_db]      # d       (intmTriplets,3)
    |

geom3d\models\GemNet\GemNet.py:398:9: N806 Variable `Rb` in function should be lowercase
    |
396 |         # ---------------------------------- a - b <- d ---------------------------------- #
397 |         Ra = R[id4_int_a[id4_expand_intm_ab]]  # a       (intmTriplets,3)
398 |         Rb = R[id4_int_b[id4_expand_intm_ab]]  # b       (intmTriplets,3)
    |         ^^ N806
399 |         # Rb = R[id_a[id4_expand_intm_db]      # d       (intmTriplets,3)
400 |         Rd = R[id_c[id4_expand_intm_db]]  # d       (intmTriplets,3)
    |

geom3d\models\GemNet\GemNet.py:400:9: N806 Variable `Rd` in function should be lowercase
    |
398 |         Rb = R[id4_int_b[id4_expand_intm_ab]]  # b       (intmTriplets,3)
399 |         # Rb = R[id_a[id4_expand_intm_db]      # d       (intmTriplets,3)
400 |         Rd = R[id_c[id4_expand_intm_db]]  # d       (intmTriplets,3)
    |         ^^ N806
401 | 
402 |         R_ba = Ra - Rb  # (intmTriplets,3)
    |

geom3d\models\GemNet\GemNet.py:402:9: N806 Variable `R_ba` in function should be lowercase
    |
400 |         Rd = R[id_c[id4_expand_intm_db]]  # d       (intmTriplets,3)
401 | 
402 |         R_ba = Ra - Rb  # (intmTriplets,3)
    |         ^^^^ N806
403 |         R_bd = Rd - Rb  # (intmTriplets,3)
404 |         angle_abd = GemNet.calculate_neighbor_angles(R_ba, R_bd)  # (intmTriplets,)
    |

geom3d\models\GemNet\GemNet.py:403:9: N806 Variable `R_bd` in function should be lowercase
    |
402 |         R_ba = Ra - Rb  # (intmTriplets,3)
403 |         R_bd = Rd - Rb  # (intmTriplets,3)
    |         ^^^^ N806
404 |         angle_abd = GemNet.calculate_neighbor_angles(R_ba, R_bd)  # (intmTriplets,)
    |

geom3d\models\GemNet\GemNet.py:407:9: N806 Variable `R_bd_proj` in function should be lowercase
    |
406 |         # project for calculating gamma
407 |         R_bd_proj = GemNet.vector_rejection(R_bd, R_ba)  # a - b -| d
    |         ^^^^^^^^^ N806
408 |         R_bd_proj = R_bd_proj[id4_expand_abd]  # (nQuadruplets,)
    |

geom3d\models\GemNet\GemNet.py:408:9: N806 Variable `R_bd_proj` in function should be lowercase
    |
406 |         # project for calculating gamma
407 |         R_bd_proj = GemNet.vector_rejection(R_bd, R_ba)  # a - b -| d
408 |         R_bd_proj = R_bd_proj[id4_expand_abd]  # (nQuadruplets,)
    |         ^^^^^^^^^ N806
409 | 
410 |         # --------------------------------- c -> a <- b ---------------------------------- #
    |

geom3d\models\GemNet\GemNet.py:411:9: N806 Variable `Rc` in function should be lowercase
    |
410 |         # --------------------------------- c -> a <- b ---------------------------------- #
411 |         Rc = R[id_c[id4_reduce_intm_ca]]  # c      (intmTriplets,3)
    |         ^^ N806
412 |         Ra = R[id_a[id4_reduce_intm_ca]]  # a      (intmTriplets,3)
413 |         # Ra = R[id4_int_a[id4_reduce_intm_ab]] # a      (intmTriplets,3)
    |

geom3d\models\GemNet\GemNet.py:412:9: N806 Variable `Ra` in function should be lowercase
    |
410 |         # --------------------------------- c -> a <- b ---------------------------------- #
411 |         Rc = R[id_c[id4_reduce_intm_ca]]  # c      (intmTriplets,3)
412 |         Ra = R[id_a[id4_reduce_intm_ca]]  # a      (intmTriplets,3)
    |         ^^ N806
413 |         # Ra = R[id4_int_a[id4_reduce_intm_ab]] # a      (intmTriplets,3)
414 |         Rb = R[id4_int_b[id4_reduce_intm_ab]]  # b      (intmTriplets,3)
    |

geom3d\models\GemNet\GemNet.py:413:9: ERA001 Found commented-out code
    |
411 |         Rc = R[id_c[id4_reduce_intm_ca]]  # c      (intmTriplets,3)
412 |         Ra = R[id_a[id4_reduce_intm_ca]]  # a      (intmTriplets,3)
413 |         # Ra = R[id4_int_a[id4_reduce_intm_ab]] # a      (intmTriplets,3)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
414 |         Rb = R[id4_int_b[id4_reduce_intm_ab]]  # b      (intmTriplets,3)
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:414:9: N806 Variable `Rb` in function should be lowercase
    |
412 |         Ra = R[id_a[id4_reduce_intm_ca]]  # a      (intmTriplets,3)
413 |         # Ra = R[id4_int_a[id4_reduce_intm_ab]] # a      (intmTriplets,3)
414 |         Rb = R[id4_int_b[id4_reduce_intm_ab]]  # b      (intmTriplets,3)
    |         ^^ N806
415 | 
416 |         R_ac = Rc - Ra  # (intmTriplets,3)
    |

geom3d\models\GemNet\GemNet.py:416:9: N806 Variable `R_ac` in function should be lowercase
    |
414 |         Rb = R[id4_int_b[id4_reduce_intm_ab]]  # b      (intmTriplets,3)
415 | 
416 |         R_ac = Rc - Ra  # (intmTriplets,3)
    |         ^^^^ N806
417 |         R_ab = Rb - Ra  # (intmTriplets,3)
418 |         angle_cab = GemNet.calculate_neighbor_angles(R_ab, R_ac)  # (intmTriplets,)
    |

geom3d\models\GemNet\GemNet.py:417:9: N806 Variable `R_ab` in function should be lowercase
    |
416 |         R_ac = Rc - Ra  # (intmTriplets,3)
417 |         R_ab = Rb - Ra  # (intmTriplets,3)
    |         ^^^^ N806
418 |         angle_cab = GemNet.calculate_neighbor_angles(R_ab, R_ac)  # (intmTriplets,)
419 |         angle_cab = angle_cab[id4_reduce_cab]  # (nQuadruplets,)
    |

geom3d\models\GemNet\GemNet.py:422:9: N806 Variable `R_ac_proj` in function should be lowercase
    |
421 |         # project for calculating gamma
422 |         R_ac_proj = GemNet.vector_rejection(R_ac, R_ab)  # c |- a - b
    |         ^^^^^^^^^ N806
423 |         R_ac_proj = R_ac_proj[id4_reduce_cab]  # (nQuadruplets,)
    |

geom3d\models\GemNet\GemNet.py:423:9: N806 Variable `R_ac_proj` in function should be lowercase
    |
421 |         # project for calculating gamma
422 |         R_ac_proj = GemNet.vector_rejection(R_ac, R_ab)  # c |- a - b
423 |         R_ac_proj = R_ac_proj[id4_reduce_cab]  # (nQuadruplets,)
    |         ^^^^^^^^^ N806
424 | 
425 |         # -------------------------------- c -> a - b <- d -------------------------------- #
    |

geom3d\models\GemNet\GemNet.py:433:9: ANN205 Missing return type annotation for staticmethod `calculate_angles3`
    |
432 |     @staticmethod
433 |     def calculate_angles3(R, id_c, id_a, id3_reduce_ca, id3_expand_ba):
    |         ^^^^^^^^^^^^^^^^^ ANN205
434 |         """Calculate angles for triplet-based message passing.
    |
    = help: Add return type annotation

geom3d\models\GemNet\GemNet.py:433:9: D417 Missing argument descriptions in the docstring for `calculate_angles3`: `R`, `id3_expand_ba`, `id3_reduce_ca`, `id_a`, `id_c`
    |
432 |     @staticmethod
433 |     def calculate_angles3(R, id_c, id_a, id3_reduce_ca, id3_expand_ba):
    |         ^^^^^^^^^^^^^^^^^ D417
434 |         """Calculate angles for triplet-based message passing.
    |

geom3d\models\GemNet\GemNet.py:433:27: N803 Argument name `R` should be lowercase
    |
432 |     @staticmethod
433 |     def calculate_angles3(R, id_c, id_a, id3_reduce_ca, id3_expand_ba):
    |                           ^ N803
434 |         """Calculate angles for triplet-based message passing.
    |

geom3d\models\GemNet\GemNet.py:455:9: N806 Variable `Rc` in function should be lowercase
    |
454 |         """
455 |         Rc = R[id_c[id3_reduce_ca]]
    |         ^^ N806
456 |         Ra = R[id_a[id3_reduce_ca]]
457 |         Rb = R[id_c[id3_expand_ba]]
    |

geom3d\models\GemNet\GemNet.py:456:9: N806 Variable `Ra` in function should be lowercase
    |
454 |         """
455 |         Rc = R[id_c[id3_reduce_ca]]
456 |         Ra = R[id_a[id3_reduce_ca]]
    |         ^^ N806
457 |         Rb = R[id_c[id3_expand_ba]]
    |

geom3d\models\GemNet\GemNet.py:457:9: N806 Variable `Rb` in function should be lowercase
    |
455 |         Rc = R[id_c[id3_reduce_ca]]
456 |         Ra = R[id_a[id3_reduce_ca]]
457 |         Rb = R[id_c[id3_expand_ba]]
    |         ^^ N806
458 | 
459 |         # difference vectors
    |

geom3d\models\GemNet\GemNet.py:460:9: N806 Variable `R_ac` in function should be lowercase
    |
459 |         # difference vectors
460 |         R_ac = Rc - Ra  # shape = (nTriplets,3)
    |         ^^^^ N806
461 |         R_ab = Rb - Ra  # shape = (nTriplets,3)
    |

geom3d\models\GemNet\GemNet.py:461:9: N806 Variable `R_ab` in function should be lowercase
    |
459 |         # difference vectors
460 |         R_ac = Rc - Ra  # shape = (nTriplets,3)
461 |         R_ab = Rb - Ra  # shape = (nTriplets,3)
    |         ^^^^ N806
462 | 
463 |         # angle in triplets
    |

geom3d\models\GemNet\GemNet.py:466:9: D102 Missing docstring in public method
    |
464 |         return GemNet.calculate_neighbor_angles(R_ac, R_ab)  # (nTriplets,)
465 | 
466 |     def forward(self, z, positions, inputs):
    |         ^^^^^^^ D102
467 |         Z, R = z, positions
468 |         id_a, id_c, _id_undir, id_swap = (
    |

geom3d\models\GemNet\GemNet.py:467:9: N806 Variable `Z` in function should be lowercase
    |
466 |     def forward(self, z, positions, inputs):
467 |         Z, R = z, positions
    |         ^ N806
468 |         id_a, id_c, _id_undir, id_swap = (
469 |             inputs["id_a"],
    |

geom3d\models\GemNet\GemNet.py:467:12: N806 Variable `R` in function should be lowercase
    |
466 |     def forward(self, z, positions, inputs):
467 |         Z, R = z, positions
    |            ^ N806
468 |         id_a, id_c, _id_undir, id_swap = (
469 |             inputs["id_a"],
    |

geom3d\models\GemNet\GemNet.py:476:20: N806 Variable `Kidx4` in function should be lowercase
    |
474 |         id3_expand_ba, id3_reduce_ca = inputs["id3_expand_ba"], inputs["id3_reduce_ca"]
475 |         if not self.triplets_only:
476 |             batch, Kidx4, Kidx3 = (
    |                    ^^^^^ N806
477 |                 inputs["batch"],
478 |                 inputs["Kidx4"],
    |

geom3d\models\GemNet\GemNet.py:476:27: N806 Variable `Kidx3` in function should be lowercase
    |
474 |         id3_expand_ba, id3_reduce_ca = inputs["id3_expand_ba"], inputs["id3_reduce_ca"]
475 |         if not self.triplets_only:
476 |             batch, Kidx4, Kidx3 = (
    |                           ^^^^^ N806
477 |                 inputs["batch"],
478 |                 inputs["Kidx4"],
    |

geom3d\models\GemNet\GemNet.py:499:20: N806 Variable `Kidx4` in function should be lowercase
    |
497 |             )
498 |         else:
499 |             batch, Kidx4, Kidx3 = inputs["batch"], None, inputs["Kidx3"]
    |                    ^^^^^ N806
500 |             id4_int_b, id4_int_a = None, None
501 |             id4_reduce_ca, _id4_expand_db = None, None
    |

geom3d\models\GemNet\GemNet.py:499:27: N806 Variable `Kidx3` in function should be lowercase
    |
497 |             )
498 |         else:
499 |             batch, Kidx4, Kidx3 = inputs["batch"], None, inputs["Kidx3"]
    |                           ^^^^^ N806
500 |             id4_int_b, id4_int_a = None, None
501 |             id4_reduce_ca, _id4_expand_db = None, None
    |

geom3d\models\GemNet\GemNet.py:507:9: N806 Variable `D_ca` in function should be lowercase
    |
506 |         # Calculate distances
507 |         D_ca, V_ca = self.calculate_interatomic_vectors(R, id_c, id_a)
    |         ^^^^ N806
508 | 
509 |         if not self.triplets_only:
    |

geom3d\models\GemNet\GemNet.py:507:15: N806 Variable `V_ca` in function should be lowercase
    |
506 |         # Calculate distances
507 |         D_ca, V_ca = self.calculate_interatomic_vectors(R, id_c, id_a)
    |               ^^^^ N806
508 | 
509 |         if not self.triplets_only:
    |

geom3d\models\GemNet\GemNet.py:510:13: N806 Variable `D_ab` in function should be lowercase
    |
509 |         if not self.triplets_only:
510 |             D_ab, _ = self.calculate_interatomic_vectors(R, id4_int_b, id4_int_a)
    |             ^^^^ N806
511 | 
512 |             # Calculate angles
    |

geom3d\models\GemNet\GemNet.py:513:13: N806 Variable `Phi_cab` in function should be lowercase
    |
512 |             # Calculate angles
513 |             Phi_cab, Phi_abd, Theta_cabd = self.calculate_angles(
    |             ^^^^^^^ N806
514 |                 R,
515 |                 id_c,
    |

geom3d\models\GemNet\GemNet.py:513:22: N806 Variable `Phi_abd` in function should be lowercase
    |
512 |             # Calculate angles
513 |             Phi_cab, Phi_abd, Theta_cabd = self.calculate_angles(
    |                      ^^^^^^^ N806
514 |                 R,
515 |                 id_c,
    |

geom3d\models\GemNet\GemNet.py:513:31: N806 Variable `Theta_cabd` in function should be lowercase
    |
512 |             # Calculate angles
513 |             Phi_cab, Phi_abd, Theta_cabd = self.calculate_angles(
    |                               ^^^^^^^^^^ N806
514 |                 R,
515 |                 id_c,
    |

geom3d\models\GemNet\GemNet.py:532:9: N806 Variable `Angles3_cab` in function should be lowercase
    |
530 |         rbf = self.rbf_basis(D_ca)
531 |         # Triplet Interaction
532 |         Angles3_cab = self.calculate_angles3(
    |         ^^^^^^^^^^^ N806
533 |             R, id_c, id_a, id3_reduce_ca, id3_expand_ba
534 |         )
    |

geom3d\models\GemNet\GemNet.py:557:9: N806 Variable `E_a` in function should be lowercase
    |
555 |         rbf_out = self.mlp_rbf_out(rbf)
556 | 
557 |         E_a, F_ca = self.out_blocks[0](h, m, rbf_out, id_a)
    |         ^^^ N806
558 |         # (nAtoms, num_targets), (nEdges, num_targets)
    |

geom3d\models\GemNet\GemNet.py:557:14: N806 Variable `F_ca` in function should be lowercase
    |
555 |         rbf_out = self.mlp_rbf_out(rbf)
556 | 
557 |         E_a, F_ca = self.out_blocks[0](h, m, rbf_out, id_a)
    |              ^^^^ N806
558 |         # (nAtoms, num_targets), (nEdges, num_targets)
    |

geom3d\models\GemNet\GemNet.py:558:9: ERA001 Found commented-out code
    |
557 |         E_a, F_ca = self.out_blocks[0](h, m, rbf_out, id_a)
558 |         # (nAtoms, num_targets), (nEdges, num_targets)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
559 | 
560 |         for i in range(self.num_blocks):
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:583:13: N806 Variable `E` in function should be lowercase
    |
581 |             )  # (nAtoms, emb_size_atom), (nEdges, emb_size_edge)
582 | 
583 |             E, F = self.out_blocks[i + 1](h, m, rbf_out, id_a)
    |             ^ N806
584 |             # (nAtoms, num_targets), (nEdges, num_targets)
585 |             F_ca += F
    |

geom3d\models\GemNet\GemNet.py:583:16: N806 Variable `F` in function should be lowercase
    |
581 |             )  # (nAtoms, emb_size_atom), (nEdges, emb_size_edge)
582 | 
583 |             E, F = self.out_blocks[i + 1](h, m, rbf_out, id_a)
    |                ^ N806
584 |             # (nAtoms, num_targets), (nEdges, num_targets)
585 |             F_ca += F
    |

geom3d\models\GemNet\GemNet.py:584:13: ERA001 Found commented-out code
    |
583 |             E, F = self.out_blocks[i + 1](h, m, rbf_out, id_a)
584 |             # (nAtoms, num_targets), (nEdges, num_targets)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
585 |             F_ca += F
586 |             E_a += E
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:585:13: N806 Variable `F_ca` in function should be lowercase
    |
583 |             E, F = self.out_blocks[i + 1](h, m, rbf_out, id_a)
584 |             # (nAtoms, num_targets), (nEdges, num_targets)
585 |             F_ca += F
    |             ^^^^ N806
586 |             E_a += E
    |

geom3d\models\GemNet\GemNet.py:586:13: N806 Variable `E_a` in function should be lowercase
    |
584 |             # (nAtoms, num_targets), (nEdges, num_targets)
585 |             F_ca += F
586 |             E_a += E
    |             ^^^ N806
587 | 
588 |         nMolecules = torch.max(batch) + 1
    |

geom3d\models\GemNet\GemNet.py:588:9: N806 Variable `nMolecules` in function should be lowercase
    |
586 |             E_a += E
587 | 
588 |         nMolecules = torch.max(batch) + 1
    |         ^^^^^^^^^^ N806
589 |         if self.extensive:
590 |             E_a = scatter(E_a, batch, dim=0, dim_size=nMolecules, reduce="add")
    |

geom3d\models\GemNet\GemNet.py:590:13: N806 Variable `E_a` in function should be lowercase
    |
588 |         nMolecules = torch.max(batch) + 1
589 |         if self.extensive:
590 |             E_a = scatter(E_a, batch, dim=0, dim_size=nMolecules, reduce="add")
    |             ^^^ N806
591 |             # (nMolecules, num_targets)
592 |         else:
    |

geom3d\models\GemNet\GemNet.py:591:13: ERA001 Found commented-out code
    |
589 |         if self.extensive:
590 |             E_a = scatter(E_a, batch, dim=0, dim_size=nMolecules, reduce="add")
591 |             # (nMolecules, num_targets)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
592 |         else:
593 |             E_a = scatter(E_a, batch, dim=0, dim_size=nMolecules, reduce="mean")
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:593:13: N806 Variable `E_a` in function should be lowercase
    |
591 |             # (nMolecules, num_targets)
592 |         else:
593 |             E_a = scatter(E_a, batch, dim=0, dim_size=nMolecules, reduce="mean")
    |             ^^^ N806
594 |             # (nMolecules, num_targets)
    |

geom3d\models\GemNet\GemNet.py:594:13: ERA001 Found commented-out code
    |
592 |         else:
593 |             E_a = scatter(E_a, batch, dim=0, dim_size=nMolecules, reduce="mean")
594 |             # (nMolecules, num_targets)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
595 | 
596 |         return E_a
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:598:9: D102 Missing docstring in public method
    |
596 |         return E_a
597 | 
598 |     def forward_with_gathered_index(self, z, positions, inputs, batch, periodic_index_mapping):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
599 |         Z, R = z, positions
600 |         id_a, id_c, _id_undir, id_swap = (
    |

geom3d\models\GemNet\GemNet.py:599:9: N806 Variable `Z` in function should be lowercase
    |
598 |     def forward_with_gathered_index(self, z, positions, inputs, batch, periodic_index_mapping):
599 |         Z, R = z, positions
    |         ^ N806
600 |         id_a, id_c, _id_undir, id_swap = (
601 |             inputs["id_a"],
    |

geom3d\models\GemNet\GemNet.py:599:12: N806 Variable `R` in function should be lowercase
    |
598 |     def forward_with_gathered_index(self, z, positions, inputs, batch, periodic_index_mapping):
599 |         Z, R = z, positions
    |            ^ N806
600 |         id_a, id_c, _id_undir, id_swap = (
601 |             inputs["id_a"],
    |

geom3d\models\GemNet\GemNet.py:609:9: ERA001 Found commented-out code
    |
608 |         # if not self.triplets_only:
609 |         #     batch, Kidx4, Kidx3 = (
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
610 |         #         inputs["batch"],
611 |         #         inputs["Kidx4"],
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:610:9: ERA001 Found commented-out code
    |
608 |         # if not self.triplets_only:
609 |         #     batch, Kidx4, Kidx3 = (
610 |         #         inputs["batch"],
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
611 |         #         inputs["Kidx4"],
612 |         #         inputs["Kidx3"],
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:611:9: ERA001 Found commented-out code
    |
609 |         #     batch, Kidx4, Kidx3 = (
610 |         #         inputs["batch"],
611 |         #         inputs["Kidx4"],
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
612 |         #         inputs["Kidx3"],
613 |         #     )
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:612:9: ERA001 Found commented-out code
    |
610 |         #         inputs["batch"],
611 |         #         inputs["Kidx4"],
612 |         #         inputs["Kidx3"],
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
613 |         #     )
614 |         #     id4_int_b, id4_int_a = inputs["id4_int_b"], inputs["id4_int_a"]
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:613:9: ERA001 Found commented-out code
    |
611 |         #         inputs["Kidx4"],
612 |         #         inputs["Kidx3"],
613 |         #     )
    |         ^^^^^^^ ERA001
614 |         #     id4_int_b, id4_int_a = inputs["id4_int_b"], inputs["id4_int_a"]
615 |         #     id4_reduce_ca, id4_expand_db = (
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:614:9: ERA001 Found commented-out code
    |
612 |         #         inputs["Kidx3"],
613 |         #     )
614 |         #     id4_int_b, id4_int_a = inputs["id4_int_b"], inputs["id4_int_a"]
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
615 |         #     id4_reduce_ca, id4_expand_db = (
616 |         #         inputs["id4_reduce_ca"],
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:615:9: ERA001 Found commented-out code
    |
613 |         #     )
614 |         #     id4_int_b, id4_int_a = inputs["id4_int_b"], inputs["id4_int_a"]
615 |         #     id4_reduce_ca, id4_expand_db = (
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
616 |         #         inputs["id4_reduce_ca"],
617 |         #         inputs["id4_expand_db"],
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:616:9: ERA001 Found commented-out code
    |
614 |         #     id4_int_b, id4_int_a = inputs["id4_int_b"], inputs["id4_int_a"]
615 |         #     id4_reduce_ca, id4_expand_db = (
616 |         #         inputs["id4_reduce_ca"],
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
617 |         #         inputs["id4_expand_db"],
618 |         #     )
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:617:9: ERA001 Found commented-out code
    |
615 |         #     id4_reduce_ca, id4_expand_db = (
616 |         #         inputs["id4_reduce_ca"],
617 |         #         inputs["id4_expand_db"],
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
618 |         #     )
619 |         #     id4_reduce_cab, id4_expand_abd = (
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:618:9: ERA001 Found commented-out code
    |
616 |         #         inputs["id4_reduce_ca"],
617 |         #         inputs["id4_expand_db"],
618 |         #     )
    |         ^^^^^^^ ERA001
619 |         #     id4_reduce_cab, id4_expand_abd = (
620 |         #         inputs["id4_reduce_cab"],
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:619:9: ERA001 Found commented-out code
    |
617 |         #         inputs["id4_expand_db"],
618 |         #     )
619 |         #     id4_reduce_cab, id4_expand_abd = (
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
620 |         #         inputs["id4_reduce_cab"],
621 |         #         inputs["id4_expand_abd"],
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:620:9: ERA001 Found commented-out code
    |
618 |         #     )
619 |         #     id4_reduce_cab, id4_expand_abd = (
620 |         #         inputs["id4_reduce_cab"],
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
621 |         #         inputs["id4_expand_abd"],
622 |         #     )
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:621:9: ERA001 Found commented-out code
    |
619 |         #     id4_reduce_cab, id4_expand_abd = (
620 |         #         inputs["id4_reduce_cab"],
621 |         #         inputs["id4_expand_abd"],
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
622 |         #     )
623 |         #     id4_reduce_intm_ca, id4_expand_intm_db = (
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:622:9: ERA001 Found commented-out code
    |
620 |         #         inputs["id4_reduce_cab"],
621 |         #         inputs["id4_expand_abd"],
622 |         #     )
    |         ^^^^^^^ ERA001
623 |         #     id4_reduce_intm_ca, id4_expand_intm_db = (
624 |         #         inputs["id4_reduce_intm_ca"],
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:623:9: ERA001 Found commented-out code
    |
621 |         #         inputs["id4_expand_abd"],
622 |         #     )
623 |         #     id4_reduce_intm_ca, id4_expand_intm_db = (
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
624 |         #         inputs["id4_reduce_intm_ca"],
625 |         #         inputs["id4_expand_intm_db"],
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:624:9: ERA001 Found commented-out code
    |
622 |         #     )
623 |         #     id4_reduce_intm_ca, id4_expand_intm_db = (
624 |         #         inputs["id4_reduce_intm_ca"],
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
625 |         #         inputs["id4_expand_intm_db"],
626 |         #     )
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:625:9: ERA001 Found commented-out code
    |
623 |         #     id4_reduce_intm_ca, id4_expand_intm_db = (
624 |         #         inputs["id4_reduce_intm_ca"],
625 |         #         inputs["id4_expand_intm_db"],
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
626 |         #     )
627 |         #     id4_reduce_intm_ab, id4_expand_intm_ab = (
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:626:9: ERA001 Found commented-out code
    |
624 |         #         inputs["id4_reduce_intm_ca"],
625 |         #         inputs["id4_expand_intm_db"],
626 |         #     )
    |         ^^^^^^^ ERA001
627 |         #     id4_reduce_intm_ab, id4_expand_intm_ab = (
628 |         #         inputs["id4_reduce_intm_ab"],
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:627:9: ERA001 Found commented-out code
    |
625 |         #         inputs["id4_expand_intm_db"],
626 |         #     )
627 |         #     id4_reduce_intm_ab, id4_expand_intm_ab = (
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
628 |         #         inputs["id4_reduce_intm_ab"],
629 |         #         inputs["id4_expand_intm_ab"],
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:628:9: ERA001 Found commented-out code
    |
626 |         #     )
627 |         #     id4_reduce_intm_ab, id4_expand_intm_ab = (
628 |         #         inputs["id4_reduce_intm_ab"],
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
629 |         #         inputs["id4_expand_intm_ab"],
630 |         #     )
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:629:9: ERA001 Found commented-out code
    |
627 |         #     id4_reduce_intm_ab, id4_expand_intm_ab = (
628 |         #         inputs["id4_reduce_intm_ab"],
629 |         #         inputs["id4_expand_intm_ab"],
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
630 |         #     )
631 |         # else:
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:630:9: ERA001 Found commented-out code
    |
628 |         #         inputs["id4_reduce_intm_ab"],
629 |         #         inputs["id4_expand_intm_ab"],
630 |         #     )
    |         ^^^^^^^ ERA001
631 |         # else:
632 |         Kidx4, Kidx3 = None, inputs["Kidx3"]
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:631:9: ERA001 Found commented-out code
    |
629 |         #         inputs["id4_expand_intm_ab"],
630 |         #     )
631 |         # else:
    |         ^^^^^^^ ERA001
632 |         Kidx4, Kidx3 = None, inputs["Kidx3"]
633 |         _id4_int_b, _id4_int_a = None, None
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:632:9: N806 Variable `Kidx4` in function should be lowercase
    |
630 |         #     )
631 |         # else:
632 |         Kidx4, Kidx3 = None, inputs["Kidx3"]
    |         ^^^^^ N806
633 |         _id4_int_b, _id4_int_a = None, None
634 |         id4_reduce_ca, _id4_expand_db = None, None
    |

geom3d\models\GemNet\GemNet.py:632:16: N806 Variable `Kidx3` in function should be lowercase
    |
630 |         #     )
631 |         # else:
632 |         Kidx4, Kidx3 = None, inputs["Kidx3"]
    |                ^^^^^ N806
633 |         _id4_int_b, _id4_int_a = None, None
634 |         id4_reduce_ca, _id4_expand_db = None, None
    |

geom3d\models\GemNet\GemNet.py:640:9: N806 Variable `D_ca` in function should be lowercase
    |
639 |         # Calculate distances
640 |         D_ca, V_ca = self.calculate_interatomic_vectors(R, id_c, id_a)
    |         ^^^^ N806
641 | 
642 |         # if not self.triplets_only:
    |

geom3d\models\GemNet\GemNet.py:640:15: N806 Variable `V_ca` in function should be lowercase
    |
639 |         # Calculate distances
640 |         D_ca, V_ca = self.calculate_interatomic_vectors(R, id_c, id_a)
    |               ^^^^ N806
641 | 
642 |         # if not self.triplets_only:
    |

geom3d\models\GemNet\GemNet.py:643:9: ERA001 Found commented-out code
    |
642 |         # if not self.triplets_only:
643 |         #     D_ab, _ = self.calculate_interatomic_vectors(R, id4_int_b, id4_int_a)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
644 | 
645 |         #     # Calculate angles
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:646:9: ERA001 Found commented-out code
    |
645 |         #     # Calculate angles
646 |         #     Phi_cab, Phi_abd, Theta_cabd = self.calculate_angles(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
647 |         #         R,
648 |         #         id_c,
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:658:9: ERA001 Found commented-out code
    |
656 |         #         id4_expand_intm_ab,
657 |         #         id4_reduce_intm_ab,
658 |         #     )
    |         ^^^^^^^ ERA001
659 | 
660 |         #     cbf4 = self.cbf_basis(D_ab, Phi_abd, id4_expand_intm_ab, None)
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:660:9: ERA001 Found commented-out code
    |
658 |         #     )
659 | 
660 |         #     cbf4 = self.cbf_basis(D_ab, Phi_abd, id4_expand_intm_ab, None)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
661 |         #     sbf4 = self.sbf_basis(D_ca, Phi_cab, Theta_cabd, id4_reduce_ca, Kidx4)
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:661:9: ERA001 Found commented-out code
    |
660 |         #     cbf4 = self.cbf_basis(D_ab, Phi_abd, id4_expand_intm_ab, None)
661 |         #     sbf4 = self.sbf_basis(D_ca, Phi_cab, Theta_cabd, id4_reduce_ca, Kidx4)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
662 | 
663 |         rbf = self.rbf_basis(D_ca)
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:665:9: N806 Variable `Angles3_cab` in function should be lowercase
    |
663 |         rbf = self.rbf_basis(D_ca)
664 |         # Triplet Interaction
665 |         Angles3_cab = self.calculate_angles3(
    |         ^^^^^^^^^^^ N806
666 |             R, id_c, id_a, id3_reduce_ca, id3_expand_ba
667 |         )
    |

geom3d\models\GemNet\GemNet.py:687:9: N806 Variable `E_a` in function should be lowercase
    |
685 |         rbf_out = self.mlp_rbf_out(rbf)
686 | 
687 |         E_a, F_ca = self.out_blocks[0](h, m, rbf_out, id_a)
    |         ^^^ N806
688 |         # (nAtoms, num_targets), (nEdges, num_targets)
    |

geom3d\models\GemNet\GemNet.py:687:14: N806 Variable `F_ca` in function should be lowercase
    |
685 |         rbf_out = self.mlp_rbf_out(rbf)
686 | 
687 |         E_a, F_ca = self.out_blocks[0](h, m, rbf_out, id_a)
    |              ^^^^ N806
688 |         # (nAtoms, num_targets), (nEdges, num_targets)
    |

geom3d\models\GemNet\GemNet.py:688:9: ERA001 Found commented-out code
    |
687 |         E_a, F_ca = self.out_blocks[0](h, m, rbf_out, id_a)
688 |         # (nAtoms, num_targets), (nEdges, num_targets)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
689 | 
690 |         for i in range(self.num_blocks):
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:713:13: N806 Variable `E` in function should be lowercase
    |
711 |             )  # (nAtoms, emb_size_atom), (nEdges, emb_size_edge)
712 | 
713 |             E, F = self.out_blocks[i + 1](h, m, rbf_out, id_a)
    |             ^ N806
714 |             # (nAtoms, num_targets), (nEdges, num_targets)
715 |             F_ca += F
    |

geom3d\models\GemNet\GemNet.py:713:16: N806 Variable `F` in function should be lowercase
    |
711 |             )  # (nAtoms, emb_size_atom), (nEdges, emb_size_edge)
712 | 
713 |             E, F = self.out_blocks[i + 1](h, m, rbf_out, id_a)
    |                ^ N806
714 |             # (nAtoms, num_targets), (nEdges, num_targets)
715 |             F_ca += F
    |

geom3d\models\GemNet\GemNet.py:714:13: ERA001 Found commented-out code
    |
713 |             E, F = self.out_blocks[i + 1](h, m, rbf_out, id_a)
714 |             # (nAtoms, num_targets), (nEdges, num_targets)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
715 |             F_ca += F
716 |             E_a += E
    |
    = help: Remove commented-out code

geom3d\models\GemNet\GemNet.py:715:13: N806 Variable `F_ca` in function should be lowercase
    |
713 |             E, F = self.out_blocks[i + 1](h, m, rbf_out, id_a)
714 |             # (nAtoms, num_targets), (nEdges, num_targets)
715 |             F_ca += F
    |             ^^^^ N806
716 |             E_a += E
    |

geom3d\models\GemNet\GemNet.py:716:13: N806 Variable `E_a` in function should be lowercase
    |
714 |             # (nAtoms, num_targets), (nEdges, num_targets)
715 |             F_ca += F
716 |             E_a += E
    |             ^^^ N806
717 | 
718 |         nMolecules = torch.max(batch) + 1
    |

geom3d\models\GemNet\GemNet.py:718:9: N806 Variable `nMolecules` in function should be lowercase
    |
716 |             E_a += E
717 | 
718 |         nMolecules = torch.max(batch) + 1
    |         ^^^^^^^^^^ N806
719 |         if self.extensive:
720 |             E_a = scatter(E_a, batch, dim=0, dim_size=nMolecules, reduce="add")
    |

geom3d\models\GemNet\GemNet.py:720:13: N806 Variable `E_a` in function should be lowercase
    |
718 |         nMolecules = torch.max(batch) + 1
719 |         if self.extensive:
720 |             E_a = scatter(E_a, batch, dim=0, dim_size=nMolecules, reduce="add")
    |             ^^^ N806
721 |         else:
722 |             E_a = scatter(E_a, batch, dim=0, dim_size=nMolecules, reduce="mean")
    |

geom3d\models\GemNet\GemNet.py:722:13: N806 Variable `E_a` in function should be lowercase
    |
720 |             E_a = scatter(E_a, batch, dim=0, dim_size=nMolecules, reduce="add")
721 |         else:
722 |             E_a = scatter(E_a, batch, dim=0, dim_size=nMolecules, reduce="mean")
    |             ^^^ N806
723 | 
724 |         return E_a
    |

geom3d\models\GemNet\GemNet.py:726:9: D102 Missing docstring in public method
    |
724 |         return E_a
725 | 
726 |     def predict(self, inputs):
    |         ^^^^^^^ D102
727 |         E, F = self(inputs)
728 |         E = E.detach().cpu()
    |

geom3d\models\GemNet\GemNet.py:727:9: N806 Variable `E` in function should be lowercase
    |
726 |     def predict(self, inputs):
727 |         E, F = self(inputs)
    |         ^ N806
728 |         E = E.detach().cpu()
729 |         F = F.detach().cpu()
    |

geom3d\models\GemNet\GemNet.py:727:12: N806 Variable `F` in function should be lowercase
    |
726 |     def predict(self, inputs):
727 |         E, F = self(inputs)
    |            ^ N806
728 |         E = E.detach().cpu()
729 |         F = F.detach().cpu()
    |

geom3d\models\GemNet\GemNet.py:728:9: N806 Variable `E` in function should be lowercase
    |
726 |     def predict(self, inputs):
727 |         E, F = self(inputs)
728 |         E = E.detach().cpu()
    |         ^ N806
729 |         F = F.detach().cpu()
730 |         return E, F
    |

geom3d\models\GemNet\GemNet.py:729:9: N806 Variable `F` in function should be lowercase
    |
727 |         E, F = self(inputs)
728 |         E = E.detach().cpu()
729 |         F = F.detach().cpu()
    |         ^ N806
730 |         return E, F
    |

geom3d\models\GemNet\GemNet.py:732:9: D102 Missing docstring in public method
    |
730 |         return E, F
731 | 
732 |     def load_weights(self, path):
    |         ^^^^^^^^^^^^ D102
733 |         self.load_state_dict(torch.load(path))
    |

geom3d\models\GemNet\GemNet.py:735:9: D102 Missing docstring in public method
    |
733 |         self.load_state_dict(torch.load(path))
734 | 
735 |     def save_weights(self, path):
    |         ^^^^^^^^^^^^ D102
736 |         torch.save(self.state_dict(), path)
    |

geom3d\models\GemNet\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\GemNet\__init__.py:1:21: F401 `.GemNet.GemNet` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .GemNet import GemNet
  |                     ^^^^^^ F401
  |
  = help: Use an explicit re-export: `GemNet as GemNet`

geom3d\models\GemNet\initializers.py:1:1: D100 Missing docstring in public module
geom3d\models\GemNet\initializers.py:4:5: ANN202 Missing return type annotation for private function `_standardize`
  |
4 | def _standardize(kernel):
  |     ^^^^^^^^^^^^ ANN202
5 |     """Makes sure that Var(W) = 1 and E[W] = 0."""
6 |     eps = 1e-6
  |
  = help: Add return type annotation

geom3d\models\GemNet\initializers.py:5:5: D401 First line of docstring should be in imperative mood: "Makes sure that Var(W) = 1 and E[W] = 0."
  |
4 | def _standardize(kernel):
5 |     """Makes sure that Var(W) = 1 and E[W] = 0."""
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
6 |     eps = 1e-6
  |

geom3d\models\GemNet\initializers.py:8:5: SIM108 Use ternary operator `axis = [0, 1] if len(kernel.shape) == 3 else 1` instead of `if`-`else`-block
   |
 6 |       eps = 1e-6
 7 |   
 8 |       if len(kernel.shape) == 3:
   |  _____^
 9 | |         axis = [0, 1]  # last dimension is output dimension
10 | |     else:
11 | |         axis = 1
   | |________________^ SIM108
12 |   
13 |       var, mean = torch.var_mean(kernel, dim=axis, unbiased=True, keepdim=True)
   |
   = help: Replace `if`-`else`-block with `axis = [0, 1] if len(kernel.shape) == 3 else 1`

geom3d\models\GemNet\initializers.py:8:29: PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   |
 6 |     eps = 1e-6
 7 | 
 8 |     if len(kernel.shape) == 3:
   |                             ^ PLR2004
 9 |         axis = [0, 1]  # last dimension is output dimension
10 |     else:
   |

geom3d\models\GemNet\initializers.py:18:5: D205 1 blank line required between summary line and description
   |
17 |   def he_orthogonal_init(tensor):
18 |       """Generate a weight matrix with variance according to He initialization.
   |  _____^
19 | |     Based on a random (semi-)orthogonal matrix neural networks
20 | |     are expected to learn better when features are decorrelated
21 | |     (stated by eg. "Reducing overfitting in deep networks by decorrelating representations",
22 | |     "Dropout: a simple way to prevent neural networks from overfitting",
23 | |     "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks").
24 | |     """
   | |_______^ D205
25 |       tensor = torch.nn.init.orthogonal_(tensor)
   |
   = help: Insert single blank line

geom3d\models\GemNet\initializers.py:27:29: PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   |
25 |     tensor = torch.nn.init.orthogonal_(tensor)
26 | 
27 |     if len(tensor.shape) == 3:
   |                             ^ PLR2004
28 |         fan_in = tensor.shape[:-1].numel()
29 |     else:
   |

geom3d\models\GemNet\layers\atom_update_block.py:1:1: INP001 File `geom3d\models\GemNet\layers\atom_update_block.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\models\GemNet\layers\atom_update_block.py:1:1: D100 Missing docstring in public module
geom3d\models\GemNet\layers\atom_update_block.py:4:1: TID252 Prefer absolute imports over relative imports from parent modules
  |
2 | from torch_geometric.utils import scatter
3 | 
4 | from ..initializers import he_orthogonal_init
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ TID252
5 | from .base_layers import Dense, ResidualLayer
6 | from .scaling import ScalingFactor
  |
  = help: Replace relative imports from parent modules with absolute imports

geom3d\models\GemNet\layers\atom_update_block.py:27:9: PLR0913 Too many arguments in function definition (7 > 5)
   |
25 |     """
26 | 
27 |     def __init__(
   |         ^^^^^^^^ PLR0913
28 |         self,
29 |         emb_size_atom: int,
   |

geom3d\models\GemNet\layers\atom_update_block.py:27:9: D107 Missing docstring in `__init__`
   |
25 |     """
26 | 
27 |     def __init__(
   |         ^^^^^^^^ D107
28 |         self,
29 |         emb_size_atom: int,
   |

geom3d\models\GemNet\layers\atom_update_block.py:32:9: N803 Argument name `nHidden` should be lowercase
   |
30 |         emb_size_edge: int,
31 |         emb_size_rbf: int,
32 |         nHidden: int,
   |         ^^^^^^^^^^^^ N803
33 |         activation=None,
34 |         scale_file=None,
   |

geom3d\models\GemNet\layers\atom_update_block.py:46:9: D102 Missing docstring in public method
   |
44 |         self.layers = self.get_mlp(emb_size_atom, nHidden, activation)
45 | 
46 |     def get_mlp(self, units, nHidden, activation):
   |         ^^^^^^^ D102
47 |         dense1 = Dense(self.emb_size_edge, units, activation=activation, bias=False)
48 |         res = [
   |

geom3d\models\GemNet\layers\atom_update_block.py:46:30: N803 Argument name `nHidden` should be lowercase
   |
44 |         self.layers = self.get_mlp(emb_size_atom, nHidden, activation)
45 | 
46 |     def get_mlp(self, units, nHidden, activation):
   |                              ^^^^^^^ N803
47 |         dense1 = Dense(self.emb_size_edge, units, activation=activation, bias=False)
48 |         res = [
   |

geom3d\models\GemNet\layers\atom_update_block.py:56:9: D205 1 blank line required between summary line and description
   |
55 |       def forward(self, h, m, rbf, id_j):
56 |           """Returns
   |  _________^
57 | |         -------
58 | |             h: Tensor, shape=(nAtoms, emb_size_atom)
59 | |                 Atom embedding.
60 | | 
61 | |         """
   | |___________^ D205
62 |           nAtoms = h.shape[0]
   |
   = help: Insert single blank line

geom3d\models\GemNet\layers\atom_update_block.py:56:9: D401 First line of docstring should be in imperative mood: "Returns"
   |
55 |       def forward(self, h, m, rbf, id_j):
56 |           """Returns
   |  _________^
57 | |         -------
58 | |             h: Tensor, shape=(nAtoms, emb_size_atom)
59 | |                 Atom embedding.
60 | | 
61 | |         """
   | |___________^ D401
62 |           nAtoms = h.shape[0]
   |

geom3d\models\GemNet\layers\atom_update_block.py:62:9: N806 Variable `nAtoms` in function should be lowercase
   |
61 |         """
62 |         nAtoms = h.shape[0]
   |         ^^^^^^ N806
63 | 
64 |         mlp_rbf = self.dense_rbf(rbf)  # (nEdges, emb_size_edge)
   |

geom3d\models\GemNet\layers\atom_update_block.py:99:9: PLR0913 Too many arguments in function definition (10 > 5)
    |
 97 |     """
 98 | 
 99 |     def __init__(
    |         ^^^^^^^^ PLR0913
100 |         self,
101 |         emb_size_atom: int,
    |

geom3d\models\GemNet\layers\atom_update_block.py:99:9: D107 Missing docstring in `__init__`
    |
 97 |     """
 98 | 
 99 |     def __init__(
    |         ^^^^^^^^ D107
100 |         self,
101 |         emb_size_atom: int,
    |

geom3d\models\GemNet\layers\atom_update_block.py:104:9: N803 Argument name `nHidden` should be lowercase
    |
102 |         emb_size_edge: int,
103 |         emb_size_rbf: int,
104 |         nHidden: int,
    |         ^^^^^^^^^^^^ N803
105 |         num_targets: int,
106 |         activation=None,
    |

geom3d\models\GemNet\layers\atom_update_block.py:107:9: FBT002 Boolean default positional argument in function definition
    |
105 |         num_targets: int,
106 |         activation=None,
107 |         direct_forces=True,
    |         ^^^^^^^^^^^^^ FBT002
108 |         output_init="HeOrthogonal",
109 |         scale_file=None,
    |

geom3d\models\GemNet\layers\atom_update_block.py:111:9: ANN003 Missing type annotation for `**kwargs`
    |
109 |         scale_file=None,
110 |         name: str = "output",
111 |         **kwargs,
    |         ^^^^^^^^ ANN003
112 |     ):
    |

geom3d\models\GemNet\layers\atom_update_block.py:125:9: S101 Use of `assert` detected
    |
123 |         )
124 | 
125 |         assert isinstance(output_init, str)
    |         ^^^^^^ S101
126 |         self.output_init = output_init
127 |         self.direct_forces = direct_forces
    |

geom3d\models\GemNet\layers\atom_update_block.py:145:9: D102 Missing docstring in public method
    |
143 |         self.reset_parameters()
144 | 
145 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
146 |         if self.output_init.lower() == "heorthogonal":
147 |             he_orthogonal_init(self.out_energy.weight)
    |

geom3d\models\GemNet\layers\atom_update_block.py:159:9: D205 1 blank line required between summary line and description
    |
158 |       def forward(self, h, m, rbf, id_j):
159 |           """Returns
    |  _________^
160 | |         -------
161 | |             (E, F): tuple
162 | |             - E: Tensor, shape=(nAtoms, num_targets)
163 | |             - F: Tensor, shape=(nEdges, num_targets)
164 | |             Energy and force prediction
165 | | 
166 | |         """
    | |___________^ D205
167 |           nAtoms = h.shape[0]
    |
    = help: Insert single blank line

geom3d\models\GemNet\layers\atom_update_block.py:159:9: D401 First line of docstring should be in imperative mood: "Returns"
    |
158 |       def forward(self, h, m, rbf, id_j):
159 |           """Returns
    |  _________^
160 | |         -------
161 | |             (E, F): tuple
162 | |             - E: Tensor, shape=(nAtoms, num_targets)
163 | |             - F: Tensor, shape=(nEdges, num_targets)
164 | |             Energy and force prediction
165 | | 
166 | |         """
    | |___________^ D401
167 |           nAtoms = h.shape[0]
    |

geom3d\models\GemNet\layers\atom_update_block.py:167:9: N806 Variable `nAtoms` in function should be lowercase
    |
166 |         """
167 |         nAtoms = h.shape[0]
    |         ^^^^^^ N806
168 | 
169 |         rbf_mlp = self.dense_rbf(rbf)  # (nEdges, emb_size_edge)
    |

geom3d\models\GemNet\layers\atom_update_block.py:173:9: N806 Variable `x_E` in function should be lowercase
    |
172 |         # -------------------------------------- Energy Prediction -------------------------------------- #
173 |         x_E = scatter(x, id_j, dim=0, dim_size=nAtoms, reduce="add")  # (nAtoms, emb_size_edge)
    |         ^^^ N806
174 |         x_E = self.scale_sum(m, x_E)
    |

geom3d\models\GemNet\layers\atom_update_block.py:174:9: N806 Variable `x_E` in function should be lowercase
    |
172 |         # -------------------------------------- Energy Prediction -------------------------------------- #
173 |         x_E = scatter(x, id_j, dim=0, dim_size=nAtoms, reduce="add")  # (nAtoms, emb_size_edge)
174 |         x_E = self.scale_sum(m, x_E)
    |         ^^^ N806
175 | 
176 |         for _i, layer in enumerate(self.seq_energy):
    |

geom3d\models\GemNet\layers\atom_update_block.py:177:13: N806 Variable `x_E` in function should be lowercase
    |
176 |         for _i, layer in enumerate(self.seq_energy):
177 |             x_E = layer(x_E)  # (nAtoms, emb_size_atom)
    |             ^^^ N806
178 | 
179 |         x_E = self.out_energy(x_E)  # (nAtoms, num_targets)
    |

geom3d\models\GemNet\layers\atom_update_block.py:179:9: N806 Variable `x_E` in function should be lowercase
    |
177 |             x_E = layer(x_E)  # (nAtoms, emb_size_atom)
178 | 
179 |         x_E = self.out_energy(x_E)  # (nAtoms, num_targets)
    |         ^^^ N806
180 | 
181 |         # --------------------------------------- Force Prediction -------------------------------------- #
    |

geom3d\models\GemNet\layers\atom_update_block.py:184:13: N806 Variable `x_F` in function should be lowercase
    |
182 |         if self.direct_forces:
183 | 
184 |             x_F = self.scale_rbf(m, x)
    |             ^^^ N806
185 | 
186 |             for _i, layer in enumerate(self.seq_forces):
    |

geom3d\models\GemNet\layers\atom_update_block.py:187:17: N806 Variable `x_F` in function should be lowercase
    |
186 |             for _i, layer in enumerate(self.seq_forces):
187 |                 x_F = layer(x_F)  # (nEdges, emb_size_edge)
    |                 ^^^ N806
188 | 
189 |             x_F = self.out_forces(x_F)  # (nEdges, num_targets)
    |

geom3d\models\GemNet\layers\atom_update_block.py:189:13: N806 Variable `x_F` in function should be lowercase
    |
187 |                 x_F = layer(x_F)  # (nEdges, emb_size_edge)
188 | 
189 |             x_F = self.out_forces(x_F)  # (nEdges, num_targets)
    |             ^^^ N806
190 |         else:
191 |             x_F = 0
    |

geom3d\models\GemNet\layers\atom_update_block.py:191:13: N806 Variable `x_F` in function should be lowercase
    |
189 |             x_F = self.out_forces(x_F)  # (nEdges, num_targets)
190 |         else:
191 |             x_F = 0
    |             ^^^ N806
192 |         # ----------------------------------------------------------------------------------------------- #
    |

geom3d\models\GemNet\layers\base_layers.py:1:1: INP001 File `geom3d\models\GemNet\layers\base_layers.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\models\GemNet\layers\base_layers.py:1:1: D100 Missing docstring in public module
geom3d\models\GemNet\layers\base_layers.py:3:1: TID252 Prefer absolute imports over relative imports from parent modules
  |
1 | import torch
2 | 
3 | from ..initializers import he_orthogonal_init
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ TID252
  |
  = help: Replace relative imports from parent modules with absolute imports

geom3d\models\GemNet\layers\base_layers.py:20:9: D107 Missing docstring in `__init__`
   |
18 |     """
19 | 
20 |     def __init__(
   |         ^^^^^^^^ D107
21 |         self, in_features, out_features, bias=False, activation=None, name=None
22 |     ):
   |

geom3d\models\GemNet\layers\base_layers.py:21:42: FBT002 Boolean default positional argument in function definition
   |
20 |     def __init__(
21 |         self, in_features, out_features, bias=False, activation=None, name=None
   |                                          ^^^^ FBT002
22 |     ):
23 |         super().__init__()
   |

geom3d\models\GemNet\layers\base_layers.py:21:71: ARG002 Unused method argument: `name`
   |
20 |     def __init__(
21 |         self, in_features, out_features, bias=False, activation=None, name=None
   |                                                                       ^^^^ ARG002
22 |     ):
23 |         super().__init__()
   |

geom3d\models\GemNet\layers\base_layers.py:42:9: D102 Missing docstring in public method
   |
40 |             )
41 | 
42 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
43 |         he_orthogonal_init(self.linear.weight)
44 |         if self.linear.bias is not None:
   |

geom3d\models\GemNet\layers\base_layers.py:47:9: D102 Missing docstring in public method
   |
45 |             self.linear.bias.data.fill_(0)
46 | 
47 |     def forward(self, x):
   |         ^^^^^^^ D102
48 |         x = self.linear(x)
49 |         return self._activation(x)
   |

geom3d\models\GemNet\layers\base_layers.py:52:7: D101 Missing docstring in public class
   |
52 | class ScaledSiLU(torch.nn.Module):
   |       ^^^^^^^^^^ D101
53 |     def __init__(self):
54 |         super().__init__()
   |

geom3d\models\GemNet\layers\base_layers.py:53:9: D107 Missing docstring in `__init__`
   |
52 | class ScaledSiLU(torch.nn.Module):
53 |     def __init__(self):
   |         ^^^^^^^^ D107
54 |         super().__init__()
55 |         self.scale_factor = 1 / 0.6
   |

geom3d\models\GemNet\layers\base_layers.py:58:9: D102 Missing docstring in public method
   |
56 |         self._activation = torch.nn.SiLU()
57 | 
58 |     def forward(self, x):
   |         ^^^^^^^ D102
59 |         return self._activation(x) * self.scale_factor
   |

geom3d\models\GemNet\layers\base_layers.py:76:9: D107 Missing docstring in `__init__`
   |
74 |     """
75 | 
76 |     def __init__(self, units: int, nLayers: int = 2, activation=None, name=None):
   |         ^^^^^^^^ D107
77 |         super().__init__()
78 |         self.dense_mlp = torch.nn.Sequential(
   |

geom3d\models\GemNet\layers\base_layers.py:76:36: N803 Argument name `nLayers` should be lowercase
   |
74 |     """
75 | 
76 |     def __init__(self, units: int, nLayers: int = 2, activation=None, name=None):
   |                                    ^^^^^^^^^^^^ N803
77 |         super().__init__()
78 |         self.dense_mlp = torch.nn.Sequential(
   |

geom3d\models\GemNet\layers\base_layers.py:76:71: ARG002 Unused method argument: `name`
   |
74 |     """
75 | 
76 |     def __init__(self, units: int, nLayers: int = 2, activation=None, name=None):
   |                                                                       ^^^^ ARG002
77 |         super().__init__()
78 |         self.dense_mlp = torch.nn.Sequential(
   |

geom3d\models\GemNet\layers\base_layers.py:86:9: D102 Missing docstring in public method
   |
84 |         self.inv_sqrt_2 = 1 / (2.0 ** 0.5)
85 | 
86 |     def forward(self, inputs):
   |         ^^^^^^^ D102
87 |         x = self.dense_mlp(inputs)
88 |         x = inputs + x
   |

geom3d\models\GemNet\layers\basis_layers.py:1:1: INP001 File `geom3d\models\GemNet\layers\basis_layers.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\models\GemNet\layers\basis_layers.py:1:1: D100 Missing docstring in public module
geom3d\models\GemNet\layers\basis_layers.py:23:9: D107 Missing docstring in `__init__`
   |
21 |     """
22 | 
23 |     def __init__(
   |         ^^^^^^^^ D107
24 |         self,
25 |         num_radial: int,
   |

geom3d\models\GemNet\layers\basis_layers.py:28:9: ARG002 Unused method argument: `name`
   |
26 |         cutoff: float,
27 |         envelope_exponent: int = 5,
28 |         name="bessel_basis",
   |         ^^^^ ARG002
29 |     ):
30 |         super().__init__()
   |

geom3d\models\GemNet\layers\basis_layers.py:45:9: D102 Missing docstring in public method
   |
43 |         )
44 | 
45 |     def forward(self, d):
   |         ^^^^^^^ D102
46 |         d = d[:, None]  # (nEdges,1)
47 |         d_scaled = d * self.inv_cutoff
   |

geom3d\models\GemNet\layers\basis_layers.py:70:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
68 |     """
69 | 
70 |     def __init__(
   |         ^^^^^^^^ PLR0913
71 |         self,
72 |         num_spherical: int,
   |

geom3d\models\GemNet\layers\basis_layers.py:70:9: D107 Missing docstring in `__init__`
   |
68 |     """
69 | 
70 |     def __init__(
   |         ^^^^^^^^ D107
71 |         self,
72 |         num_spherical: int,
   |

geom3d\models\GemNet\layers\basis_layers.py:76:9: FBT001 Boolean-typed positional argument in function definition
   |
74 |         cutoff: float,
75 |         envelope_exponent: int = 5,
76 |         efficient: bool = False,
   |         ^^^^^^^^^ FBT001
77 |         name: str = "spherical_basis",
78 |     ):
   |

geom3d\models\GemNet\layers\basis_layers.py:76:9: FBT002 Boolean default positional argument in function definition
   |
74 |         cutoff: float,
75 |         envelope_exponent: int = 5,
76 |         efficient: bool = False,
   |         ^^^^^^^^^ FBT002
77 |         name: str = "spherical_basis",
78 |     ):
   |

geom3d\models\GemNet\layers\basis_layers.py:77:9: ARG002 Unused method argument: `name`
   |
75 |         envelope_exponent: int = 5,
76 |         efficient: bool = False,
77 |         name: str = "spherical_basis",
   |         ^^^^ ARG002
78 |     ):
79 |         super().__init__()
   |

geom3d\models\GemNet\layers\basis_layers.py:81:9: S101 Use of `assert` detected
   |
79 |         super().__init__()
80 | 
81 |         assert num_radial <= 64
   |         ^^^^^^ S101
82 |         self.efficient = efficient
83 |         self.num_radial = num_radial
   |

geom3d\models\GemNet\layers\basis_layers.py:81:30: PLR2004 Magic value used in comparison, consider replacing `64` with a constant variable
   |
79 |         super().__init__()
80 | 
81 |         assert num_radial <= 64
   |                              ^^ PLR2004
82 |         self.efficient = efficient
83 |         self.num_radial = num_radial
   |

geom3d\models\GemNet\layers\basis_layers.py:90:9: N806 Variable `Y_lm` in function should be lowercase
   |
88 |         # retrieve formulas
89 |         bessel_formulas = bessel_basis(num_spherical, num_radial)
90 |         Y_lm = real_sph_harm(
   |         ^^^^ N806
91 |             num_spherical, spherical_coordinates=True, zero_m_only=True
92 |         )
   |

geom3d\models\GemNet\layers\basis_layers.py:105:13: E741 Ambiguous variable name: `l`
    |
103 |         modules = {"sin": torch.sin, "cos": torch.cos, "sqrt": torch.sqrt}
104 |         m = 0  # only single angle
105 |         for l in range(len(Y_lm)):  # num_spherical
    |             ^ E741
106 |             if l == 0:
107 |                 # Y_00 is only a constant -> function returns value and not tensor
    |

geom3d\models\GemNet\layers\basis_layers.py:110:61: B023 Function definition does not bind loop variable `first_sph`
    |
108 |                 first_sph = sym.lambdify([theta], Y_lm[l][m], modules)
109 |                 self.sph_funcs.append(
110 |                     lambda theta: torch.zeros_like(theta) + first_sph(theta)
    |                                                             ^^^^^^^^^ B023
111 |                 )
112 |             else:
    |

geom3d\models\GemNet\layers\basis_layers.py:119:9: D102 Missing docstring in public method
    |
117 |                 )
118 | 
119 |     def forward(self, D_ca, Angle_cab, id3_reduce_ca, Kidx):
    |         ^^^^^^^ D102
120 | 
121 |         d_scaled = D_ca * self.inv_cutoff  # (nEdges,)
    |

geom3d\models\GemNet\layers\basis_layers.py:119:23: N803 Argument name `D_ca` should be lowercase
    |
117 |                 )
118 | 
119 |     def forward(self, D_ca, Angle_cab, id3_reduce_ca, Kidx):
    |                       ^^^^ N803
120 | 
121 |         d_scaled = D_ca * self.inv_cutoff  # (nEdges,)
    |

geom3d\models\GemNet\layers\basis_layers.py:119:29: N803 Argument name `Angle_cab` should be lowercase
    |
117 |                 )
118 | 
119 |     def forward(self, D_ca, Angle_cab, id3_reduce_ca, Kidx):
    |                             ^^^^^^^^^ N803
120 | 
121 |         d_scaled = D_ca * self.inv_cutoff  # (nEdges,)
    |

geom3d\models\GemNet\layers\basis_layers.py:119:55: N803 Argument name `Kidx` should be lowercase
    |
117 |                 )
118 | 
119 |     def forward(self, D_ca, Angle_cab, id3_reduce_ca, Kidx):
    |                                                       ^^^^ N803
120 | 
121 |         d_scaled = D_ca * self.inv_cutoff  # (nEdges,)
    |

geom3d\models\GemNet\layers\basis_layers.py:144:9: RET505 Unnecessary `else` after `return` statement
    |
142 |             #       m: 0 0  0 0  0 0
143 |             return (rbf_env * sph).view(-1, self.num_spherical * self.num_radial)
144 |         else:
    |         ^^^^ RET505
145 |             rbf_env = rbf_env.view(-1, self.num_spherical, self.num_radial)
146 |             rbf_env = torch.transpose(
    |
    = help: Remove unnecessary `else`

geom3d\models\GemNet\layers\basis_layers.py:152:13: N806 Variable `Kmax` in function should be lowercase
    |
150 |             # Zero padded dense matrix
151 |             # maximum number of neighbors, catch empty id_reduce_ji with maximum
152 |             Kmax = 0 if sph.shape[0]==0 else torch.max(torch.max(Kidx + 1), torch.tensor(0))
    |             ^^^^ N806
153 |             nEdges = d_scaled.shape[0]
    |

geom3d\models\GemNet\layers\basis_layers.py:153:13: N806 Variable `nEdges` in function should be lowercase
    |
151 |             # maximum number of neighbors, catch empty id_reduce_ji with maximum
152 |             Kmax = 0 if sph.shape[0]==0 else torch.max(torch.max(Kidx + 1), torch.tensor(0))
153 |             nEdges = d_scaled.shape[0]
    |             ^^^^^^ N806
154 | 
155 |             sph2 = torch.zeros(
    |

geom3d\models\GemNet\layers\basis_layers.py:160:13: ERA001 Found commented-out code
    |
158 |             sph2[id3_reduce_ca, Kidx] = sph
159 | 
160 |             # (num_spherical, nEdges, num_radial), (nEdges, Kmax, num_spherical)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
161 |             return rbf_env, sph2
    |
    = help: Remove commented-out code

geom3d\models\GemNet\layers\basis_layers.py:182:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
180 |     """
181 | 
182 |     def __init__(
    |         ^^^^^^^^ PLR0913
183 |         self,
184 |         num_spherical: int,
    |

geom3d\models\GemNet\layers\basis_layers.py:182:9: D107 Missing docstring in `__init__`
    |
180 |     """
181 | 
182 |     def __init__(
    |         ^^^^^^^^ D107
183 |         self,
184 |         num_spherical: int,
    |

geom3d\models\GemNet\layers\basis_layers.py:188:9: FBT002 Boolean default positional argument in function definition
    |
186 |         cutoff: float,
187 |         envelope_exponent: int = 5,
188 |         efficient=False,
    |         ^^^^^^^^^ FBT002
189 |         name: str = "tensor_basis",
190 |     ):
    |

geom3d\models\GemNet\layers\basis_layers.py:189:9: ARG002 Unused method argument: `name`
    |
187 |         envelope_exponent: int = 5,
188 |         efficient=False,
189 |         name: str = "tensor_basis",
    |         ^^^^ ARG002
190 |     ):
191 |         super().__init__()
    |

geom3d\models\GemNet\layers\basis_layers.py:193:9: S101 Use of `assert` detected
    |
191 |         super().__init__()
192 | 
193 |         assert num_radial <= 64
    |         ^^^^^^ S101
194 |         self.num_radial = num_radial
195 |         self.num_spherical = num_spherical
    |

geom3d\models\GemNet\layers\basis_layers.py:193:30: PLR2004 Magic value used in comparison, consider replacing `64` with a constant variable
    |
191 |         super().__init__()
192 | 
193 |         assert num_radial <= 64
    |                              ^^ PLR2004
194 |         self.num_radial = num_radial
195 |         self.num_spherical = num_spherical
    |

geom3d\models\GemNet\layers\basis_layers.py:203:9: N806 Variable `Y_lm` in function should be lowercase
    |
201 |         # retrieve formulas
202 |         bessel_formulas = bessel_basis(num_spherical, num_radial)
203 |         Y_lm = real_sph_harm(
    |         ^^^^ N806
204 |             num_spherical, spherical_coordinates=True, zero_m_only=False
205 |         )
    |

geom3d\models\GemNet\layers\basis_layers.py:215:13: E741 Ambiguous variable name: `l`
    |
213 |         phi = sym.symbols("phi")
214 |         modules = {"sin": torch.sin, "cos": torch.cos, "sqrt": torch.sqrt}
215 |         for l in range(len(Y_lm)):  # num_spherical
    |             ^ E741
216 |             for m in range(len(Y_lm[l])):
217 |                 if (
    |

geom3d\models\GemNet\layers\basis_layers.py:223:27: B023 Function definition does not bind loop variable `first_sph`
    |
221 |                     self.sph_funcs.append(
222 |                         lambda theta, phi: torch.zeros_like(theta)
223 |                         + first_sph(theta, phi)
    |                           ^^^^^^^^^ B023
224 |                     )
225 |                 else:
    |

geom3d\models\GemNet\layers\basis_layers.py:238:9: D102 Missing docstring in public method
    |
236 |         )
237 | 
238 |     def forward(self, D_ca, Alpha_cab, Theta_cabd, id4_reduce_ca, Kidx):
    |         ^^^^^^^ D102
239 | 
240 |         d_scaled = D_ca * self.inv_cutoff
    |

geom3d\models\GemNet\layers\basis_layers.py:238:23: N803 Argument name `D_ca` should be lowercase
    |
236 |         )
237 | 
238 |     def forward(self, D_ca, Alpha_cab, Theta_cabd, id4_reduce_ca, Kidx):
    |                       ^^^^ N803
239 | 
240 |         d_scaled = D_ca * self.inv_cutoff
    |

geom3d\models\GemNet\layers\basis_layers.py:238:29: N803 Argument name `Alpha_cab` should be lowercase
    |
236 |         )
237 | 
238 |     def forward(self, D_ca, Alpha_cab, Theta_cabd, id4_reduce_ca, Kidx):
    |                             ^^^^^^^^^ N803
239 | 
240 |         d_scaled = D_ca * self.inv_cutoff
    |

geom3d\models\GemNet\layers\basis_layers.py:238:40: N803 Argument name `Theta_cabd` should be lowercase
    |
236 |         )
237 | 
238 |     def forward(self, D_ca, Alpha_cab, Theta_cabd, id4_reduce_ca, Kidx):
    |                                        ^^^^^^^^^^ N803
239 | 
240 |         d_scaled = D_ca * self.inv_cutoff
    |

geom3d\models\GemNet\layers\basis_layers.py:238:67: N803 Argument name `Kidx` should be lowercase
    |
236 |         )
237 | 
238 |     def forward(self, D_ca, Alpha_cab, Theta_cabd, id4_reduce_ca, Kidx):
    |                                                                   ^^^^ N803
239 | 
240 |         d_scaled = D_ca * self.inv_cutoff
    |

geom3d\models\GemNet\layers\basis_layers.py:280:9: RET505 Unnecessary `else` after `return` statement
    |
278 |             return rbf_env * sph  # (nQuadruplets, num_spherical**2 * num_radial)
279 | 
280 |         else:
    |         ^^^^ RET505
281 |             rbf_env = torch.transpose(rbf_env, 0, 1)  # (num_spherical**2, nEdges, num_radial)
    |
    = help: Remove unnecessary `else`

geom3d\models\GemNet\layers\basis_layers.py:285:13: N806 Variable `Kmax` in function should be lowercase
    |
283 |             # Zero padded dense matrix
284 |             # maximum number of neighbors, catch empty id_reduce_ji with maximum
285 |             Kmax = 0 if sph.shape[0]==0 else torch.max(torch.max(Kidx + 1), torch.tensor(0))
    |             ^^^^ N806
286 |             nEdges = d_scaled.shape[0]
    |

geom3d\models\GemNet\layers\basis_layers.py:286:13: N806 Variable `nEdges` in function should be lowercase
    |
284 |             # maximum number of neighbors, catch empty id_reduce_ji with maximum
285 |             Kmax = 0 if sph.shape[0]==0 else torch.max(torch.max(Kidx + 1), torch.tensor(0))
286 |             nEdges = d_scaled.shape[0]
    |             ^^^^^^ N806
287 | 
288 |             sph2 = torch.zeros(
    |

geom3d\models\GemNet\layers\basis_layers.py:293:13: ERA001 Found commented-out code
    |
291 |             sph2[id4_reduce_ca, Kidx] = sph
292 | 
293 |             # (num_spherical**2, nEdges, num_radial), (nEdges, Kmax, num_spherical**2)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
294 |             return rbf_env, sph2
    |
    = help: Remove commented-out code

geom3d\models\GemNet\layers\basis_utils.py:1:1: INP001 File `geom3d\models\GemNet\layers\basis_utils.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\models\GemNet\layers\basis_utils.py:1:1: D100 Missing docstring in public module
geom3d\models\GemNet\layers\basis_utils.py:7:5: N802 Function name `Jn` should be lowercase
  |
7 | def Jn(r, n):
  |     ^^ N802
8 |     """Numerical spherical bessel functions of order n."""
9 |     return sp.spherical_jn(n, r)
  |

geom3d\models\GemNet\layers\basis_utils.py:12:5: N802 Function name `Jn_zeros` should be lowercase
   |
12 | def Jn_zeros(n, k):
   |     ^^^^^^^^ N802
13 |     """Compute the first k zeros of the spherical bessel functions up to order n (excluded)."""
14 |     zerosj = np.zeros((n, k), dtype="float32")
   |

geom3d\models\GemNet\layers\basis_utils.py:29:5: D401 First line of docstring should be in imperative mood: "Computes the sympy formulas for the spherical bessel functions up to order n (excluded)."
   |
28 | def spherical_bessel_formulas(n):
29 |     """Computes the sympy formulas for the spherical bessel functions up to order n (excluded)."""
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
30 |     x = sym.symbols("x")
31 |     # j_i = (-x)^i * (1/x * d/dx)^î * sin(x)/x
   |

geom3d\models\GemNet\layers\basis_utils.py:31:5: ERA001 Found commented-out code
   |
29 |     """Computes the sympy formulas for the spherical bessel functions up to order n (excluded)."""
30 |     x = sym.symbols("x")
31 |     # j_i = (-x)^i * (1/x * d/dx)^î * sin(x)/x
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
32 |     j = [sym.sin(x) / x]  # j_0
33 |     a = sym.sin(x) / x
   |
   = help: Remove commented-out code

geom3d\models\GemNet\layers\basis_utils.py:42:5: D205 1 blank line required between summary line and description
   |
41 |   def bessel_basis(n, k):
42 |       """Compute the sympy formulas for the normalized and rescaled spherical bessel functions up to
   |  _____^
43 | |     order n (excluded) and maximum frequency k (excluded).
44 | | 
45 | |     Returns
46 | |     -------
47 | |         bess_basis: list
48 | |             Bessel basis formulas taking in a single argument x.
49 | |             Has length n where each element has length k. -> In total n*k many.
50 | | 
51 | |     """
   | |_______^ D205
52 |       zeros = Jn_zeros(n, k)
53 |       normalizer = []
   |
   = help: Insert single blank line

geom3d\models\GemNet\layers\basis_utils.py:78:5: D417 Missing argument descriptions in the docstring for `sph_harm_prefactor`: `l`, `m`
   |
78 | def sph_harm_prefactor(l, m):
   |     ^^^^^^^^^^^^^^^^^^ D417
79 |     """Computes the constant pre-factor for the spherical harmonic of degree l and order m.
   |

geom3d\models\GemNet\layers\basis_utils.py:78:24: E741 Ambiguous variable name: `l`
   |
78 | def sph_harm_prefactor(l, m):
   |                        ^ E741
79 |     """Computes the constant pre-factor for the spherical harmonic of degree l and order m.
   |

geom3d\models\GemNet\layers\basis_utils.py:79:5: D401 First line of docstring should be in imperative mood: "Computes the constant pre-factor for the spherical harmonic of degree l and order m."
   |
78 |   def sph_harm_prefactor(l, m):
79 |       """Computes the constant pre-factor for the spherical harmonic of degree l and order m.
   |  _____^
80 | | 
81 | |     Parameters
82 | |     ----------
83 | |         l: int
84 | |             Degree of the spherical harmonic. l >= 0
85 | |         m: int
86 | |             Order of the spherical harmonic. -l <= m <= l
87 | | 
88 | |     Returns
89 | |     -------
90 | |         factor: float
91 | | 
92 | |     """
   | |_______^ D401
93 |       # sqrt((2*l+1)/4*pi * (l-m)!/(l+m)! )
94 |       return (
   |

geom3d\models\GemNet\layers\basis_utils.py:102:5: C901 `associated_legendre_polynomials` is too complex (11 > 10)
    |
102 | def associated_legendre_polynomials(L, zero_m_only=True, pos_m_only=True):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ C901
103 |     """Computes string formulas of the associated legendre polynomials up to degree L (excluded).
    |

geom3d\models\GemNet\layers\basis_utils.py:102:5: D417 Missing argument descriptions in the docstring for `associated_legendre_polynomials`: `L`, `pos_m_only`, `zero_m_only`
    |
102 | def associated_legendre_polynomials(L, zero_m_only=True, pos_m_only=True):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D417
103 |     """Computes string formulas of the associated legendre polynomials up to degree L (excluded).
    |

geom3d\models\GemNet\layers\basis_utils.py:102:37: N803 Argument name `L` should be lowercase
    |
102 | def associated_legendre_polynomials(L, zero_m_only=True, pos_m_only=True):
    |                                     ^ N803
103 |     """Computes string formulas of the associated legendre polynomials up to degree L (excluded).
    |

geom3d\models\GemNet\layers\basis_utils.py:102:40: FBT002 Boolean default positional argument in function definition
    |
102 | def associated_legendre_polynomials(L, zero_m_only=True, pos_m_only=True):
    |                                        ^^^^^^^^^^^ FBT002
103 |     """Computes string formulas of the associated legendre polynomials up to degree L (excluded).
    |

geom3d\models\GemNet\layers\basis_utils.py:102:58: FBT002 Boolean default positional argument in function definition
    |
102 | def associated_legendre_polynomials(L, zero_m_only=True, pos_m_only=True):
    |                                                          ^^^^^^^^^^ FBT002
103 |     """Computes string formulas of the associated legendre polynomials up to degree L (excluded).
    |

geom3d\models\GemNet\layers\basis_utils.py:103:5: D401 First line of docstring should be in imperative mood: "Computes string formulas of the associated legendre polynomials up to degree L (excluded)."
    |
102 |   def associated_legendre_polynomials(L, zero_m_only=True, pos_m_only=True):
103 |       """Computes string formulas of the associated legendre polynomials up to degree L (excluded).
    |  _____^
104 | | 
105 | |     Parameters
106 | |     ----------
107 | |         L: int
108 | |             Degree up to which to calculate the associated legendre polynomials (degree L is excluded).
109 | |         zero_m_only: bool
110 | |             If True only calculate the polynomials for the polynomials where m=0.
111 | |         pos_m_only: bool
112 | |             If True only calculate the polynomials for the polynomials where m>=0. Overwritten by zero_m_only.
113 | | 
114 | |     Returns
115 | |     -------
116 | |         polynomials: list
117 | |             Contains the sympy functions of the polynomials (in total L many if zero_m_only is True else L^2 many).
118 | | 
119 | |     """
    | |_______^ D401
120 |       # calculations from http://web.cmb.usc.edu/people/alber/Software/tomominer/docs/cpp/group__legendre__polynomials.html
121 |       z = sym.symbols("z")
    |

geom3d\models\GemNet\layers\basis_utils.py:122:5: N806 Variable `P_l_m` in function should be lowercase
    |
120 |     # calculations from http://web.cmb.usc.edu/people/alber/Software/tomominer/docs/cpp/group__legendre__polynomials.html
121 |     z = sym.symbols("z")
122 |     P_l_m = [[0] * (2 * l + 1) for l in range(L)]  # for order l: -l <= m <= l
    |     ^^^^^ N806
123 | 
124 |     P_l_m[0][0] = 1
    |

geom3d\models\GemNet\layers\basis_utils.py:122:36: E741 Ambiguous variable name: `l`
    |
120 |     # calculations from http://web.cmb.usc.edu/people/alber/Software/tomominer/docs/cpp/group__legendre__polynomials.html
121 |     z = sym.symbols("z")
122 |     P_l_m = [[0] * (2 * l + 1) for l in range(L)]  # for order l: -l <= m <= l
    |                                    ^ E741
123 | 
124 |     P_l_m[0][0] = 1
    |

geom3d\models\GemNet\layers\basis_utils.py:127:13: ERA001 Found commented-out code
    |
125 |     if L > 0:
126 |         if zero_m_only:
127 |             # m = 0
    |             ^^^^^^^ ERA001
128 |             P_l_m[1][0] = z
129 |             for l in range(2, L):
    |
    = help: Remove commented-out code

geom3d\models\GemNet\layers\basis_utils.py:129:17: E741 Ambiguous variable name: `l`
    |
127 |             # m = 0
128 |             P_l_m[1][0] = z
129 |             for l in range(2, L):
    |                 ^ E741
130 |                 P_l_m[l][0] = sym.simplify(
131 |                     ((2 * l - 1) * z * P_l_m[l - 1][0] - (l - 1) * P_l_m[l - 2][0]) / l
    |

geom3d\models\GemNet\layers\basis_utils.py:134:9: RET505 Unnecessary `else` after `return` statement
    |
132 |                 )
133 |             return P_l_m
134 |         else:
    |         ^^^^ RET505
135 |             # for m >= 0
136 |             for l in range(1, L):
    |
    = help: Remove unnecessary `else`

geom3d\models\GemNet\layers\basis_utils.py:136:17: E741 Ambiguous variable name: `l`
    |
134 |         else:
135 |             # for m >= 0
136 |             for l in range(1, L):
    |                 ^ E741
137 |                 P_l_m[l][l] = sym.simplify(
138 |                     (1 - 2 * l) * (1 - z ** 2) ** 0.5 * P_l_m[l - 1][l - 1]
    |

geom3d\models\GemNet\layers\basis_utils.py:146:17: E741 Ambiguous variable name: `l`
    |
144 |                 )  # P_10, P_21, P_32, P_43
145 | 
146 |             for l in range(2, L):
    |                 ^ E741
147 |                 for m in range(l - 1):  # P_20, P_30, P_31
148 |                     P_l_m[l][m] = sym.simplify(
    |

geom3d\models\GemNet\layers\basis_utils.py:158:21: E741 Ambiguous variable name: `l`
    |
156 |             if not pos_m_only:
157 |                 # for m < 0: P_l(-m) = (-1)^m * (l-m)!/(l+m)! * P_lm
158 |                 for l in range(1, L):
    |                     ^ E741
159 |                     for m in range(1, l + 1):  # P_1(-1), P_2(-1) P_2(-2)
160 |                         P_l_m[l][-m] = sym.simplify(
    |

geom3d\models\GemNet\layers\basis_utils.py:171:5: C901 `real_sph_harm` is too complex (14 > 10)
    |
171 | def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
    |     ^^^^^^^^^^^^^ C901
172 |     """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
173 |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
    |

geom3d\models\GemNet\layers\basis_utils.py:171:5: PLR0912 Too many branches (14 > 12)
    |
171 | def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
    |     ^^^^^^^^^^^^^ PLR0912
172 |     """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
173 |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
    |

geom3d\models\GemNet\layers\basis_utils.py:171:5: D417 Missing argument descriptions in the docstring for `real_sph_harm`: `L`, `spherical_coordinates`, `zero_m_only`
    |
171 | def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
    |     ^^^^^^^^^^^^^ D417
172 |     """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
173 |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
    |

geom3d\models\GemNet\layers\basis_utils.py:171:19: N803 Argument name `L` should be lowercase
    |
171 | def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
    |                   ^ N803
172 |     """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
173 |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
    |

geom3d\models\GemNet\layers\basis_utils.py:171:45: FBT002 Boolean default positional argument in function definition
    |
171 | def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
    |                                             ^^^^^^^^^^^ FBT002
172 |     """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
173 |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
    |

geom3d\models\GemNet\layers\basis_utils.py:172:5: D205 1 blank line required between summary line and description
    |
171 |   def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
172 |       """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
    |  _____^
173 | |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
174 | | 
175 | |     Parameters
176 | |     ----------
177 | |         L: int
178 | |             Degree up to which to calculate the spherical harmonics (degree L is excluded).
179 | |         spherical_coordinates: bool
180 | |             - True: Expects the input of the formula strings to be phi and theta.
181 | |             - False: Expects the input of the formula strings to be x, y and z.
182 | |         zero_m_only: bool
183 | |             If True only calculate the harmonics where m=0.
184 | | 
185 | |     Returns
186 | |     -------
187 | |         Y_lm_real: list
188 | |             Computes formula strings of the the real part of the spherical harmonics up
189 | |             to degree L (where degree L is not excluded).
190 | |             In total L^2 many sph harm exist up to degree L (excluded). However, if zero_m_only only is True then
191 | |             the total count is reduced to be only L many.
192 | | 
193 | |     """
    | |_______^ D205
194 |       z = sym.symbols("z")
195 |       P_l_m = associated_legendre_polynomials(L, zero_m_only)
    |
    = help: Insert single blank line

geom3d\models\GemNet\layers\basis_utils.py:172:5: D401 First line of docstring should be in imperative mood: "Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded)."
    |
171 |   def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
172 |       """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
    |  _____^
173 | |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
174 | | 
175 | |     Parameters
176 | |     ----------
177 | |         L: int
178 | |             Degree up to which to calculate the spherical harmonics (degree L is excluded).
179 | |         spherical_coordinates: bool
180 | |             - True: Expects the input of the formula strings to be phi and theta.
181 | |             - False: Expects the input of the formula strings to be x, y and z.
182 | |         zero_m_only: bool
183 | |             If True only calculate the harmonics where m=0.
184 | | 
185 | |     Returns
186 | |     -------
187 | |         Y_lm_real: list
188 | |             Computes formula strings of the the real part of the spherical harmonics up
189 | |             to degree L (where degree L is not excluded).
190 | |             In total L^2 many sph harm exist up to degree L (excluded). However, if zero_m_only only is True then
191 | |             the total count is reduced to be only L many.
192 | | 
193 | |     """
    | |_______^ D401
194 |       z = sym.symbols("z")
195 |       P_l_m = associated_legendre_polynomials(L, zero_m_only)
    |

geom3d\models\GemNet\layers\basis_utils.py:195:5: N806 Variable `P_l_m` in function should be lowercase
    |
193 |     """
194 |     z = sym.symbols("z")
195 |     P_l_m = associated_legendre_polynomials(L, zero_m_only)
    |     ^^^^^ N806
196 |     if zero_m_only:
197 |         # for all m != 0: Y_lm = 0
    |

geom3d\models\GemNet\layers\basis_utils.py:198:9: N806 Variable `Y_l_m` in function should be lowercase
    |
196 |     if zero_m_only:
197 |         # for all m != 0: Y_lm = 0
198 |         Y_l_m = [[0] for l in range(L)]
    |         ^^^^^ N806
199 |     else:
200 |         Y_l_m = [[0] * (2 * l + 1) for l in range(L)]  # for order l: -l <= m <= l
    |

geom3d\models\GemNet\layers\basis_utils.py:198:26: E741 Ambiguous variable name: `l`
    |
196 |     if zero_m_only:
197 |         # for all m != 0: Y_lm = 0
198 |         Y_l_m = [[0] for l in range(L)]
    |                          ^ E741
199 |     else:
200 |         Y_l_m = [[0] * (2 * l + 1) for l in range(L)]  # for order l: -l <= m <= l
    |

geom3d\models\GemNet\layers\basis_utils.py:200:9: N806 Variable `Y_l_m` in function should be lowercase
    |
198 |         Y_l_m = [[0] for l in range(L)]
199 |     else:
200 |         Y_l_m = [[0] * (2 * l + 1) for l in range(L)]  # for order l: -l <= m <= l
    |         ^^^^^ N806
201 | 
202 |     # convert expressions to spherical coordiantes
    |

geom3d\models\GemNet\layers\basis_utils.py:200:40: E741 Ambiguous variable name: `l`
    |
198 |         Y_l_m = [[0] for l in range(L)]
199 |     else:
200 |         Y_l_m = [[0] * (2 * l + 1) for l in range(L)]  # for order l: -l <= m <= l
    |                                        ^ E741
201 | 
202 |     # convert expressions to spherical coordiantes
    |

geom3d\models\GemNet\layers\basis_utils.py:206:13: E741 Ambiguous variable name: `l`
    |
204 |         # replace z by cos(theta)
205 |         theta = sym.symbols("theta")
206 |         for l in range(L):
    |             ^ E741
207 |             for m in range(len(P_l_m[l])):
208 |                 if not isinstance(P_l_m[l][m], int):
    |

geom3d\models\GemNet\layers\basis_utils.py:212:5: ERA001 Found commented-out code
    |
211 |     ## calculate Y_lm
212 |     # Y_lm = N * P_lm(cos(theta)) * exp(i*m*phi)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
213 |     #             { sqrt(2) * (-1)^m * N * P_l|m| * sin(|m|*phi)   if m < 0
214 |     # Y_lm_real = { Y_lm                                           if m = 0
    |
    = help: Remove commented-out code

geom3d\models\GemNet\layers\basis_utils.py:217:9: E741 Ambiguous variable name: `l`
    |
215 |     #             { sqrt(2) * (-1)^m * N * P_lm * cos(m*phi)       if m > 0
216 | 
217 |     for l in range(L):
    |         ^ E741
218 |         Y_l_m[l][0] = sym.simplify(sph_harm_prefactor(l, 0) * P_l_m[l][0])  # Y_l0
    |

geom3d\models\GemNet\layers\basis_utils.py:222:13: E741 Ambiguous variable name: `l`
    |
220 |     if not zero_m_only:
221 |         phi = sym.symbols("phi")
222 |         for l in range(1, L):
    |             ^ E741
223 |             # m > 0
224 |             for m in range(1, l + 1):
    |

geom3d\models\GemNet\layers\basis_utils.py:247:17: E741 Ambiguous variable name: `l`
    |
245 |             x = sym.symbols("x")
246 |             y = sym.symbols("y")
247 |             for l in range(L):
    |                 ^ E741
248 |                 for m in range(len(Y_l_m[l])):
249 |                     Y_l_m[l][m] = sym.simplify(Y_l_m[l][m].subs(phi, sym.atan2(y, x)))
    |

geom3d\models\GemNet\layers\efficient.py:1:1: INP001 File `geom3d\models\GemNet\layers\efficient.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\models\GemNet\layers\efficient.py:1:1: D100 Missing docstring in public module
geom3d\models\GemNet\layers\efficient.py:3:1: TID252 Prefer absolute imports over relative imports from parent modules
  |
1 | import torch
2 | 
3 | from ..initializers import he_orthogonal_init
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ TID252
  |
  = help: Replace relative imports from parent modules with absolute imports

geom3d\models\GemNet\layers\efficient.py:20:9: D107 Missing docstring in `__init__`
   |
18 |     """
19 | 
20 |     def __init__(
   |         ^^^^^^^^ D107
21 |         self,
22 |         num_spherical: int,
   |

geom3d\models\GemNet\layers\efficient.py:25:9: ARG002 Unused method argument: `name`
   |
23 |         num_radial: int,
24 |         emb_size_interm: int,
25 |         name="EfficientDownProj",
   |         ^^^^ ARG002
26 |     ):
27 |         super().__init__()
   |

geom3d\models\GemNet\layers\efficient.py:35:9: D102 Missing docstring in public method
   |
33 |         self.reset_parameters()
34 | 
35 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
36 |         self.weight = torch.nn.Parameter(
37 |             torch.empty((self.num_spherical, self.num_radial, self.emb_size_interm)),
   |

geom3d\models\GemNet\layers\efficient.py:43:9: D205 1 blank line required between summary line and description
   |
42 |       def forward(self, tbf):
43 |           """Returns
   |  _________^
44 | |         -------
45 | |             (rbf_W1, sph): tuple
46 | |             - rbf_W1: Tensor, shape=(nEdges, emb_size_interm, num_spherical)
47 | |             - sph: Tensor, shape=(nEdges, Kmax, num_spherical)
48 | | 
49 | |         """
   | |___________^ D205
50 |           rbf_env, sph = tbf
51 |           # (num_spherical, nEdges, num_radial), (nEdges, Kmax, num_spherical) ;  Kmax = maximum number of neighbors of the edges
   |
   = help: Insert single blank line

geom3d\models\GemNet\layers\efficient.py:43:9: D401 First line of docstring should be in imperative mood: "Returns"
   |
42 |       def forward(self, tbf):
43 |           """Returns
   |  _________^
44 | |         -------
45 | |             (rbf_W1, sph): tuple
46 | |             - rbf_W1: Tensor, shape=(nEdges, emb_size_interm, num_spherical)
47 | |             - sph: Tensor, shape=(nEdges, Kmax, num_spherical)
48 | | 
49 | |         """
   | |___________^ D401
50 |           rbf_env, sph = tbf
51 |           # (num_spherical, nEdges, num_radial), (nEdges, Kmax, num_spherical) ;  Kmax = maximum number of neighbors of the edges
   |

geom3d\models\GemNet\layers\efficient.py:54:9: N806 Variable `rbf_W1` in function should be lowercase
   |
53 |         # MatMul: mul + sum over num_radial
54 |         rbf_W1 = torch.matmul(rbf_env, self.weight)  # (num_spherical, nEdges , emb_size_interm)
   |         ^^^^^^ N806
55 |         rbf_W1 = rbf_W1.permute(1, 2, 0)  # (nEdges, emb_size_interm, num_spherical)
   |

geom3d\models\GemNet\layers\efficient.py:55:9: N806 Variable `rbf_W1` in function should be lowercase
   |
53 |         # MatMul: mul + sum over num_radial
54 |         rbf_W1 = torch.matmul(rbf_env, self.weight)  # (num_spherical, nEdges , emb_size_interm)
55 |         rbf_W1 = rbf_W1.permute(1, 2, 0)  # (nEdges, emb_size_interm, num_spherical)
   |         ^^^^^^ N806
56 | 
57 |         sph = torch.transpose(sph, 1, 2)  # (nEdges, num_spherical, Kmax)
   |

geom3d\models\GemNet\layers\efficient.py:73:9: D107 Missing docstring in `__init__`
   |
71 |     """
72 | 
73 |     def __init__(self, emb_size_interm: int, emb_size: int, name="EfficientHadamard"):
   |         ^^^^^^^^ D107
74 |         super().__init__()
75 |         self.emb_size_interm = emb_size_interm
   |

geom3d\models\GemNet\layers\efficient.py:73:61: ARG002 Unused method argument: `name`
   |
71 |     """
72 | 
73 |     def __init__(self, emb_size_interm: int, emb_size: int, name="EfficientHadamard"):
   |                                                             ^^^^ ARG002
74 |         super().__init__()
75 |         self.emb_size_interm = emb_size_interm
   |

geom3d\models\GemNet\layers\efficient.py:80:9: D102 Missing docstring in public method
   |
78 |         self.reset_parameters()
79 | 
80 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
81 |         self.weight = torch.nn.Parameter(
82 |             torch.empty((self.emb_size, 1, self.emb_size_interm), requires_grad=True)
   |

geom3d\models\GemNet\layers\efficient.py:86:44: N803 Argument name `Kidx` should be lowercase
   |
84 |         he_orthogonal_init(self.weight)
85 | 
86 |     def forward(self, basis, m, id_reduce, Kidx):
   |                                            ^^^^ N803
87 |         """Returns
88 |         -------
   |

geom3d\models\GemNet\layers\efficient.py:87:9: D205 1 blank line required between summary line and description
   |
86 |       def forward(self, basis, m, id_reduce, Kidx):
87 |           """Returns
   |  _________^
88 | |         -------
89 | |             m_ca: Tensor, shape=(nEdges, emb_size)
90 | |                 Edge embeddings.
91 | | 
92 | |         """
   | |___________^ D205
93 |           # quadruplets: m = m_db , triplets: m = m_ba
94 |           # num_spherical is actually num_spherical**2 for quadruplets
   |
   = help: Insert single blank line

geom3d\models\GemNet\layers\efficient.py:87:9: D401 First line of docstring should be in imperative mood: "Returns"
   |
86 |       def forward(self, basis, m, id_reduce, Kidx):
87 |           """Returns
   |  _________^
88 | |         -------
89 | |             m_ca: Tensor, shape=(nEdges, emb_size)
90 | |                 Edge embeddings.
91 | | 
92 | |         """
   | |___________^ D401
93 |           # quadruplets: m = m_db , triplets: m = m_ba
94 |           # num_spherical is actually num_spherical**2 for quadruplets
   |

geom3d\models\GemNet\layers\efficient.py:95:9: N806 Variable `rbf_W1` in function should be lowercase
   |
93 |         # quadruplets: m = m_db , triplets: m = m_ba
94 |         # num_spherical is actually num_spherical**2 for quadruplets
95 |         rbf_W1, sph = basis  # (nEdges, emb_size_interm, num_spherical) ,  (nEdges, num_spherical, Kmax)
   |         ^^^^^^ N806
96 |         nEdges = rbf_W1.shape[0]
   |

geom3d\models\GemNet\layers\efficient.py:96:9: N806 Variable `nEdges` in function should be lowercase
   |
94 |         # num_spherical is actually num_spherical**2 for quadruplets
95 |         rbf_W1, sph = basis  # (nEdges, emb_size_interm, num_spherical) ,  (nEdges, num_spherical, Kmax)
96 |         nEdges = rbf_W1.shape[0]
   |         ^^^^^^ N806
97 | 
98 |         # Create (zero-padded) dense matrix of the neighboring edge embeddings.
   |

geom3d\models\GemNet\layers\efficient.py:101:13: N806 Variable `Kmax` in function should be lowercase
    |
 99 |         # maximum number of neighbors, catch empty id_reduce_ji with maximum
100 |         if sph.shape[2]==0:
101 |             Kmax = 0
    |             ^^^^ N806
102 |         else:
103 |             Kmax = torch.max(torch.max(Kidx + 1), torch.tensor(0))
    |

geom3d\models\GemNet\layers\efficient.py:103:13: N806 Variable `Kmax` in function should be lowercase
    |
101 |             Kmax = 0
102 |         else:
103 |             Kmax = torch.max(torch.max(Kidx + 1), torch.tensor(0))
    |             ^^^^ N806
104 |         m2 = torch.zeros(nEdges, Kmax, self.emb_size, device=self.weight.device, dtype=m.dtype)
105 |         m2[id_reduce, Kidx] = m  # (nQuadruplets or nTriplets, emb_size) -> (nEdges, Kmax, emb_size)
    |

geom3d\models\GemNet\layers\efficient.py:110:9: N806 Variable `rbf_W1_sum_k` in function should be lowercase
    |
109 |         # MatMul: mul + sum over num_spherical
110 |         rbf_W1_sum_k = torch.matmul(
    |         ^^^^^^^^^^^^ N806
111 |             rbf_W1, sum_k
112 |         )  # (nEdges, emb_size_interm, emb_size)
    |

geom3d\models\GemNet\layers\efficient.py:136:9: D107 Missing docstring in `__init__`
    |
134 |     """
135 | 
136 |     def __init__(
    |         ^^^^^^^^ D107
137 |         self,
138 |         emb_size: int,
    |

geom3d\models\GemNet\layers\efficient.py:141:9: ARG002 Unused method argument: `name`
    |
139 |         emb_size_interm: int,
140 |         units_out: int,
141 |         name="EfficientBilinear",
    |         ^^^^ ARG002
142 |     ):
143 |         super().__init__()
    |

geom3d\models\GemNet\layers\efficient.py:150:9: D102 Missing docstring in public method
    |
148 |         self.reset_parameters()
149 | 
150 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
151 |         self.weight = torch.nn.Parameter(
152 |             torch.empty(
    |

geom3d\models\GemNet\layers\efficient.py:159:44: N803 Argument name `Kidx` should be lowercase
    |
157 |         he_orthogonal_init(self.weight)
158 | 
159 |     def forward(self, basis, m, id_reduce, Kidx):
    |                                            ^^^^ N803
160 |         """Returns
161 |         -------
    |

geom3d\models\GemNet\layers\efficient.py:160:9: D205 1 blank line required between summary line and description
    |
159 |       def forward(self, basis, m, id_reduce, Kidx):
160 |           """Returns
    |  _________^
161 | |         -------
162 | |             m_ca: Tensor, shape=(nEdges, units_out)
163 | |                 Edge embeddings.
164 | | 
165 | |         """
    | |___________^ D205
166 |           # quadruplets: m = m_db , triplets: m = m_ba
167 |           # num_spherical is actually num_spherical**2 for quadruplets
    |
    = help: Insert single blank line

geom3d\models\GemNet\layers\efficient.py:160:9: D401 First line of docstring should be in imperative mood: "Returns"
    |
159 |       def forward(self, basis, m, id_reduce, Kidx):
160 |           """Returns
    |  _________^
161 | |         -------
162 | |             m_ca: Tensor, shape=(nEdges, units_out)
163 | |                 Edge embeddings.
164 | | 
165 | |         """
    | |___________^ D401
166 |           # quadruplets: m = m_db , triplets: m = m_ba
167 |           # num_spherical is actually num_spherical**2 for quadruplets
    |

geom3d\models\GemNet\layers\efficient.py:168:9: N806 Variable `rbf_W1` in function should be lowercase
    |
166 |         # quadruplets: m = m_db , triplets: m = m_ba
167 |         # num_spherical is actually num_spherical**2 for quadruplets
168 |         rbf_W1, sph = basis  # (nEdges, emb_size_interm, num_spherical) ,  (nEdges, num_spherical, Kmax)
    |         ^^^^^^ N806
169 |         nEdges = rbf_W1.shape[0]
    |

geom3d\models\GemNet\layers\efficient.py:169:9: N806 Variable `nEdges` in function should be lowercase
    |
167 |         # num_spherical is actually num_spherical**2 for quadruplets
168 |         rbf_W1, sph = basis  # (nEdges, emb_size_interm, num_spherical) ,  (nEdges, num_spherical, Kmax)
169 |         nEdges = rbf_W1.shape[0]
    |         ^^^^^^ N806
170 | 
171 |         # Create (zero-padded) dense matrix of the neighboring edge embeddings.
    |

geom3d\models\GemNet\layers\efficient.py:173:9: N806 Variable `Kmax` in function should be lowercase
    |
171 |         # Create (zero-padded) dense matrix of the neighboring edge embeddings.
172 |         # maximum number of neighbors, catch empty id_reduce_ji with maximum
173 |         Kmax = 0 if sph.shape[2]==0 else torch.max(torch.max(Kidx + 1), torch.tensor(0))
    |         ^^^^ N806
174 |         m2 = torch.zeros(nEdges, Kmax, self.emb_size, device=self.weight.device, dtype=m.dtype)
175 |         m2[id_reduce, Kidx] = m  # (nQuadruplets or nTriplets, emb_size) -> (nEdges, Kmax, emb_size)
    |

geom3d\models\GemNet\layers\efficient.py:180:9: N806 Variable `rbf_W1_sum_k` in function should be lowercase
    |
179 |         # MatMul: mul + sum over num_spherical
180 |         rbf_W1_sum_k = torch.matmul(
    |         ^^^^^^^^^^^^ N806
181 |             rbf_W1, sum_k
182 |         )  # (nEdges, emb_size_interm, emb_size)
    |

geom3d\models\GemNet\layers\embedding_block.py:1:1: INP001 File `geom3d\models\GemNet\layers\embedding_block.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\models\GemNet\layers\embedding_block.py:1:1: D100 Missing docstring in public module
geom3d\models\GemNet\layers\embedding_block.py:17:9: D107 Missing docstring in `__init__`
   |
15 |     """
16 | 
17 |     def __init__(self, node_class, emb_size, name=None):
   |         ^^^^^^^^ D107
18 |         super().__init__()
19 |         self.node_class = node_class
   |

geom3d\models\GemNet\layers\embedding_block.py:17:46: ARG002 Unused method argument: `name`
   |
15 |     """
16 | 
17 |     def __init__(self, node_class, emb_size, name=None):
   |                                              ^^^^ ARG002
18 |         super().__init__()
19 |         self.node_class = node_class
   |

geom3d\models\GemNet\layers\embedding_block.py:27:23: N803 Argument name `Z` should be lowercase
   |
25 |         torch.nn.init.uniform_(self.embeddings.weight, a=-np.sqrt(3), b=np.sqrt(3))
26 | 
27 |     def forward(self, Z):
   |                       ^ N803
28 |         """Returns
29 |         -------
   |

geom3d\models\GemNet\layers\embedding_block.py:28:9: D205 1 blank line required between summary line and description
   |
27 |       def forward(self, Z):
28 |           """Returns
   |  _________^
29 | |         -------
30 | |             h: Tensor, shape=(nAtoms, emb_size)
31 | |                 Atom embeddings.
32 | | 
33 | |         """
   | |___________^ D205
34 |           return self.embeddings(Z)  # -1 because Z.min()=1 (==Hydrogen)
   |
   = help: Insert single blank line

geom3d\models\GemNet\layers\embedding_block.py:28:9: D401 First line of docstring should be in imperative mood: "Returns"
   |
27 |       def forward(self, Z):
28 |           """Returns
   |  _________^
29 | |         -------
30 | |             h: Tensor, shape=(nAtoms, emb_size)
31 | |                 Atom embeddings.
32 | | 
33 | |         """
   | |___________^ D401
34 |           return self.embeddings(Z)  # -1 because Z.min()=1 (==Hydrogen)
   |

geom3d\models\GemNet\layers\embedding_block.py:53:9: D107 Missing docstring in `__init__`
   |
51 |     """
52 | 
53 |     def __init__(
   |         ^^^^^^^^ D107
54 |         self, atom_features, edge_features, out_features, activation=None, name=None
55 |     ):
   |

geom3d\models\GemNet\layers\embedding_block.py:54:76: ARG002 Unused method argument: `name`
   |
53 |     def __init__(
54 |         self, atom_features, edge_features, out_features, activation=None, name=None
   |                                                                            ^^^^ ARG002
55 |     ):
56 |         super().__init__()
   |

geom3d\models\GemNet\layers\embedding_block.py:61:9: D205 1 blank line required between summary line and description
   |
60 |       def forward(self, h, m_rbf, idnb_a, idnb_c):
61 |           """Returns
   |  _________^
62 | |         -------
63 | |             m_ca: Tensor, shape=(nEdges, emb_size)
64 | |                 Edge embeddings.
65 | | 
66 | |         """
   | |___________^ D205
67 |           # m_rbf: shape (nEdges, nFeatures)
68 |           # in embedding block: m_rbf = rbf ; In interaction block: m_rbf = m_ca
   |
   = help: Insert single blank line

geom3d\models\GemNet\layers\embedding_block.py:61:9: D401 First line of docstring should be in imperative mood: "Returns"
   |
60 |       def forward(self, h, m_rbf, idnb_a, idnb_c):
61 |           """Returns
   |  _________^
62 | |         -------
63 | |             m_ca: Tensor, shape=(nEdges, emb_size)
64 | |                 Edge embeddings.
65 | | 
66 | |         """
   | |___________^ D401
67 |           # m_rbf: shape (nEdges, nFeatures)
68 |           # in embedding block: m_rbf = rbf ; In interaction block: m_rbf = m_ca
   |

geom3d\models\GemNet\layers\embedding_block.py:67:9: ERA001 Found commented-out code
   |
66 |         """
67 |         # m_rbf: shape (nEdges, nFeatures)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
68 |         # in embedding block: m_rbf = rbf ; In interaction block: m_rbf = m_ca
   |
   = help: Remove commented-out code

geom3d\models\GemNet\layers\envelope.py:1:1: INP001 File `geom3d\models\GemNet\layers\envelope.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\models\GemNet\layers\envelope.py:1:1: D100 Missing docstring in public module
geom3d\models\GemNet\layers\envelope.py:14:9: D107 Missing docstring in `__init__`
   |
12 |     """
13 | 
14 |     def __init__(self, p, name="envelope"):
   |         ^^^^^^^^ D107
15 |         super().__init__()
16 |         assert p > 0
   |

geom3d\models\GemNet\layers\envelope.py:14:27: ARG002 Unused method argument: `name`
   |
12 |     """
13 | 
14 |     def __init__(self, p, name="envelope"):
   |                           ^^^^ ARG002
15 |         super().__init__()
16 |         assert p > 0
   |

geom3d\models\GemNet\layers\envelope.py:16:9: S101 Use of `assert` detected
   |
14 |     def __init__(self, p, name="envelope"):
15 |         super().__init__()
16 |         assert p > 0
   |         ^^^^^^ S101
17 |         self.p = p
18 |         self.a = -(self.p + 1) * (self.p + 2) / 2
   |

geom3d\models\GemNet\layers\envelope.py:22:9: D102 Missing docstring in public method
   |
20 |         self.c = -self.p * (self.p + 1) / 2
21 | 
22 |     def forward(self, d_scaled):
   |         ^^^^^^^ D102
23 |         env_val = (
24 |             1
   |

geom3d\models\GemNet\layers\interaction_block.py:1:1: INP001 File `geom3d\models\GemNet\layers\interaction_block.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\models\GemNet\layers\interaction_block.py:1:1: D100 Missing docstring in public module
geom3d\models\GemNet\layers\interaction_block.py:50:9: PLR0913 Too many arguments in function definition (16 > 5)
   |
48 |     """
49 | 
50 |     def __init__(
   |         ^^^^^^^^ PLR0913
51 |         self,
52 |         emb_size_atom,
   |

geom3d\models\GemNet\layers\interaction_block.py:50:9: D107 Missing docstring in `__init__`
   |
48 |     """
49 | 
50 |     def __init__(
   |         ^^^^^^^^ D107
51 |         self,
52 |         emb_size_atom,
   |

geom3d\models\GemNet\layers\interaction_block.py:159:9: PLR0913 Too many arguments in function definition (18 > 5)
    |
157 |         self.inv_sqrt_3 = 1 / (3.0 ** 0.5)
158 | 
159 |     def forward(self,
    |         ^^^^^^^ PLR0913
160 |             h,
161 |             m,
    |

geom3d\models\GemNet\layers\interaction_block.py:165:13: N803 Argument name `Kidx4` should be lowercase
    |
163 |             cbf4,
164 |             sbf4,
165 |             Kidx4,
    |             ^^^^^ N803
166 |             rbf3,
167 |             cbf3,
    |

geom3d\models\GemNet\layers\interaction_block.py:168:13: N803 Argument name `Kidx3` should be lowercase
    |
166 |             rbf3,
167 |             cbf3,
168 |             Kidx3,
    |             ^^^^^ N803
169 |             id_swap,
170 |             id3_expand_ba,
    |

geom3d\models\GemNet\layers\interaction_block.py:178:9: D205 1 blank line required between summary line and description
    |
176 |               id_c,
177 |               id_a):
178 |           """Returns
    |  _________^
179 | |         -------
180 | |             h: Tensor, shape=(nEdges, emb_size_atom)
181 | |                 Atom embeddings.
182 | |             m: Tensor, shape=(nEdges, emb_size_edge)
183 | |                 Edge embeddings (c->a).
184 | | 
185 | |         """
    | |___________^ D205
186 |           # Initial transformation
187 |           x_ca_skip = self.dense_ca(m)  # (nEdges, emb_size_edge)
    |
    = help: Insert single blank line

geom3d\models\GemNet\layers\interaction_block.py:178:9: D401 First line of docstring should be in imperative mood: "Returns"
    |
176 |               id_c,
177 |               id_a):
178 |           """Returns
    |  _________^
179 | |         -------
180 | |             h: Tensor, shape=(nEdges, emb_size_atom)
181 | |                 Atom embeddings.
182 | |             m: Tensor, shape=(nEdges, emb_size_edge)
183 | |                 Edge embeddings (c->a).
184 | | 
185 | |         """
    | |___________^ D401
186 |           # Initial transformation
187 |           x_ca_skip = self.dense_ca(m)  # (nEdges, emb_size_edge)
    |

geom3d\models\GemNet\layers\interaction_block.py:270:9: PLR0913 Too many arguments in function definition (14 > 5)
    |
268 |     """
269 | 
270 |     def __init__(
    |         ^^^^^^^^ PLR0913
271 |         self,
272 |         emb_size_atom,
    |

geom3d\models\GemNet\layers\interaction_block.py:270:9: D107 Missing docstring in `__init__`
    |
268 |     """
269 | 
270 |     def __init__(
    |         ^^^^^^^^ D107
271 |         self,
272 |         emb_size_atom,
    |

geom3d\models\GemNet\layers\interaction_block.py:275:9: ARG002 Unused method argument: `emb_size_quad`
    |
273 |         emb_size_edge,
274 |         emb_size_trip,
275 |         emb_size_quad,
    |         ^^^^^^^^^^^^^ ARG002
276 |         emb_size_rbf,
277 |         emb_size_cbf,
    |

geom3d\models\GemNet\layers\interaction_block.py:286:9: ANN003 Missing type annotation for `**kwargs`
    |
284 |         scale_file=None,
285 |         name="Interaction",
286 |         **kwargs,
    |         ^^^^^^^^ ANN003
287 |     ):
288 |         super().__init__()
    |

geom3d\models\GemNet\layers\interaction_block.py:286:11: ARG002 Unused method argument: `kwargs`
    |
284 |         scale_file=None,
285 |         name="Interaction",
286 |         **kwargs,
    |           ^^^^^^ ARG002
287 |     ):
288 |         super().__init__()
    |

geom3d\models\GemNet\layers\interaction_block.py:364:9: PLR0913 Too many arguments in function definition (11 > 5)
    |
362 |         self.inv_sqrt_2 = 1 / (2.0 ** 0.5)
363 | 
364 |     def forward(self,
    |         ^^^^^^^ PLR0913
365 |             h,
366 |             m,
    |

geom3d\models\GemNet\layers\interaction_block.py:369:13: N803 Argument name `Kidx3` should be lowercase
    |
367 |             rbf3,
368 |             cbf3,
369 |             Kidx3,
    |             ^^^^^ N803
370 |             id_swap,
371 |             id3_expand_ba,
    |

geom3d\models\GemNet\layers\interaction_block.py:376:13: ANN003 Missing type annotation for `**kwargs`
    |
374 |             id_c,
375 |             id_a,
376 |             **kwargs):
    |             ^^^^^^^^ ANN003
377 |         """Returns
378 |         -------
    |

geom3d\models\GemNet\layers\interaction_block.py:376:15: ARG002 Unused method argument: `kwargs`
    |
374 |             id_c,
375 |             id_a,
376 |             **kwargs):
    |               ^^^^^^ ARG002
377 |         """Returns
378 |         -------
    |

geom3d\models\GemNet\layers\interaction_block.py:377:9: D205 1 blank line required between summary line and description
    |
375 |               id_a,
376 |               **kwargs):
377 |           """Returns
    |  _________^
378 | |         -------
379 | |             h: Tensor, shape=(nEdges, emb_size_atom)
380 | |                 Atom embeddings.
381 | |             m: Tensor, shape=(nEdges, emb_size_edge)
382 | |                 Edge embeddings (c->a).
383 | | 
384 | |         """
    | |___________^ D205
385 |           # Initial transformation
386 |           x_ca_skip = self.dense_ca(m)  # (nEdges, emb_size_edge)
    |
    = help: Insert single blank line

geom3d\models\GemNet\layers\interaction_block.py:377:9: D401 First line of docstring should be in imperative mood: "Returns"
    |
375 |               id_a,
376 |               **kwargs):
377 |           """Returns
    |  _________^
378 | |         -------
379 | |             h: Tensor, shape=(nEdges, emb_size_atom)
380 | |                 Atom embeddings.
381 | |             m: Tensor, shape=(nEdges, emb_size_edge)
382 | |                 Edge embeddings (c->a).
383 | | 
384 | |         """
    | |___________^ D401
385 |           # Initial transformation
386 |           x_ca_skip = self.dense_ca(m)  # (nEdges, emb_size_edge)
    |

geom3d\models\GemNet\layers\interaction_block.py:450:9: PLR0913 Too many arguments in function definition (9 > 5)
    |
448 |     """
449 | 
450 |     def __init__(
    |         ^^^^^^^^ PLR0913
451 |         self,
452 |         emb_size_edge,
    |

geom3d\models\GemNet\layers\interaction_block.py:450:9: D107 Missing docstring in `__init__`
    |
448 |     """
449 | 
450 |     def __init__(
    |         ^^^^^^^^ D107
451 |         self,
452 |         emb_size_edge,
    |

geom3d\models\GemNet\layers\interaction_block.py:461:9: ANN003 Missing type annotation for `**kwargs`
    |
459 |         scale_file=None,
460 |         name="QuadrupletInteraction",
461 |         **kwargs,
    |         ^^^^^^^^ ANN003
462 |     ):
463 |         super().__init__()
    |

geom3d\models\GemNet\layers\interaction_block.py:461:11: ARG002 Unused method argument: `kwargs`
    |
459 |         scale_file=None,
460 |         name="QuadrupletInteraction",
461 |         **kwargs,
    |           ^^^^^^ ARG002
462 |     ):
463 |         super().__init__()
    |

geom3d\models\GemNet\layers\interaction_block.py:518:9: PLR0913 Too many arguments in function definition (9 > 5)
    |
516 |         self.inv_sqrt_2 = 1 / (2.0 ** 0.5)
517 | 
518 |     def forward(self,
    |         ^^^^^^^ PLR0913
519 |             m,
520 |             rbf,
    |

geom3d\models\GemNet\layers\interaction_block.py:523:13: N803 Argument name `Kidx4` should be lowercase
    |
521 |             cbf,
522 |             sbf,
523 |             Kidx4,
    |             ^^^^^ N803
524 |             id_swap,
525 |             id4_reduce_ca,
    |

geom3d\models\GemNet\layers\interaction_block.py:528:9: D205 1 blank line required between summary line and description
    |
526 |               id4_expand_intm_db,
527 |               id4_expand_abd):
528 |           """Returns
    |  _________^
529 | |         -------
530 | |             m: Tensor, shape=(nEdges, emb_size_edge)
531 | |                 Edge embeddings (c->a).
532 | | 
533 | |         """
    | |___________^ D205
534 |           x_db = self.dense_db(m)  # (nEdges, emb_size_edge)
    |
    = help: Insert single blank line

geom3d\models\GemNet\layers\interaction_block.py:528:9: D401 First line of docstring should be in imperative mood: "Returns"
    |
526 |               id4_expand_intm_db,
527 |               id4_expand_abd):
528 |           """Returns
    |  _________^
529 | |         -------
530 | |             m: Tensor, shape=(nEdges, emb_size_edge)
531 | |                 Edge embeddings (c->a).
532 | | 
533 | |         """
    | |___________^ D401
534 |           x_db = self.dense_db(m)  # (nEdges, emb_size_edge)
    |

geom3d\models\GemNet\layers\interaction_block.py:554:9: ERA001 Found commented-out code
    |
553 |         # Basis representation:
554 |         # rbf(d_db)
    |         ^^^^^^^^^^^ ERA001
555 |         # cbf(d_ba, angle_abd)
556 |         # sbf(d_ca, angle_cab, angle_cabd)
    |
    = help: Remove commented-out code

geom3d\models\GemNet\layers\interaction_block.py:555:9: ERA001 Found commented-out code
    |
553 |         # Basis representation:
554 |         # rbf(d_db)
555 |         # cbf(d_ba, angle_abd)
    |         ^^^^^^^^^^^^^^^^^^^^^^ ERA001
556 |         # sbf(d_ca, angle_cab, angle_cabd)
    |
    = help: Remove commented-out code

geom3d\models\GemNet\layers\interaction_block.py:556:9: ERA001 Found commented-out code
    |
554 |         # rbf(d_db)
555 |         # cbf(d_ba, angle_abd)
556 |         # sbf(d_ca, angle_cab, angle_cabd)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
557 | 
558 |         # Upproject embeddings
    |
    = help: Remove commented-out code

geom3d\models\GemNet\layers\interaction_block.py:591:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
589 |     """
590 | 
591 |     def __init__(
    |         ^^^^^^^^ PLR0913
592 |         self,
593 |         emb_size_edge,
    |

geom3d\models\GemNet\layers\interaction_block.py:591:9: D107 Missing docstring in `__init__`
    |
589 |     """
590 | 
591 |     def __init__(
    |         ^^^^^^^^ D107
592 |         self,
593 |         emb_size_edge,
    |

geom3d\models\GemNet\layers\interaction_block.py:601:9: ANN003 Missing type annotation for `**kwargs`
    |
599 |         scale_file=None,
600 |         name="TripletInteraction",
601 |         **kwargs,
    |         ^^^^^^^^ ANN003
602 |     ):
603 |         super().__init__()
    |

geom3d\models\GemNet\layers\interaction_block.py:601:11: ARG002 Unused method argument: `kwargs`
    |
599 |         scale_file=None,
600 |         name="TripletInteraction",
601 |         **kwargs,
    |           ^^^^^^ ARG002
602 |     ):
603 |         super().__init__()
    |

geom3d\models\GemNet\layers\interaction_block.py:653:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
651 |         self.inv_sqrt_2 = 1 / (2.0) ** 0.5
652 | 
653 |     def forward(self,
    |         ^^^^^^^ PLR0913
654 |             m,
655 |             rbf3,
    |

geom3d\models\GemNet\layers\interaction_block.py:657:13: N803 Argument name `Kidx3` should be lowercase
    |
655 |             rbf3,
656 |             cbf3,
657 |             Kidx3,
    |             ^^^^^ N803
658 |             id_swap,
659 |             id3_expand_ba,
    |

geom3d\models\GemNet\layers\interaction_block.py:661:9: D205 1 blank line required between summary line and description
    |
659 |               id3_expand_ba,
660 |               id3_reduce_ca):
661 |           """Returns
    |  _________^
662 | |         -------
663 | |             m: Tensor, shape=(nEdges, emb_size_edge)
664 | |                 Edge embeddings (c->a).
665 | | 
666 | |         """
    | |___________^ D205
667 |           # Dense transformation
668 |           x_ba = self.dense_ba(m)  # (nEdges, emb_size_edge)
    |
    = help: Insert single blank line

geom3d\models\GemNet\layers\interaction_block.py:661:9: D401 First line of docstring should be in imperative mood: "Returns"
    |
659 |               id3_expand_ba,
660 |               id3_reduce_ca):
661 |           """Returns
    |  _________^
662 | |         -------
663 | |             m: Tensor, shape=(nEdges, emb_size_edge)
664 | |                 Edge embeddings (c->a).
665 | | 
666 | |         """
    | |___________^ D401
667 |           # Dense transformation
668 |           x_ba = self.dense_ba(m)  # (nEdges, emb_size_edge)
    |

geom3d\models\GemNet\layers\interaction_block.py:685:9: ERA001 Found commented-out code
    |
684 |         # Basis representation:
685 |         # rbf(d_ba)
    |         ^^^^^^^^^^^ ERA001
686 |         # cbf(d_ca, angle_cab)
    |
    = help: Remove commented-out code

geom3d\models\GemNet\layers\interaction_block.py:686:9: ERA001 Found commented-out code
    |
684 |         # Basis representation:
685 |         # rbf(d_ba)
686 |         # cbf(d_ca, angle_cab)
    |         ^^^^^^^^^^^^^^^^^^^^^^ ERA001
687 | 
688 |         # Up project embeddings
    |
    = help: Remove commented-out code

geom3d\models\GemNet\layers\scaling.py:1:1: INP001 File `geom3d\models\GemNet\layers\scaling.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\models\GemNet\layers\scaling.py:1:1: D100 Missing docstring in public module
geom3d\models\GemNet\layers\scaling.py:6:1: TID252 Prefer absolute imports over relative imports from parent modules
  |
4 | import torch
5 | 
6 | from ..utils import read_value_json, update_json
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ TID252
  |
  = help: Replace relative imports from parent modules with absolute imports

geom3d\models\GemNet\layers\scaling.py:6:1: TID252 Prefer absolute imports over relative imports from parent modules
  |
4 | import torch
5 | 
6 | from ..utils import read_value_json, update_json
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ TID252
  |
  = help: Replace relative imports from parent modules with absolute imports

geom3d\models\GemNet\layers\scaling.py:12:5: N815 Variable `activeVar` in class scope should not be mixedCase
   |
10 |     """All added variables are processed in the order of creation."""
11 | 
12 |     activeVar = None
   |     ^^^^^^^^^ N815
13 |     queue = None
14 |     fitting_mode = False
   |

geom3d\models\GemNet\layers\scaling.py:16:9: D107 Missing docstring in `__init__`
   |
14 |     fitting_mode = False
15 | 
16 |     def __init__(self, variable, scale_file, name):
   |         ^^^^^^^^ D107
17 |         self.variable = variable  # variable to find value for
18 |         self.scale_file = scale_file
   |

geom3d\models\GemNet\layers\scaling.py:35:9: D102 Missing docstring in public method
   |
33 |                 self._add2queue()
34 | 
35 |     def reset():
   |         ^^^^^ D102
36 |         AutomaticFit.activeVar = None
37 |         AutomaticFit.all_processed = False
   |

geom3d\models\GemNet\layers\scaling.py:39:9: D102 Missing docstring in public method
   |
37 |         AutomaticFit.all_processed = False
38 | 
39 |     def fitting_completed():
   |         ^^^^^^^^^^^^^^^^^ D102
40 |         return AutomaticFit.queue is None
   |

geom3d\models\GemNet\layers\scaling.py:42:9: D102 Missing docstring in public method
   |
40 |         return AutomaticFit.queue is None
41 | 
42 |     def set2fitmode():
   |         ^^^^^^^^^^^ D102
43 |         AutomaticFit.reset()
44 |         AutomaticFit.fitting_mode = True
   |

geom3d\models\GemNet\layers\scaling.py:47:23: G004 Logging statement uses f-string
   |
46 |     def _add2queue(self) -> None:
47 |         logging.debug(f"Add {self._name} to queue.")
   |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
48 |         # check that same variable is not added twice
49 |         for var in AutomaticFit.queue:
   |

geom3d\models\GemNet\layers\scaling.py:50:30: SLF001 Private member accessed: `_name`
   |
48 |         # check that same variable is not added twice
49 |         for var in AutomaticFit.queue:
50 |             if self._name == var._name:
   |                              ^^^^^^^^^ SLF001
51 |                 msg = f"Variable with the same name ({self._name}) was already added to queue!"
52 |                 raise ValueError(
   |

geom3d\models\GemNet\layers\scaling.py:72:17: G004 Logging statement uses f-string
   |
70 |         if value is None:
71 |             logging.info(
72 |                 f"Initialize variable {self._name}' to {self.variable.numpy():.3f}"
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
73 |             )
74 |         else:
   |

geom3d\models\GemNet\layers\scaling.py:76:27: G004 Logging statement uses f-string
   |
74 |         else:
75 |             self._fitted = True
76 |             logging.debug(f"Set scale factor {self._name} : {value}")
   |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
77 |             with torch.no_grad():
78 |                 self.variable.copy_(torch.tensor(value))
   |

geom3d\models\GemNet\layers\scaling.py:93:9: D107 Missing docstring in `__init__`
   |
91 |     """
92 | 
93 |     def __init__(self, variable, scale_file, name):
   |         ^^^^^^^^ D107
94 |         super().__init__(variable, scale_file, name)
   |

geom3d\models\GemNet\layers\scaling.py:105:9: D205 1 blank line required between summary line and description
    |
104 |       def observe(self, x, y):
105 |           """Observe variances for inut x and output y.
    |  _________^
106 | |         The scaling factor alpha is calculated s.t. Var(alpha * y) ~ Var(x).
107 | |         """
    | |___________^ D205
108 |           if self._fitted:
109 |               return
    |
    = help: Insert single blank line

geom3d\models\GemNet\layers\scaling.py:113:13: N806 Variable `nSamples` in function should be lowercase
    |
111 |         # only track stats for current variable
112 |         if AutomaticFit.activeVar == self:
113 |             nSamples = y.shape[0]
    |             ^^^^^^^^ N806
114 |             self.variance_in += torch.mean(torch.var(x, dim=0)) * nSamples
115 |             self.variance_out += torch.mean(torch.var(y, dim=0)) * nSamples
    |

geom3d\models\GemNet\layers\scaling.py:134:17: ISC003 Explicitly concatenated string should be implicitly concatenated
    |
132 |               value = np.sqrt(1 / ratio, dtype="float32")
133 |               logging.info(
134 |                   f"Variable: {self._name}, Var_in: {self.variance_in.numpy():.3f}, Var_out: {self.variance_out.numpy():.3f}, "
    |  _________________^
135 | |                 + f"Ratio: {ratio:.3f} => Scaling factor: {value:.3f}"
    | |______________________________________________________________________^ ISC003
136 |               )
    |

geom3d\models\GemNet\layers\scaling.py:134:17: G003 Logging statement uses `+`
    |
132 |               value = np.sqrt(1 / ratio, dtype="float32")
133 |               logging.info(
134 |                   f"Variable: {self._name}, Var_in: {self.variance_in.numpy():.3f}, Var_out: {self.variance_out.numpy():.3f}, "
    |  _________________^
135 | |                 + f"Ratio: {ratio:.3f} => Scaling factor: {value:.3f}"
    | |______________________________________________________________________^ G003
136 |               )
    |

geom3d\models\GemNet\layers\scaling.py:157:9: D107 Missing docstring in `__init__`
    |
155 |     """
156 | 
157 |     def __init__(self, scale_file, name, device=None):
    |         ^^^^^^^^ D107
158 |         super().__init__()
    |

geom3d\models\GemNet\layers\scaling.py:165:9: D102 Missing docstring in public method
    |
163 |         self.autofit = AutoScaleFit(self.scale_factor, scale_file, name)
164 | 
165 |     def forward(self, x_ref, y):
    |         ^^^^^^^ D102
166 |         y = y * self.scale_factor
167 |         self.autofit.observe(x_ref, y)
    |

geom3d\models\GemNet\utils.py:1:1: D100 Missing docstring in public module
geom3d\models\GemNet\utils.py:7:5: ERA001 Found commented-out code
  |
5 |     # """ """
6 |     # if not path.endswith(".json"):
7 |     #     raise UserWarning(f"Path {path} is not a json-path.")
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
8 | 
9 |     # with open(path, "r") as f:
  |
  = help: Remove commented-out code

geom3d\models\GemNet\utils.py:10:5: ERA001 Found commented-out code
   |
 9 |     # with open(path, "r") as f:
10 |     #    content = json.load(f)
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
11 |     # return content
12 |     """ """
   |
   = help: Remove commented-out code

geom3d\models\GemNet\utils.py:11:5: ERA001 Found commented-out code
   |
 9 |     # with open(path, "r") as f:
10 |     #    content = json.load(f)
11 |     # return content
   |     ^^^^^^^^^^^^^^^^ ERA001
12 |     """ """
13 |     if path is None:
   |
   = help: Remove commented-out code

geom3d\models\GemNet\utils.py:12:5: D419 Docstring is empty
   |
10 |     #    content = json.load(f)
11 |     # return content
12 |     """ """
   |     ^^^^^^^ D419
13 |     if path is None:
14 |         return None  # or raise an error, depending on your requirements
   |

geom3d\models\GemNet\utils.py:19:14: PTH123 `open()` should be replaced by `Path.open()`
   |
17 |         raise UserWarning(msg)
18 |     try:
19 |         with open(path) as f:
   |              ^^^^ PTH123
20 |             return json.load(f)
21 |     except FileNotFoundError:
   |

geom3d\models\GemNet\utils.py:27:5: D419 Docstring is empty
   |
26 | def update_json(path, data):
27 |     """ """
   |     ^^^^^^^ D419
28 |     if not path.endswith(".json"):
29 |         msg = f"Path {path} is not a json-path."
   |

geom3d\models\GemNet\utils.py:38:5: D419 Docstring is empty
   |
37 | def write_json(path, data):
38 |     """ """
   |     ^^^^^^^ D419
39 |     if not path.endswith(".json"):
40 |         msg = f"Path {path} is not a json-path."
   |

geom3d\models\GemNet\utils.py:43:10: PTH123 `open()` should be replaced by `Path.open()`
   |
41 |         raise UserWarning(msg)
42 | 
43 |     with open(path, "w", encoding="utf-8") as f:
   |          ^^^^ PTH123
44 |         json.dump(data, f, ensure_ascii=False, indent=4)
   |

geom3d\models\GemNet\utils.py:48:5: D419 Docstring is empty
   |
47 | def read_value_json(path, key):
48 |     """ """
   |     ^^^^^^^ D419
49 |     content = read_json(path)
   |

geom3d\models\GemNet\utils.py:52:5: ERA001 Found commented-out code
   |
51 |     # if key in content.keys():
52 |     #     return content[key]
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
53 |     # else:
54 |     #     return None
   |
   = help: Remove commented-out code

geom3d\models\GemNet\utils.py:53:5: ERA001 Found commented-out code
   |
51 |     # if key in content.keys():
52 |     #     return content[key]
53 |     # else:
   |     ^^^^^^^ ERA001
54 |     #     return None
55 |     if content is not None:
   |
   = help: Remove commented-out code

geom3d\models\GemNet\utils.py:54:5: ERA001 Found commented-out code
   |
52 |     #     return content[key]
53 |     # else:
54 |     #     return None
   |     ^^^^^^^^^^^^^^^^^ ERA001
55 |     if content is not None:
56 |         if key in content:
   |
   = help: Remove commented-out code

geom3d\models\GemNet\utils.py:58:9: RET505 Unnecessary `else` after `return` statement
   |
56 |         if key in content:
57 |             return content[key]
58 |         else:
   |         ^^^^ RET505
59 |             return None
60 |     else:
   |
   = help: Remove unnecessary `else`

geom3d\models\GeoSSL_DDM.py:1:1: N999 Invalid module name: 'GeoSSL_DDM'
geom3d\models\GeoSSL_DDM.py:1:1: D100 Missing docstring in public module
geom3d\models\GeoSSL_DDM.py:3:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | import numpy as np
2 | import torch
3 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
4 | from torch import nn
5 | from torch_scatter import scatter_add
  |

geom3d\models\GeoSSL_DDM.py:8:7: D101 Missing docstring in public class
   |
 8 | class MultiLayerPerceptron(nn.Module):
   |       ^^^^^^^^^^^^^^^^^^^^ D101
 9 |     def __init__(self, input_dim, hidden_dims, activation="relu", dropout=0):
10 |         super().__init__()
   |

geom3d\models\GeoSSL_DDM.py:9:9: D107 Missing docstring in `__init__`
   |
 8 | class MultiLayerPerceptron(nn.Module):
 9 |     def __init__(self, input_dim, hidden_dims, activation="relu", dropout=0):
   |         ^^^^^^^^ D107
10 |         super().__init__()
   |

geom3d\models\GeoSSL_DDM.py:28:9: D102 Missing docstring in public method
   |
26 |         self.reset_parameters()
27 | 
28 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
29 |         for _i, layer in enumerate(self.layers):
30 |             nn.init.xavier_uniform_(layer.weight)
   |

geom3d\models\GeoSSL_DDM.py:33:9: D102 Missing docstring in public method
   |
31 |             nn.init.constant_(layer.bias, 0.)
32 | 
33 |     def forward(self, input):
   |         ^^^^^^^ D102
34 |         x = input
35 |         for i, layer in enumerate(self.layers):
   |

geom3d\models\GeoSSL_DDM.py:33:23: A002 Argument `input` is shadowing a Python builtin
   |
31 |             nn.init.constant_(layer.bias, 0.)
32 | 
33 |     def forward(self, input):
   |                       ^^^^^ A002
34 |         x = input
35 |         for i, layer in enumerate(self.layers):
   |

geom3d\models\GeoSSL_DDM.py:45:7: N801 Class name `GeoSSL_DDM` should use CapWords convention
   |
45 | class GeoSSL_DDM(torch.nn.Module):
   |       ^^^^^^^^^^ N801
46 |     def __init__(self, emb_dim, sigma_begin, sigma_end, num_noise_level, noise_type, anneal_power):
47 |         super().__init__()
   |

geom3d\models\GeoSSL_DDM.py:45:7: D101 Missing docstring in public class
   |
45 | class GeoSSL_DDM(torch.nn.Module):
   |       ^^^^^^^^^^ D101
46 |     def __init__(self, emb_dim, sigma_begin, sigma_end, num_noise_level, noise_type, anneal_power):
47 |         super().__init__()
   |

geom3d\models\GeoSSL_DDM.py:46:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
45 | class GeoSSL_DDM(torch.nn.Module):
46 |     def __init__(self, emb_dim, sigma_begin, sigma_end, num_noise_level, noise_type, anneal_power):
   |         ^^^^^^^^ PLR0913
47 |         super().__init__()
   |

geom3d\models\GeoSSL_DDM.py:46:9: D107 Missing docstring in `__init__`
   |
45 | class GeoSSL_DDM(torch.nn.Module):
46 |     def __init__(self, emb_dim, sigma_begin, sigma_end, num_noise_level, noise_type, anneal_power):
   |         ^^^^^^^^ D107
47 |         super().__init__()
   |

geom3d\models\GeoSSL_DDM.py:59:9: D102 Missing docstring in public method
   |
59 |     def forward(self, data, node_feature, distance):
   |         ^^^^^^^ D102
60 |         self.device = self.sigmas.device
   |

geom3d\models\GeoSSL_PDM.py:1:1: N999 Invalid module name: 'GeoSSL_PDM'
geom3d\models\GeoSSL_PDM.py:1:1: D205 1 blank line required between summary line and description
  |
1 | / """credit to https://github.com/jiaor17/3D-EMGP/blob/main/mgp/models/denoise_prednoise.py
2 | | We modify the pipeline to better fit the NCSN pipeline.
3 | | """
  | |___^ D205
4 |   
5 |   import numpy as np
  |
  = help: Insert single blank line

geom3d\models\GeoSSL_PDM.py:18:7: N801 Class name `GeoSSL_PDM` should use CapWords convention
   |
18 | class GeoSSL_PDM(torch.nn.Module):
   |       ^^^^^^^^^^ N801
19 |     def __init__(self, emb_dim, sigma_begin, sigma_end, num_noise_level, noise_type, anneal_power):
20 |         super().__init__()
   |

geom3d\models\GeoSSL_PDM.py:18:7: D101 Missing docstring in public class
   |
18 | class GeoSSL_PDM(torch.nn.Module):
   |       ^^^^^^^^^^ D101
19 |     def __init__(self, emb_dim, sigma_begin, sigma_end, num_noise_level, noise_type, anneal_power):
20 |         super().__init__()
   |

geom3d\models\GeoSSL_PDM.py:19:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
18 | class GeoSSL_PDM(torch.nn.Module):
19 |     def __init__(self, emb_dim, sigma_begin, sigma_end, num_noise_level, noise_type, anneal_power):
   |         ^^^^^^^^ PLR0913
20 |         super().__init__()
21 |         self.emb_dim = emb_dim
   |

geom3d\models\GeoSSL_PDM.py:19:9: D107 Missing docstring in `__init__`
   |
18 | class GeoSSL_PDM(torch.nn.Module):
19 |     def __init__(self, emb_dim, sigma_begin, sigma_end, num_noise_level, noise_type, anneal_power):
   |         ^^^^^^^^ D107
20 |         super().__init__()
21 |         self.emb_dim = emb_dim
   |

geom3d\models\GeoSSL_PDM.py:35:9: ANN205 Missing return type annotation for staticmethod `get_score_target`
   |
33 |     @staticmethod
34 |     @torch.no_grad()
35 |     def get_score_target(pos_perturbed, pos_target, node2graph, noise_type):
   |         ^^^^^^^^^^^^^^^^ ANN205
36 |         # s = - (pos_perturbed @ (pos_perturbed.T @ pos_perturbed) - pos_target @ (pos_target.T @ pos_perturbed)) / (torch.norm(pos_perturbed.T @ pos_perturbed) + torch.norm(pos_target.T @ pos_perturbed))
37 |         if noise_type == "riemann":
   |
   = help: Add return type annotation

geom3d\models\GeoSSL_PDM.py:35:9: D102 Missing docstring in public method
   |
33 |     @staticmethod
34 |     @torch.no_grad()
35 |     def get_score_target(pos_perturbed, pos_target, node2graph, noise_type):
   |         ^^^^^^^^^^^^^^^^ D102
36 |         # s = - (pos_perturbed @ (pos_perturbed.T @ pos_perturbed) - pos_target @ (pos_target.T @ pos_perturbed)) / (torch.norm(pos_perturbed.T @ pos_perturbed) + torch.norm(pos_target.T @ pos_perturbed))
37 |         if noise_type == "riemann":
   |

geom3d\models\GeoSSL_PDM.py:36:9: ERA001 Found commented-out code
   |
34 |     @torch.no_grad()
35 |     def get_score_target(pos_perturbed, pos_target, node2graph, noise_type):
36 |         # s = - (pos_perturbed @ (pos_perturbed.T @ pos_perturbed) - pos_target @ (pos_target.T @ pos_perturbed)) / (torch.norm(pos_perturbed.T @ pos_perturbed) + torch.norm(pos_target.T @ pos_perturbed))
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
37 |         if noise_type == "riemann":
38 |             v = pos_target.shape[-1]
   |
   = help: Remove commented-out code

geom3d\models\GeoSSL_PDM.py:51:9: RET505 Unnecessary `else` after `return` statement
   |
49 |             otp = otp[node2graph]
50 |             return - 2 * (pos_perturbed_c.unsqueeze(1) @ ptp - pos_c.unsqueeze(1) @ otp).squeeze(1) / (torch.norm(ptp,dim=(1,2)) + torch.norm(otp,dim=(1,2))).unsqueeze(-1).repeat([1,3])
51 |         else:
   |         ^^^^ RET505
52 |             return pos_target - pos_perturbed
   |
   = help: Remove unnecessary `else`

geom3d\models\GeoSSL_PDM.py:54:9: PLR0913 Too many arguments in function definition (7 > 5)
   |
52 |             return pos_target - pos_perturbed
53 | 
54 |     def forward(self, data, energy, molecule_repr, pos_noise_pred, pos_perturbed, pos_target, debug=False):
   |         ^^^^^^^ PLR0913
55 |         self.device = self.sigmas.device
   |

geom3d\models\GeoSSL_PDM.py:54:9: D102 Missing docstring in public method
   |
52 |             return pos_target - pos_perturbed
53 | 
54 |     def forward(self, data, energy, molecule_repr, pos_noise_pred, pos_perturbed, pos_target, debug=False):
   |         ^^^^^^^ D102
55 |         self.device = self.sigmas.device
   |

geom3d\models\GeoSSL_PDM.py:54:29: ARG002 Unused method argument: `energy`
   |
52 |             return pos_target - pos_perturbed
53 | 
54 |     def forward(self, data, energy, molecule_repr, pos_noise_pred, pos_perturbed, pos_target, debug=False):
   |                             ^^^^^^ ARG002
55 |         self.device = self.sigmas.device
   |

geom3d\models\GeoSSL_PDM.py:54:95: FBT002 Boolean default positional argument in function definition
   |
52 |             return pos_target - pos_perturbed
53 | 
54 |     def forward(self, data, energy, molecule_repr, pos_noise_pred, pos_perturbed, pos_target, debug=False):
   |                                                                                               ^^^^^ FBT002
55 |         self.device = self.sigmas.device
   |

geom3d\models\GeoSSL_PDM.py:54:95: ARG002 Unused method argument: `debug`
   |
52 |             return pos_target - pos_perturbed
53 | 
54 |     def forward(self, data, energy, molecule_repr, pos_noise_pred, pos_perturbed, pos_target, debug=False):
   |                                                                                               ^^^^^ ARG002
55 |         self.device = self.sigmas.device
   |

geom3d\models\Graphormer\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\Graphormer\__init__.py:4:46: F401 `.graphormer.GraphormerEncoder` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
2 | # Licensed under the MIT License.
3 | 
4 | from .graphormer import GraphormerEncoder as Graphormer
  |                                              ^^^^^^^^^^ F401
5 | from .graphormer_graph_encoder import (
6 |     GraphormerGraphEncoder,
  |
  = help: Use an explicit re-export: `GraphormerEncoder as GraphormerEncoder`

geom3d\models\Graphormer\__init__.py:6:5: F401 `.graphormer_graph_encoder.GraphormerGraphEncoder` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
4 | from .graphormer import GraphormerEncoder as Graphormer
5 | from .graphormer_graph_encoder import (
6 |     GraphormerGraphEncoder,
  |     ^^^^^^^^^^^^^^^^^^^^^^ F401
7 |     init_graphormer_params,
8 | )
  |
  = help: Use an explicit re-export: `GraphormerGraphEncoder as GraphormerGraphEncoder`

geom3d\models\Graphormer\__init__.py:7:5: F401 `.graphormer_graph_encoder.init_graphormer_params` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
5 | from .graphormer_graph_encoder import (
6 |     GraphormerGraphEncoder,
7 |     init_graphormer_params,
  |     ^^^^^^^^^^^^^^^^^^^^^^ F401
8 | )
  |
  = help: Use an explicit re-export: `init_graphormer_params as init_graphormer_params`

geom3d\models\Graphormer\graphormer.py:1:1: D100 Missing docstring in public module
geom3d\models\Graphormer\graphormer.py:10:8: N812 Lowercase `functional` imported as non-lowercase `F`
   |
 9 | import torch
10 | import torch.nn.functional as F
   |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
11 | from torch import nn
   |

geom3d\models\Graphormer\graphormer.py:17:7: D101 Missing docstring in public class
   |
17 | class GraphormerEncoder(nn.Module):
   |       ^^^^^^^^^^^^^^^^^ D101
18 |     def __init__(self, args):
19 |         super().__init__()
   |

geom3d\models\Graphormer\graphormer.py:18:9: D107 Missing docstring in `__init__`
   |
17 | class GraphormerEncoder(nn.Module):
18 |     def __init__(self, args):
   |         ^^^^^^^^ D107
19 |         super().__init__()
20 |         self.max_nodes = args.max_nodes
   |

geom3d\models\Graphormer\graphormer.py:74:9: D102 Missing docstring in public method
   |
72 |                 raise NotImplementedError
73 | 
74 |     def reset_output_layer_parameters(self):
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
75 |         self.lm_output_learned_bias = nn.Parameter(torch.zeros(1))
76 |         if self.embed_out is not None:
   |

geom3d\models\Graphormer\graphormer.py:79:9: D102 Missing docstring in public method
   |
77 |             self.embed_out.reset_parameters()
78 | 
79 |     def forward(self, batched_data, perturb=None, masked_tokens=None, **unused):
   |         ^^^^^^^ D102
80 |         inner_states, graph_rep = self.graph_encoder(
81 |             batched_data,
   |

geom3d\models\Graphormer\graphormer.py:79:71: ANN003 Missing type annotation for `**unused`
   |
77 |             self.embed_out.reset_parameters()
78 | 
79 |     def forward(self, batched_data, perturb=None, masked_tokens=None, **unused):
   |                                                                       ^^^^^^^^ ANN003
80 |         inner_states, graph_rep = self.graph_encoder(
81 |             batched_data,
   |

geom3d\models\Graphormer\graphormer.py:79:73: ARG002 Unused method argument: `unused`
   |
77 |             self.embed_out.reset_parameters()
78 | 
79 |     def forward(self, batched_data, perturb=None, masked_tokens=None, **unused):
   |                                                                         ^^^^^^ ARG002
80 |         inner_states, graph_rep = self.graph_encoder(
81 |             batched_data,
   |

geom3d\models\Graphormer\graphormer.py:109:9: D102 Missing docstring in public method
    |
107 |         return self.max_nodes
108 | 
109 |     def upgrade_state_dict_named(self, state_dict, name):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^ D102
110 |         if not self.load_softmax:
111 |             for k in list(state_dict.keys()):
    |

geom3d\models\Graphormer\graphormer.py:109:52: ARG002 Unused method argument: `name`
    |
107 |         return self.max_nodes
108 | 
109 |     def upgrade_state_dict_named(self, state_dict, name):
    |                                                    ^^^^ ARG002
110 |         if not self.load_softmax:
111 |             for k in list(state_dict.keys()):
    |

geom3d\models\Graphormer\graphormer.py:118:5: D103 Missing docstring in public function
    |
117 | # only for reference
118 | def base_architecture(args):
    |     ^^^^^^^^^^^^^^^^^ D103
119 |     args.dropout = getattr(args, "dropout", 0.1)
120 |     args.attention_dropout = getattr(args, "attention_dropout", 0.1)
    |

geom3d\models\Graphormer\graphormer.py:139:5: D103 Missing docstring in public function
    |
138 | # only for reference
139 | def graphormer_base_architecture(args):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
140 |     if args.pretrained_model_name in ("pcqm4mv1_graphormer_base", "pcqm4mv2_graphormer_base", "pcqm4mv1_graphormer_base_for_molhiv"):
141 |         args.encoder_layers = 12
    |

geom3d\models\Graphormer\graphormer.py:168:5: D103 Missing docstring in public function
    |
167 | # only for reference
168 | def graphormer_slim_architecture(args):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
169 |     args.encoder_embed_dim = getattr(args, "encoder_embed_dim", 80)
    |

geom3d\models\Graphormer\graphormer.py:187:5: D103 Missing docstring in public function
    |
186 | # only for reference
187 | def graphormer_large_architecture(args):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
188 |     args.encoder_embed_dim = getattr(args, "encoder_embed_dim", 1024)
    |

geom3d\models\Graphormer\graphormer_graph_encoder.py:1:1: D100 Missing docstring in public module
geom3d\models\Graphormer\graphormer_graph_encoder.py:43:7: D101 Missing docstring in public class
   |
43 | class GraphormerGraphEncoder(nn.Module):
   |       ^^^^^^^^^^^^^^^^^^^^^^ D101
44 |     def __init__(
45 |         self,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:44:9: C901 `__init__` is too complex (11 > 10)
   |
43 | class GraphormerGraphEncoder(nn.Module):
44 |     def __init__(
   |         ^^^^^^^^ C901
45 |         self,
46 |         num_atoms: int,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:44:9: PLR0913 Too many arguments in function definition (27 > 5)
   |
43 | class GraphormerGraphEncoder(nn.Module):
44 |     def __init__(
   |         ^^^^^^^^ PLR0913
45 |         self,
46 |         num_atoms: int,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:44:9: D107 Missing docstring in `__init__`
   |
43 | class GraphormerGraphEncoder(nn.Module):
44 |     def __init__(
   |         ^^^^^^^^ D107
45 |         self,
46 |         num_atoms: int,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:62:9: FBT001 Boolean-typed positional argument in function definition
   |
60 |         activation_dropout: float = 0.1,
61 |         layerdrop: float = 0.0,
62 |         encoder_normalize_before: bool = False,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^ FBT001
63 |         pre_layernorm: bool = False,
64 |         apply_init: bool = False,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:62:9: FBT002 Boolean default positional argument in function definition
   |
60 |         activation_dropout: float = 0.1,
61 |         layerdrop: float = 0.0,
62 |         encoder_normalize_before: bool = False,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^ FBT002
63 |         pre_layernorm: bool = False,
64 |         apply_init: bool = False,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:63:9: FBT001 Boolean-typed positional argument in function definition
   |
61 |         layerdrop: float = 0.0,
62 |         encoder_normalize_before: bool = False,
63 |         pre_layernorm: bool = False,
   |         ^^^^^^^^^^^^^ FBT001
64 |         apply_init: bool = False,
65 |         activation_fn: str = "gelu",
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:63:9: FBT002 Boolean default positional argument in function definition
   |
61 |         layerdrop: float = 0.0,
62 |         encoder_normalize_before: bool = False,
63 |         pre_layernorm: bool = False,
   |         ^^^^^^^^^^^^^ FBT002
64 |         apply_init: bool = False,
65 |         activation_fn: str = "gelu",
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:64:9: FBT001 Boolean-typed positional argument in function definition
   |
62 |         encoder_normalize_before: bool = False,
63 |         pre_layernorm: bool = False,
64 |         apply_init: bool = False,
   |         ^^^^^^^^^^ FBT001
65 |         activation_fn: str = "gelu",
66 |         embed_scale: Optional[float] = None,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:64:9: FBT002 Boolean default positional argument in function definition
   |
62 |         encoder_normalize_before: bool = False,
63 |         pre_layernorm: bool = False,
64 |         apply_init: bool = False,
   |         ^^^^^^^^^^ FBT002
65 |         activation_fn: str = "gelu",
66 |         embed_scale: Optional[float] = None,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:66:22: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
64 |         apply_init: bool = False,
65 |         activation_fn: str = "gelu",
66 |         embed_scale: Optional[float] = None,
   |                      ^^^^^^^^ FA100
67 |         freeze_embeddings: bool = False,
68 |         n_trans_layers_to_freeze: int = 0,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:67:9: FBT001 Boolean-typed positional argument in function definition
   |
65 |         activation_fn: str = "gelu",
66 |         embed_scale: Optional[float] = None,
67 |         freeze_embeddings: bool = False,
   |         ^^^^^^^^^^^^^^^^^ FBT001
68 |         n_trans_layers_to_freeze: int = 0,
69 |         export: bool = False,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:67:9: FBT002 Boolean default positional argument in function definition
   |
65 |         activation_fn: str = "gelu",
66 |         embed_scale: Optional[float] = None,
67 |         freeze_embeddings: bool = False,
   |         ^^^^^^^^^^^^^^^^^ FBT002
68 |         n_trans_layers_to_freeze: int = 0,
69 |         export: bool = False,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:69:9: FBT001 Boolean-typed positional argument in function definition
   |
67 |         freeze_embeddings: bool = False,
68 |         n_trans_layers_to_freeze: int = 0,
69 |         export: bool = False,
   |         ^^^^^^ FBT001
70 |         traceable: bool = False,
71 |         q_noise: float = 0.0,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:69:9: FBT002 Boolean default positional argument in function definition
   |
67 |         freeze_embeddings: bool = False,
68 |         n_trans_layers_to_freeze: int = 0,
69 |         export: bool = False,
   |         ^^^^^^ FBT002
70 |         traceable: bool = False,
71 |         q_noise: float = 0.0,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:70:9: FBT001 Boolean-typed positional argument in function definition
   |
68 |         n_trans_layers_to_freeze: int = 0,
69 |         export: bool = False,
70 |         traceable: bool = False,
   |         ^^^^^^^^^ FBT001
71 |         q_noise: float = 0.0,
72 |         qn_block_size: int = 8,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:70:9: FBT002 Boolean default positional argument in function definition
   |
68 |         n_trans_layers_to_freeze: int = 0,
69 |         export: bool = False,
70 |         traceable: bool = False,
   |         ^^^^^^^^^ FBT002
71 |         q_noise: float = 0.0,
72 |         qn_block_size: int = 8,
   |

geom3d\models\Graphormer\graphormer_graph_encoder.py:163:9: PLR0913 Too many arguments in function definition (11 > 5)
    |
161 |             freeze_module_params(self.layers[layer])
162 | 
163 |     def build_graphormer_graph_encoder_layer(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
164 |         self,
165 |         embedding_dim,
    |

geom3d\models\Graphormer\graphormer_graph_encoder.py:163:9: D102 Missing docstring in public method
    |
161 |             freeze_module_params(self.layers[layer])
162 | 
163 |     def build_graphormer_graph_encoder_layer(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
164 |         self,
165 |         embedding_dim,
    |

geom3d\models\Graphormer\graphormer_graph_encoder.py:191:9: C901 `forward` is too complex (11 > 10)
    |
189 |         )
190 | 
191 |     def forward(
    |         ^^^^^^^ C901
192 |         self,
193 |         batched_data,
    |

geom3d\models\Graphormer\graphormer_graph_encoder.py:191:9: D102 Missing docstring in public method
    |
189 |         )
190 | 
191 |     def forward(
    |         ^^^^^^^ D102
192 |         self,
193 |         batched_data,
    |

geom3d\models\Graphormer\graphormer_graph_encoder.py:195:9: FBT001 Boolean-typed positional argument in function definition
    |
193 |         batched_data,
194 |         perturb=None,
195 |         last_state_only: bool = False,
    |         ^^^^^^^^^^^^^^^ FBT001
196 |         token_embeddings: Optional[torch.Tensor] = None,
197 |         attn_mask: Optional[torch.Tensor] = None,
    |

geom3d\models\Graphormer\graphormer_graph_encoder.py:195:9: FBT002 Boolean default positional argument in function definition
    |
193 |         batched_data,
194 |         perturb=None,
195 |         last_state_only: bool = False,
    |         ^^^^^^^^^^^^^^^ FBT002
196 |         token_embeddings: Optional[torch.Tensor] = None,
197 |         attn_mask: Optional[torch.Tensor] = None,
    |

geom3d\models\Graphormer\graphormer_graph_encoder.py:196:27: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
194 |         perturb=None,
195 |         last_state_only: bool = False,
196 |         token_embeddings: Optional[torch.Tensor] = None,
    |                           ^^^^^^^^ FA100
197 |         attn_mask: Optional[torch.Tensor] = None,
198 |     ) -> Tuple[torch.Tensor, torch.Tensor]:
    |

geom3d\models\Graphormer\graphormer_graph_encoder.py:197:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
195 |         last_state_only: bool = False,
196 |         token_embeddings: Optional[torch.Tensor] = None,
197 |         attn_mask: Optional[torch.Tensor] = None,
    |                    ^^^^^^^^ FA100
198 |     ) -> Tuple[torch.Tensor, torch.Tensor]:
199 |         # compute padding mask. This is needed for multi-head attention
    |

geom3d\models\Graphormer\graphormer_graph_encoder.py:198:10: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
    |
196 |         token_embeddings: Optional[torch.Tensor] = None,
197 |         attn_mask: Optional[torch.Tensor] = None,
198 |     ) -> Tuple[torch.Tensor, torch.Tensor]:
    |          ^^^^^ FA100
199 |         # compute padding mask. This is needed for multi-head attention
200 |         data_x = batched_data["x"]
    |

geom3d\models\Graphormer\graphormer_graph_encoder.py:215:13: ERA001 Found commented-out code
    |
214 |         if perturb is not None:
215 |             #ic(torch.mean(torch.abs(x[:, 1, :])))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
216 |             #ic(torch.mean(torch.abs(perturb)))
217 |             x[:, 1:, :] += perturb
    |
    = help: Remove commented-out code

geom3d\models\Graphormer\graphormer_graph_encoder.py:216:13: ERA001 Found commented-out code
    |
214 |         if perturb is not None:
215 |             #ic(torch.mean(torch.abs(x[:, 1, :])))
216 |             #ic(torch.mean(torch.abs(perturb)))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
217 |             x[:, 1:, :] += perturb
    |
    = help: Remove commented-out code

geom3d\models\Graphormer\graphormer_graph_encoder.py:260:9: RET505 Unnecessary `else` after `return` statement
    |
258 |         if self.traceable:
259 |             return torch.stack(inner_states), graph_rep
260 |         else:
    |         ^^^^ RET505
261 |             return inner_states, graph_rep
    |
    = help: Remove unnecessary `else`

geom3d\models\Graphormer\layers\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\Graphormer\layers\__init__.py:4:45: F401 `.graphormer_graph_encoder_layer.GraphormerGraphEncoderLayer` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
2 | # Licensed under the MIT License.
3 | 
4 | from .graphormer_graph_encoder_layer import GraphormerGraphEncoderLayer
  |                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
5 | from .graphormer_layers import GraphAttnBias, GraphNodeFeature
6 | from .multihead_attention import MultiheadAttention
  |
  = help: Use an explicit re-export: `GraphormerGraphEncoderLayer as GraphormerGraphEncoderLayer`

geom3d\models\Graphormer\layers\__init__.py:5:32: F401 `.graphormer_layers.GraphAttnBias` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
4 | from .graphormer_graph_encoder_layer import GraphormerGraphEncoderLayer
5 | from .graphormer_layers import GraphAttnBias, GraphNodeFeature
  |                                ^^^^^^^^^^^^^ F401
6 | from .multihead_attention import MultiheadAttention
  |
  = help: Use an explicit re-export: `GraphAttnBias as GraphAttnBias`

geom3d\models\Graphormer\layers\__init__.py:5:47: F401 `.graphormer_layers.GraphNodeFeature` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
4 | from .graphormer_graph_encoder_layer import GraphormerGraphEncoderLayer
5 | from .graphormer_layers import GraphAttnBias, GraphNodeFeature
  |                                               ^^^^^^^^^^^^^^^^ F401
6 | from .multihead_attention import MultiheadAttention
  |
  = help: Use an explicit re-export: `GraphNodeFeature as GraphNodeFeature`

geom3d\models\Graphormer\layers\__init__.py:6:34: F401 `.multihead_attention.MultiheadAttention` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
4 | from .graphormer_graph_encoder_layer import GraphormerGraphEncoderLayer
5 | from .graphormer_layers import GraphAttnBias, GraphNodeFeature
6 | from .multihead_attention import MultiheadAttention
  |                                  ^^^^^^^^^^^^^^^^^^ F401
  |
  = help: Use an explicit re-export: `MultiheadAttention as MultiheadAttention`

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:1:1: D100 Missing docstring in public module
geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:23:7: D101 Missing docstring in public class
   |
23 | class GraphormerGraphEncoderLayer(nn.Module):
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^ D101
24 |     def __init__(
25 |         self,
   |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:24:9: PLR0913 Too many arguments in function definition (12 > 5)
   |
23 | class GraphormerGraphEncoderLayer(nn.Module):
24 |     def __init__(
   |         ^^^^^^^^ PLR0913
25 |         self,
26 |         embedding_dim: int = 768,
   |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:24:9: D107 Missing docstring in `__init__`
   |
23 | class GraphormerGraphEncoderLayer(nn.Module):
24 |     def __init__(
   |         ^^^^^^^^ D107
25 |         self,
26 |         embedding_dim: int = 768,
   |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:33:9: FBT001 Boolean-typed positional argument in function definition
   |
31 |         activation_dropout: float = 0.1,
32 |         activation_fn: str = "relu",
33 |         export: bool = False,
   |         ^^^^^^ FBT001
34 |         q_noise: float = 0.0,
35 |         qn_block_size: int = 8,
   |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:33:9: FBT002 Boolean default positional argument in function definition
   |
31 |         activation_dropout: float = 0.1,
32 |         activation_fn: str = "relu",
33 |         export: bool = False,
   |         ^^^^^^ FBT002
34 |         q_noise: float = 0.0,
35 |         qn_block_size: int = 8,
   |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:36:18: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
34 |         q_noise: float = 0.0,
35 |         qn_block_size: int = 8,
36 |         init_fn: Optional[Callable] = None,
   |                  ^^^^^^^^ FA100
37 |         pre_layernorm: bool = False,
38 |     ) -> None:
   |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:37:9: FBT001 Boolean-typed positional argument in function definition
   |
35 |         qn_block_size: int = 8,
36 |         init_fn: Optional[Callable] = None,
37 |         pre_layernorm: bool = False,
   |         ^^^^^^^^^^^^^ FBT001
38 |     ) -> None:
39 |         super().__init__()
   |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:37:9: FBT002 Boolean default positional argument in function definition
   |
35 |         qn_block_size: int = 8,
36 |         init_fn: Optional[Callable] = None,
37 |         pre_layernorm: bool = False,
   |         ^^^^^^^^^^^^^ FBT002
38 |     ) -> None:
39 |         super().__init__()
   |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:89:9: D102 Missing docstring in public method
   |
87 |         self.final_layer_norm = LayerNorm(self.embedding_dim, export=export)
88 | 
89 |     def build_fc1(self, input_dim, output_dim, q_noise, qn_block_size):
   |         ^^^^^^^^^ D102
90 |         return quant_noise(nn.Linear(input_dim, output_dim), q_noise, qn_block_size)
   |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:92:9: D102 Missing docstring in public method
   |
90 |         return quant_noise(nn.Linear(input_dim, output_dim), q_noise, qn_block_size)
91 | 
92 |     def build_fc2(self, input_dim, output_dim, q_noise, qn_block_size):
   |         ^^^^^^^^^ D102
93 |         return quant_noise(nn.Linear(input_dim, output_dim), q_noise, qn_block_size)
   |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:95:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
93 |         return quant_noise(nn.Linear(input_dim, output_dim), q_noise, qn_block_size)
94 | 
95 |     def build_self_attention(
   |         ^^^^^^^^^^^^^^^^^^^^ PLR0913
96 |         self,
97 |         embed_dim,
   |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:95:9: D102 Missing docstring in public method
   |
93 |         return quant_noise(nn.Linear(input_dim, output_dim), q_noise, qn_block_size)
94 | 
95 |     def build_self_attention(
   |         ^^^^^^^^^^^^^^^^^^^^ D102
96 |         self,
97 |         embed_dim,
   |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:100:9: ARG002 Unused method argument: `self_attention`
    |
 98 |         num_attention_heads,
 99 |         dropout,
100 |         self_attention,
    |         ^^^^^^^^^^^^^^ ARG002
101 |         q_noise,
102 |         qn_block_size,
    |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:116:25: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
114 |         self,
115 |         x: torch.Tensor,
116 |         self_attn_bias: Optional[torch.Tensor] = None,
    |                         ^^^^^^^^ FA100
117 |         self_attn_mask: Optional[torch.Tensor] = None,
118 |         self_attn_padding_mask: Optional[torch.Tensor] = None,
    |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:117:25: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
115 |         x: torch.Tensor,
116 |         self_attn_bias: Optional[torch.Tensor] = None,
117 |         self_attn_mask: Optional[torch.Tensor] = None,
    |                         ^^^^^^^^ FA100
118 |         self_attn_padding_mask: Optional[torch.Tensor] = None,
119 |     ):
    |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:118:33: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
116 |         self_attn_bias: Optional[torch.Tensor] = None,
117 |         self_attn_mask: Optional[torch.Tensor] = None,
118 |         self_attn_padding_mask: Optional[torch.Tensor] = None,
    |                                 ^^^^^^^^ FA100
119 |     ):
120 |         """LayerNorm is applied either before or after the self-attention/ffn
    |

geom3d\models\Graphormer\layers\graphormer_graph_encoder_layer.py:120:9: D205 1 blank line required between summary line and description
    |
118 |           self_attn_padding_mask: Optional[torch.Tensor] = None,
119 |       ):
120 |           """LayerNorm is applied either before or after the self-attention/ffn
    |  _________^
121 | |         modules similar to the original Transformer implementation.
122 | |         """
    | |___________^ D205
123 |           # x: T x B x C
124 |           residual = x
    |
    = help: Insert single blank line

geom3d\models\Graphormer\layers\graphormer_layers.py:1:1: D100 Missing docstring in public module
geom3d\models\Graphormer\layers\graphormer_layers.py:15:5: D103 Missing docstring in public function
   |
15 | def init_params(module, n_layers):
   |     ^^^^^^^^^^^ D103
16 |     if isinstance(module, nn.Linear):
17 |         module.weight.data.normal_(mean=0.0, std=0.02 / math.sqrt(n_layers))
   |

geom3d\models\Graphormer\layers\graphormer_layers.py:27:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
25 |     """Compute node features for each node in the graph."""
26 | 
27 |     def __init__(
   |         ^^^^^^^^ PLR0913
28 |         self, num_heads, num_atoms, num_in_degree, num_out_degree, hidden_dim, n_layers
29 |     ):
   |

geom3d\models\Graphormer\layers\graphormer_layers.py:27:9: D107 Missing docstring in `__init__`
   |
25 |     """Compute node features for each node in the graph."""
26 | 
27 |     def __init__(
   |         ^^^^^^^^ D107
28 |         self, num_heads, num_atoms, num_in_degree, num_out_degree, hidden_dim, n_layers
29 |     ):
   |

geom3d\models\Graphormer\layers\graphormer_layers.py:45:9: D102 Missing docstring in public method
   |
43 |         self.apply(lambda module: init_params(module, n_layers=n_layers))
44 | 
45 |     def forward(self, batched_data):
   |         ^^^^^^^ D102
46 |         x, in_degree, out_degree = (
47 |             batched_data["x"],
   |

geom3d\models\Graphormer\layers\graphormer_layers.py:57:9: ERA001 Found commented-out code
   |
56 |         # if self.flag and perturb is not None:
57 |         #     node_feature += perturb
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
58 | 
59 |         node_feature = (
   |
   = help: Remove commented-out code

geom3d\models\Graphormer\layers\graphormer_layers.py:74:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
72 |     """Compute attention bias for each head."""
73 | 
74 |     def __init__(
   |         ^^^^^^^^ PLR0913
75 |         self,
76 |         num_heads,
   |

geom3d\models\Graphormer\layers\graphormer_layers.py:74:9: D107 Missing docstring in `__init__`
   |
72 |     """Compute attention bias for each head."""
73 | 
74 |     def __init__(
   |         ^^^^^^^^ D107
75 |         self,
76 |         num_heads,
   |

geom3d\models\Graphormer\layers\graphormer_layers.py:77:9: ARG002 Unused method argument: `num_atoms`
   |
75 |         self,
76 |         num_heads,
77 |         num_atoms,
   |         ^^^^^^^^^ ARG002
78 |         num_edges,
79 |         num_spatial,
   |

geom3d\models\Graphormer\layers\graphormer_layers.py:81:9: ARG002 Unused method argument: `hidden_dim`
   |
79 |         num_spatial,
80 |         num_edge_dis,
81 |         hidden_dim,
   |         ^^^^^^^^^^ ARG002
82 |         edge_type,
83 |         multi_hop_max_dist,
   |

geom3d\models\Graphormer\layers\graphormer_layers.py:102:9: D102 Missing docstring in public method
    |
100 |         self.apply(lambda module: init_params(module, n_layers=n_layers))
101 | 
102 |     def forward(self, batched_data):
    |         ^^^^^^^ D102
103 |         attn_bias, spatial_pos, x = batched_data["attn_bias"], batched_data["spatial_pos"], batched_data["x"]
104 |         edge_input, attn_edge_type = batched_data["edge_input"], batched_data["attn_edge_type"]
    |

geom3d\models\Graphormer\layers\graphormer_layers.py:129:13: ERA001 Found commented-out code
    |
127 |                 spatial_pos_ = spatial_pos_.clamp(0, self.multi_hop_max_dist)
128 |                 edge_input = edge_input[:, :, :, :self.multi_hop_max_dist, :]
129 |             # [n_graph, n_node, n_node, max_dist, n_head]
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
130 |             edge_input = self.edge_encoder(edge_input).mean(-2)
131 |             max_dist = edge_input.size(-2)
    |
    = help: Remove commented-out code

geom3d\models\Graphormer\layers\multihead_attention.py:1:1: D100 Missing docstring in public module
geom3d\models\Graphormer\layers\multihead_attention.py:27:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
25 |     """
26 | 
27 |     def __init__(
   |         ^^^^^^^^ PLR0913
28 |         self,
29 |         embed_dim,
   |

geom3d\models\Graphormer\layers\multihead_attention.py:27:9: D107 Missing docstring in `__init__`
   |
25 |     """
26 | 
27 |     def __init__(
   |         ^^^^^^^^ D107
28 |         self,
29 |         embed_dim,
   |

geom3d\models\Graphormer\layers\multihead_attention.py:34:9: FBT002 Boolean default positional argument in function definition
   |
32 |         vdim=None,
33 |         dropout=0.0,
34 |         bias=True,
   |         ^^^^ FBT002
35 |         self_attention=False,
36 |         q_noise=0.0,
   |

geom3d\models\Graphormer\layers\multihead_attention.py:35:9: FBT002 Boolean default positional argument in function definition
   |
33 |         dropout=0.0,
34 |         bias=True,
35 |         self_attention=False,
   |         ^^^^^^^^^^^^^^ FBT002
36 |         q_noise=0.0,
37 |         qn_block_size=8,
   |

geom3d\models\Graphormer\layers\multihead_attention.py:51:9: S101 Use of `assert` detected
   |
50 |         self.head_dim = embed_dim // num_heads
51 |         assert (
   |         ^^^^^^ S101
52 |             self.head_dim * num_heads == self.embed_dim
53 |         ), "embed_dim must be divisible by num_heads"
   |

geom3d\models\Graphormer\layers\multihead_attention.py:58:9: S101 Use of `assert` detected
   |
56 |         self.self_attention = self_attention
57 | 
58 |         assert self.self_attention, "Only support self attention"
   |         ^^^^^^ S101
59 | 
60 |         assert not self.self_attention or self.qkv_same_dim, (
   |

geom3d\models\Graphormer\layers\multihead_attention.py:60:9: S101 Use of `assert` detected
   |
58 |         assert self.self_attention, "Only support self attention"
59 | 
60 |         assert not self.self_attention or self.qkv_same_dim, (
   |         ^^^^^^ S101
61 |             "Self-attention requires query, key and " "value to be of the same size"
62 |         )
   |

geom3d\models\Graphormer\layers\multihead_attention.py:82:9: D102 Missing docstring in public method
   |
80 |         self.onnx_trace = False
81 | 
82 |     def prepare_for_onnx_export_(self):
   |         ^^^^^^^^^^^^^^^^^^^^^^^^ D102
83 |         raise NotImplementedError
   |

geom3d\models\Graphormer\layers\multihead_attention.py:85:9: D102 Missing docstring in public method
   |
83 |         raise NotImplementedError
84 | 
85 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
86 |         if self.qkv_same_dim:
87 |             # Empirically observed the convergence to be much better with
   |

geom3d\models\Graphormer\layers\multihead_attention.py:101:9: C901 `forward` is too complex (14 > 10)
    |
 99 |             nn.init.constant_(self.out_proj.bias, 0.0)
100 | 
101 |     def forward(
    |         ^^^^^^^ C901
102 |         self,
103 |         query,
    |

geom3d\models\Graphormer\layers\multihead_attention.py:101:9: PLR0913 Too many arguments in function definition (9 > 5)
    |
 99 |             nn.init.constant_(self.out_proj.bias, 0.0)
100 | 
101 |     def forward(
    |         ^^^^^^^ PLR0913
102 |         self,
103 |         query,
    |

geom3d\models\Graphormer\layers\multihead_attention.py:101:9: PLR0912 Too many branches (13 > 12)
    |
 99 |             nn.init.constant_(self.out_proj.bias, 0.0)
100 | 
101 |     def forward(
    |         ^^^^^^^ PLR0912
102 |         self,
103 |         query,
    |

geom3d\models\Graphormer\layers\multihead_attention.py:101:9: PLR0915 Too many statements (55 > 50)
    |
 99 |             nn.init.constant_(self.out_proj.bias, 0.0)
100 | 
101 |     def forward(
    |         ^^^^^^^ PLR0915
102 |         self,
103 |         query,
    |

geom3d\models\Graphormer\layers\multihead_attention.py:101:9: D417 Missing argument descriptions in the docstring for `forward`: `attn_bias`, `key`, `query`, `value`
    |
 99 |             nn.init.constant_(self.out_proj.bias, 0.0)
100 | 
101 |     def forward(
    |         ^^^^^^^ D417
102 |         self,
103 |         query,
    |

geom3d\models\Graphormer\layers\multihead_attention.py:104:14: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
102 |         self,
103 |         query,
104 |         key: Optional[Tensor],
    |              ^^^^^^^^ FA100
105 |         value: Optional[Tensor],
106 |         attn_bias: Optional[Tensor],
    |

geom3d\models\Graphormer\layers\multihead_attention.py:105:16: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
103 |         query,
104 |         key: Optional[Tensor],
105 |         value: Optional[Tensor],
    |                ^^^^^^^^ FA100
106 |         attn_bias: Optional[Tensor],
107 |         key_padding_mask: Optional[Tensor] = None,
    |

geom3d\models\Graphormer\layers\multihead_attention.py:106:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
104 |         key: Optional[Tensor],
105 |         value: Optional[Tensor],
106 |         attn_bias: Optional[Tensor],
    |                    ^^^^^^^^ FA100
107 |         key_padding_mask: Optional[Tensor] = None,
108 |         need_weights: bool = True,
    |

geom3d\models\Graphormer\layers\multihead_attention.py:107:27: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
105 |         value: Optional[Tensor],
106 |         attn_bias: Optional[Tensor],
107 |         key_padding_mask: Optional[Tensor] = None,
    |                           ^^^^^^^^ FA100
108 |         need_weights: bool = True,
109 |         attn_mask: Optional[Tensor] = None,
    |

geom3d\models\Graphormer\layers\multihead_attention.py:108:9: FBT001 Boolean-typed positional argument in function definition
    |
106 |         attn_bias: Optional[Tensor],
107 |         key_padding_mask: Optional[Tensor] = None,
108 |         need_weights: bool = True,
    |         ^^^^^^^^^^^^ FBT001
109 |         attn_mask: Optional[Tensor] = None,
110 |         before_softmax: bool = False,
    |

geom3d\models\Graphormer\layers\multihead_attention.py:108:9: FBT002 Boolean default positional argument in function definition
    |
106 |         attn_bias: Optional[Tensor],
107 |         key_padding_mask: Optional[Tensor] = None,
108 |         need_weights: bool = True,
    |         ^^^^^^^^^^^^ FBT002
109 |         attn_mask: Optional[Tensor] = None,
110 |         before_softmax: bool = False,
    |

geom3d\models\Graphormer\layers\multihead_attention.py:109:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
107 |         key_padding_mask: Optional[Tensor] = None,
108 |         need_weights: bool = True,
109 |         attn_mask: Optional[Tensor] = None,
    |                    ^^^^^^^^ FA100
110 |         before_softmax: bool = False,
111 |         need_head_weights: bool = False,
    |

geom3d\models\Graphormer\layers\multihead_attention.py:110:9: FBT001 Boolean-typed positional argument in function definition
    |
108 |         need_weights: bool = True,
109 |         attn_mask: Optional[Tensor] = None,
110 |         before_softmax: bool = False,
    |         ^^^^^^^^^^^^^^ FBT001
111 |         need_head_weights: bool = False,
112 |     ) -> Tuple[Tensor, Optional[Tensor]]:
    |

geom3d\models\Graphormer\layers\multihead_attention.py:110:9: FBT002 Boolean default positional argument in function definition
    |
108 |         need_weights: bool = True,
109 |         attn_mask: Optional[Tensor] = None,
110 |         before_softmax: bool = False,
    |         ^^^^^^^^^^^^^^ FBT002
111 |         need_head_weights: bool = False,
112 |     ) -> Tuple[Tensor, Optional[Tensor]]:
    |

geom3d\models\Graphormer\layers\multihead_attention.py:111:9: FBT001 Boolean-typed positional argument in function definition
    |
109 |         attn_mask: Optional[Tensor] = None,
110 |         before_softmax: bool = False,
111 |         need_head_weights: bool = False,
    |         ^^^^^^^^^^^^^^^^^ FBT001
112 |     ) -> Tuple[Tensor, Optional[Tensor]]:
113 |         """Input shape: Time x Batch x Channel.
    |

geom3d\models\Graphormer\layers\multihead_attention.py:111:9: FBT002 Boolean default positional argument in function definition
    |
109 |         attn_mask: Optional[Tensor] = None,
110 |         before_softmax: bool = False,
111 |         need_head_weights: bool = False,
    |         ^^^^^^^^^^^^^^^^^ FBT002
112 |     ) -> Tuple[Tensor, Optional[Tensor]]:
113 |         """Input shape: Time x Batch x Channel.
    |

geom3d\models\Graphormer\layers\multihead_attention.py:112:10: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
    |
110 |         before_softmax: bool = False,
111 |         need_head_weights: bool = False,
112 |     ) -> Tuple[Tensor, Optional[Tensor]]:
    |          ^^^^^ FA100
113 |         """Input shape: Time x Batch x Channel.
    |

geom3d\models\Graphormer\layers\multihead_attention.py:112:24: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
110 |         before_softmax: bool = False,
111 |         need_head_weights: bool = False,
112 |     ) -> Tuple[Tensor, Optional[Tensor]]:
    |                        ^^^^^^^^ FA100
113 |         """Input shape: Time x Batch x Channel.
    |

geom3d\models\Graphormer\layers\multihead_attention.py:137:9: S101 Use of `assert` detected
    |
135 |         tgt_len, bsz, embed_dim = query.size()
136 |         src_len = tgt_len
137 |         assert embed_dim == self.embed_dim, f"query dim {embed_dim} != {self.embed_dim}"
    |         ^^^^^^ S101
138 |         assert list(query.size()) == [tgt_len, bsz, embed_dim]
139 |         if key is not None:
    |

geom3d\models\Graphormer\layers\multihead_attention.py:138:9: S101 Use of `assert` detected
    |
136 |         src_len = tgt_len
137 |         assert embed_dim == self.embed_dim, f"query dim {embed_dim} != {self.embed_dim}"
138 |         assert list(query.size()) == [tgt_len, bsz, embed_dim]
    |         ^^^^^^ S101
139 |         if key is not None:
140 |             src_len, key_bsz, _ = key.size()
    |

geom3d\models\Graphormer\layers\multihead_attention.py:142:17: S101 Use of `assert` detected
    |
140 |             src_len, key_bsz, _ = key.size()
141 |             if not torch.jit.is_scripting():
142 |                 assert key_bsz == bsz
    |                 ^^^^^^ S101
143 |                 assert value is not None
144 |                 assert src_len, bsz == value.shape[:2]
    |

geom3d\models\Graphormer\layers\multihead_attention.py:143:17: S101 Use of `assert` detected
    |
141 |             if not torch.jit.is_scripting():
142 |                 assert key_bsz == bsz
143 |                 assert value is not None
    |                 ^^^^^^ S101
144 |                 assert src_len, bsz == value.shape[:2]
    |

geom3d\models\Graphormer\layers\multihead_attention.py:144:17: S101 Use of `assert` detected
    |
142 |                 assert key_bsz == bsz
143 |                 assert value is not None
144 |                 assert src_len, bsz == value.shape[:2]
    |                 ^^^^^^ S101
145 | 
146 |         q = self.q_proj(query)
    |

geom3d\models\Graphormer\layers\multihead_attention.py:169:9: S101 Use of `assert` detected
    |
167 |             )
168 | 
169 |         assert k is not None
    |         ^^^^^^ S101
170 |         assert k.size(1) == src_len
    |

geom3d\models\Graphormer\layers\multihead_attention.py:170:9: S101 Use of `assert` detected
    |
169 |         assert k is not None
170 |         assert k.size(1) == src_len
    |         ^^^^^^ S101
171 | 
172 |         # This is part of a workaround to get around fork/join parallelism
    |

geom3d\models\Graphormer\layers\multihead_attention.py:178:13: S101 Use of `assert` detected
    |
177 |         if key_padding_mask is not None:
178 |             assert key_padding_mask.size(0) == bsz
    |             ^^^^^^ S101
179 |             assert key_padding_mask.size(1) == src_len
180 |         attn_weights = torch.bmm(q, k.transpose(1, 2))
    |

geom3d\models\Graphormer\layers\multihead_attention.py:179:13: S101 Use of `assert` detected
    |
177 |         if key_padding_mask is not None:
178 |             assert key_padding_mask.size(0) == bsz
179 |             assert key_padding_mask.size(1) == src_len
    |             ^^^^^^ S101
180 |         attn_weights = torch.bmm(q, k.transpose(1, 2))
181 |         attn_weights = self.apply_sparse_mask(attn_weights, tgt_len, src_len, bsz)
    |

geom3d\models\Graphormer\layers\multihead_attention.py:183:9: S101 Use of `assert` detected
    |
181 |         attn_weights = self.apply_sparse_mask(attn_weights, tgt_len, src_len, bsz)
182 | 
183 |         assert list(attn_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]
    |         ^^^^^^ S101
184 | 
185 |         if attn_bias is not None:
    |

geom3d\models\Graphormer\layers\multihead_attention.py:210:9: S101 Use of `assert` detected
    |
208 |         attn_probs = self.dropout_module(attn_weights)
209 | 
210 |         assert v is not None
    |         ^^^^^^ S101
211 |         attn = torch.bmm(attn_probs, v)
212 |         assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]
    |

geom3d\models\Graphormer\layers\multihead_attention.py:212:9: S101 Use of `assert` detected
    |
210 |         assert v is not None
211 |         attn = torch.bmm(attn_probs, v)
212 |         assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]
    |         ^^^^^^ S101
213 | 
214 |         attn = attn.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)
    |

geom3d\models\Graphormer\layers\multihead_attention.py:217:23: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
215 |         attn = self.out_proj(attn)
216 | 
217 |         attn_weights: Optional[Tensor] = None
    |                       ^^^^^^^^ FA100
218 |         if need_weights:
219 |             attn_weights = attn_weights_float.view(
    |

geom3d\models\Graphormer\layers\multihead_attention.py:228:9: D102 Missing docstring in public method
    |
226 |         return attn, attn_weights
227 | 
228 |     def apply_sparse_mask(self, attn_weights, tgt_len: int, src_len: int, bsz: int):
    |         ^^^^^^^^^^^^^^^^^ D102
229 |         return attn_weights
    |

geom3d\models\Graphormer\layers\multihead_attention.py:228:47: ARG002 Unused method argument: `tgt_len`
    |
226 |         return attn, attn_weights
227 | 
228 |     def apply_sparse_mask(self, attn_weights, tgt_len: int, src_len: int, bsz: int):
    |                                               ^^^^^^^ ARG002
229 |         return attn_weights
    |

geom3d\models\Graphormer\layers\multihead_attention.py:228:61: ARG002 Unused method argument: `src_len`
    |
226 |         return attn, attn_weights
227 | 
228 |     def apply_sparse_mask(self, attn_weights, tgt_len: int, src_len: int, bsz: int):
    |                                                             ^^^^^^^ ARG002
229 |         return attn_weights
    |

geom3d\models\Graphormer\layers\multihead_attention.py:228:75: ARG002 Unused method argument: `bsz`
    |
226 |         return attn, attn_weights
227 | 
228 |     def apply_sparse_mask(self, attn_weights, tgt_len: int, src_len: int, bsz: int):
    |                                                                           ^^^ ARG002
229 |         return attn_weights
    |

geom3d\models\Graphormer\layers\multihead_attention.py:231:9: D102 Missing docstring in public method
    |
229 |         return attn_weights
230 | 
231 |     def upgrade_state_dict_named(self, state_dict, name):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^ D102
232 |         prefix = name + "." if name != "" else ""
233 |         items_to_add = {}
    |

geom3d\models\Graphormer\modules\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\Graphormer\modules\__init__.py:1:30: F401 `.fairseq_dropout.FairseqDropout` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .fairseq_dropout import FairseqDropout
  |                              ^^^^^^^^^^^^^^ F401
2 | from .layer_drop import LayerDropModuleList
3 | from .layer_norm import LayerNorm
  |
  = help: Use an explicit re-export: `FairseqDropout as FairseqDropout`

geom3d\models\Graphormer\modules\__init__.py:2:25: F401 `.layer_drop.LayerDropModuleList` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .fairseq_dropout import FairseqDropout
2 | from .layer_drop import LayerDropModuleList
  |                         ^^^^^^^^^^^^^^^^^^^ F401
3 | from .layer_norm import LayerNorm
4 | from .quant_noise import quant_noise
  |
  = help: Use an explicit re-export: `LayerDropModuleList as LayerDropModuleList`

geom3d\models\Graphormer\modules\__init__.py:3:25: F401 `.layer_norm.LayerNorm` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .fairseq_dropout import FairseqDropout
2 | from .layer_drop import LayerDropModuleList
3 | from .layer_norm import LayerNorm
  |                         ^^^^^^^^^ F401
4 | from .quant_noise import quant_noise
  |
  = help: Use an explicit re-export: `LayerNorm as LayerNorm`

geom3d\models\Graphormer\modules\__init__.py:4:26: F401 `.quant_noise.quant_noise` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
2 | from .layer_drop import LayerDropModuleList
3 | from .layer_norm import LayerNorm
4 | from .quant_noise import quant_noise
  |                          ^^^^^^^^^^^ F401
  |
  = help: Use an explicit re-export: `quant_noise as quant_noise`

geom3d\models\Graphormer\modules\fairseq_dropout.py:1:1: D100 Missing docstring in public module
geom3d\models\Graphormer\modules\fairseq_dropout.py:3:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | from typing import List, Optional
2 | 
3 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
4 | from torch import nn
  |

geom3d\models\Graphormer\modules\fairseq_dropout.py:7:7: D101 Missing docstring in public class
  |
7 | class FairseqDropout(nn.Module):
  |       ^^^^^^^^^^^^^^ D101
8 |     def __init__(self, p, module_name=None):
9 |         super().__init__()
  |

geom3d\models\Graphormer\modules\fairseq_dropout.py:8:9: D107 Missing docstring in `__init__`
   |
 7 | class FairseqDropout(nn.Module):
 8 |     def __init__(self, p, module_name=None):
   |         ^^^^^^^^ D107
 9 |         super().__init__()
10 |         self.p = p
   |

geom3d\models\Graphormer\modules\fairseq_dropout.py:14:9: D102 Missing docstring in public method
   |
12 |         self.apply_during_inference = False
13 | 
14 |     def forward(self, x, inplace: bool = False):
   |         ^^^^^^^ D102
15 |         if self.p > 0 and (self.training or self.apply_during_inference):
16 |             return F.dropout(x, p=self.p, training=True, inplace=inplace)
   |

geom3d\models\Graphormer\modules\fairseq_dropout.py:14:26: FBT001 Boolean-typed positional argument in function definition
   |
12 |         self.apply_during_inference = False
13 | 
14 |     def forward(self, x, inplace: bool = False):
   |                          ^^^^^^^ FBT001
15 |         if self.p > 0 and (self.training or self.apply_during_inference):
16 |             return F.dropout(x, p=self.p, training=True, inplace=inplace)
   |

geom3d\models\Graphormer\modules\fairseq_dropout.py:14:26: FBT002 Boolean default positional argument in function definition
   |
12 |         self.apply_during_inference = False
13 | 
14 |     def forward(self, x, inplace: bool = False):
   |                          ^^^^^^^ FBT002
15 |         if self.p > 0 and (self.training or self.apply_during_inference):
16 |             return F.dropout(x, p=self.p, training=True, inplace=inplace)
   |

geom3d\models\Graphormer\modules\fairseq_dropout.py:17:9: RET505 Unnecessary `else` after `return` statement
   |
15 |         if self.p > 0 and (self.training or self.apply_during_inference):
16 |             return F.dropout(x, p=self.p, training=True, inplace=inplace)
17 |         else:
   |         ^^^^ RET505
18 |             return x
   |
   = help: Remove unnecessary `else`

geom3d\models\Graphormer\modules\fairseq_dropout.py:20:9: D102 Missing docstring in public method
   |
18 |             return x
19 | 
20 |     def make_generation_fast_(
   |         ^^^^^^^^^^^^^^^^^^^^^ D102
21 |         self,
22 |         name: str,
   |

geom3d\models\Graphormer\modules\fairseq_dropout.py:22:9: ARG002 Unused method argument: `name`
   |
20 |     def make_generation_fast_(
21 |         self,
22 |         name: str,
   |         ^^^^ ARG002
23 |         retain_dropout: bool = False,
24 |         retain_dropout_modules: Optional[List[str]] = None,
   |

geom3d\models\Graphormer\modules\fairseq_dropout.py:23:9: FBT001 Boolean-typed positional argument in function definition
   |
21 |         self,
22 |         name: str,
23 |         retain_dropout: bool = False,
   |         ^^^^^^^^^^^^^^ FBT001
24 |         retain_dropout_modules: Optional[List[str]] = None,
25 |         **kwargs
   |

geom3d\models\Graphormer\modules\fairseq_dropout.py:23:9: FBT002 Boolean default positional argument in function definition
   |
21 |         self,
22 |         name: str,
23 |         retain_dropout: bool = False,
   |         ^^^^^^^^^^^^^^ FBT002
24 |         retain_dropout_modules: Optional[List[str]] = None,
25 |         **kwargs
   |

geom3d\models\Graphormer\modules\fairseq_dropout.py:24:33: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
22 |         name: str,
23 |         retain_dropout: bool = False,
24 |         retain_dropout_modules: Optional[List[str]] = None,
   |                                 ^^^^^^^^ FA100
25 |         **kwargs
26 |     ):
   |

geom3d\models\Graphormer\modules\fairseq_dropout.py:24:42: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
22 |         name: str,
23 |         retain_dropout: bool = False,
24 |         retain_dropout_modules: Optional[List[str]] = None,
   |                                          ^^^^ FA100
25 |         **kwargs
26 |     ):
   |

geom3d\models\Graphormer\modules\fairseq_dropout.py:25:9: ANN003 Missing type annotation for `**kwargs`
   |
23 |         retain_dropout: bool = False,
24 |         retain_dropout_modules: Optional[List[str]] = None,
25 |         **kwargs
   |         ^^^^^^^^ ANN003
26 |     ):
27 |         if retain_dropout:
   |

geom3d\models\Graphormer\modules\fairseq_dropout.py:25:11: ARG002 Unused method argument: `kwargs`
   |
23 |         retain_dropout: bool = False,
24 |         retain_dropout_modules: Optional[List[str]] = None,
25 |         **kwargs
   |           ^^^^^^ ARG002
26 |     ):
27 |         if retain_dropout:
   |

geom3d\models\Graphormer\modules\layer_drop.py:1:1: D100 Missing docstring in public module
geom3d\models\Graphormer\modules\layer_drop.py:7:5: D205 1 blank line required between summary line and description
   |
 6 |   class LayerDropModuleList(nn.ModuleList):
 7 |       """A LayerDrop implementation based on :class:`torch.nn.ModuleList`.
   |  _____^
 8 | |     We refresh the choice of which layers to drop every time we iterate
 9 | |     over the LayerDropModuleList instance. During evaluation we always
10 | |     iterate over all layers.
11 | |     Usage::
12 | |         layers = LayerDropList(p=0.5, modules=[layer1, layer2, layer3])
13 | |         for layer in layers:  # this might iterate over layers 1 and 3
14 | |             x = layer(x)
15 | |         for layer in layers:  # this might iterate over all layers
16 | |             x = layer(x)
17 | |         for layer in layers:  # this might not iterate over any layers
18 | |             x = layer(x).
19 | | 
20 | |     Args:
21 | |     ----
22 | |         p (float): probability of dropping out each layer
23 | |         modules (iterable, optional): an iterable of modules to add
24 | | 
25 | |     """
   | |_______^ D205
26 |   
27 |       def __init__(self, p, modules=None):
   |
   = help: Insert single blank line

geom3d\models\Graphormer\modules\layer_drop.py:27:9: D107 Missing docstring in `__init__`
   |
25 |     """
26 | 
27 |     def __init__(self, p, modules=None):
   |         ^^^^^^^^ D107
28 |         super().__init__(modules)
29 |         self.p = p
   |

geom3d\models\Graphormer\modules\layer_drop.py:31:9: D105 Missing docstring in magic method
   |
29 |         self.p = p
30 | 
31 |     def __iter__(self):
   |         ^^^^^^^^ D105
32 |         dropout_probs = torch.empty(len(self)).uniform_()
33 |         for i, m in enumerate(super().__iter__()):
   |

geom3d\models\Graphormer\modules\layer_norm.py:1:1: D100 Missing docstring in public module
geom3d\models\Graphormer\modules\layer_norm.py:9:11: D101 Missing docstring in public class
   |
 7 |     has_fused_layernorm = True
 8 | 
 9 |     class FusedLayerNorm(_FusedLayerNorm):
   |           ^^^^^^^^^^^^^^ D101
10 |         @torch.jit.unused
11 |         def forward(self, x):
   |

geom3d\models\Graphormer\modules\layer_norm.py:11:13: D102 Missing docstring in public method
   |
 9 |     class FusedLayerNorm(_FusedLayerNorm):
10 |         @torch.jit.unused
11 |         def forward(self, x):
   |             ^^^^^^^ D102
12 |             if not x.is_cuda:
13 |                 return super().forward(x)
   |

geom3d\models\Graphormer\modules\layer_norm.py:14:13: RET505 Unnecessary `else` after `return` statement
   |
12 |             if not x.is_cuda:
13 |                 return super().forward(x)
14 |             else:
   |             ^^^^ RET505
15 |                 with torch.cuda.device(x.device):
16 |                     return super().forward(x)
   |
   = help: Remove unnecessary `else`

geom3d\models\Graphormer\modules\layer_norm.py:22:5: N802 Function name `LayerNorm` should be lowercase
   |
22 | def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):
   |     ^^^^^^^^^ N802
23 |     if torch.jit.is_scripting() or torch.jit.is_tracing():
24 |         export = True
   |

geom3d\models\Graphormer\modules\layer_norm.py:22:5: D103 Missing docstring in public function
   |
22 | def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):
   |     ^^^^^^^^^ D103
23 |     if torch.jit.is_scripting() or torch.jit.is_tracing():
24 |         export = True
   |

geom3d\models\Graphormer\modules\layer_norm.py:22:43: FBT002 Boolean default positional argument in function definition
   |
22 | def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):
   |                                           ^^^^^^^^^^^^^^^^^^ FBT002
23 |     if torch.jit.is_scripting() or torch.jit.is_tracing():
24 |         export = True
   |

geom3d\models\Graphormer\modules\layer_norm.py:22:68: FBT002 Boolean default positional argument in function definition
   |
22 | def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):
   |                                                                    ^^^^^^ FBT002
23 |     if torch.jit.is_scripting() or torch.jit.is_tracing():
24 |         export = True
   |

geom3d\models\Graphormer\modules\quant_noise.py:1:1: D100 Missing docstring in public module
geom3d\models\Graphormer\modules\quant_noise.py:7:5: D205 1 blank line required between summary line and description
   |
 6 |   def quant_noise(module, p, block_size):
 7 |       """Wraps modules and applies quantization noise to the weights for
   |  _____^
 8 | |     subsequent quantization with Iterative Product Quantization as
 9 | |     described in "Training with Quantization Noise for Extreme Model Compression"
10 | |     Args:
11 | |         - module: nn.Module
12 | |         - p: amount of Quantization Noise
13 | |         - block_size: size of the blocks for subsequent quantization with iPQ
14 | |     Remarks:
15 | |         - Module weights must have the right sizes wrt the block size
16 | |         - Only Linear, Embedding and Conv2d modules are supported for the moment
17 | |         - For more detail on how to quantize by blocks with convolutional weights,
18 | |           see "And the Bit Goes Down: Revisiting the Quantization of Neural Networks"
19 | |         - We implement the simplest form of noise here as stated in the paper
20 | |           which consists in randomly dropping blocks.
21 | |     """
   | |_______^ D205
22 |       # if no quantization noise, don't register hook
23 |       if p <= 0:
   |
   = help: Insert single blank line

geom3d\models\Graphormer\modules\quant_noise.py:7:5: D401 First line of docstring should be in imperative mood: "Wraps modules and applies quantization noise to the weights for"
   |
 6 |   def quant_noise(module, p, block_size):
 7 |       """Wraps modules and applies quantization noise to the weights for
   |  _____^
 8 | |     subsequent quantization with Iterative Product Quantization as
 9 | |     described in "Training with Quantization Noise for Extreme Model Compression"
10 | |     Args:
11 | |         - module: nn.Module
12 | |         - p: amount of Quantization Noise
13 | |         - block_size: size of the blocks for subsequent quantization with iPQ
14 | |     Remarks:
15 | |         - Module weights must have the right sizes wrt the block size
16 | |         - Only Linear, Embedding and Conv2d modules are supported for the moment
17 | |         - For more detail on how to quantize by blocks with convolutional weights,
18 | |           see "And the Bit Goes Down: Revisiting the Quantization of Neural Networks"
19 | |         - We implement the simplest form of noise here as stated in the paper
20 | |           which consists in randomly dropping blocks.
21 | |     """
   | |_______^ D401
22 |       # if no quantization noise, don't register hook
23 |       if p <= 0:
   |

geom3d\models\Graphormer\modules\quant_noise.py:27:5: S101 Use of `assert` detected
   |
26 |     # supported modules
27 |     assert isinstance(module, (nn.Linear, nn.Embedding, nn.Conv2d))
   |     ^^^^^^ S101
28 | 
29 |     # test whether module.weight has the right sizes wrt block_size
   |

geom3d\models\Graphormer\modules\quant_noise.py:30:37: PLR2004 Magic value used in comparison, consider replacing `4` with a constant variable
   |
29 |     # test whether module.weight has the right sizes wrt block_size
30 |     is_conv = module.weight.ndim == 4
   |                                     ^ PLR2004
31 | 
32 |     # 2D matrix
   |

geom3d\models\Graphormer\modules\quant_noise.py:34:9: S101 Use of `assert` detected
   |
32 |     # 2D matrix
33 |     if not is_conv:
34 |         assert (
   |         ^^^^^^ S101
35 |             module.weight.size(1) % block_size == 0
36 |         ), "Input features must be a multiple of block sizes"
   |

geom3d\models\Graphormer\modules\quant_noise.py:40:9: S101 Use of `assert` detected
   |
38 |     # 4D matrix
39 |     elif module.kernel_size == (1, 1):
40 |         assert (
   |         ^^^^^^ S101
41 |             module.in_channels % block_size == 0
42 |         ), "Input channels must be a multiple of block sizes"
   |

geom3d\models\Graphormer\modules\quant_noise.py:46:9: S101 Use of `assert` detected
   |
44 |     else:
45 |         k = module.kernel_size[0] * module.kernel_size[1]
46 |         assert k % block_size == 0, "Kernel size must be a multiple of block size"
   |         ^^^^^^ S101
47 | 
48 |     def _forward_pre_hook(mod, input) -> None:
   |

geom3d\models\Graphormer\modules\quant_noise.py:48:32: A002 Argument `input` is shadowing a Python builtin
   |
46 |         assert k % block_size == 0, "Kernel size must be a multiple of block size"
47 | 
48 |     def _forward_pre_hook(mod, input) -> None:
   |                                ^^^^^ A002
49 |         # no noise for evaluation
50 |         if mod.training:
   |

geom3d\models\Graphormer\modules\quant_noise.py:48:32: ARG001 Unused function argument: `input`
   |
46 |         assert k % block_size == 0, "Kernel size must be a multiple of block size"
47 | 
48 |     def _forward_pre_hook(mod, input) -> None:
   |                                ^^^^^ ARG001
49 |         # no noise for evaluation
50 |         if mod.training:
   |

geom3d\models\Graphormer\modules\utils.py:1:1: D100 Missing docstring in public module
geom3d\models\Graphormer\modules\utils.py:5:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
4 | import torch
5 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
  |

geom3d\models\Graphormer\modules\utils.py:8:5: D103 Missing docstring in public function
   |
 8 | def softmax(x, dim: int, onnx_trace: bool = False):
   |     ^^^^^^^ D103
 9 |     if onnx_trace:
10 |         return F.softmax(x.float(), dim=dim)
   |

geom3d\models\Graphormer\modules\utils.py:8:26: FBT001 Boolean-typed positional argument in function definition
   |
 8 | def softmax(x, dim: int, onnx_trace: bool = False):
   |                          ^^^^^^^^^^ FBT001
 9 |     if onnx_trace:
10 |         return F.softmax(x.float(), dim=dim)
   |

geom3d\models\Graphormer\modules\utils.py:8:26: FBT002 Boolean default positional argument in function definition
   |
 8 | def softmax(x, dim: int, onnx_trace: bool = False):
   |                          ^^^^^^^^^^ FBT002
 9 |     if onnx_trace:
10 |         return F.softmax(x.float(), dim=dim)
   |

geom3d\models\Graphormer\modules\utils.py:11:5: RET505 Unnecessary `else` after `return` statement
   |
 9 |     if onnx_trace:
10 |         return F.softmax(x.float(), dim=dim)
11 |     else:
   |     ^^^^ RET505
12 |         return F.softmax(x, dim=dim, dtype=torch.float32)
   |
   = help: Remove unnecessary `else`

geom3d\models\Graphormer\modules\utils.py:16:5: D401 First line of docstring should be in imperative mood: "Returns the activation function corresponding to `activation`."
   |
15 | def get_activation_fn(activation: str) -> Callable:
16 |     """Returns the activation function corresponding to `activation`."""
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
17 |     # from fairseq.modules import gelu, gelu_accurate
   |

geom3d\models\Graphormer\modules\utils.py:17:5: ERA001 Found commented-out code
   |
15 | def get_activation_fn(activation: str) -> Callable:
16 |     """Returns the activation function corresponding to `activation`."""
17 |     # from fairseq.modules import gelu, gelu_accurate
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
18 | 
19 |     if activation == "relu":
   |
   = help: Remove commented-out code

geom3d\models\Graphormer\modules\utils.py:21:5: ERA001 Found commented-out code
   |
19 |     if activation == "relu":
20 |         return F.relu
21 |     # elif activation == "relu_squared":
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
22 |     #     return relu_squared
23 |     # elif activation == "gelu":
   |
   = help: Remove commented-out code

geom3d\models\Graphormer\modules\utils.py:22:5: ERA001 Found commented-out code
   |
20 |         return F.relu
21 |     # elif activation == "relu_squared":
22 |     #     return relu_squared
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
23 |     # elif activation == "gelu":
24 |     #     return gelu
   |
   = help: Remove commented-out code

geom3d\models\Graphormer\modules\utils.py:23:5: ERA001 Found commented-out code
   |
21 |     # elif activation == "relu_squared":
22 |     #     return relu_squared
23 |     # elif activation == "gelu":
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
24 |     #     return gelu
25 |     # elif activation == "gelu_fast":
   |
   = help: Remove commented-out code

geom3d\models\Graphormer\modules\utils.py:24:5: ERA001 Found commented-out code
   |
22 |     #     return relu_squared
23 |     # elif activation == "gelu":
24 |     #     return gelu
   |     ^^^^^^^^^^^^^^^^^ ERA001
25 |     # elif activation == "gelu_fast":
26 |     #     deprecation_warning(
   |
   = help: Remove commented-out code

geom3d\models\Graphormer\modules\utils.py:25:5: ERA001 Found commented-out code
   |
23 |     # elif activation == "gelu":
24 |     #     return gelu
25 |     # elif activation == "gelu_fast":
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
26 |     #     deprecation_warning(
27 |     #         "--activation-fn=gelu_fast has been renamed to gelu_accurate"
   |
   = help: Remove commented-out code

geom3d\models\Graphormer\modules\utils.py:27:5: ERA001 Found commented-out code
   |
25 |     # elif activation == "gelu_fast":
26 |     #     deprecation_warning(
27 |     #         "--activation-fn=gelu_fast has been renamed to gelu_accurate"
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
28 |     #     )
29 |     #     return gelu_accurate
   |
   = help: Remove commented-out code

geom3d\models\Graphormer\modules\utils.py:28:5: ERA001 Found commented-out code
   |
26 |     #     deprecation_warning(
27 |     #         "--activation-fn=gelu_fast has been renamed to gelu_accurate"
28 |     #     )
   |     ^^^^^^^ ERA001
29 |     #     return gelu_accurate
30 |     # elif activation == "gelu_accurate":
   |
   = help: Remove commented-out code

geom3d\models\Graphormer\modules\utils.py:29:5: ERA001 Found commented-out code
   |
27 |     #         "--activation-fn=gelu_fast has been renamed to gelu_accurate"
28 |     #     )
29 |     #     return gelu_accurate
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
30 |     # elif activation == "gelu_accurate":
31 |     #     return gelu_accurate
   |
   = help: Remove commented-out code

geom3d\models\Graphormer\modules\utils.py:30:5: ERA001 Found commented-out code
   |
28 |     #     )
29 |     #     return gelu_accurate
30 |     # elif activation == "gelu_accurate":
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
31 |     #     return gelu_accurate
32 |     elif activation == "tanh":
   |
   = help: Remove commented-out code

geom3d\models\Graphormer\modules\utils.py:31:5: ERA001 Found commented-out code
   |
29 |     #     return gelu_accurate
30 |     # elif activation == "gelu_accurate":
31 |     #     return gelu_accurate
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
32 |     elif activation == "tanh":
33 |         return torch.tanh
   |
   = help: Remove commented-out code

geom3d\models\Graphormer\modules\utils.py:32:5: RET505 Unnecessary `elif` after `return` statement
   |
30 |     # elif activation == "gelu_accurate":
31 |     #     return gelu_accurate
32 |     elif activation == "tanh":
   |     ^^^^ RET505
33 |         return torch.tanh
34 |     elif activation == "linear":
   |
   = help: Remove unnecessary `elif`

geom3d\models\MLP.py:1:1: N999 Invalid module name: 'MLP'
geom3d\models\MLP.py:1:1: F403 `from collections import *` used; unable to detect undefined names
  |
1 | from collections import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^ F403
2 | 
3 | from torch import nn
  |

geom3d\models\MLP.py:1:1: D100 Missing docstring in public module
geom3d\models\MLP.py:6:7: D101 Missing docstring in public class
  |
6 | class MLP(nn.Module):
  |       ^^^ D101
7 |     def __init__(self, ECFP_dim, hidden_dim, output_dim):
8 |         super().__init__()
  |

geom3d\models\MLP.py:7:9: D107 Missing docstring in `__init__`
  |
6 | class MLP(nn.Module):
7 |     def __init__(self, ECFP_dim, hidden_dim, output_dim):
  |         ^^^^^^^^ D107
8 |         super().__init__()
9 |         self.ECFP_dim = ECFP_dim
  |

geom3d\models\MLP.py:7:24: N803 Argument name `ECFP_dim` should be lowercase
  |
6 | class MLP(nn.Module):
7 |     def __init__(self, ECFP_dim, hidden_dim, output_dim):
  |                        ^^^^^^^^ N803
8 |         super().__init__()
9 |         self.ECFP_dim = ECFP_dim
  |

geom3d\models\MLP.py:15:18: F405 `OrderedDict` may be undefined, or defined from star imports
   |
13 |         layer_dim = [self.ECFP_dim, *self.hidden_dim]
14 | 
15 |         layers = OrderedDict()
   |                  ^^^^^^^^^^^ F405
16 |         for layer_idx, (in_dim, out_dim) in enumerate(zip(layer_dim[:-1], layer_dim[1:])):
17 |             layers[f"fc layer {layer_idx}"] = nn.Linear(in_dim, out_dim)
   |

geom3d\models\MLP.py:22:9: D102 Missing docstring in public method
   |
20 |         self.fc_layers = nn.Linear(layer_dim[-1], self.output_dim)
21 | 
22 |     def represent(self, x):
   |         ^^^^^^^^^ D102
23 |         return self.represent_layers(x)
   |

geom3d\models\MLP.py:25:9: D102 Missing docstring in public method
   |
23 |         return self.represent_layers(x)
24 | 
25 |     def forward(self, x):
   |         ^^^^^^^ D102
26 |         x = self.represent(x)
27 |         return self.fc_layers(x)
   |

geom3d\models\NequIP\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\NequIP\model\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\NequIP\model\__init__.py:12:1: PLE0604 Invalid object in `__all__`, must contain only strings
   |
10 | )
11 | 
12 | __all__ = [
   | ^^^^^^^ PLE0604
13 |     SimpleIrrepsConfig,
14 |     EnergyModel,
   |

geom3d\models\NequIP\model\_build.py:4:1: ERA001 Found commented-out code
  |
2 | import inspect
3 | 
4 | # from stk_search.geom3d.models.NequIP.data import AtomicDataset
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
5 | from stk_search.geom3d.models.NequIP.data.transforms import TypeMapper
6 | from stk_search.geom3d.models.NequIP.nn import GraphModuleMixin
  |
  = help: Remove commented-out code

geom3d\models\NequIP\model\_build.py:10:5: C901 `model_from_config` is too complex (15 > 10)
   |
10 | def model_from_config(
   |     ^^^^^^^^^^^^^^^^^ C901
11 |     config, initialize: bool=False, dataset=None
12 | ) -> GraphModuleMixin:
   |

geom3d\models\NequIP\model\_build.py:10:5: PLR0912 Too many branches (15 > 12)
   |
10 | def model_from_config(
   |     ^^^^^^^^^^^^^^^^^ PLR0912
11 |     config, initialize: bool=False, dataset=None
12 | ) -> GraphModuleMixin:
   |

geom3d\models\NequIP\model\_build.py:10:5: D417 Missing argument description in the docstring for `model_from_config`: `config`
   |
10 | def model_from_config(
   |     ^^^^^^^^^^^^^^^^^ D417
11 |     config, initialize: bool=False, dataset=None
12 | ) -> GraphModuleMixin:
   |

geom3d\models\NequIP\model\_build.py:11:13: FBT001 Boolean-typed positional argument in function definition
   |
10 | def model_from_config(
11 |     config, initialize: bool=False, dataset=None
   |             ^^^^^^^^^^ FBT001
12 | ) -> GraphModuleMixin:
13 |     """Build a model based on `config`.
   |

geom3d\models\NequIP\model\_build.py:11:13: FBT002 Boolean default positional argument in function definition
   |
10 | def model_from_config(
11 |     config, initialize: bool=False, dataset=None
   |             ^^^^^^^^^^ FBT002
12 | ) -> GraphModuleMixin:
13 |     """Build a model based on `config`.
   |

geom3d\models\NequIP\model\_build.py:42:13: S101 Use of `assert` detected
   |
40 |     if type_mapper is not None:
41 |         if "num_types" in config:
42 |             assert (
   |             ^^^^^^ S101
43 |                 config["num_types"] == type_mapper.num_types
44 |             ), "inconsistant config & dataset"
   |

geom3d\models\NequIP\model\_build.py:46:13: S101 Use of `assert` detected
   |
44 |             ), "inconsistant config & dataset"
45 |         if "type_names" in config:
46 |             assert (
   |             ^^^^^^ S101
47 |                 config["type_names"] == type_mapper.type_names
48 |             ), "inconsistant config & dataset"
   |

geom3d\models\NequIP\model\_build.py:58:5: ERA001 Found commented-out code
   |
57 |     model = None
58 |     # print("builders", builders)
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
59 |     # print()
   |
   = help: Remove commented-out code

geom3d\models\NequIP\model\_build.py:59:5: ERA001 Found commented-out code
   |
57 |     model = None
58 |     # print("builders", builders)
59 |     # print()
   |     ^^^^^^^^^ ERA001
60 | 
61 |     for builder in builders:
   |
   = help: Remove commented-out code

geom3d\models\NequIP\model\_build.py:62:9: ERA001 Found commented-out code
   |
61 |     for builder in builders:
62 |         # print("builder", builder)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
63 |         pnames = inspect.signature(builder).parameters
64 |         # print("pnames", pnames)
   |
   = help: Remove commented-out code

geom3d\models\NequIP\model\_build.py:64:9: ERA001 Found commented-out code
   |
62 |         # print("builder", builder)
63 |         pnames = inspect.signature(builder).parameters
64 |         # print("pnames", pnames)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
65 |         params = {}
66 |         if "initialize" in pnames:
   |
   = help: Remove commented-out code

geom3d\models\NequIP\model\_build.py:96:9: ERA001 Found commented-out code
   |
94 |                 msg
95 |             )
96 |         # print("params", params)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
97 |         model = builder(**params)
98 |         if model is not None and not isinstance(model, GraphModuleMixin):
   |
   = help: Remove commented-out code

geom3d\models\NequIP\model\_build.py:103:9: ERA001 Found commented-out code
    |
101 |                 msg
102 |             )
103 |         # print(builder, model)
    |         ^^^^^^^^^^^^^^^^^^^^^^^ ERA001
104 |         # print()
    |
    = help: Remove commented-out code

geom3d\models\NequIP\model\_build.py:104:9: ERA001 Found commented-out code
    |
102 |             )
103 |         # print(builder, model)
104 |         # print()
    |         ^^^^^^^^^ ERA001
105 | 
106 |     return model
    |
    = help: Remove commented-out code

geom3d\models\NequIP\model\_eng.py:19:5: N802 Function name `SimpleIrrepsConfig` should be lowercase
   |
19 | def SimpleIrrepsConfig(config, prefix: Optional[str] = None) -> None:
   |     ^^^^^^^^^^^^^^^^^^ N802
20 |     """Builder that pre-processes options to allow "simple" configuration of irreps."""
21 |     # We allow some simpler parameters to be provided, but if they are,
   |

geom3d\models\NequIP\model\_eng.py:19:40: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
19 | def SimpleIrrepsConfig(config, prefix: Optional[str] = None) -> None:
   |                                        ^^^^^^^^ FA100
20 |     """Builder that pre-processes options to allow "simple" configuration of irreps."""
21 |     # We allow some simpler parameters to be provided, but if they are,
   |

geom3d\models\NequIP\model\_eng.py:39:5: S101 Use of `assert` detected
   |
37 |         (f"{prefix}{k}" in config) or (k in config) for k in real_irreps_keys
38 |     )
39 |     assert has_simple or has_full
   |     ^^^^^^ S101
40 | 
41 |     update = {}
   |

geom3d\models\NequIP\model\_eng.py:58:25: E741 Ambiguous variable name: `l`
   |
56 |                     (num_features, (l, p))
57 |                     for p in ((1, -1) if parity else (1,))
58 |                     for l in range(lmax + 1)
   |                         ^ E741
59 |                 ]
60 |             )
   |

geom3d\models\NequIP\model\_eng.py:76:13: S101 Use of `assert` detected
   |
74 |     for k, v in update.items():
75 |         if k in config:
76 |             assert (
   |             ^^^^^^ S101
77 |                 config[k] == v
78 |             ), f"For key {k}, the full irreps options had value `{config[k]}` inconsistant with the value derived from the simple irreps options `{v}`"
   |

geom3d\models\NequIP\model\_eng.py:82:5: N802 Function name `EnergyModel` should be lowercase
   |
82 | def EnergyModel(
   |     ^^^^^^^^^^^ N802
83 |     config, initialize: bool, dataset: Optional[AtomicDataset] = None
84 | ) -> SequentialGraphNetwork:
   |

geom3d\models\NequIP\model\_eng.py:83:13: FBT001 Boolean-typed positional argument in function definition
   |
82 | def EnergyModel(
83 |     config, initialize: bool, dataset: Optional[AtomicDataset] = None
   |             ^^^^^^^^^^ FBT001
84 | ) -> SequentialGraphNetwork:
85 |     """Base default energy model archetecture.
   |

geom3d\models\NequIP\model\_eng.py:83:13: ARG001 Unused function argument: `initialize`
   |
82 | def EnergyModel(
83 |     config, initialize: bool, dataset: Optional[AtomicDataset] = None
   |             ^^^^^^^^^^ ARG001
84 | ) -> SequentialGraphNetwork:
85 |     """Base default energy model archetecture.
   |

geom3d\models\NequIP\model\_eng.py:83:31: ARG001 Unused function argument: `dataset`
   |
82 | def EnergyModel(
83 |     config, initialize: bool, dataset: Optional[AtomicDataset] = None
   |                               ^^^^^^^ ARG001
84 | ) -> SequentialGraphNetwork:
85 |     """Base default energy model archetecture.
   |

geom3d\models\NequIP\model\_eng.py:83:40: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
82 | def EnergyModel(
83 |     config, initialize: bool, dataset: Optional[AtomicDataset] = None
   |                                        ^^^^^^^^ FA100
84 | ) -> SequentialGraphNetwork:
85 |     """Base default energy model archetecture.
   |

geom3d\models\NequIP\model\_eng.py:85:5: D401 First line of docstring should be in imperative mood: "Base default energy model archetecture."
   |
83 |       config, initialize: bool, dataset: Optional[AtomicDataset] = None
84 |   ) -> SequentialGraphNetwork:
85 |       """Base default energy model archetecture.
   |  _____^
86 | | 
87 | |     For minimal and full configuration option listings, see ``minimal.yaml`` and ``example.yaml``.
88 | |     """
   | |_______^ D401
89 |       logging.debug("Start building the network model")
   |

geom3d\models\NequIP\model\_eng.py:92:5: ERA001 Found commented-out code
   |
91 |     # builder_utils.add_avg_num_neighbors(
92 |     #     config=config, initialize=initialize, dataset=dataset
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
93 |     # )
   |
   = help: Remove commented-out code

geom3d\models\NequIP\model\_eng.py:93:5: ERA001 Found commented-out code
   |
91 |     # builder_utils.add_avg_num_neighbors(
92 |     #     config=config, initialize=initialize, dataset=dataset
93 |     # )
   |     ^^^ ERA001
94 | 
95 |     num_layers = config.get("num_layers", 3)
   |
   = help: Remove commented-out code

geom3d\models\NequIP\model\_eng.py:114:15: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
112 |     layers.update(
113 |         {
114 |             # TODO: the next linear throws out all L > 0, don't create them in the last layer of convnet
    |               ^^^^ TD002
115 |             # -- output block --
116 |             "conv_to_output_hidden": AtomwiseLinear,
    |

geom3d\models\NequIP\model\_eng.py:114:15: TD003 Missing issue link on the line following this TODO
    |
112 |     layers.update(
113 |         {
114 |             # TODO: the next linear throws out all L > 0, don't create them in the last layer of convnet
    |               ^^^^ TD003
115 |             # -- output block --
116 |             "conv_to_output_hidden": AtomwiseLinear,
    |

geom3d\models\NequIP\model\_eng.py:114:15: FIX002 Line contains TODO, consider resolving the issue
    |
112 |     layers.update(
113 |         {
114 |             # TODO: the next linear throws out all L > 0, don't create them in the last layer of convnet
    |               ^^^^ FIX002
115 |             # -- output block --
116 |             "conv_to_output_hidden": AtomwiseLinear,
    |

geom3d\models\NequIP\model\_grads.py:11:5: N802 Function name `ForceOutput` should be lowercase
   |
11 | def ForceOutput(model: GraphModuleMixin) -> GradientOutput:
   |     ^^^^^^^^^^^ N802
12 |     r"""Add forces to a model that predicts energy.
   |

geom3d\models\NequIP\model\_grads.py:35:5: N802 Function name `PartialForceOutput` should be lowercase
   |
35 | def PartialForceOutput(model: GraphModuleMixin) -> GradientOutput:
   |     ^^^^^^^^^^^^^^^^^^ N802
36 |     r"""Add forces and partial forces to a model that predicts energy.
   |

geom3d\models\NequIP\model\_grads.py:56:5: N802 Function name `StressForceOutput` should be lowercase
   |
56 | def StressForceOutput(model: GraphModuleMixin) -> GradientOutput:
   |     ^^^^^^^^^^^^^^^^^ N802
57 |     r"""Add forces and stresses to a model that predicts energy.
   |

geom3d\models\NequIP\model\_scaling.py:16:5: N802 Function name `RescaleEnergyEtc` should be lowercase
   |
16 | def RescaleEnergyEtc(
   |     ^^^^^^^^^^^^^^^^ N802
17 |     model: GraphModuleMixin, config, dataset: AtomicDataset, initialize: bool
18 | ):
   |

geom3d\models\NequIP\model\_scaling.py:16:5: ANN202 Missing return type annotation for private function `RescaleEnergyEtc`
   |
16 | def RescaleEnergyEtc(
   |     ^^^^^^^^^^^^^^^^ ANN202
17 |     model: GraphModuleMixin, config, dataset: AtomicDataset, initialize: bool
18 | ):
   |
   = help: Add return type annotation

geom3d\models\NequIP\model\_scaling.py:17:62: FBT001 Boolean-typed positional argument in function definition
   |
16 | def RescaleEnergyEtc(
17 |     model: GraphModuleMixin, config, dataset: AtomicDataset, initialize: bool
   |                                                              ^^^^^^^^^^ FBT001
18 | ):
19 |     return GlobalRescale(
   |

geom3d\models\NequIP\model\_scaling.py:36:5: N802 Function name `GlobalRescale` should be lowercase
   |
36 | def GlobalRescale(
   |     ^^^^^^^^^^^^^ N802
37 |     model: GraphModuleMixin,
38 |     config,
   |

geom3d\models\NequIP\model\_scaling.py:36:5: C901 `GlobalRescale` is too complex (11 > 10)
   |
36 | def GlobalRescale(
   |     ^^^^^^^^^^^^^ C901
37 |     model: GraphModuleMixin,
38 |     config,
   |

geom3d\models\NequIP\model\_scaling.py:36:5: PLR0913 Too many arguments in function definition (11 > 5)
   |
36 | def GlobalRescale(
   |     ^^^^^^^^^^^^^ PLR0913
37 |     model: GraphModuleMixin,
38 |     config,
   |

geom3d\models\NequIP\model\_scaling.py:36:5: ANN202 Missing return type annotation for private function `GlobalRescale`
   |
36 | def GlobalRescale(
   |     ^^^^^^^^^^^^^ ANN202
37 |     model: GraphModuleMixin,
38 |     config,
   |
   = help: Add return type annotation

geom3d\models\NequIP\model\_scaling.py:40:5: FBT001 Boolean-typed positional argument in function definition
   |
38 |     config,
39 |     dataset: AtomicDataset,
40 |     initialize: bool,
   |     ^^^^^^^^^^ FBT001
41 |     module_prefix: str,
42 |     default_scale: Union[str, float, list],
   |

geom3d\models\NequIP\model\_scaling.py:42:20: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
40 |     initialize: bool,
41 |     module_prefix: str,
42 |     default_scale: Union[str, float, list],
   |                    ^^^^^ FA100
43 |     default_shift: Union[str, float, list],
44 |     default_scale_keys: list,
   |

geom3d\models\NequIP\model\_scaling.py:43:20: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
41 |     module_prefix: str,
42 |     default_scale: Union[str, float, list],
43 |     default_shift: Union[str, float, list],
   |                    ^^^^^ FA100
44 |     default_scale_keys: list,
45 |     default_shift_keys: list,
   |

geom3d\models\NequIP\model\_scaling.py:58:13: G004 Logging statement uses f-string
   |
56 |       if global_shift is not None:
57 |           logging.warning(
58 |               f"!!!! Careful global_shift is set to {global_shift}."
   |  _____________^
59 | |             f"The model for {default_shift_keys} will no longer be size extensive"
   | |__________________________________________________________________________________^ G004
60 |           )
   |

geom3d\models\NequIP\model\_scaling.py:87:26: G004 Logging statement uses f-string
   |
85 |             s = global_scale
86 |             global_scale = computed_stats[str_names.index(global_scale)]
87 |             logging.info(f"Replace string {s} to {global_scale}")
   |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
88 |         if isinstance(global_shift, str):
89 |             s = global_shift
   |

geom3d\models\NequIP\model\_scaling.py:91:26: G004 Logging statement uses f-string
   |
89 |             s = global_shift
90 |             global_shift = computed_stats[str_names.index(global_shift)]
91 |             logging.info(f"Replace string {s} to {global_shift}")
   |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
92 | 
93 |         if global_scale is not None and global_scale < RESCALE_THRESHOLD:
   |

geom3d\models\NequIP\model\_scaling.py:100:13: G004 Logging statement uses f-string
    |
 99 |         logging.info(
100 |             f"Initially outputs are globally scaled by: {global_scale}, total_energy are globally shifted by {global_shift}."
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
101 |         )
    |

geom3d\models\NequIP\model\_scaling.py:111:5: S101 Use of `assert` detected
    |
110 |     error_string = "keys need to be a list"
111 |     assert isinstance(default_scale_keys, list), error_string
    |     ^^^^^^ S101
112 |     assert isinstance(default_shift_keys, list), error_string
113 |     assert isinstance(default_related_scale_keys, list), error_string
    |

geom3d\models\NequIP\model\_scaling.py:112:5: S101 Use of `assert` detected
    |
110 |     error_string = "keys need to be a list"
111 |     assert isinstance(default_scale_keys, list), error_string
112 |     assert isinstance(default_shift_keys, list), error_string
    |     ^^^^^^ S101
113 |     assert isinstance(default_related_scale_keys, list), error_string
114 |     assert isinstance(default_related_shift_keys, list), error_string
    |

geom3d\models\NequIP\model\_scaling.py:113:5: S101 Use of `assert` detected
    |
111 |     assert isinstance(default_scale_keys, list), error_string
112 |     assert isinstance(default_shift_keys, list), error_string
113 |     assert isinstance(default_related_scale_keys, list), error_string
    |     ^^^^^^ S101
114 |     assert isinstance(default_related_shift_keys, list), error_string
    |

geom3d\models\NequIP\model\_scaling.py:114:5: S101 Use of `assert` detected
    |
112 |     assert isinstance(default_shift_keys, list), error_string
113 |     assert isinstance(default_related_scale_keys, list), error_string
114 |     assert isinstance(default_related_shift_keys, list), error_string
    |     ^^^^^^ S101
115 | 
116 |     # == Build the model ==
    |

geom3d\models\NequIP\model\_scaling.py:130:5: N802 Function name `PerSpeciesRescale` should be lowercase
    |
130 | def PerSpeciesRescale(
    |     ^^^^^^^^^^^^^^^^^ N802
131 |     model: GraphModuleMixin,
132 |     config,
    |

geom3d\models\NequIP\model\_scaling.py:130:5: C901 `PerSpeciesRescale` is too complex (16 > 10)
    |
130 | def PerSpeciesRescale(
    |     ^^^^^^^^^^^^^^^^^ C901
131 |     model: GraphModuleMixin,
132 |     config,
    |

geom3d\models\NequIP\model\_scaling.py:130:5: PLR0912 Too many branches (18 > 12)
    |
130 | def PerSpeciesRescale(
    |     ^^^^^^^^^^^^^^^^^ PLR0912
131 |     model: GraphModuleMixin,
132 |     config,
    |

geom3d\models\NequIP\model\_scaling.py:130:5: PLR0915 Too many statements (52 > 50)
    |
130 | def PerSpeciesRescale(
    |     ^^^^^^^^^^^^^^^^^ PLR0915
131 |     model: GraphModuleMixin,
132 |     config,
    |

geom3d\models\NequIP\model\_scaling.py:130:5: ANN202 Missing return type annotation for private function `PerSpeciesRescale`
    |
130 | def PerSpeciesRescale(
    |     ^^^^^^^^^^^^^^^^^ ANN202
131 |     model: GraphModuleMixin,
132 |     config,
    |
    = help: Add return type annotation

geom3d\models\NequIP\model\_scaling.py:134:5: FBT001 Boolean-typed positional argument in function definition
    |
132 |     config,
133 |     dataset: AtomicDataset,
134 |     initialize: bool,
    |     ^^^^^^^^^^ FBT001
135 | ):
136 |     """Add global rescaling for energy(-based quantities).
    |

geom3d\models\NequIP\model\_scaling.py:162:9: SIM102 Use a single `if` statement instead of nested `if` statements
    |
160 |           # THIS CHECK IS ONLY GOOD ENOUGH FOR EMITTING WARNINGS
161 |           has_global_shift = config.get("global_rescale_shift", None) is not None
162 |           if has_global_shift:
    |  _________^
163 | |             if shifts is not None:
    | |__________________________________^ SIM102
164 |                   # using default of per_atom shift
165 |                   msg = "A global_rescale_shift was provided, but the default per-atom energy shift was not disabled."
    |
    = help: Combine `if` statements using `and`

geom3d\models\NequIP\model\_scaling.py:187:30: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
185 |                 raise ValueError(msg)
186 | 
187 |         if len(str_names) == 2:
    |                              ^ PLR2004
188 |             # Both computed from dataset
189 |             arguments_in_dataset_units = True
    |

geom3d\models\NequIP\model\_scaling.py:197:17: S101 Use of `assert` detected
    |
195 |                 arguments_in_dataset_units = True
196 |             else:
197 |                 assert config[
    |                 ^^^^^^ S101
198 |                     module_prefix + "_arguments_in_dataset_units"
199 |                 ], "Requested to set either the shifts or scales of the per_species_rescale using dataset values, but chose to provide the other in non-dataset units. Please give the explictly specified shifts/scales in dataset units and set per_species_rescale_arguments_in_dataset_units"
    |

geom3d\models\NequIP\model\_scaling.py:212:26: G004 Logging statement uses f-string
    |
210 |             s = scales
211 |             scales = computed_stats[str_names.index(scales)].squeeze(-1)  # energy is 1D
212 |             logging.info(f"Replace string {s} to {scales}")
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
213 |         elif isinstance(scales, (list, float)):
214 |             scales = torch.as_tensor(scales)
    |

geom3d\models\NequIP\model\_scaling.py:219:26: G004 Logging statement uses f-string
    |
217 |             s = shifts
218 |             shifts = computed_stats[str_names.index(shifts)].squeeze(-1)  # energy is 1D
219 |             logging.info(f"Replace string {s} to {shifts}")
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
220 |         elif isinstance(shifts, (list, float)):
221 |             shifts = torch.as_tensor(shifts)
    |

geom3d\models\NequIP\model\_scaling.py:230:13: G004 Logging statement uses f-string
    |
229 |         logging.info(
230 |             f"Atomic outputs are scaled by: {TypeMapper.format(scales, config['type_names'])}, shifted by {TypeMapper.format(shifts, config['type_names'])}."
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
231 |         )
    |

geom3d\models\NequIP\model\_scaling.py:245:5: ERA001 Found commented-out code
    |
243 |         arguments_in_dataset_units = False
244 | 
245 |     # print("PerSpeciesRescale scales", scales)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
246 |     # print("PerSpeciesRescale shifts", shifts)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\model\_scaling.py:246:5: ERA001 Found commented-out code
    |
245 |     # print("PerSpeciesRescale scales", scales)
246 |     # print("PerSpeciesRescale shifts", shifts)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
247 | 
248 |     # insert in per species shift
    |
    = help: Remove commented-out code

geom3d\models\NequIP\model\_scaling.py:269:5: C901 `_compute_stats` is too complex (11 > 10)
    |
269 | def _compute_stats(
    |     ^^^^^^^^^^^^^^ C901
270 |     str_names: List[str], dataset, stride: int, kwargs: Optional[dict] = None
271 | ):
    |

geom3d\models\NequIP\model\_scaling.py:269:5: ANN202 Missing return type annotation for private function `_compute_stats`
    |
269 | def _compute_stats(
    |     ^^^^^^^^^^^^^^ ANN202
270 |     str_names: List[str], dataset, stride: int, kwargs: Optional[dict] = None
271 | ):
    |
    = help: Add return type annotation

geom3d\models\NequIP\model\_scaling.py:269:5: D417 Missing argument description in the docstring for `_compute_stats`: `kwargs`
    |
269 | def _compute_stats(
    |     ^^^^^^^^^^^^^^ D417
270 |     str_names: List[str], dataset, stride: int, kwargs: Optional[dict] = None
271 | ):
    |

geom3d\models\NequIP\model\_scaling.py:270:16: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
269 | def _compute_stats(
270 |     str_names: List[str], dataset, stride: int, kwargs: Optional[dict] = None
    |                ^^^^ FA100
271 | ):
272 |     """Return the values of statistics over dataset
    |

geom3d\models\NequIP\model\_scaling.py:270:57: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
269 | def _compute_stats(
270 |     str_names: List[str], dataset, stride: int, kwargs: Optional[dict] = None
    |                                                         ^^^^^^^^ FA100
271 | ):
272 |     """Return the values of statistics over dataset
    |

geom3d\models\NequIP\model\_scaling.py:272:5: D205 1 blank line required between summary line and description
    |
270 |       str_names: List[str], dataset, stride: int, kwargs: Optional[dict] = None
271 |   ):
272 |       """Return the values of statistics over dataset
    |  _____^
273 | |     quantity name should be dataset_key_stat, where key can be any key
274 | |     that exists in the dataset, stat can be mean, std.
275 | | 
276 | |     Args:
277 | |     ----
278 | |     str_names: list of strings that define the quantity to compute
279 | |     dataset: dataset object to run the stats over
280 | |     stride: # frames to skip for every one frame to include
281 | | 
282 | |     """
    | |_______^ D205
283 |       # parse the list of string to field, mode
284 |       # and record which quantity correspond to which computed_item
    |
    = help: Insert single blank line

geom3d\models\NequIP\model\_scaling.py:298:13: PLW2901 `for` loop variable `name` overwritten by assignment target
    |
296 |         # remove dataset prefix
297 |         if name.startswith("dataset_"):
298 |             name = name[len("dataset_") :]
    |             ^^^^ PLW2901
299 |         # identify per_species and per_atom modes
300 |         prefix = ""
    |

geom3d\models\NequIP\model\_scaling.py:302:13: PLW2901 `for` loop variable `name` overwritten by assignment target
    |
300 |         prefix = ""
301 |         if name.startswith("per_species_"):
302 |             name = name[len("per_species_") :]
    |             ^^^^ PLW2901
303 |             prefix = "per_species_"
304 |         elif name.startswith("per_atom_"):
    |

geom3d\models\NequIP\model\_scaling.py:305:13: PLW2901 `for` loop variable `name` overwritten by assignment target
    |
303 |             prefix = "per_species_"
304 |         elif name.startswith("per_atom_"):
305 |             name = name[len("per_atom_") :]
    |             ^^^^ PLW2901
306 |             prefix = "per_atom_"
    |

geom3d\models\NequIP\model\_scaling.py:327:13: SIM102 Use a single `if` statement instead of nested `if` statements
    |
325 |               stat_modes += [stat_mode]
326 |               stat_fields += [field]
327 |               if stat_mode.startswith("per_species_"):
    |  _____________^
328 | |                 if field in kwargs:
    | |___________________________________^ SIM102
329 |                       input_kwargs[field + stat_mode] = kwargs[field]
330 |           tuple_ids += [tuple_id_map[stat]]
    |
    = help: Combine `if` statements using `and`

geom3d\models\NequIP\model\_weight_init.py:11:5: ANN202 Missing return type annotation for private function `initialize_from_state`
   |
10 | # == Load old state ==
11 | def initialize_from_state(config: Config, model: GraphModuleMixin, initialize: bool):
   |     ^^^^^^^^^^^^^^^^^^^^^ ANN202
12 |     """Initialize the model from the state dict file given by the config options `initial_model_state`.
   |
   = help: Add return type annotation

geom3d\models\NequIP\model\_weight_init.py:11:68: FBT001 Boolean-typed positional argument in function definition
   |
10 | # == Load old state ==
11 | def initialize_from_state(config: Config, model: GraphModuleMixin, initialize: bool):
   |                                                                    ^^^^^^^^^^ FBT001
12 |     """Initialize the model from the state dict file given by the config options `initial_model_state`.
   |

geom3d\models\NequIP\model\_weight_init.py:29:5: ANN202 Missing return type annotation for private function `load_model_state`
   |
29 | def load_model_state(
   |     ^^^^^^^^^^^^^^^^ ANN202
30 |     config: Config,
31 |     model: GraphModuleMixin,
   |
   = help: Add return type annotation

geom3d\models\NequIP\model\_weight_init.py:32:5: FBT001 Boolean-typed positional argument in function definition
   |
30 |     config: Config,
31 |     model: GraphModuleMixin,
32 |     initialize: bool,
   |     ^^^^^^^^^^ FBT001
33 |     _prefix: str = "load_model_state",
34 | ):
   |

geom3d\models\NequIP\model\_weight_init.py:32:5: ARG001 Unused function argument: `initialize`
   |
30 |     config: Config,
31 |     model: GraphModuleMixin,
32 |     initialize: bool,
   |     ^^^^^^^^^^ ARG001
33 |     _prefix: str = "load_model_state",
34 | ):
   |

geom3d\models\NequIP\model\_weight_init.py:61:3: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
61 | # TODO: does this normalization make any sense
   |   ^^^^ TD002
62 | # def unit_orthogonal_init_(t: torch.Tensor):
63 | #     """Orthogonal init with <x_i^2> = 1"""
   |

geom3d\models\NequIP\model\_weight_init.py:61:3: TD003 Missing issue link on the line following this TODO
   |
61 | # TODO: does this normalization make any sense
   |   ^^^^ TD003
62 | # def unit_orthogonal_init_(t: torch.Tensor):
63 | #     """Orthogonal init with <x_i^2> = 1"""
   |

geom3d\models\NequIP\model\_weight_init.py:61:3: FIX002 Line contains TODO, consider resolving the issue
   |
61 | # TODO: does this normalization make any sense
   |   ^^^^ FIX002
62 | # def unit_orthogonal_init_(t: torch.Tensor):
63 | #     """Orthogonal init with <x_i^2> = 1"""
   |

geom3d\models\NequIP\model\_weight_init.py:63:1: ERA001 Found commented-out code
   |
61 | # TODO: does this normalization make any sense
62 | # def unit_orthogonal_init_(t: torch.Tensor):
63 | #     """Orthogonal init with <x_i^2> = 1"""
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
64 | #     assert t.ndim == 2
65 | #     torch.nn.init.orthogonal_(t, gain=math.sqrt(max(t.shape)))
   |
   = help: Remove commented-out code

geom3d\models\NequIP\model\_weight_init.py:64:1: ERA001 Found commented-out code
   |
62 | # def unit_orthogonal_init_(t: torch.Tensor):
63 | #     """Orthogonal init with <x_i^2> = 1"""
64 | #     assert t.ndim == 2
   | ^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
65 | #     torch.nn.init.orthogonal_(t, gain=math.sqrt(max(t.shape)))
   |
   = help: Remove commented-out code

geom3d\models\NequIP\model\_weight_init.py:65:1: ERA001 Found commented-out code
   |
63 | #     """Orthogonal init with <x_i^2> = 1"""
64 | #     assert t.ndim == 2
65 | #     torch.nn.init.orthogonal_(t, gain=math.sqrt(max(t.shape)))
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
   |
   = help: Remove commented-out code

geom3d\models\NequIP\model\_weight_init.py:68:5: N802 Function name `uniform_initialize_FCs` should be lowercase
   |
68 | def uniform_initialize_FCs(model: GraphModuleMixin, initialize: bool):
   |     ^^^^^^^^^^^^^^^^^^^^^^ N802
69 |     """Initialize ``e3nn.nn.FullyConnectedNet``s with unit uniform initialization."""
70 |     if initialize:
   |

geom3d\models\NequIP\model\_weight_init.py:68:5: ANN202 Missing return type annotation for private function `uniform_initialize_FCs`
   |
68 | def uniform_initialize_FCs(model: GraphModuleMixin, initialize: bool):
   |     ^^^^^^^^^^^^^^^^^^^^^^ ANN202
69 |     """Initialize ``e3nn.nn.FullyConnectedNet``s with unit uniform initialization."""
70 |     if initialize:
   |
   = help: Add return type annotation

geom3d\models\NequIP\model\_weight_init.py:68:53: FBT001 Boolean-typed positional argument in function definition
   |
68 | def uniform_initialize_FCs(model: GraphModuleMixin, initialize: bool):
   |                                                     ^^^^^^^^^^ FBT001
69 |     """Initialize ``e3nn.nn.FullyConnectedNet``s with unit uniform initialization."""
70 |     if initialize:
   |

geom3d\models\NequIP\model\builder_utils.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\model\builder_utils.py:8:5: ANN202 Missing return type annotation for private function `_add_avg_num_neighbors_helper`
   |
 8 | def _add_avg_num_neighbors_helper(data):
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ANN202
 9 |     counts = torch.unique(
10 |         data[AtomicDataDict.EDGE_INDEX_KEY][0],
   |
   = help: Add return type annotation

geom3d\models\NequIP\model\builder_utils.py:22:5: D103 Missing docstring in public function
   |
22 | def add_avg_num_neighbors(
   |     ^^^^^^^^^^^^^^^^^^^^^ D103
23 |     config: Config,
24 |     initialize: bool,
   |

geom3d\models\NequIP\model\builder_utils.py:24:5: FBT001 Boolean-typed positional argument in function definition
   |
22 | def add_avg_num_neighbors(
23 |     config: Config,
24 |     initialize: bool,
   |     ^^^^^^^^^^ FBT001
25 |     dataset: Optional[AtomicDataset] = None,
26 | ) -> Optional[float]:
   |

geom3d\models\NequIP\model\builder_utils.py:25:14: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
23 |     config: Config,
24 |     initialize: bool,
25 |     dataset: Optional[AtomicDataset] = None,
   |              ^^^^^^^^ FA100
26 | ) -> Optional[float]:
27 |     # Compute avg_num_neighbors
   |

geom3d\models\NequIP\model\builder_utils.py:26:6: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
24 |     initialize: bool,
25 |     dataset: Optional[AtomicDataset] = None,
26 | ) -> Optional[float]:
   |      ^^^^^^^^ FA100
27 |     # Compute avg_num_neighbors
28 |     annkey: str = "avg_num_neighbors"
   |

geom3d\models\NequIP\model\builder_utils.py:48:5: ERA001 Found commented-out code
   |
46 |         ann = ann.item()
47 |         var_nn = var_nn.item()
48 |     # print("add_avg_num_neighbors ann", ann)
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
49 |     # print("add_avg_num_neighbors var_nn", var_nn)
   |
   = help: Remove commented-out code

geom3d\models\NequIP\model\builder_utils.py:49:5: ERA001 Found commented-out code
   |
47 |         var_nn = var_nn.item()
48 |     # print("add_avg_num_neighbors ann", ann)
49 |     # print("add_avg_num_neighbors var_nn", var_nn)
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
50 | 
51 |     # make sure its valid
   |
   = help: Remove commented-out code

geom3d\models\NequIP\model\builder_utils.py:60:5: ANN202 Missing return type annotation for private function `_add_avg_num_atoms_helper`
   |
60 | def _add_avg_num_atoms_helper(data):
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ ANN202
61 |     counts = torch.unique(
62 |         data[AtomicDataDict.BATCH_KEY],
   |
   = help: Add return type annotation

geom3d\models\NequIP\model\builder_utils.py:69:5: D103 Missing docstring in public function
   |
69 | def add_avg_num_atoms(
   |     ^^^^^^^^^^^^^^^^^ D103
70 |     config: Config,
71 |     initialize: bool,
   |

geom3d\models\NequIP\model\builder_utils.py:71:5: FBT001 Boolean-typed positional argument in function definition
   |
69 | def add_avg_num_atoms(
70 |     config: Config,
71 |     initialize: bool,
   |     ^^^^^^^^^^ FBT001
72 |     dataset: Optional[AtomicDataset] = None,
73 | ) -> Optional[float]:
   |

geom3d\models\NequIP\model\builder_utils.py:72:14: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
70 |     config: Config,
71 |     initialize: bool,
72 |     dataset: Optional[AtomicDataset] = None,
   |              ^^^^^^^^ FA100
73 | ) -> Optional[float]:
74 |     # Compute avg_num_atoms
   |

geom3d\models\NequIP\model\builder_utils.py:73:6: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
71 |     initialize: bool,
72 |     dataset: Optional[AtomicDataset] = None,
73 | ) -> Optional[float]:
   |      ^^^^^^^^ FA100
74 |     # Compute avg_num_atoms
75 |     anakey: str = "avg_num_atoms"
   |

geom3d\models\NequIP\nn\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\NequIP\nn\_atomwise.py:34:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
32 |         self,
33 |         field: str = AtomicDataDict.NODE_FEATURES_KEY,
34 |         out_field: Optional[str] = None,
   |                    ^^^^^^^^ FA100
35 |         irreps_in=None,
36 |         irreps_out=None,
   |

geom3d\models\NequIP\nn\_atomwise.py:65:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
63 |         self,
64 |         field: str,
65 |         out_field: Optional[str] = None,
   |                    ^^^^^^^^ FA100
66 |         reduce="sum",
67 |         avg_num_atoms=None,
   |

geom3d\models\NequIP\nn\_atomwise.py:73:9: S101 Use of `assert` detected
   |
71 |             irreps_in = {}
72 |         super().__init__()
73 |         assert reduce in ("sum", "mean", "normalized_sum")
   |         ^^^^^^ S101
74 |         self.constant = 1.0
75 |         if reduce == "normalized_sum":
   |

geom3d\models\NequIP\nn\_atomwise.py:76:13: S101 Use of `assert` detected
   |
74 |         self.constant = 1.0
75 |         if reduce == "normalized_sum":
76 |             assert avg_num_atoms is not None
   |             ^^^^^^ S101
77 |             self.constant = float(avg_num_atoms) ** -0.5
78 |             reduce = "sum"
   |

geom3d\models\NequIP\nn\_atomwise.py:126:9: PLR0913 Too many arguments in function definition (10 > 5)
    |
124 |     has_shifts: bool
125 | 
126 |     def __init__(
    |         ^^^^^^^^ PLR0913
127 |         self,
128 |         field: str,
    |

geom3d\models\NequIP\nn\_atomwise.py:130:21: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
128 |         field: str,
129 |         num_types: int,
130 |         type_names: List[str],
    |                     ^^^^ FA100
131 |         shifts: Optional[List[float]],
132 |         scales: Optional[List[float]],
    |

geom3d\models\NequIP\nn\_atomwise.py:131:17: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
129 |         num_types: int,
130 |         type_names: List[str],
131 |         shifts: Optional[List[float]],
    |                 ^^^^^^^^ FA100
132 |         scales: Optional[List[float]],
133 |         arguments_in_dataset_units: bool,
    |

geom3d\models\NequIP\nn\_atomwise.py:131:26: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
129 |         num_types: int,
130 |         type_names: List[str],
131 |         shifts: Optional[List[float]],
    |                          ^^^^ FA100
132 |         scales: Optional[List[float]],
133 |         arguments_in_dataset_units: bool,
    |

geom3d\models\NequIP\nn\_atomwise.py:132:17: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
130 |         type_names: List[str],
131 |         shifts: Optional[List[float]],
132 |         scales: Optional[List[float]],
    |                 ^^^^^^^^ FA100
133 |         arguments_in_dataset_units: bool,
134 |         out_field: Optional[str] = None,
    |

geom3d\models\NequIP\nn\_atomwise.py:132:26: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
130 |         type_names: List[str],
131 |         shifts: Optional[List[float]],
132 |         scales: Optional[List[float]],
    |                          ^^^^ FA100
133 |         arguments_in_dataset_units: bool,
134 |         out_field: Optional[str] = None,
    |

geom3d\models\NequIP\nn\_atomwise.py:133:9: FBT001 Boolean-typed positional argument in function definition
    |
131 |         shifts: Optional[List[float]],
132 |         scales: Optional[List[float]],
133 |         arguments_in_dataset_units: bool,
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^ FBT001
134 |         out_field: Optional[str] = None,
135 |         scales_trainable: bool = False,
    |

geom3d\models\NequIP\nn\_atomwise.py:134:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
132 |         scales: Optional[List[float]],
133 |         arguments_in_dataset_units: bool,
134 |         out_field: Optional[str] = None,
    |                    ^^^^^^^^ FA100
135 |         scales_trainable: bool = False,
136 |         shifts_trainable: bool = False,
    |

geom3d\models\NequIP\nn\_atomwise.py:135:9: FBT001 Boolean-typed positional argument in function definition
    |
133 |         arguments_in_dataset_units: bool,
134 |         out_field: Optional[str] = None,
135 |         scales_trainable: bool = False,
    |         ^^^^^^^^^^^^^^^^ FBT001
136 |         shifts_trainable: bool = False,
137 |         irreps_in=None,
    |

geom3d\models\NequIP\nn\_atomwise.py:135:9: FBT002 Boolean default positional argument in function definition
    |
133 |         arguments_in_dataset_units: bool,
134 |         out_field: Optional[str] = None,
135 |         scales_trainable: bool = False,
    |         ^^^^^^^^^^^^^^^^ FBT002
136 |         shifts_trainable: bool = False,
137 |         irreps_in=None,
    |

geom3d\models\NequIP\nn\_atomwise.py:136:9: FBT001 Boolean-typed positional argument in function definition
    |
134 |         out_field: Optional[str] = None,
135 |         scales_trainable: bool = False,
136 |         shifts_trainable: bool = False,
    |         ^^^^^^^^^^^^^^^^ FBT001
137 |         irreps_in=None,
138 |     ):
    |

geom3d\models\NequIP\nn\_atomwise.py:136:9: FBT002 Boolean default positional argument in function definition
    |
134 |         out_field: Optional[str] = None,
135 |         scales_trainable: bool = False,
136 |         shifts_trainable: bool = False,
    |         ^^^^^^^^^^^^^^^^ FBT002
137 |         irreps_in=None,
138 |     ):
    |

geom3d\models\NequIP\nn\_atomwise.py:157:13: S101 Use of `assert` detected
    |
155 |             if len(shifts.reshape([-1])) == 1:
156 |                 shifts = torch.ones(num_types) * shifts
157 |             assert shifts.shape == (num_types,), f"Invalid shape of shifts {shifts}"
    |             ^^^^^^ S101
158 |             self.shifts_trainable = shifts_trainable
159 |             if shifts_trainable:
    |

geom3d\models\NequIP\nn\_atomwise.py:169:13: S101 Use of `assert` detected
    |
167 |             if len(scales.reshape([-1])) == 1:
168 |                 scales = torch.ones(num_types) * scales
169 |             assert scales.shape == (num_types,), f"Invalid shape of scales {scales}"
    |             ^^^^^^ S101
170 |             self.scales_trainable = scales_trainable
171 |             if scales_trainable:
    |

geom3d\models\NequIP\nn\_atomwise.py:185:9: S101 Use of `assert` detected
    |
183 |         species_idx = data[AtomicDataDict.ATOM_TYPE_KEY]
184 |         in_field = data[self.field]
185 |         assert len(in_field) == len(
    |         ^^^^^^ S101
186 |             species_idx
187 |         ), "in_field doesnt seem to have correct per-atom shape"
    |

geom3d\models\NequIP\nn\_atomwise.py:196:9: SIM102 Use a single `if` statement instead of nested `if` statements
    |
195 |       def update_for_rescale(self, rescale_module) -> None:
196 |           if hasattr(rescale_module, "related_scale_keys"):
    |  _________^
197 | |             if self.out_field not in rescale_module.related_scale_keys:
    | |_______________________________________________________________________^ SIM102
198 |                   return
199 |           if self.arguments_in_dataset_units and rescale_module.has_scale:
    |
    = help: Combine `if` statements using `and`

geom3d\models\NequIP\nn\_atomwise.py:201:17: G004 Logging statement uses f-string
    |
199 |           if self.arguments_in_dataset_units and rescale_module.has_scale:
200 |               logging.debug(
201 |                   f"PerSpeciesScaleShift's arguments were in dataset units; rescaling:\n  "
    |  _________________^
202 | |                 f"Original scales: {TypeMapper.format(self.scales, self.type_names) if self.has_scales else 'n/a'} "
203 | |                 f"shifts: {TypeMapper.format(self.shifts, self.type_names) if self.has_shifts else 'n/a'}"
    | |__________________________________________________________________________________________________________^ G004
204 |               )
205 |               with torch.no_grad():
    |

geom3d\models\NequIP\nn\_atomwise.py:211:17: G004 Logging statement uses f-string
    |
209 |                       self.shifts.div_(rescale_module.scale_by)
210 |               logging.debug(
211 |                   f"  New scales: {TypeMapper.format(self.scales, self.type_names) if self.has_scales else 'n/a'} "
    |  _________________^
212 | |                 f"shifts: {TypeMapper.format(self.shifts, self.type_names) if self.has_shifts else 'n/a'}"
    | |__________________________________________________________________________________________________________^ G004
213 |               )
    |

geom3d\models\NequIP\nn\_concat.py:12:35: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
10 |     """Concatenate multiple fields into one."""
11 | 
12 |     def __init__(self, in_fields: List[str], out_field: str, irreps_in=None):
   |                                   ^^^^ FA100
13 |         if irreps_in is None:
14 |             irreps_in = {}
   |

geom3d\models\NequIP\nn\_convnetlayer.py:24:5: D205 1 blank line required between summary line and description
   |
23 |   class ConvNetLayer(GraphModuleMixin, torch.nn.Module):
24 |       """Args:
   |  _____^
25 | |     ----
26 | | 
27 | |     """
   | |_______^ D205
28 |   
29 |       resnet: bool
   |
   = help: Insert single blank line

geom3d\models\NequIP\nn\_convnetlayer.py:24:5: D400 First line should end with a period
   |
23 |   class ConvNetLayer(GraphModuleMixin, torch.nn.Module):
24 |       """Args:
   |  _____^
25 | |     ----
26 | | 
27 | |     """
   | |_______^ D400
28 |   
29 |       resnet: bool
   |
   = help: Add period

geom3d\models\NequIP\nn\_convnetlayer.py:24:5: D415 First line should end with a period, question mark, or exclamation point
   |
23 |   class ConvNetLayer(GraphModuleMixin, torch.nn.Module):
24 |       """Args:
   |  _____^
25 | |     ----
26 | | 
27 | |     """
   | |_______^ D415
28 |   
29 |       resnet: bool
   |
   = help: Add closing punctuation

geom3d\models\NequIP\nn\_convnetlayer.py:31:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
29 |     resnet: bool
30 | 
31 |     def __init__(
   |         ^^^^^^^^ PLR0913
32 |         self,
33 |         irreps_in,
   |

geom3d\models\NequIP\nn\_convnetlayer.py:36:29: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
34 |         feature_irreps_hidden,
35 |         convolution=InteractionBlock,
36 |         convolution_kwargs: Optional[dict] = None,
   |                             ^^^^^^^^ FA100
37 |         num_layers: int = 3,
38 |         resnet: bool = False,
   |

geom3d\models\NequIP\nn\_convnetlayer.py:38:9: FBT001 Boolean-typed positional argument in function definition
   |
36 |         convolution_kwargs: Optional[dict] = None,
37 |         num_layers: int = 3,
38 |         resnet: bool = False,
   |         ^^^^^^ FBT001
39 |         nonlinearity_type: str = "gate",
40 |         nonlinearity_scalars: Optional[Dict[int, Callable]] = None,
   |

geom3d\models\NequIP\nn\_convnetlayer.py:38:9: FBT002 Boolean default positional argument in function definition
   |
36 |         convolution_kwargs: Optional[dict] = None,
37 |         num_layers: int = 3,
38 |         resnet: bool = False,
   |         ^^^^^^ FBT002
39 |         nonlinearity_type: str = "gate",
40 |         nonlinearity_scalars: Optional[Dict[int, Callable]] = None,
   |

geom3d\models\NequIP\nn\_convnetlayer.py:40:31: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
38 |         resnet: bool = False,
39 |         nonlinearity_type: str = "gate",
40 |         nonlinearity_scalars: Optional[Dict[int, Callable]] = None,
   |                               ^^^^^^^^ FA100
41 |         nonlinearity_gates: Optional[Dict[int, Callable]] = None,
42 |     ):
   |

geom3d\models\NequIP\nn\_convnetlayer.py:40:40: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
38 |         resnet: bool = False,
39 |         nonlinearity_type: str = "gate",
40 |         nonlinearity_scalars: Optional[Dict[int, Callable]] = None,
   |                                        ^^^^ FA100
41 |         nonlinearity_gates: Optional[Dict[int, Callable]] = None,
42 |     ):
   |

geom3d\models\NequIP\nn\_convnetlayer.py:41:29: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
39 |         nonlinearity_type: str = "gate",
40 |         nonlinearity_scalars: Optional[Dict[int, Callable]] = None,
41 |         nonlinearity_gates: Optional[Dict[int, Callable]] = None,
   |                             ^^^^^^^^ FA100
42 |     ):
43 |         if nonlinearity_gates is None:
   |

geom3d\models\NequIP\nn\_convnetlayer.py:41:38: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
39 |         nonlinearity_type: str = "gate",
40 |         nonlinearity_scalars: Optional[Dict[int, Callable]] = None,
41 |         nonlinearity_gates: Optional[Dict[int, Callable]] = None,
   |                                      ^^^^ FA100
42 |     ):
43 |         if nonlinearity_gates is None:
   |

geom3d\models\NequIP\nn\_convnetlayer.py:51:9: S101 Use of `assert` detected
   |
49 |         super().__init__()
50 |         # initialization
51 |         assert nonlinearity_type in ("gate", "norm")
   |         ^^^^^^ S101
52 |         # make the nonlin dicts from parity ints instead of convinience strs
53 |         nonlinearity_scalars = {
   |

geom3d\models\NequIP\nn\_convnetlayer.py:131:11: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
129 |         self.equivariant_nonlin = equivariant_nonlin
130 | 
131 |         # TODO: partial resnet?
    |           ^^^^ TD002
132 |         if irreps_layer_out == irreps_layer_out_prev and resnet:
133 |             # We are doing resnet updates and can for this layer
    |

geom3d\models\NequIP\nn\_convnetlayer.py:131:11: TD003 Missing issue link on the line following this TODO
    |
129 |         self.equivariant_nonlin = equivariant_nonlin
130 | 
131 |         # TODO: partial resnet?
    |           ^^^^ TD003
132 |         if irreps_layer_out == irreps_layer_out_prev and resnet:
133 |             # We are doing resnet updates and can for this layer
    |

geom3d\models\NequIP\nn\_convnetlayer.py:131:11: FIX002 Line contains TODO, consider resolving the issue
    |
129 |         self.equivariant_nonlin = equivariant_nonlin
130 | 
131 |         # TODO: partial resnet?
    |           ^^^^ FIX002
132 |         if irreps_layer_out == irreps_layer_out_prev and resnet:
133 |             # We are doing resnet updates and can for this layer
    |

geom3d\models\NequIP\nn\_convnetlayer.py:138:11: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
136 |             self.resnet = False
137 | 
138 |         # TODO: last convolution should go to explicit irreps out
    |           ^^^^ TD002
139 |         logging.debug(
140 |             f" parameters used to initialize {convolution.__name__}={convolution_kwargs}"
    |

geom3d\models\NequIP\nn\_convnetlayer.py:138:11: TD003 Missing issue link on the line following this TODO
    |
136 |             self.resnet = False
137 | 
138 |         # TODO: last convolution should go to explicit irreps out
    |           ^^^^ TD003
139 |         logging.debug(
140 |             f" parameters used to initialize {convolution.__name__}={convolution_kwargs}"
    |

geom3d\models\NequIP\nn\_convnetlayer.py:138:11: FIX002 Line contains TODO, consider resolving the issue
    |
136 |             self.resnet = False
137 | 
138 |         # TODO: last convolution should go to explicit irreps out
    |           ^^^^ FIX002
139 |         logging.debug(
140 |             f" parameters used to initialize {convolution.__name__}={convolution_kwargs}"
    |

geom3d\models\NequIP\nn\_convnetlayer.py:140:13: G004 Logging statement uses f-string
    |
138 |         # TODO: last convolution should go to explicit irreps out
139 |         logging.debug(
140 |             f" parameters used to initialize {convolution.__name__}={convolution_kwargs}"
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
141 |         )
    |

geom3d\models\NequIP\nn\_grad_output.py:33:14: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
31 |         func: GraphModuleMixin,
32 |         of: str,
33 |         wrt: Union[str, List[str]],
   |              ^^^^^ FA100
34 |         out_field: Optional[List[str]] = None,
35 |         sign: float = 1.0,
   |

geom3d\models\NequIP\nn\_grad_output.py:33:25: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
31 |         func: GraphModuleMixin,
32 |         of: str,
33 |         wrt: Union[str, List[str]],
   |                         ^^^^ FA100
34 |         out_field: Optional[List[str]] = None,
35 |         sign: float = 1.0,
   |

geom3d\models\NequIP\nn\_grad_output.py:34:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
32 |         of: str,
33 |         wrt: Union[str, List[str]],
34 |         out_field: Optional[List[str]] = None,
   |                    ^^^^^^^^ FA100
35 |         sign: float = 1.0,
36 |     ):
   |

geom3d\models\NequIP\nn\_grad_output.py:34:29: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
32 |         of: str,
33 |         wrt: Union[str, List[str]],
34 |         out_field: Optional[List[str]] = None,
   |                             ^^^^ FA100
35 |         sign: float = 1.0,
36 |     ):
   |

geom3d\models\NequIP\nn\_grad_output.py:39:9: S101 Use of `assert` detected
   |
37 |         super().__init__()
38 |         sign = float(sign)
39 |         assert sign in (1.0, -1.0)
   |         ^^^^^^ S101
40 |         self.sign = sign
41 |         self._negate = sign == -1.0
   |

geom3d\models\NequIP\nn\_grad_output.py:55:13: S101 Use of `assert` detected
   |
53 |             self.out_field = [f"d({of})/d({e})" for e in self.wrt]
54 |         else:
55 |             assert len(out_field) == len(
   |             ^^^^^^ S101
56 |                 self.wrt
57 |             ), "Out field names must be given for all w.r.t tensors"
   |

geom3d\models\NequIP\nn\_grad_output.py:77:9: ERA001 Found commented-out code
   |
75 |         if self.skip:
76 |             return self.func(data)
77 |         # print("after", data.keys())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
78 |         # # dict_keys(['edge_index', 'pos', 'batch', 'ptr', 'cell', 'pbc', 'edge_cell_shift', 'r_max', 'atom_types'])
79 |         # print("edge_index", data['edge_index'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:78:9: ERA001 Found commented-out code
   |
76 |             return self.func(data)
77 |         # print("after", data.keys())
78 |         # # dict_keys(['edge_index', 'pos', 'batch', 'ptr', 'cell', 'pbc', 'edge_cell_shift', 'r_max', 'atom_types'])
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
79 |         # print("edge_index", data['edge_index'].size())
80 |         # print("pos", data['pos'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:79:9: ERA001 Found commented-out code
   |
77 |         # print("after", data.keys())
78 |         # # dict_keys(['edge_index', 'pos', 'batch', 'ptr', 'cell', 'pbc', 'edge_cell_shift', 'r_max', 'atom_types'])
79 |         # print("edge_index", data['edge_index'].size())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
80 |         # print("pos", data['pos'].size())
81 |         # print("atom_types", data['atom_types'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:80:9: ERA001 Found commented-out code
   |
78 |         # # dict_keys(['edge_index', 'pos', 'batch', 'ptr', 'cell', 'pbc', 'edge_cell_shift', 'r_max', 'atom_types'])
79 |         # print("edge_index", data['edge_index'].size())
80 |         # print("pos", data['pos'].size())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
81 |         # print("atom_types", data['atom_types'].size())
82 |         # print("batch", data['batch'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:81:9: ERA001 Found commented-out code
   |
79 |         # print("edge_index", data['edge_index'].size())
80 |         # print("pos", data['pos'].size())
81 |         # print("atom_types", data['atom_types'].size())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
82 |         # print("batch", data['batch'].size())
83 |         # print("r_max", data['r_max'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:82:9: ERA001 Found commented-out code
   |
80 |         # print("pos", data['pos'].size())
81 |         # print("atom_types", data['atom_types'].size())
82 |         # print("batch", data['batch'].size())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
83 |         # print("r_max", data['r_max'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:83:9: ERA001 Found commented-out code
   |
81 |         # print("atom_types", data['atom_types'].size())
82 |         # print("batch", data['batch'].size())
83 |         # print("r_max", data['r_max'].size())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
84 | 
85 |         # print("ptr", data['ptr'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:85:9: ERA001 Found commented-out code
   |
83 |         # print("r_max", data['r_max'].size())
84 | 
85 |         # print("ptr", data['ptr'].size())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
86 |         # print("cell", data['cell'].size())
87 |         # print("pbc", data['pbc'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:86:9: ERA001 Found commented-out code
   |
85 |         # print("ptr", data['ptr'].size())
86 |         # print("cell", data['cell'].size())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
87 |         # print("pbc", data['pbc'].size())
88 |         # print("edge_cell_shift", data['edge_cell_shift'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:87:9: ERA001 Found commented-out code
   |
85 |         # print("ptr", data['ptr'].size())
86 |         # print("cell", data['cell'].size())
87 |         # print("pbc", data['pbc'].size())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
88 |         # print("edge_cell_shift", data['edge_cell_shift'].size())
89 |         # del data['ptr']
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:88:9: ERA001 Found commented-out code
   |
86 |         # print("cell", data['cell'].size())
87 |         # print("pbc", data['pbc'].size())
88 |         # print("edge_cell_shift", data['edge_cell_shift'].size())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
89 |         # del data['ptr']
90 |         # del data['cell']
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:89:9: ERA001 Found commented-out code
   |
87 |         # print("pbc", data['pbc'].size())
88 |         # print("edge_cell_shift", data['edge_cell_shift'].size())
89 |         # del data['ptr']
   |         ^^^^^^^^^^^^^^^^^ ERA001
90 |         # del data['cell']
91 |         # del data['pbc']
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:90:9: ERA001 Found commented-out code
   |
88 |         # print("edge_cell_shift", data['edge_cell_shift'].size())
89 |         # del data['ptr']
90 |         # del data['cell']
   |         ^^^^^^^^^^^^^^^^^^ ERA001
91 |         # del data['pbc']
92 |         # del data['edge_cell_shift']
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:91:9: ERA001 Found commented-out code
   |
89 |         # del data['ptr']
90 |         # del data['cell']
91 |         # del data['pbc']
   |         ^^^^^^^^^^^^^^^^^ ERA001
92 |         # del data['edge_cell_shift']
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:92:9: ERA001 Found commented-out code
   |
90 |         # del data['cell']
91 |         # del data['pbc']
92 |         # del data['edge_cell_shift']
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
93 | 
94 |         # print("after", data.keys())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:94:9: ERA001 Found commented-out code
   |
92 |         # del data['edge_cell_shift']
93 | 
94 |         # print("after", data.keys())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
95 |         # print("edge_index", data['edge_index'].size())
96 |         # print("pos", data['pos'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:95:9: ERA001 Found commented-out code
   |
94 |         # print("after", data.keys())
95 |         # print("edge_index", data['edge_index'].size())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
96 |         # print("pos", data['pos'].size())
97 |         # print("atom_types", data['atom_types'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:96:9: ERA001 Found commented-out code
   |
94 |         # print("after", data.keys())
95 |         # print("edge_index", data['edge_index'].size())
96 |         # print("pos", data['pos'].size())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
97 |         # print("atom_types", data['atom_types'].size())
98 |         # print("batch", data['batch'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:97:9: ERA001 Found commented-out code
   |
95 |         # print("edge_index", data['edge_index'].size())
96 |         # print("pos", data['pos'].size())
97 |         # print("atom_types", data['atom_types'].size())
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
98 |         # print("batch", data['batch'].size())
99 |         # # print("r_max", data['r_max'].size())
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:98:9: ERA001 Found commented-out code
    |
 96 |         # print("pos", data['pos'].size())
 97 |         # print("atom_types", data['atom_types'].size())
 98 |         # print("batch", data['batch'].size())
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
 99 |         # # print("r_max", data['r_max'].size())
100 |         # # print("ptr", data['ptr'].size())
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:99:9: ERA001 Found commented-out code
    |
 97 |         # print("atom_types", data['atom_types'].size())
 98 |         # print("batch", data['batch'].size())
 99 |         # # print("r_max", data['r_max'].size())
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
100 |         # # print("ptr", data['ptr'].size())
101 |         # # print("cell", data['cell'].size())
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:100:9: ERA001 Found commented-out code
    |
 98 |         # print("batch", data['batch'].size())
 99 |         # # print("r_max", data['r_max'].size())
100 |         # # print("ptr", data['ptr'].size())
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
101 |         # # print("cell", data['cell'].size())
102 |         # # print("pbc", data['pbc'].size())
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:101:9: ERA001 Found commented-out code
    |
 99 |         # # print("r_max", data['r_max'].size())
100 |         # # print("ptr", data['ptr'].size())
101 |         # # print("cell", data['cell'].size())
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
102 |         # # print("pbc", data['pbc'].size())
103 |         # # print("edge_cell_shift", data['edge_cell_shift'].size())
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:102:9: ERA001 Found commented-out code
    |
100 |         # # print("ptr", data['ptr'].size())
101 |         # # print("cell", data['cell'].size())
102 |         # # print("pbc", data['pbc'].size())
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
103 |         # # print("edge_cell_shift", data['edge_cell_shift'].size())
104 |         # # exit()
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:103:9: ERA001 Found commented-out code
    |
101 |         # # print("cell", data['cell'].size())
102 |         # # print("pbc", data['pbc'].size())
103 |         # # print("edge_cell_shift", data['edge_cell_shift'].size())
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
104 |         # # exit()
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:104:9: ERA001 Found commented-out code
    |
102 |         # # print("pbc", data['pbc'].size())
103 |         # # print("edge_cell_shift", data['edge_cell_shift'].size())
104 |         # # exit()
    |         ^^^^^^^^^^ ERA001
105 | 
106 |         # set req grad
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:108:28: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
106 |         # set req grad
107 |         wrt_tensors = []
108 |         old_requires_grad: List[bool] = []
    |                            ^^^^ FA100
109 |         for k in self.wrt:
110 |             old_requires_grad.append(data[k].requires_grad)
    |

geom3d\models\NequIP\nn\_grad_output.py:111:36: FBT003 Boolean positional value in function call
    |
109 |         for k in self.wrt:
110 |             old_requires_grad.append(data[k].requires_grad)
111 |             data[k].requires_grad_(True)
    |                                    ^^^^ FBT003
112 |             wrt_tensors.append(data[k])
113 |         # run func
    |

geom3d\models\NequIP\nn\_grad_output.py:117:15: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
115 |         # Get grads
116 |         grads = torch.autograd.grad(
117 |             # TODO:
    |               ^^^^ TD002
118 |             # This makes sense for scalar batch-level or batch-wise outputs, specifically because d(sum(batches))/d wrt = sum(d batch / d wrt) = d my_batch / d wrt
119 |             # for a well-behaved example level like energy where d other_batch / d wrt is always zero. (In other words, the energy of example 1 in the batch is completely unaffect by changes in the position of atoms in another example.)
    |

geom3d\models\NequIP\nn\_grad_output.py:117:15: TD005 Missing issue description after `TODO`
    |
115 |         # Get grads
116 |         grads = torch.autograd.grad(
117 |             # TODO:
    |               ^^^^ TD005
118 |             # This makes sense for scalar batch-level or batch-wise outputs, specifically because d(sum(batches))/d wrt = sum(d batch / d wrt) = d my_batch / d wrt
119 |             # for a well-behaved example level like energy where d other_batch / d wrt is always zero. (In other words, the energy of example 1 in the batch is completely unaffect by changes in the position of atoms in another example.)
    |

geom3d\models\NequIP\nn\_grad_output.py:117:15: TD003 Missing issue link on the line following this TODO
    |
115 |         # Get grads
116 |         grads = torch.autograd.grad(
117 |             # TODO:
    |               ^^^^ TD003
118 |             # This makes sense for scalar batch-level or batch-wise outputs, specifically because d(sum(batches))/d wrt = sum(d batch / d wrt) = d my_batch / d wrt
119 |             # for a well-behaved example level like energy where d other_batch / d wrt is always zero. (In other words, the energy of example 1 in the batch is completely unaffect by changes in the position of atoms in another example.)
    |

geom3d\models\NequIP\nn\_grad_output.py:117:15: FIX002 Line contains TODO, consider resolving the issue
    |
115 |         # Get grads
116 |         grads = torch.autograd.grad(
117 |             # TODO:
    |               ^^^^ FIX002
118 |             # This makes sense for scalar batch-level or batch-wise outputs, specifically because d(sum(batches))/d wrt = sum(d batch / d wrt) = d my_batch / d wrt
119 |             # for a well-behaved example level like energy where d other_batch / d wrt is always zero. (In other words, the energy of example 1 in the batch is completely unaffect by changes in the position of atoms in another example.)
    |

geom3d\models\NequIP\nn\_grad_output.py:125:9: ERA001 Found commented-out code
    |
123 |             create_graph=self.training,  # needed to allow gradients of this output during training
124 |         )
125 |         # return
    |         ^^^^^^^^ ERA001
126 |         # grad is optional[tensor]?
127 |         for out, grad in zip(self.out_field, grads):
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:129:53: RUF003 Comment contains ambiguous `’` (RIGHT SINGLE QUOTATION MARK). Did you mean ``` (GRAVE ACCENT)?
    |
127 |         for out, grad in zip(self.out_field, grads):
128 |             if grad is None:
129 |                 # From the docs: "If an output doesn’t require_grad, then the gradient can be None"
    |                                                     ^ RUF003
130 |                 msg = "Something is wrong, gradient couldn't be computed"
131 |                 raise RuntimeError(msg)
    |

geom3d\models\NequIP\nn\_grad_output.py:134:17: PLW2901 `for` loop variable `grad` overwritten by assignment target
    |
133 |             if self._negate:
134 |                 grad = torch.neg(grad)
    |                 ^^^^ PLW2901
135 |             data[out] = grad
    |

geom3d\models\NequIP\nn\_grad_output.py:161:9: FBT001 Boolean-typed positional argument in function definition
    |
159 |         self,
160 |         func: GraphModuleMixin,
161 |         vectorize: bool = False,
    |         ^^^^^^^^^ FBT001
162 |         vectorize_warnings: bool = False,
163 |     ):
    |

geom3d\models\NequIP\nn\_grad_output.py:161:9: FBT002 Boolean default positional argument in function definition
    |
159 |         self,
160 |         func: GraphModuleMixin,
161 |         vectorize: bool = False,
    |         ^^^^^^^^^ FBT002
162 |         vectorize_warnings: bool = False,
163 |     ):
    |

geom3d\models\NequIP\nn\_grad_output.py:162:9: FBT001 Boolean-typed positional argument in function definition
    |
160 |         func: GraphModuleMixin,
161 |         vectorize: bool = False,
162 |         vectorize_warnings: bool = False,
    |         ^^^^^^^^^^^^^^^^^^ FBT001
163 |     ):
164 |         super().__init__()
    |

geom3d\models\NequIP\nn\_grad_output.py:162:9: FBT002 Boolean default positional argument in function definition
    |
160 |         func: GraphModuleMixin,
161 |         vectorize: bool = False,
162 |         vectorize_warnings: bool = False,
    |         ^^^^^^^^^^^^^^^^^^ FBT002
163 |     ):
164 |         super().__init__()
    |

geom3d\models\NequIP\nn\_grad_output.py:169:13: SLF001 Private member accessed: `_C`
    |
167 |         if vectorize_warnings:
168 |             # See https://pytorch.org/docs/stable/generated/torch.autograd.functional.jacobian.html
169 |             torch._C._debug_only_display_vmap_fallback_warnings(True)
    |             ^^^^^^^^ SLF001
170 | 
171 |         # check and init irreps
    |

geom3d\models\NequIP\nn\_grad_output.py:169:13: SLF001 Private member accessed: `_debug_only_display_vmap_fallback_warnings`
    |
167 |         if vectorize_warnings:
168 |             # See https://pytorch.org/docs/stable/generated/torch.autograd.functional.jacobian.html
169 |             torch._C._debug_only_display_vmap_fallback_warnings(True)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
170 | 
171 |         # check and init irreps
    |

geom3d\models\NequIP\nn\_grad_output.py:169:65: FBT003 Boolean positional value in function call
    |
167 |         if vectorize_warnings:
168 |             # See https://pytorch.org/docs/stable/generated/torch.autograd.functional.jacobian.html
169 |             torch._C._debug_only_display_vmap_fallback_warnings(True)
    |                                                                 ^^^^ FBT003
170 | 
171 |         # check and init irreps
    |

geom3d\models\NequIP\nn\_grad_output.py:185:13: D401 First line of docstring should be in imperative mood: "Wrapper from pos to atomic energy."
    |
184 |         def wrapper(pos: torch.Tensor) -> torch.Tensor:
185 |             """Wrapper from pos to atomic energy."""
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
186 |             nonlocal data, out_data
187 |             data[AtomicDataDict.POSITIONS_KEY] = pos
    |

geom3d\models\NequIP\nn\_grad_output.py:200:9: ERA001 Found commented-out code
    |
198 |         )
199 |         partial_forces = partial_forces.negative()
200 |         # output is [n_at, n_at, 3]
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
201 | 
202 |         out_data[AtomicDataDict.PARTIAL_FORCE_KEY] = partial_forces
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\_grad_output.py:228:9: FBT001 Boolean-typed positional argument in function definition
    |
226 |         self,
227 |         func: GraphModuleMixin,
228 |         do_forces: bool = True,
    |         ^^^^^^^^^ FBT001
229 |     ):
230 |         super().__init__()
    |

geom3d\models\NequIP\nn\_grad_output.py:228:9: FBT002 Boolean default positional argument in function definition
    |
226 |         self,
227 |         func: GraphModuleMixin,
228 |         do_forces: bool = True,
    |         ^^^^^^^^^ FBT002
229 |     ):
230 |         super().__init__()
    |

geom3d\models\NequIP\nn\_grad_output.py:232:9: B028 No explicit `stacklevel` keyword argument found
    |
230 |         super().__init__()
231 | 
232 |         warnings.warn(
    |         ^^^^^^^^^^^^^ B028
233 |             "!! Stresses in NequIP are in BETA and UNDER DEVELOPMENT: _please_ carefully check the sanity of your results and report any (potential) issues on the GitHub"
234 |         )
    |

geom3d\models\NequIP\nn\_grad_output.py:286:37: FBT003 Boolean positional value in function call
    |
284 |             device=pos.device,
285 |         )
286 |         displacement.requires_grad_(True)
    |                                     ^^^^ FBT003
287 |         data["_displacement"] = displacement
288 |         # in the above paper, the infinitesimal distortion is *symmetric*
    |

geom3d\models\NequIP\nn\_grad_output.py:301:28: FBT003 Boolean positional value in function call
    |
299 |         symmetric_displacement = 0.5 * (displacement + displacement.transpose(-1, -2))
300 |         did_pos_req_grad: bool = pos.requires_grad
301 |         pos.requires_grad_(True)
    |                            ^^^^ FBT003
302 |         # bmm is natom in batch
303 |         data[AtomicDataDict.POSITIONS_KEY] = pos + torch.bmm(
    |

geom3d\models\NequIP\nn\_grad_output.py:372:32: FBT003 Boolean positional value in function call
    |
370 |         if not did_pos_req_grad:
371 |             # don't give later modules one that does
372 |             pos.requires_grad_(False)
    |                                ^^^^^ FBT003
373 | 
374 |         return data
    |

geom3d\models\NequIP\nn\_graph_mixin.py:26:9: C901 `_init_irreps` is too complex (12 > 10)
   |
24 |     """
25 | 
26 |     def _init_irreps(
   |         ^^^^^^^^^^^^ C901
27 |         self,
28 |         irreps_in: Optional[Dict[str, Any]] = None,
   |

geom3d\models\NequIP\nn\_graph_mixin.py:28:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
26 |     def _init_irreps(
27 |         self,
28 |         irreps_in: Optional[Dict[str, Any]] = None,
   |                    ^^^^^^^^ FA100
29 |         my_irreps_in: Optional[Dict[str, Any]] = None,
30 |         required_irreps_in: Sequence[str] = [],
   |

geom3d\models\NequIP\nn\_graph_mixin.py:28:29: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
26 |     def _init_irreps(
27 |         self,
28 |         irreps_in: Optional[Dict[str, Any]] = None,
   |                             ^^^^ FA100
29 |         my_irreps_in: Optional[Dict[str, Any]] = None,
30 |         required_irreps_in: Sequence[str] = [],
   |

geom3d\models\NequIP\nn\_graph_mixin.py:29:23: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
27 |         self,
28 |         irreps_in: Optional[Dict[str, Any]] = None,
29 |         my_irreps_in: Optional[Dict[str, Any]] = None,
   |                       ^^^^^^^^ FA100
30 |         required_irreps_in: Sequence[str] = [],
31 |         irreps_out: Optional[Dict[str, Any]] = None,
   |

geom3d\models\NequIP\nn\_graph_mixin.py:29:32: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
27 |         self,
28 |         irreps_in: Optional[Dict[str, Any]] = None,
29 |         my_irreps_in: Optional[Dict[str, Any]] = None,
   |                                ^^^^ FA100
30 |         required_irreps_in: Sequence[str] = [],
31 |         irreps_out: Optional[Dict[str, Any]] = None,
   |

geom3d\models\NequIP\nn\_graph_mixin.py:31:21: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
29 |         my_irreps_in: Optional[Dict[str, Any]] = None,
30 |         required_irreps_in: Sequence[str] = [],
31 |         irreps_out: Optional[Dict[str, Any]] = None,
   |                     ^^^^^^^^ FA100
32 |     ) -> None:
33 |         """Setup the expected data fields and their irreps for this graph module.
   |

geom3d\models\NequIP\nn\_graph_mixin.py:31:30: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
29 |         my_irreps_in: Optional[Dict[str, Any]] = None,
30 |         required_irreps_in: Sequence[str] = [],
31 |         irreps_out: Optional[Dict[str, Any]] = None,
   |                              ^^^^ FA100
32 |     ) -> None:
33 |         """Setup the expected data fields and their irreps for this graph module.
   |

geom3d\models\NequIP\nn\_graph_mixin.py:33:9: D401 First line of docstring should be in imperative mood: "Setup the expected data fields and their irreps for this graph module."
   |
31 |           irreps_out: Optional[Dict[str, Any]] = None,
32 |       ) -> None:
33 |           """Setup the expected data fields and their irreps for this graph module.
   |  _________^
34 | | 
35 | |         ``None`` is a valid irreps in the context for anything that is invariant but not well described by an ``e3nn.o3.Irreps``. An example are edge indexes in a graph, which are invariant but are integers, not ``0e`` scalars.
36 | | 
37 | |         Args:
38 | |         ----
39 | |             irreps_in (dict): maps names of all input fields from previous modules or
40 | |                 data to their corresponding irreps
41 | |             my_irreps_in (dict): maps names of fields to the irreps they must have for
42 | |                 this graph module. Will be checked for consistancy with ``irreps_in``
43 | |             required_irreps_in: sequence of names of fields that must be present in
44 | |                 ``irreps_in``, but that can have any irreps.
45 | |             irreps_out (dict): mapping names of fields that are modified/output by
46 | |                 this graph module to their irreps.
47 | | 
48 | |         """
   | |___________^ D401
49 |           # Coerce
50 |           if irreps_out is None:
   |

geom3d\models\NequIP\nn\_graph_mixin.py:57:21: SLF001 Private member accessed: `_fix_irreps_dict`
   |
55 |             irreps_in = {}
56 |         irreps_in = {} if irreps_in is None else irreps_in
57 |         irreps_in = AtomicDataDict._fix_irreps_dict(irreps_in)
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
58 |         # positions are *always* 1o, and always present
59 |         if AtomicDataDict.POSITIONS_KEY in irreps_in:
   |

geom3d\models\NequIP\nn\_graph_mixin.py:59:9: SIM102 Use a single `if` statement instead of nested `if` statements
   |
57 |           irreps_in = AtomicDataDict._fix_irreps_dict(irreps_in)
58 |           # positions are *always* 1o, and always present
59 |           if AtomicDataDict.POSITIONS_KEY in irreps_in:
   |  _________^
60 | |             if irreps_in[AtomicDataDict.POSITIONS_KEY] != o3.Irreps("1x1o"):
   | |____________________________________________________________________________^ SIM102
61 |                   msg = f"Positions must have irreps 1o, got instead `{irreps_in[AtomicDataDict.POSITIONS_KEY]}`"
62 |                   raise ValueError(
   |
   = help: Combine `if` statements using `and`

geom3d\models\NequIP\nn\_graph_mixin.py:67:9: SIM102 Use a single `if` statement instead of nested `if` statements
   |
65 |           irreps_in[AtomicDataDict.POSITIONS_KEY] = o3.Irreps("1o")
66 |           # edges are also always present
67 |           if AtomicDataDict.EDGE_INDEX_KEY in irreps_in:
   |  _________^
68 | |             if irreps_in[AtomicDataDict.EDGE_INDEX_KEY] is not None:
   | |____________________________________________________________________^ SIM102
69 |                   msg = f"Edge indexes must have irreps None, got instead `{irreps_in[AtomicDataDict.EDGE_INDEX_KEY]}`"
70 |                   raise ValueError(
   |
   = help: Combine `if` statements using `and`

geom3d\models\NequIP\nn\_graph_mixin.py:75:24: SLF001 Private member accessed: `_fix_irreps_dict`
   |
73 |         irreps_in[AtomicDataDict.EDGE_INDEX_KEY] = None
74 | 
75 |         my_irreps_in = AtomicDataDict._fix_irreps_dict(my_irreps_in)
   |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
76 | 
77 |         irreps_out = AtomicDataDict._fix_irreps_dict(irreps_out)
   |

geom3d\models\NequIP\nn\_graph_mixin.py:77:22: SLF001 Private member accessed: `_fix_irreps_dict`
   |
75 |         my_irreps_in = AtomicDataDict._fix_irreps_dict(my_irreps_in)
76 | 
77 |         irreps_out = AtomicDataDict._fix_irreps_dict(irreps_out)
   |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
78 |         # Confirm compatibility:
79 |         # with my_irreps_in
   |

geom3d\models\NequIP\nn\_graph_mixin.py:100:47: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
    |
 98 |         self.irreps_out = new_out
 99 | 
100 |     def _add_independent_irreps(self, irreps: Dict[str, Any]) -> None:
    |                                               ^^^^ FA100
101 |         """Insert some independent irreps that need to be exposed to the self.irreps_in and self.irreps_out.
102 |         The terms that have already appeared in the irreps_in will be removed.
    |

geom3d\models\NequIP\nn\_graph_mixin.py:101:9: D205 1 blank line required between summary line and description
    |
100 |       def _add_independent_irreps(self, irreps: Dict[str, Any]) -> None:
101 |           """Insert some independent irreps that need to be exposed to the self.irreps_in and self.irreps_out.
    |  _________^
102 | |         The terms that have already appeared in the irreps_in will be removed.
103 | | 
104 | |         Args:
105 | |         ----
106 | |             irreps (dict): maps names of all new fields
107 | | 
108 | |         """
    | |___________^ D205
109 |           irreps = {
110 |               key: irrep for key, irrep in irreps.items() if key not in self.irreps_in
    |
    = help: Insert single blank line

geom3d\models\NequIP\nn\_graph_mixin.py:112:21: SLF001 Private member accessed: `_fix_irreps_dict`
    |
110 |             key: irrep for key, irrep in irreps.items() if key not in self.irreps_in
111 |         }
112 |         irreps_in = AtomicDataDict._fix_irreps_dict(irreps)
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
113 |         irreps_out = AtomicDataDict._fix_irreps_dict(
114 |             {key: irrep for key, irrep in irreps.items() if key not in self.irreps_out}
    |

geom3d\models\NequIP\nn\_graph_mixin.py:113:22: SLF001 Private member accessed: `_fix_irreps_dict`
    |
111 |         }
112 |         irreps_in = AtomicDataDict._fix_irreps_dict(irreps)
113 |         irreps_out = AtomicDataDict._fix_irreps_dict(
    |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
114 |             {key: irrep for key, irrep in irreps.items() if key not in self.irreps_out}
115 |         )
    |

geom3d\models\NequIP\nn\_graph_mixin.py:119:9: ANN202 Missing return type annotation for private function `_make_tracing_inputs`
    |
117 |         self.irreps_out.update(irreps_out)
118 | 
119 |     def _make_tracing_inputs(self, n):
    |         ^^^^^^^^^^^^^^^^^^^^ ANN202
120 |         # We impliment this to be able to trace graph modules
121 |         out = []
    |
    = help: Add return type annotation

geom3d\models\NequIP\nn\_graph_mixin.py:123:21: S311 Standard pseudo-random generators are not suitable for cryptographic purposes
    |
121 |         out = []
122 |         for _ in range(n):
123 |             batch = random.randint(1, 4)
    |                     ^^^^^^^^^^^^^^^^^^^^ S311
124 |             # TODO: handle None case
125 |             # TODO: do only required inputs
    |

geom3d\models\NequIP\nn\_graph_mixin.py:124:15: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
122 |         for _ in range(n):
123 |             batch = random.randint(1, 4)
124 |             # TODO: handle None case
    |               ^^^^ TD002
125 |             # TODO: do only required inputs
126 |             # TODO: dummy input if empty?
    |

geom3d\models\NequIP\nn\_graph_mixin.py:124:15: TD003 Missing issue link on the line following this TODO
    |
122 |         for _ in range(n):
123 |             batch = random.randint(1, 4)
124 |             # TODO: handle None case
    |               ^^^^ TD003
125 |             # TODO: do only required inputs
126 |             # TODO: dummy input if empty?
    |

geom3d\models\NequIP\nn\_graph_mixin.py:124:15: FIX002 Line contains TODO, consider resolving the issue
    |
122 |         for _ in range(n):
123 |             batch = random.randint(1, 4)
124 |             # TODO: handle None case
    |               ^^^^ FIX002
125 |             # TODO: do only required inputs
126 |             # TODO: dummy input if empty?
    |

geom3d\models\NequIP\nn\_graph_mixin.py:125:15: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
123 |             batch = random.randint(1, 4)
124 |             # TODO: handle None case
125 |             # TODO: do only required inputs
    |               ^^^^ TD002
126 |             # TODO: dummy input if empty?
127 |             out.append(
    |

geom3d\models\NequIP\nn\_graph_mixin.py:125:15: TD003 Missing issue link on the line following this TODO
    |
123 |             batch = random.randint(1, 4)
124 |             # TODO: handle None case
125 |             # TODO: do only required inputs
    |               ^^^^ TD003
126 |             # TODO: dummy input if empty?
127 |             out.append(
    |

geom3d\models\NequIP\nn\_graph_mixin.py:125:15: FIX002 Line contains TODO, consider resolving the issue
    |
123 |             batch = random.randint(1, 4)
124 |             # TODO: handle None case
125 |             # TODO: do only required inputs
    |               ^^^^ FIX002
126 |             # TODO: dummy input if empty?
127 |             out.append(
    |

geom3d\models\NequIP\nn\_graph_mixin.py:126:15: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
124 |             # TODO: handle None case
125 |             # TODO: do only required inputs
126 |             # TODO: dummy input if empty?
    |               ^^^^ TD002
127 |             out.append(
128 |                 {
    |

geom3d\models\NequIP\nn\_graph_mixin.py:126:15: TD003 Missing issue link on the line following this TODO
    |
124 |             # TODO: handle None case
125 |             # TODO: do only required inputs
126 |             # TODO: dummy input if empty?
    |               ^^^^ TD003
127 |             out.append(
128 |                 {
    |

geom3d\models\NequIP\nn\_graph_mixin.py:126:15: FIX002 Line contains TODO, consider resolving the issue
    |
124 |             # TODO: handle None case
125 |             # TODO: do only required inputs
126 |             # TODO: dummy input if empty?
    |               ^^^^ FIX002
127 |             out.append(
128 |                 {
    |

geom3d\models\NequIP\nn\_graph_mixin.py:152:18: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
    |
150 |     def __init__(
151 |         self,
152 |         modules: Union[Sequence[GraphModuleMixin], Dict[str, GraphModuleMixin]],
    |                  ^^^^^ FA100
153 |     ):
154 |         if isinstance(modules, dict):
    |

geom3d\models\NequIP\nn\_graph_mixin.py:152:52: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
    |
150 |     def __init__(
151 |         self,
152 |         modules: Union[Sequence[GraphModuleMixin], Dict[str, GraphModuleMixin]],
    |                                                    ^^^^ FA100
153 |     ):
154 |         if isinstance(modules, dict):
    |

geom3d\models\NequIP\nn\_graph_mixin.py:158:9: ERA001 Found commented-out code
    |
156 |         else:
157 |             module_list = list(modules)
158 |         # print("module_list", module_list)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
159 |         # check in/out irreps compatible
160 |         for m1, m2 in zip(module_list, module_list[1:]):
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\_graph_mixin.py:161:13: S101 Use of `assert` detected
    |
159 |         # check in/out irreps compatible
160 |         for m1, m2 in zip(module_list, module_list[1:]):
161 |             assert AtomicDataDict._irreps_compatible(
    |             ^^^^^^ S101
162 |                 m1.irreps_out, m2.irreps_in
163 |             ), f"Incompatible irreps_out from {type(m1).__name__} for input to {type(m2).__name__}: {m1.irreps_out} -> {m2.irreps_in}"
    |

geom3d\models\NequIP\nn\_graph_mixin.py:161:20: SLF001 Private member accessed: `_irreps_compatible`
    |
159 |         # check in/out irreps compatible
160 |         for m1, m2 in zip(module_list, module_list[1:]):
161 |             assert AtomicDataDict._irreps_compatible(
    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
162 |                 m1.irreps_out, m2.irreps_in
163 |             ), f"Incompatible irreps_out from {type(m1).__name__} for input to {type(m2).__name__}: {m1.irreps_out} -> {m2.irreps_in}"
    |

geom3d\models\NequIP\nn\_graph_mixin.py:177:9: ANN206 Missing return type annotation for classmethod `from_parameters`
    |
176 |     @classmethod
177 |     def from_parameters(
    |         ^^^^^^^^^^^^^^^ ANN206
178 |         cls,
179 |         shared_params: Mapping,
    |
    = help: Add return type annotation

geom3d\models\NequIP\nn\_graph_mixin.py:180:17: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
    |
178 |         cls,
179 |         shared_params: Mapping,
180 |         layers: Dict[str, Union[Callable, Tuple[Callable, Dict[str, Any]]]],
    |                 ^^^^ FA100
181 |         irreps_in: Optional[dict] = None,
182 |     ):
    |

geom3d\models\NequIP\nn\_graph_mixin.py:180:27: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
    |
178 |         cls,
179 |         shared_params: Mapping,
180 |         layers: Dict[str, Union[Callable, Tuple[Callable, Dict[str, Any]]]],
    |                           ^^^^^ FA100
181 |         irreps_in: Optional[dict] = None,
182 |     ):
    |

geom3d\models\NequIP\nn\_graph_mixin.py:180:43: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
    |
178 |         cls,
179 |         shared_params: Mapping,
180 |         layers: Dict[str, Union[Callable, Tuple[Callable, Dict[str, Any]]]],
    |                                           ^^^^^ FA100
181 |         irreps_in: Optional[dict] = None,
182 |     ):
    |

geom3d\models\NequIP\nn\_graph_mixin.py:180:59: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
    |
178 |         cls,
179 |         shared_params: Mapping,
180 |         layers: Dict[str, Union[Callable, Tuple[Callable, Dict[str, Any]]]],
    |                                                           ^^^^ FA100
181 |         irreps_in: Optional[dict] = None,
182 |     ):
    |

geom3d\models\NequIP\nn\_graph_mixin.py:181:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
179 |         shared_params: Mapping,
180 |         layers: Dict[str, Union[Callable, Tuple[Callable, Dict[str, Any]]]],
181 |         irreps_in: Optional[dict] = None,
    |                    ^^^^^^^^ FA100
182 |     ):
183 |         r"""Construct a ``SequentialGraphModule`` of modules built from a shared set of parameters.
    |

geom3d\models\NequIP\nn\_graph_mixin.py:209:17: TRY004 Prefer `TypeError` exception for invalid type
    |
207 |             if not isinstance(name, str):
208 |                 msg = f"`'name'` must be a str; got `{name}`"
209 |                 raise ValueError(msg)
    |                 ^^^^^^^^^^^^^^^^^^^^^ TRY004
210 |             if isinstance(builder, tuple):
211 |                 builder, params = builder
    |

geom3d\models\NequIP\nn\_graph_mixin.py:211:17: PLW2901 `for` loop variable `builder` overwritten by assignment target
    |
209 |                 raise ValueError(msg)
210 |             if isinstance(builder, tuple):
211 |                 builder, params = builder
    |                 ^^^^^^^ PLW2901
212 |             else:
213 |                 params = {}
    |

geom3d\models\NequIP\nn\_graph_mixin.py:257:9: S101 Use of `assert` detected
    |
256 |         """
257 |         assert AtomicDataDict._irreps_compatible(self.irreps_out, module.irreps_in)
    |         ^^^^^^ S101
258 |         self.add_module(name, module)
259 |         self.irreps_out = dict(module.irreps_out)
    |

geom3d\models\NequIP\nn\_graph_mixin.py:257:16: SLF001 Private member accessed: `_irreps_compatible`
    |
256 |         """
257 |         assert AtomicDataDict._irreps_compatible(self.irreps_out, module.irreps_in)
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
258 |         self.add_module(name, module)
259 |         self.irreps_out = dict(module.irreps_out)
    |

geom3d\models\NequIP\nn\_graph_mixin.py:266:17: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
264 |         name: str,
265 |         builder: Callable,
266 |         params: Optional[Dict[str, Any]] = None,
    |                 ^^^^^^^^ FA100
267 |     ) -> None:
268 |         r"""Build a module from parameters and append it.
    |

geom3d\models\NequIP\nn\_graph_mixin.py:266:26: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
    |
264 |         name: str,
265 |         builder: Callable,
266 |         params: Optional[Dict[str, Any]] = None,
    |                          ^^^^ FA100
267 |     ) -> None:
268 |         r"""Build a module from parameters and append it.
    |

geom3d\models\NequIP\nn\_graph_mixin.py:293:16: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
291 |         name: str,
292 |         module: GraphModuleMixin,
293 |         after: Optional[str] = None,
    |                ^^^^^^^^ FA100
294 |         before: Optional[str] = None,
295 |     ) -> None:
    |

geom3d\models\NequIP\nn\_graph_mixin.py:294:17: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
292 |         module: GraphModuleMixin,
293 |         after: Optional[str] = None,
294 |         before: Optional[str] = None,
    |                 ^^^^^^^^ FA100
295 |     ) -> None:
296 |         """Insert a module after the module with name ``after``.
    |

geom3d\models\NequIP\nn\_graph_mixin.py:309:9: RET506 Unnecessary `elif` after `raise` statement
    |
307 |             msg = "Only one of before or after argument needs to be defined"
308 |             raise ValueError(msg)
309 |         elif before is None:
    |         ^^^^ RET506
310 |             insert_location = after
311 |         else:
    |
    = help: Remove unnecessary `elif`

geom3d\models\NequIP\nn\_graph_mixin.py:331:13: S101 Use of `assert` detected
    |
329 |         # sanity check the compatibility
330 |         if idx > 0:
331 |             assert AtomicDataDict._irreps_compatible(
    |             ^^^^^^ S101
332 |                 module_list[idx - 1].irreps_out, module.irreps_in
333 |             )
    |

geom3d\models\NequIP\nn\_graph_mixin.py:331:20: SLF001 Private member accessed: `_irreps_compatible`
    |
329 |         # sanity check the compatibility
330 |         if idx > 0:
331 |             assert AtomicDataDict._irreps_compatible(
    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
332 |                 module_list[idx - 1].irreps_out, module.irreps_in
333 |             )
    |

geom3d\models\NequIP\nn\_graph_mixin.py:335:13: S101 Use of `assert` detected
    |
333 |             )
334 |         if len(module_list) > idx:
335 |             assert AtomicDataDict._irreps_compatible(
    |             ^^^^^^ S101
336 |                 module_list[idx + 1].irreps_in, module.irreps_out
337 |             )
    |

geom3d\models\NequIP\nn\_graph_mixin.py:335:20: SLF001 Private member accessed: `_irreps_compatible`
    |
333 |             )
334 |         if len(module_list) > idx:
335 |             assert AtomicDataDict._irreps_compatible(
    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
336 |                 module_list[idx + 1].irreps_in, module.irreps_out
337 |             )
    |

geom3d\models\NequIP\nn\_graph_mixin.py:341:13: SLF001 Private member accessed: `_add_independent_irreps`
    |
339 |         # insert the new irreps_out to the later modules
340 |         for _module_id, next_module in enumerate(module_list[idx + 1 :]):
341 |             next_module._add_independent_irreps(module.irreps_out)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
342 | 
343 |         # update the final wrapper irreps_out
    |

geom3d\models\NequIP\nn\_graph_mixin.py:347:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
347 |     def insert_from_parameters(
    |         ^^^^^^^^^^^^^^^^^^^^^^ PLR0913
348 |         self,
349 |         shared_params: Mapping,
    |

geom3d\models\NequIP\nn\_graph_mixin.py:352:17: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
350 |         name: str,
351 |         builder: Callable,
352 |         params: Optional[Dict[str, Any]] = None,
    |                 ^^^^^^^^ FA100
353 |         after: Optional[str] = None,
354 |         before: Optional[str] = None,
    |

geom3d\models\NequIP\nn\_graph_mixin.py:352:26: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
    |
350 |         name: str,
351 |         builder: Callable,
352 |         params: Optional[Dict[str, Any]] = None,
    |                          ^^^^ FA100
353 |         after: Optional[str] = None,
354 |         before: Optional[str] = None,
    |

geom3d\models\NequIP\nn\_graph_mixin.py:353:16: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
351 |         builder: Callable,
352 |         params: Optional[Dict[str, Any]] = None,
353 |         after: Optional[str] = None,
    |                ^^^^^^^^ FA100
354 |         before: Optional[str] = None,
355 |     ) -> None:
    |

geom3d\models\NequIP\nn\_graph_mixin.py:354:17: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
352 |         params: Optional[Dict[str, Any]] = None,
353 |         after: Optional[str] = None,
354 |         before: Optional[str] = None,
    |                 ^^^^^^^^ FA100
355 |     ) -> None:
356 |         r"""Build a module from parameters and insert it after ``after``.
    |

geom3d\models\NequIP\nn\_graph_mixin.py:373:9: RET506 Unnecessary `elif` after `raise` statement
    |
371 |             msg = "Only one of before or after argument needs to be defined"
372 |             raise ValueError(msg)
373 |         elif before is None:
    |         ^^^^ RET506
374 |             insert_location = after
375 |         else:
    |
    = help: Remove unnecessary `elif`

geom3d\models\NequIP\nn\_graph_mixin.py:391:23: A002 Argument `input` is shadowing a Python builtin
    |
389 |     # Copied from https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#Sequential
390 |     # with type annotations added
391 |     def forward(self, input: AtomicDataDict.Type) -> AtomicDataDict.Type:
    |                       ^^^^^ A002
392 |         for module in self:
393 |             input = module(input)
    |

geom3d\models\NequIP\nn\_graph_mixin.py:393:13: A001 Variable `input` is shadowing a Python builtin
    |
391 |     def forward(self, input: AtomicDataDict.Type) -> AtomicDataDict.Type:
392 |         for module in self:
393 |             input = module(input)
    |             ^^^^^ A001
394 |         return input
    |

geom3d\models\NequIP\nn\_interaction_block.py:16:24: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
15 | class InteractionBlock(GraphModuleMixin, torch.nn.Module):
16 |     avg_num_neighbors: Optional[float]
   |                        ^^^^^^^^ FA100
17 |     use_sc: bool
   |

geom3d\models\NequIP\nn\_interaction_block.py:19:9: PLR0913 Too many arguments in function definition (7 > 5)
   |
17 |     use_sc: bool
18 | 
19 |     def __init__(
   |         ^^^^^^^^ PLR0913
20 |         self,
21 |         irreps_in,
   |

geom3d\models\NequIP\nn\_interaction_block.py:26:9: FBT002 Boolean default positional argument in function definition
   |
24 |         invariant_neurons=8,
25 |         avg_num_neighbors=None,
26 |         use_sc=True,
   |         ^^^^^^ FBT002
27 |         nonlinearity_scalars: Optional[Dict[int, Callable]] = None,
28 |     ) -> None:
   |

geom3d\models\NequIP\nn\_interaction_block.py:27:31: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
25 |         avg_num_neighbors=None,
26 |         use_sc=True,
27 |         nonlinearity_scalars: Optional[Dict[int, Callable]] = None,
   |                               ^^^^^^^^ FA100
28 |     ) -> None:
29 |         """InteractionBlock.
   |

geom3d\models\NequIP\nn\_interaction_block.py:27:40: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
25 |         avg_num_neighbors=None,
26 |         use_sc=True,
27 |         nonlinearity_scalars: Optional[Dict[int, Callable]] = None,
   |                                        ^^^^ FA100
28 |     ) -> None:
29 |         """InteractionBlock.
   |

geom3d\models\NequIP\nn\_rescale.py:32:17: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
30 |     """
31 | 
32 |     scale_keys: List[str]
   |                 ^^^^ FA100
33 |     shift_keys: List[str]
34 |     related_scale_keys: List[str]
   |

geom3d\models\NequIP\nn\_rescale.py:33:17: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
32 |     scale_keys: List[str]
33 |     shift_keys: List[str]
   |                 ^^^^ FA100
34 |     related_scale_keys: List[str]
35 |     related_shift_keys: List[str]
   |

geom3d\models\NequIP\nn\_rescale.py:34:25: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
32 |     scale_keys: List[str]
33 |     shift_keys: List[str]
34 |     related_scale_keys: List[str]
   |                         ^^^^ FA100
35 |     related_shift_keys: List[str]
36 |     scale_trainble: bool
   |

geom3d\models\NequIP\nn\_rescale.py:35:25: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
33 |     shift_keys: List[str]
34 |     related_scale_keys: List[str]
35 |     related_shift_keys: List[str]
   |                         ^^^^ FA100
36 |     scale_trainble: bool
37 |     rescale_trainable: bool
   |

geom3d\models\NequIP\nn\_rescale.py:42:9: C901 `__init__` is too complex (17 > 10)
   |
40 |     has_shift: bool
41 | 
42 |     def __init__(
   |         ^^^^^^^^ C901
43 |         self,
44 |         model: GraphModuleMixin,
   |

geom3d\models\NequIP\nn\_rescale.py:42:9: PLR0913 Too many arguments in function definition (10 > 5)
   |
40 |     has_shift: bool
41 | 
42 |     def __init__(
   |         ^^^^^^^^ PLR0913
43 |         self,
44 |         model: GraphModuleMixin,
   |

geom3d\models\NequIP\nn\_rescale.py:42:9: PLR0912 Too many branches (20 > 12)
   |
40 |     has_shift: bool
41 | 
42 |     def __init__(
   |         ^^^^^^^^ PLR0912
43 |         self,
44 |         model: GraphModuleMixin,
   |

geom3d\models\NequIP\nn\_rescale.py:42:9: PLR0915 Too many statements (52 > 50)
   |
40 |     has_shift: bool
41 | 
42 |     def __init__(
   |         ^^^^^^^^ PLR0915
43 |         self,
44 |         model: GraphModuleMixin,
   |

geom3d\models\NequIP\nn\_rescale.py:45:21: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
43 |         self,
44 |         model: GraphModuleMixin,
45 |         scale_keys: Union[Sequence[str], str] = [],
   |                     ^^^^^ FA100
46 |         shift_keys: Union[Sequence[str], str] = [],
47 |         related_shift_keys: Union[Sequence[str], str] = [],
   |

geom3d\models\NequIP\nn\_rescale.py:46:21: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
44 |         model: GraphModuleMixin,
45 |         scale_keys: Union[Sequence[str], str] = [],
46 |         shift_keys: Union[Sequence[str], str] = [],
   |                     ^^^^^ FA100
47 |         related_shift_keys: Union[Sequence[str], str] = [],
48 |         related_scale_keys: Union[Sequence[str], str] = [],
   |

geom3d\models\NequIP\nn\_rescale.py:47:29: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
45 |         scale_keys: Union[Sequence[str], str] = [],
46 |         shift_keys: Union[Sequence[str], str] = [],
47 |         related_shift_keys: Union[Sequence[str], str] = [],
   |                             ^^^^^ FA100
48 |         related_scale_keys: Union[Sequence[str], str] = [],
49 |         scale_by=None,
   |

geom3d\models\NequIP\nn\_rescale.py:48:29: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
46 |         shift_keys: Union[Sequence[str], str] = [],
47 |         related_shift_keys: Union[Sequence[str], str] = [],
48 |         related_scale_keys: Union[Sequence[str], str] = [],
   |                             ^^^^^ FA100
49 |         scale_by=None,
50 |         shift_by=None,
   |

geom3d\models\NequIP\nn\_rescale.py:51:9: FBT001 Boolean-typed positional argument in function definition
   |
49 |         scale_by=None,
50 |         shift_by=None,
51 |         shift_trainable: bool = False,
   |         ^^^^^^^^^^^^^^^ FBT001
52 |         scale_trainable: bool = False,
53 |         irreps_in: Optional[dict] = None,
   |

geom3d\models\NequIP\nn\_rescale.py:51:9: FBT002 Boolean default positional argument in function definition
   |
49 |         scale_by=None,
50 |         shift_by=None,
51 |         shift_trainable: bool = False,
   |         ^^^^^^^^^^^^^^^ FBT002
52 |         scale_trainable: bool = False,
53 |         irreps_in: Optional[dict] = None,
   |

geom3d\models\NequIP\nn\_rescale.py:52:9: FBT001 Boolean-typed positional argument in function definition
   |
50 |         shift_by=None,
51 |         shift_trainable: bool = False,
52 |         scale_trainable: bool = False,
   |         ^^^^^^^^^^^^^^^ FBT001
53 |         irreps_in: Optional[dict] = None,
54 |     ):
   |

geom3d\models\NequIP\nn\_rescale.py:52:9: FBT002 Boolean default positional argument in function definition
   |
50 |         shift_by=None,
51 |         shift_trainable: bool = False,
52 |         scale_trainable: bool = False,
   |         ^^^^^^^^^^^^^^^ FBT002
53 |         irreps_in: Optional[dict] = None,
54 |     ):
   |

geom3d\models\NequIP\nn\_rescale.py:53:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
51 |         shift_trainable: bool = False,
52 |         scale_trainable: bool = False,
53 |         irreps_in: Optional[dict] = None,
   |                    ^^^^^^^^ FA100
54 |     ):
55 |         if irreps_in is None:
   |

geom3d\models\NequIP\nn\_rescale.py:139:9: ANN202 Missing return type annotation for private function `get_inner_model`
    |
137 |                     callback(self)
138 | 
139 |     def get_inner_model(self):
    |         ^^^^^^^^^^^^^^^ ANN202
140 |         """Get the outermost child module that is not another ``RescaleOutput``."""
141 |         model = self.model
    |
    = help: Add return type annotation

geom3d\models\NequIP\nn\_rescale.py:150:9: RET505 Unnecessary `else` after `return` statement
    |
148 |         if self.training:
149 |             return data
150 |         else:
    |         ^^^^ RET505
151 |             # Scale then shift
152 |             if self.has_scale:
    |
    = help: Remove unnecessary `else`

geom3d\models\NequIP\nn\_rescale.py:164:9: FBT001 Boolean-typed positional argument in function definition
    |
162 |         self,
163 |         data: AtomicDataDict.Type,
164 |         force_process: bool = False,
    |         ^^^^^^^^^^^^^ FBT001
165 |     ) -> AtomicDataDict.Type:
166 |         """Apply rescaling to ``data``, in place.
    |

geom3d\models\NequIP\nn\_rescale.py:164:9: FBT002 Boolean default positional argument in function definition
    |
162 |         self,
163 |         data: AtomicDataDict.Type,
164 |         force_process: bool = False,
    |         ^^^^^^^^^^^^^ FBT002
165 |     ) -> AtomicDataDict.Type:
166 |         """Apply rescaling to ``data``, in place.
    |

geom3d\models\NequIP\nn\_rescale.py:183:9: RET505 Unnecessary `else` after `return` statement
    |
181 |         if self.training and not force_process:
182 |             return data
183 |         else:
    |         ^^^^ RET505
184 |             if self.has_scale:
185 |                 for field in self.scale_keys:
    |
    = help: Remove unnecessary `else`

geom3d\models\NequIP\nn\_rescale.py:198:9: FBT001 Boolean-typed positional argument in function definition
    |
196 |         self,
197 |         data: AtomicDataDict.Type,
198 |         force_process: bool = False,
    |         ^^^^^^^^^^^^^ FBT001
199 |     ) -> AtomicDataDict.Type:
200 |         """Apply the inverse of the rescaling operation to ``data``, in place.
    |

geom3d\models\NequIP\nn\_rescale.py:198:9: FBT002 Boolean default positional argument in function definition
    |
196 |         self,
197 |         data: AtomicDataDict.Type,
198 |         force_process: bool = False,
    |         ^^^^^^^^^^^^^ FBT002
199 |     ) -> AtomicDataDict.Type:
200 |         """Apply the inverse of the rescaling operation to ``data``, in place.
    |

geom3d\models\NequIP\nn\_rescale.py:226:9: RET505 Unnecessary `else` after `return` statement
    |
224 |                         data[field] = data[field] / self.scale_by
225 |             return data
226 |         else:
    |         ^^^^ RET505
227 |             return data
    |
    = help: Remove unnecessary `else`

geom3d\models\NequIP\nn\cutoffs.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\nn\cutoffs.py:16:7: D101 Missing docstring in public class
   |
16 | class PolynomialCutoff(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^^ D101
17 |     _factor: float
18 |     p: float
   |

geom3d\models\NequIP\nn\cutoffs.py:33:9: S101 Use of `assert` detected
   |
31 |         """
32 |         super().__init__()
33 |         assert p >= 2.0
   |         ^^^^^^ S101
34 |         self.p = float(p)
35 |         self._factor = 1.0 / float(r_max)
   |

geom3d\models\NequIP\nn\cutoffs.py:33:21: PLR2004 Magic value used in comparison, consider replacing `2.0` with a constant variable
   |
31 |         """
32 |         super().__init__()
33 |         assert p >= 2.0
   |                     ^^^ PLR2004
34 |         self.p = float(p)
35 |         self._factor = 1.0 / float(r_max)
   |

geom3d\models\NequIP\nn\embedding\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\NequIP\nn\embedding\__init__.py:4:1: PLE0604 Invalid object in `__all__`, must contain only strings
  |
2 | from ._one_hot import OneHotAtomEncoding
3 | 
4 | __all__ = [OneHotAtomEncoding, SphericalHarmonicEdgeAttrs, RadialBasisEdgeEncoding]
  | ^^^^^^^ PLE0604
  |

geom3d\models\NequIP\nn\embedding\_edge.py:32:25: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
30 |     def __init__(
31 |         self,
32 |         irreps_edge_sh: Union[int, str, o3.Irreps],
   |                         ^^^^^ FA100
33 |         edge_sh_normalization: str = "component",
34 |         edge_sh_normalize: bool = True,
   |

geom3d\models\NequIP\nn\embedding\_edge.py:34:9: FBT001 Boolean-typed positional argument in function definition
   |
32 |         irreps_edge_sh: Union[int, str, o3.Irreps],
33 |         edge_sh_normalization: str = "component",
34 |         edge_sh_normalize: bool = True,
   |         ^^^^^^^^^^^^^^^^^ FBT001
35 |         irreps_in=None,
36 |         out_field: str = AtomicDataDict.EDGE_ATTRS_KEY,
   |

geom3d\models\NequIP\nn\embedding\_edge.py:34:9: FBT002 Boolean default positional argument in function definition
   |
32 |         irreps_edge_sh: Union[int, str, o3.Irreps],
33 |         edge_sh_normalization: str = "component",
34 |         edge_sh_normalize: bool = True,
   |         ^^^^^^^^^^^^^^^^^ FBT002
35 |         irreps_in=None,
36 |         out_field: str = AtomicDataDict.EDGE_ATTRS_KEY,
   |

geom3d\models\NequIP\nn\embedding\_edge.py:65:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
63 |     out_field: str
64 | 
65 |     def __init__(
   |         ^^^^^^^^ PLR0913
66 |         self,
67 |         basis=BesselBasis,
   |

geom3d\models\NequIP\nn\embedding\_one_hot.py:26:9: FBT001 Boolean-typed positional argument in function definition
   |
24 |         self,
25 |         num_types: int,
26 |         set_features: bool = True,
   |         ^^^^^^^^^^^^ FBT001
27 |         irreps_in=None,
28 |     ):
   |

geom3d\models\NequIP\nn\embedding\_one_hot.py:26:9: FBT002 Boolean default positional argument in function definition
   |
24 |         self,
25 |         num_types: int,
26 |         set_features: bool = True,
   |         ^^^^^^^^^^^^ FBT002
27 |         irreps_in=None,
28 |     ):
   |

geom3d\models\NequIP\nn\nonlinearities.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\nn\nonlinearities.py:7:5: N802 Function name `ShiftedSoftPlus` should be lowercase
  |
6 | @torch.jit.script
7 | def ShiftedSoftPlus(x):
  |     ^^^^^^^^^^^^^^^ N802
8 |     return torch.nn.functional.softplus(x) - math.log(2.0)
  |

geom3d\models\NequIP\nn\nonlinearities.py:7:5: D103 Missing docstring in public function
  |
6 | @torch.jit.script
7 | def ShiftedSoftPlus(x):
  |     ^^^^^^^^^^^^^^^ D103
8 |     return torch.nn.functional.softplus(x) - math.log(2.0)
  |

geom3d\models\NequIP\nn\radial_basis.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\nn\radial_basis.py:11:7: N801 Class name `e3nn_basis` should use CapWords convention
   |
10 | @compile_mode("trace")
11 | class e3nn_basis(nn.Module):
   |       ^^^^^^^^^^ N801
12 |     r_max: float
13 |     r_min: float
   |

geom3d\models\NequIP\nn\radial_basis.py:11:7: D101 Missing docstring in public class
   |
10 | @compile_mode("trace")
11 | class e3nn_basis(nn.Module):
   |       ^^^^^^^^^^ D101
12 |     r_max: float
13 |     r_min: float
   |

geom3d\models\NequIP\nn\radial_basis.py:17:9: D107 Missing docstring in `__init__`
   |
15 |     num_basis: int
16 | 
17 |     def __init__(
   |         ^^^^^^^^ D107
18 |         self,
19 |         r_max: float,
   |

geom3d\models\NequIP\nn\radial_basis.py:20:16: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
18 |         self,
19 |         r_max: float,
20 |         r_min: Optional[float] = None,
   |                ^^^^^^^^ FA100
21 |         e3nn_basis_name: str = "gaussian",
22 |         num_basis: int = 8,
   |

geom3d\models\NequIP\nn\radial_basis.py:30:9: D102 Missing docstring in public method
   |
28 |         self.num_basis = num_basis
29 | 
30 |     def forward(self, x: torch.Tensor) -> torch.Tensor:
   |         ^^^^^^^ D102
31 |         return soft_one_hot_linspace(
32 |             x,
   |

geom3d\models\NequIP\nn\radial_basis.py:40:9: ANN202 Missing return type annotation for private function `_make_tracing_inputs`
   |
38 |         )
39 | 
40 |     def _make_tracing_inputs(self, n: int):
   |         ^^^^^^^^^^^^^^^^^^^^ ANN202
41 |         return [{"forward": (torch.randn(5, 1),)} for _ in range(n)]
   |
   = help: Add return type annotation

geom3d\models\NequIP\nn\radial_basis.py:44:7: D101 Missing docstring in public class
   |
44 | class BesselBasis(nn.Module):
   |       ^^^^^^^^^^^ D101
45 |     r_max: float
46 |     prefactor: float
   |

geom3d\models\NequIP\nn\radial_basis.py:48:44: FBT002 Boolean default positional argument in function definition
   |
46 |     prefactor: float
47 | 
48 |     def __init__(self, r_max, num_basis=8, trainable=True):
   |                                            ^^^^^^^^^ FBT002
49 |         r"""Radial Bessel Basis, as proposed in DimeNet: https://arxiv.org/abs/2003.03123.
   |

geom3d\models\NequIP\nn\radial_basis.py:94:1: ERA001 Found commented-out code
   |
93 | # class GaussianBasis(nn.Module):
94 | #     r_max: float
   | ^^^^^^^^^^^^^^^^^^ ERA001
95 | 
96 | #     def __init__(self, r_max, r_min=0.0, num_basis=8, trainable=True):
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:97:1: ERA001 Found commented-out code
   |
96 | #     def __init__(self, r_max, r_min=0.0, num_basis=8, trainable=True):
97 | #         super().__init__()
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
98 | 
99 | #         self.trainable = trainable
   |
   = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:99:1: ERA001 Found commented-out code
    |
 97 | #         super().__init__()
 98 | 
 99 | #         self.trainable = trainable
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
100 | #         self.num_basis = num_basis
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:100:1: ERA001 Found commented-out code
    |
 99 | #         self.trainable = trainable
100 | #         self.num_basis = num_basis
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
101 | 
102 | #         self.r_max = float(r_max)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:102:1: ERA001 Found commented-out code
    |
100 | #         self.num_basis = num_basis
101 | 
102 | #         self.r_max = float(r_max)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
103 | #         self.r_min = float(r_min)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:103:1: ERA001 Found commented-out code
    |
102 | #         self.r_max = float(r_max)
103 | #         self.r_min = float(r_min)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
104 | 
105 | #         means = torch.linspace(self.r_min, self.r_max, self.num_basis)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:105:1: ERA001 Found commented-out code
    |
103 | #         self.r_min = float(r_min)
104 | 
105 | #         means = torch.linspace(self.r_min, self.r_max, self.num_basis)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
106 | #         stds = torch.full(size=means.size, fill_value=means[1] - means[0])
107 | #         if self.trainable:
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:106:1: ERA001 Found commented-out code
    |
105 | #         means = torch.linspace(self.r_min, self.r_max, self.num_basis)
106 | #         stds = torch.full(size=means.size, fill_value=means[1] - means[0])
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
107 | #         if self.trainable:
108 | #             self.means = nn.Parameter(means)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:108:1: ERA001 Found commented-out code
    |
106 | #         stds = torch.full(size=means.size, fill_value=means[1] - means[0])
107 | #         if self.trainable:
108 | #             self.means = nn.Parameter(means)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
109 | #             self.stds = nn.Parameter(stds)
110 | #         else:
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:109:1: ERA001 Found commented-out code
    |
107 | #         if self.trainable:
108 | #             self.means = nn.Parameter(means)
109 | #             self.stds = nn.Parameter(stds)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
110 | #         else:
111 | #             self.register_buffer("means", means)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:110:1: ERA001 Found commented-out code
    |
108 | #             self.means = nn.Parameter(means)
109 | #             self.stds = nn.Parameter(stds)
110 | #         else:
    | ^^^^^^^^^^^^^^^ ERA001
111 | #             self.register_buffer("means", means)
112 | #             self.register_buffer("stds", stds)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:111:1: ERA001 Found commented-out code
    |
109 | #             self.stds = nn.Parameter(stds)
110 | #         else:
111 | #             self.register_buffer("means", means)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
112 | #             self.register_buffer("stds", stds)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:112:1: ERA001 Found commented-out code
    |
110 | #         else:
111 | #             self.register_buffer("means", means)
112 | #             self.register_buffer("stds", stds)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
113 | 
114 | #     def forward(self, x: torch.Tensor) -> torch.Tensor:
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:115:1: ERA001 Found commented-out code
    |
114 | #     def forward(self, x: torch.Tensor) -> torch.Tensor:
115 | #         x = (x[..., None] - self.means) / self.stds
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
116 | #         x = x.square().mul(-0.5).exp() / self.stds  # sqrt(2 * pi)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\nn\radial_basis.py:116:1: ERA001 Found commented-out code
    |
114 | #     def forward(self, x: torch.Tensor) -> torch.Tensor:
115 | #         x = (x[..., None] - self.means) / self.stds
116 | #         x = x.square().mul(-0.5).exp() / self.stds  # sqrt(2 * pi)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
    |
    = help: Remove commented-out code

geom3d\models\NequIP\scripts\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\NequIP\scripts\_logger.py:5:5: ANN202 Missing return type annotation for private function `set_up_script_logger`
  |
5 | def set_up_script_logger(logfile: str, verbose: str = "INFO"):
  |     ^^^^^^^^^^^^^^^^^^^^ ANN202
6 |     # Configure the root logger so stuff gets printed
7 |     root_logger = logging.getLogger()
  |
  = help: Add return type annotation

geom3d\models\NequIP\scripts\benchmark.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\scripts\benchmark.py:19:5: PLR0915 Too many statements (61 > 50)
   |
19 | def main(args=None):
   |     ^^^^ PLR0915
20 |     parser = argparse.ArgumentParser(
21 |         description=textwrap.dedent(
   |

geom3d\models\NequIP\scripts\benchmark.py:19:5: D103 Missing docstring in public function
   |
19 | def main(args=None):
   |     ^^^^ D103
20 |     parser = argparse.ArgumentParser(
21 |         description=textwrap.dedent(
   |

geom3d\models\NequIP\scripts\benchmark.py:57:7: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
55 |     )
56 | 
57 |     # TODO: option to show memory use
   |       ^^^^ TD002
58 | 
59 |     # Parse the args
   |

geom3d\models\NequIP\scripts\benchmark.py:57:7: TD003 Missing issue link on the line following this TODO
   |
55 |     )
56 | 
57 |     # TODO: option to show memory use
   |       ^^^^ TD003
58 | 
59 |     # Parse the args
   |

geom3d\models\NequIP\scripts\benchmark.py:57:7: FIX002 Line contains TODO, consider resolving the issue
   |
55 |     )
56 | 
57 |     # TODO: option to show memory use
   |       ^^^^ FIX002
58 | 
59 |     # Parse the args
   |

geom3d\models\NequIP\scripts\deploy.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\scripts\deploy.py:3:4: YTT203 `sys.version_info[1]` compared to integer (python4), compare `sys.version_info` to tuple
  |
1 | import sys
2 | 
3 | if sys.version_info[1] >= 8:
  |    ^^^^^^^^^^^^^^^^^^^ YTT203
4 |     from typing import Final
5 | else:
  |

geom3d\models\NequIP\scripts\deploy.py:3:27: PLR2004 Magic value used in comparison, consider replacing `8` with a constant variable
  |
1 | import sys
2 | 
3 | if sys.version_info[1] >= 8:
  |                           ^ PLR2004
4 |     from typing import Final
5 | else:
  |

geom3d\models\NequIP\scripts\deploy.py:53:5: ANN202 Missing return type annotation for private function `_compile_for_deploy`
   |
53 | def _compile_for_deploy(model):
   |     ^^^^^^^^^^^^^^^^^^^ ANN202
54 |     model.eval()
   |
   = help: Add return type annotation

geom3d\models\NequIP\scripts\deploy.py:62:5: D417 Missing argument descriptions in the docstring for `load_deployed_model`: `device`, `freeze`, `set_global_options`
   |
62 | def load_deployed_model(
   |     ^^^^^^^^^^^^^^^^^^^ D417
63 |     model_path: Union[pathlib.Path, str],
64 |     device: Union[str, torch.device] = "cpu",
   |

geom3d\models\NequIP\scripts\deploy.py:63:17: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
62 | def load_deployed_model(
63 |     model_path: Union[pathlib.Path, str],
   |                 ^^^^^ FA100
64 |     device: Union[str, torch.device] = "cpu",
65 |     freeze: bool = True,
   |

geom3d\models\NequIP\scripts\deploy.py:64:13: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
62 | def load_deployed_model(
63 |     model_path: Union[pathlib.Path, str],
64 |     device: Union[str, torch.device] = "cpu",
   |             ^^^^^ FA100
65 |     freeze: bool = True,
66 |     set_global_options: Union[str, bool] = "warn",
   |

geom3d\models\NequIP\scripts\deploy.py:65:5: FBT001 Boolean-typed positional argument in function definition
   |
63 |     model_path: Union[pathlib.Path, str],
64 |     device: Union[str, torch.device] = "cpu",
65 |     freeze: bool = True,
   |     ^^^^^^ FBT001
66 |     set_global_options: Union[str, bool] = "warn",
67 | ) -> Tuple[torch.jit.ScriptModule, Dict[str, str]]:
   |

geom3d\models\NequIP\scripts\deploy.py:65:5: FBT002 Boolean default positional argument in function definition
   |
63 |     model_path: Union[pathlib.Path, str],
64 |     device: Union[str, torch.device] = "cpu",
65 |     freeze: bool = True,
   |     ^^^^^^ FBT002
66 |     set_global_options: Union[str, bool] = "warn",
67 | ) -> Tuple[torch.jit.ScriptModule, Dict[str, str]]:
   |

geom3d\models\NequIP\scripts\deploy.py:66:25: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
64 |     device: Union[str, torch.device] = "cpu",
65 |     freeze: bool = True,
66 |     set_global_options: Union[str, bool] = "warn",
   |                         ^^^^^ FA100
67 | ) -> Tuple[torch.jit.ScriptModule, Dict[str, str]]:
68 |     r"""Load a deployed model.
   |

geom3d\models\NequIP\scripts\deploy.py:67:6: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
   |
65 |     freeze: bool = True,
66 |     set_global_options: Union[str, bool] = "warn",
67 | ) -> Tuple[torch.jit.ScriptModule, Dict[str, str]]:
   |      ^^^^^ FA100
68 |     r"""Load a deployed model.
   |

geom3d\models\NequIP\scripts\deploy.py:67:36: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
65 |     freeze: bool = True,
66 |     set_global_options: Union[str, bool] = "warn",
67 | ) -> Tuple[torch.jit.ScriptModule, Dict[str, str]]:
   |                                    ^^^^ FA100
68 |     r"""Load a deployed model.
   |

geom3d\models\NequIP\scripts\deploy.py:84:9: B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   |
82 |       except RuntimeError as e:
83 |           msg = f"{model_path} does not seem to be a deployed NequIP model file. Did you forget to deploy it using `NequIP-deploy`? \n\n(Underlying error: {e})"
84 |           raise ValueError(
   |  _________^
85 | |             msg
86 | |         )
   | |_________^ B904
87 |       # Confirm NequIP made it
88 |       if metadata[NEQUIP_VERSION_KEY] == "":
   |

geom3d\models\NequIP\scripts\deploy.py:94:5: S101 Use of `assert` detected
   |
92 |         )
93 |     # Confirm its TorchScript
94 |     assert isinstance(model, torch.jit.ScriptModule)
   |     ^^^^^^ S101
95 |     # Make sure we're in eval mode
96 |     model.eval()
   |

geom3d\models\NequIP\scripts\deploy.py:105:5: S101 Use of `assert` detected
    |
103 |     metadata = {k: v.decode("ascii") for k, v in metadata.items()}
104 |     # Set up global settings:
105 |     assert set_global_options in (True, False, "warn")
    |     ^^^^^^ S101
106 |     if set_global_options:
107 |         global_config_dict = {}
    |

geom3d\models\NequIP\scripts\deploy.py:132:5: C901 `main` is too complex (13 > 10)
    |
132 | def main(args=None):
    |     ^^^^ C901
133 |     parser = argparse.ArgumentParser(
134 |         description="Create and view information about deployed NequIP potentials."
    |

geom3d\models\NequIP\scripts\deploy.py:132:5: PLR0912 Too many branches (17 > 12)
    |
132 | def main(args=None):
    |     ^^^^ PLR0912
133 |     parser = argparse.ArgumentParser(
134 |         description="Create and view information about deployed NequIP potentials."
    |

geom3d\models\NequIP\scripts\deploy.py:132:5: PLR0915 Too many statements (68 > 50)
    |
132 | def main(args=None):
    |     ^^^^ PLR0915
133 |     parser = argparse.ArgumentParser(
134 |         description="Create and view information about deployed NequIP potentials."
    |

geom3d\models\NequIP\scripts\deploy.py:132:5: D103 Missing docstring in public function
    |
132 | def main(args=None):
    |     ^^^^ D103
133 |     parser = argparse.ArgumentParser(
134 |         description="Create and view information about deployed NequIP potentials."
    |

geom3d\models\NequIP\scripts\deploy.py:137:8: YTT203 `sys.version_info[1]` compared to integer (python4), compare `sys.version_info` to tuple
    |
135 |     )
136 |     # backward compat for 3.6
137 |     if sys.version_info[1] > 6:
    |        ^^^^^^^^^^^^^^^^^^^ YTT203
138 |         required = {"required": True}
139 |     else:
    |

geom3d\models\NequIP\scripts\deploy.py:137:30: PLR2004 Magic value used in comparison, consider replacing `6` with a constant variable
    |
135 |     )
136 |     # backward compat for 3.6
137 |     if sys.version_info[1] > 6:
    |                              ^ PLR2004
138 |         required = {"required": True}
139 |     else:
    |

geom3d\models\NequIP\scripts\deploy.py:178:22: G004 Logging statement uses f-string
    |
176 |         config = metadata.pop(CONFIG_KEY)
177 |         metadata_str = "\n".join("  {}: {}".format(*e) for e in metadata.items())
178 |         logging.info(f"Loaded TorchScript model with metadata:\n{metadata_str}\n")
    |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
179 |         logging.info("Model was built with config:")
    |

geom3d\models\NequIP\scripts\deploy.py:228:21: A001 Variable `type` is shadowing a Python builtin
    |
226 |             type_names = {
227 |                 type: ase.data.chemical_symbols[atomic_num]
228 |                 for type, atomic_num in enumerate(config["allowed_species"])
    |                     ^^^^ A001
229 |             }
230 |         else:
    |

geom3d\models\NequIP\scripts\deploy.py:238:52: PLR2004 Magic value used in comparison, consider replacing `11` with a constant variable
    |
237 |         metadata[JIT_BAILOUT_KEY] = str(config[JIT_BAILOUT_KEY])
238 |         if int(torch.__version__.split(".")[1]) >= 11 and JIT_FUSION_STRATEGY in config:
    |                                                    ^^ PLR2004
239 |             metadata[JIT_FUSION_STRATEGY] = ";".join(
240 |                 "%s,%i" % e for e in config[JIT_FUSION_STRATEGY]
    |

geom3d\models\NequIP\scripts\evaluate.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\scripts\evaluate.py:29:5: C901 `main` is too complex (38 > 10)
   |
29 | def main(args=None, running_as_script: bool = True):
   |     ^^^^ C901
30 |     # in results dir, do: NequIP-deploy build --train-dir . deployed.pth
31 |     parser = argparse.ArgumentParser(
   |

geom3d\models\NequIP\scripts\evaluate.py:29:5: PLR0912 Too many branches (43 > 12)
   |
29 | def main(args=None, running_as_script: bool = True):
   |     ^^^^ PLR0912
30 |     # in results dir, do: NequIP-deploy build --train-dir . deployed.pth
31 |     parser = argparse.ArgumentParser(
   |

geom3d\models\NequIP\scripts\evaluate.py:29:5: PLR0915 Too many statements (172 > 50)
   |
29 | def main(args=None, running_as_script: bool = True):
   |     ^^^^ PLR0915
30 |     # in results dir, do: NequIP-deploy build --train-dir . deployed.pth
31 |     parser = argparse.ArgumentParser(
   |

geom3d\models\NequIP\scripts\evaluate.py:29:5: D103 Missing docstring in public function
   |
29 | def main(args=None, running_as_script: bool = True):
   |     ^^^^ D103
30 |     # in results dir, do: NequIP-deploy build --train-dir . deployed.pth
31 |     parser = argparse.ArgumentParser(
   |

geom3d\models\NequIP\scripts\evaluate.py:29:21: FBT001 Boolean-typed positional argument in function definition
   |
29 | def main(args=None, running_as_script: bool = True):
   |                     ^^^^^^^^^^^^^^^^^ FBT001
30 |     # in results dir, do: NequIP-deploy build --train-dir . deployed.pth
31 |     parser = argparse.ArgumentParser(
   |

geom3d\models\NequIP\scripts\evaluate.py:29:21: FBT002 Boolean default positional argument in function definition
   |
29 | def main(args=None, running_as_script: bool = True):
   |                     ^^^^^^^^^^^^^^^^^ FBT002
30 |     # in results dir, do: NequIP-deploy build --train-dir . deployed.pth
31 |     parser = argparse.ArgumentParser(
   |

geom3d\models\NequIP\scripts\evaluate.py:168:18: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
166 |         msg = "--model or --train-dir must be provided"
167 |         raise ValueError(msg)
168 |     output_type: Optional[str] = None
    |                  ^^^^^^^^ FA100
169 |     if args.output is not None:
170 |         if args.output.suffix != ".xyz":
    |

geom3d\models\NequIP\scripts\evaluate.py:178:9: S101 Use of `assert` detected
    |
176 |         output_type = "xyz"
177 |     else:
178 |         assert args.output_fields == ""
    |         ^^^^^^ S101
179 |         args.output_fields = []
    |

geom3d\models\NequIP\scripts\evaluate.py:191:17: G004 Logging statement uses f-string
    |
189 |     logger.setLevel(logging.INFO)
190 | 
191 |     logger.info(f"Using device: {device}")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^ G004
192 |     if device.type == "cuda":
193 |         logger.info(
    |

geom3d\models\NequIP\scripts\evaluate.py:201:44: FBT003 Boolean positional value in function call
    |
199 |             "Telling PyTorch to try to use deterministic algorithms... please note that this will likely error on CUDA/GPU"
200 |         )
201 |         torch.use_deterministic_algorithms(True)
    |                                            ^^^^ FBT003
202 | 
203 |     # Load model:
    |

geom3d\models\NequIP\scripts\evaluate.py:243:9: G004 Logging statement uses f-string
    |
241 |     # Load a config file
242 |     logger.info(
243 |         f"Loading {'original ' if dataset_is_from_training else ''}dataset...",
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
244 |     )
245 |     dataset_config = Config.from_file(
    |

geom3d\models\NequIP\scripts\evaluate.py:266:9: G004 Logging statement uses f-string
    |
264 |         dataset = dataset_from_config(dataset_config)
265 |     logger.info(
266 |         f"Loaded {'validation_' if dataset_is_validation else ''}dataset specified in {args.dataset_config.name}.",
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
267 |     )
    |

geom3d\models\NequIP\scripts\evaluate.py:284:17: G004 Logging statement uses f-string
    |
282 |             test_idcs = list(all_idcs - val_idcs)
283 |             logger.info(
284 |                 f"Using origial validation dataset ({len(dataset)} frames) minus validation set frames ({len(val_idcs)} frames), yielding a test set size of {len(test_idcs)} frames.",
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
285 |             )
286 |         else:
    |

geom3d\models\NequIP\scripts\evaluate.py:288:13: S101 Use of `assert` detected
    |
286 |         else:
287 |             test_idcs = list(all_idcs - train_idcs - val_idcs)
288 |             assert set(test_idcs).isdisjoint(train_idcs)
    |             ^^^^^^ S101
289 |             logger.info(
290 |                 f"Using origial training dataset ({len(dataset)} frames) minus training ({len(train_idcs)} frames) and validation frames ({len(val_idcs)} frames), yielding a test set size of {len(test_idcs)} frames.",
    |

geom3d\models\NequIP\scripts\evaluate.py:290:17: G004 Logging statement uses f-string
    |
288 |             assert set(test_idcs).isdisjoint(train_idcs)
289 |             logger.info(
290 |                 f"Using origial training dataset ({len(dataset)} frames) minus training ({len(train_idcs)} frames) and validation frames ({len(val_idcs)} frames), yielding a test set size of {len(test_idcs)} frames.",
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
291 |             )
292 |         # No matter what it should be disjoint from validation:
    |

geom3d\models\NequIP\scripts\evaluate.py:293:9: S101 Use of `assert` detected
    |
291 |             )
292 |         # No matter what it should be disjoint from validation:
293 |         assert set(test_idcs).isdisjoint(val_idcs)
    |         ^^^^^^ S101
294 |         if not do_metrics:
295 |             logger.info(
    |

geom3d\models\NequIP\scripts\evaluate.py:302:13: G004 Logging statement uses f-string
    |
300 |         test_idcs = torch.arange(dataset.len())
301 |         logger.info(
302 |             f"Using all frames from the specified test dataset, yielding a test set size of {len(test_idcs)} frames.",
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
303 |         )
304 |     else:
    |

geom3d\models\NequIP\scripts\evaluate.py:313:13: G004 Logging statement uses f-string
    |
311 |         )
312 |         logger.info(
313 |             f"Using provided test set indexes, yielding a test set size of {len(test_idcs)} frames.",
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
314 |         )
315 |     test_idcs = torch.as_tensor(test_idcs, dtype=torch.long)
    |

geom3d\models\NequIP\scripts\evaluate.py:352:36: F811 Redefinition of unused `context_stack` from line 351
    |
350 |     logger.info("Starting...")
351 |     context_stack = contextlib.ExitStack()
352 |     with contextlib.ExitStack() as context_stack:
    |                                    ^^^^^^^^^^^^^ F811
353 |         # "None" checks if in a TTY and disables if not
354 |         prog = context_stack.enter_context(tqdm(total=len(test_idcs), disable=None))
    |
    = help: Remove definition: `context_stack`

geom3d\models\NequIP\scripts\evaluate.py:366:50: PTH123 `open()` should be replaced by `Path.open()`
    |
365 |         if output_type is not None:
366 |             output = context_stack.enter_context(open(args.output, "w"))
    |                                                  ^^^^ PTH123
367 |         else:
368 |             output = None
    |

geom3d\models\NequIP\scripts\run_md.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\scripts\run_md.py:26:18: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   |
24 |     """
25 |     write(
26 |         filename=os.path.join(os.path.join(logdir, "xyz_strucs/"), prefix + ".xyz"),
   |                  ^^^^^^^^^^^^ PTH118
27 |         images=atoms,
28 |         format="extxyz",
   |

geom3d\models\NequIP\scripts\run_md.py:26:31: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   |
24 |     """
25 |     write(
26 |         filename=os.path.join(os.path.join(logdir, "xyz_strucs/"), prefix + ".xyz"),
   |                               ^^^^^^^^^^^^ PTH118
27 |         images=atoms,
28 |         format="extxyz",
   |

geom3d\models\NequIP\scripts\run_md.py:71:5: D103 Missing docstring in public function
   |
71 | def main(args=None):
   |     ^^^^ D103
72 |     parser = argparse.ArgumentParser(
73 |         description="Run Nose-Hoover MD using a deployed NequIP model."
   |

geom3d\models\NequIP\scripts\run_md.py:107:19: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
105 |     args = parser.parse_args(args=args)
106 | 
107 |     logfilename = os.path.join(args.logdir, f"ase_md_run_{time.time()}.log")
    |                   ^^^^^^^^^^^^ PTH118
108 | 
109 |     np.random.seed(args.seed)
    |

geom3d\models\NequIP\scripts\run_md.py:109:5: NPY002 Replace legacy `np.random.seed` call with `np.random.Generator`
    |
107 |     logfilename = os.path.join(args.logdir, f"ase_md_run_{time.time()}.log")
108 | 
109 |     np.random.seed(args.seed)
    |     ^^^^^^^^^^^^^^ NPY002
110 |     torch.manual_seed(args.seed)
111 |     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    |

geom3d\models\NequIP\scripts\run_md.py:113:12: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
    |
111 |     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
112 | 
113 |     if not os.path.exists(args.logdir):
    |            ^^^^^^^^^^^^^^ PTH110
114 |         os.makedirs(args.logdir)
115 |         os.makedirs(os.path.join(args.logdir, "xyz_strucs"))
    |

geom3d\models\NequIP\scripts\run_md.py:114:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
    |
113 |     if not os.path.exists(args.logdir):
114 |         os.makedirs(args.logdir)
    |         ^^^^^^^^^^^ PTH103
115 |         os.makedirs(os.path.join(args.logdir, "xyz_strucs"))
    |

geom3d\models\NequIP\scripts\run_md.py:115:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
    |
113 |     if not os.path.exists(args.logdir):
114 |         os.makedirs(args.logdir)
115 |         os.makedirs(os.path.join(args.logdir, "xyz_strucs"))
    |         ^^^^^^^^^^^ PTH103
116 | 
117 |     logging.basicConfig(filename=logfilename, format="%(message)s", level=logging.INFO)
    |

geom3d\models\NequIP\scripts\run_md.py:115:21: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
113 |     if not os.path.exists(args.logdir):
114 |         os.makedirs(args.logdir)
115 |         os.makedirs(os.path.join(args.logdir, "xyz_strucs"))
    |                     ^^^^^^^^^^^^ PTH118
116 | 
117 |     logging.basicConfig(filename=logfilename, format="%(message)s", level=logging.INFO)
    |

geom3d\models\NequIP\scripts\run_md.py:147:9: G004 Logging statement uses f-string
    |
145 |     # log first frame
146 |     logging.info(
147 |         f"\n\nStarting dynamics with Nose-Hoover Thermostat with nvt_q: {args.nvt_q}\n\n"
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
148 |     )
149 |     write_ase_md_config(curr_atoms=atoms, curr_step=0, dt=args.dt)
    |

geom3d\models\NequIP\scripts\run_md.py:150:18: G004 Logging statement uses f-string
    |
148 |     )
149 |     write_ase_md_config(curr_atoms=atoms, curr_step=0, dt=args.dt)
150 |     logging.info(f"COM [A]: {atoms.get_center_of_mass()}\n")
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
151 | 
152 |     save_to_xyz(atoms, logdir=args.logdir, prefix="nvt_")
    |

geom3d\models\NequIP\scripts\run_md.py:160:26: G004 Logging statement uses f-string
    |
158 |             write_ase_md_config(curr_atoms=atoms, curr_step=i, dt=args.dt)
159 | 
160 |             logging.info(f"COM [A]: {atoms.get_center_of_mass()}\n")
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
161 | 
162 |         # append current structure to xyz file
    |

geom3d\models\NequIP\scripts\train.py:34:29: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
32 |     "dataset_statistics_stride": 1,
33 |     "default_dtype": "float32",
34 |     "allow_tf32": False,  # TODO: until we understand equivar issues
   |                             ^^^^ TD002
35 |     "verbose": "INFO",
36 |     "model_debug_mode": False,
   |

geom3d\models\NequIP\scripts\train.py:34:29: TD003 Missing issue link on the line following this TODO
   |
32 |     "dataset_statistics_stride": 1,
33 |     "default_dtype": "float32",
34 |     "allow_tf32": False,  # TODO: until we understand equivar issues
   |                             ^^^^ TD003
35 |     "verbose": "INFO",
36 |     "model_debug_mode": False,
   |

geom3d\models\NequIP\scripts\train.py:34:29: FIX002 Line contains TODO, consider resolving the issue
   |
32 |     "dataset_statistics_stride": 1,
33 |     "default_dtype": "float32",
34 |     "allow_tf32": False,  # TODO: until we understand equivar issues
   |                             ^^^^ FIX002
35 |     "verbose": "INFO",
36 |     "model_debug_mode": False,
   |

geom3d\models\NequIP\scripts\train.py:53:5: D103 Missing docstring in public function
   |
53 | def main(args=None, running_as_script: bool = True):
   |     ^^^^ D103
54 |     config = parse_command_line(args)
   |

geom3d\models\NequIP\scripts\train.py:53:21: FBT001 Boolean-typed positional argument in function definition
   |
53 | def main(args=None, running_as_script: bool = True):
   |                     ^^^^^^^^^^^^^^^^^ FBT001
54 |     config = parse_command_line(args)
   |

geom3d\models\NequIP\scripts\train.py:53:21: FBT002 Boolean default positional argument in function definition
   |
53 | def main(args=None, running_as_script: bool = True):
   |                     ^^^^^^^^^^^^^^^^^ FBT002
54 |     config = parse_command_line(args)
   |

geom3d\models\NequIP\scripts\train.py:59:26: PTH112 `os.path.isdir()` should be replaced by `Path.is_dir()`
   |
57 |         set_up_script_logger(config.get("log", None), config.verbose)
58 | 
59 |     found_restart_file = isdir(f"{config.root}/{config.run_name}")
   |                          ^^^^^ PTH112
60 |     if found_restart_file and not config.append:
61 |         msg = (
   |

geom3d\models\NequIP\scripts\train.py:81:5: D103 Missing docstring in public function
   |
81 | def parse_command_line(args=None):
   |     ^^^^^^^^^^^^^^^^^^ D103
82 |     parser = argparse.ArgumentParser(description="Train a NequIP model.")
83 |     parser.add_argument("config", help="configuration file")
   |

geom3d\models\NequIP\scripts\train.py:116:5: D103 Missing docstring in public function
    |
116 | def fresh_start(config):
    |     ^^^^^^^^^^^ D103
117 |     # we use add_to_config cause it's a fresh start and need to record it
118 |     check_code_version(config, add_to_config=True)
    |

geom3d\models\NequIP\scripts\train.py:144:18: G004 Logging statement uses f-string
    |
142 |     # = Load the dataset =
143 |     dataset = dataset_from_config(config, prefix="dataset")
144 |     logging.info(f"Successfully loaded the data set of type {dataset}...")
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
145 |     try:
146 |         validation_dataset = dataset_from_config(config, prefix="validation_dataset")
    |

geom3d\models\NequIP\scripts\train.py:148:13: G004 Logging statement uses f-string
    |
146 |         validation_dataset = dataset_from_config(config, prefix="validation_dataset")
147 |         logging.info(
148 |             f"Successfully loaded the validation data set of type {validation_dataset}..."
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
149 |         )
150 |     except KeyError:
    |

geom3d\models\NequIP\scripts\train.py:169:9: S101 Use of `assert` detected
    |
167 |     if config.equivariance_test > 0:
168 |         n_train: int = len(trainer.dataset_train)
169 |         assert config.equivariance_test <= n_train
    |         ^^^^^^ S101
170 |         final_model.eval()
171 |         indexes = torch.randperm(n_train)[: config.equivariance_test]
    |

geom3d\models\NequIP\scripts\train.py:177:13: G004 Logging statement uses f-string
    |
175 |           final_model.train()
176 |           logging.info(
177 |               "Equivariance test passed; equivariance errors:\n"
    |  _____________^
178 | |             "   Errors are in real units, where relevant.\n"
179 | |             "   Please note that the large scale of the typical\n"
180 | |             "   shifts to the (atomic) energy can cause\n"
181 | |             "   catastrophic cancellation and give incorrectly\n"
182 | |             "   the equivariance error as zero for those fields.\n"
183 | |             f"{errstr}"
    | |_______________________^ G004
184 |           )
185 |           del errstr, indexes, n_train
    |

geom3d\models\NequIP\scripts\train.py:196:5: D103 Missing docstring in public function
    |
196 | def restart(config):
    |     ^^^^^^^ D103
197 |     # load the dictionary
198 |     restart_file = f"{config.root}/{config.run_name}/trainer.pth"
    |

geom3d\models\NequIP\scripts\train.py:210:30: G004 Logging statement uses f-string
    |
208 |             if k == "max_epochs" or k.startswith("early_stop"):
209 |                 dictionary[k] = config[k]
210 |                 logging.info(f'Update "{k}" to {dictionary[k]}')
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
211 |             elif isinstance(config[k], type(dictionary.get(k, ""))):
212 |                 msg = f'Key "{k}" is different in config and the result trainer.pth file. Please double check'
    |

geom3d\models\NequIP\scripts\train.py:244:18: G004 Logging statement uses f-string
    |
242 |     # = Load the dataset =
243 |     dataset = dataset_from_config(config, prefix="dataset")
244 |     logging.info(f"Successfully re-loaded the data set of type {dataset}...")
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
245 |     try:
246 |         validation_dataset = dataset_from_config(config, prefix="validation_dataset")
    |

geom3d\models\NequIP\scripts\train.py:248:13: G004 Logging statement uses f-string
    |
246 |         validation_dataset = dataset_from_config(config, prefix="validation_dataset")
247 |         logging.info(
248 |             f"Successfully re-loaded the validation data set of type {validation_dataset}..."
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
249 |         )
250 |     except KeyError:
    |

geom3d\models\NequIP\scripts\train.py:266:9: RET506 Unnecessary `else` after `raise` statement
    |
264 |             msg = "the `compile_model` option has been removed"
265 |             raise ValueError(msg)
266 |         else:
    |         ^^^^ RET506
267 |             warnings.warn("the `compile_model` option has been removed")
    |
    = help: Remove unnecessary `else`

geom3d\models\NequIP\scripts\train.py:267:13: B028 No explicit `stacklevel` keyword argument found
    |
265 |             raise ValueError(msg)
266 |         else:
267 |             warnings.warn("the `compile_model` option has been removed")
    |             ^^^^^^^^^^^^^ B028
    |

geom3d\models\NequIP\utils\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\NequIP\utils\__init__.py:16:1: ERA001 Found commented-out code
   |
14 | )
15 | 
16 | # from .output import Output
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
17 | # from .modules import find_first_of_type
18 | # from .misc import dtype_from_name
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\__init__.py:17:1: ERA001 Found commented-out code
   |
16 | # from .output import Output
17 | # from .modules import find_first_of_type
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
18 | # from .misc import dtype_from_name
19 | from .scatter import scatter
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\__init__.py:18:1: ERA001 Found commented-out code
   |
16 | # from .output import Output
17 | # from .modules import find_first_of_type
18 | # from .misc import dtype_from_name
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
19 | from .scatter import scatter
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\__init__.py:21:1: PLE0604 Invalid object in `__all__`, must contain only strings
   |
19 | from .scatter import scatter
20 | 
21 | __all__ = [
   | ^^^^^^^ PLE0604
22 |     instantiate_from_cls_name,
23 |     instantiate,
   |

geom3d\models\NequIP\utils\_global_options.py:24:12: PLW0602 Using global for `_latest_global_config` but no assignment is done
   |
22 |     This is useful for getting worker processes into the same state as the parent.
23 |     """
24 |     global _latest_global_config
   |            ^^^^^^^^^^^^^^^^^^^^^ PLW0602
25 |     return _latest_global_config
   |

geom3d\models\NequIP\utils\_global_options.py:28:5: C901 `_set_global_options` is too complex (12 > 10)
   |
28 | def _set_global_options(config, warn_on_override: bool = False) -> None:
   |     ^^^^^^^^^^^^^^^^^^^ C901
29 |     """Configure global options of libraries like `torch` and `e3nn` based on `config`.
   |

geom3d\models\NequIP\utils\_global_options.py:28:5: D417 Missing argument description in the docstring for `_set_global_options`: `config`
   |
28 | def _set_global_options(config, warn_on_override: bool = False) -> None:
   |     ^^^^^^^^^^^^^^^^^^^ D417
29 |     """Configure global options of libraries like `torch` and `e3nn` based on `config`.
   |

geom3d\models\NequIP\utils\_global_options.py:28:33: FBT001 Boolean-typed positional argument in function definition
   |
28 | def _set_global_options(config, warn_on_override: bool = False) -> None:
   |                                 ^^^^^^^^^^^^^^^^ FBT001
29 |     """Configure global options of libraries like `torch` and `e3nn` based on `config`.
   |

geom3d\models\NequIP\utils\_global_options.py:28:33: FBT002 Boolean default positional argument in function definition
   |
28 | def _set_global_options(config, warn_on_override: bool = False) -> None:
   |                                 ^^^^^^^^^^^^^^^^ FBT002
29 |     """Configure global options of libraries like `torch` and `e3nn` based on `config`.
   |

geom3d\models\NequIP\utils\_global_options.py:37:12: PLW0602 Using global for `_latest_global_config` but no assignment is done
   |
35 |     """
36 |     # update these options into the latest global config.
37 |     global _latest_global_config
   |            ^^^^^^^^^^^^^^^^^^^^^ PLW0602
38 |     _latest_global_config.update(dict(config))
39 |     # Set TF32 support
   |

geom3d\models\NequIP\utils\_global_options.py:41:5: SIM102 Use a single `if` statement instead of nested `if` statements
   |
39 |       # Set TF32 support
40 |       # See https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices
41 |       if torch.cuda.is_available() and "allow_tf32" in config:
   |  _____^
42 | |         if torch.torch.backends.cuda.matmul.allow_tf32 is not config["allow_tf32"]:
   | |___________________________________________________________________________________^ SIM102
43 |               # update the setting
44 |               if warn_on_override:
   |
   = help: Combine `if` statements using `and`

geom3d\models\NequIP\utils\_global_options.py:45:17: B028 No explicit `stacklevel` keyword argument found
   |
43 |             # update the setting
44 |             if warn_on_override:
45 |                 warnings.warn(
   |                 ^^^^^^^^^^^^^ B028
46 |                     f"Setting the GLOBAL value for allow_tf32 to {config['allow_tf32']} which is different than the previous value of {torch.torch.backends.cuda.matmul.allow_tf32}"
47 |                 )
   |

geom3d\models\NequIP\utils\_global_options.py:51:48: PLR2004 Magic value used in comparison, consider replacing `11` with a constant variable
   |
49 |             torch.backends.cudnn.allow_tf32 = config["allow_tf32"]
50 | 
51 |     if int(torch.__version__.split(".")[1]) >= 11:
   |                                                ^^ PLR2004
52 |         # PyTorch >= 1.11
53 |         k = "_jit_fusion_strategy"
   |

geom3d\models\NequIP\utils\_global_options.py:52:9: ERA001 Found commented-out code
   |
51 |     if int(torch.__version__.split(".")[1]) >= 11:
52 |         # PyTorch >= 1.11
   |         ^^^^^^^^^^^^^^^^^ ERA001
53 |         k = "_jit_fusion_strategy"
54 |         if k in config:
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\_global_options.py:58:17: B028 No explicit `stacklevel` keyword argument found
   |
56 |             old_strat = torch.jit.set_fusion_strategy(new_strat)
57 |             if warn_on_override and old_strat != new_strat:
58 |                 warnings.warn(
   |                 ^^^^^^^^^^^^^ B028
59 |                     f"Setting the GLOBAL value for jit fusion strategy to `{new_strat}` which is different than the previous value of `{old_strat}`"
60 |                 )
   |

geom3d\models\NequIP\utils\_global_options.py:67:25: SLF001 Private member accessed: `_C`
   |
65 |         if k in config:
66 |             new_depth = config[k]
67 |             old_depth = torch._C._jit_set_bailout_depth(new_depth)
   |                         ^^^^^^^^ SLF001
68 |             if warn_on_override and old_depth != new_depth:
69 |                 warnings.warn(
   |

geom3d\models\NequIP\utils\_global_options.py:67:25: SLF001 Private member accessed: `_jit_set_bailout_depth`
   |
65 |         if k in config:
66 |             new_depth = config[k]
67 |             old_depth = torch._C._jit_set_bailout_depth(new_depth)
   |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
68 |             if warn_on_override and old_depth != new_depth:
69 |                 warnings.warn(
   |

geom3d\models\NequIP\utils\_global_options.py:69:17: B028 No explicit `stacklevel` keyword argument found
   |
67 |             old_depth = torch._C._jit_set_bailout_depth(new_depth)
68 |             if warn_on_override and old_depth != new_depth:
69 |                 warnings.warn(
   |                 ^^^^^^^^^^^^^ B028
70 |                     f"Setting the GLOBAL value for jit bailout depth to `{new_depth}` which is different than the previous value of `{old_depth}`"
71 |                 )
   |

geom3d\models\NequIP\utils\_global_options.py:73:7: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
71 |                 )
72 | 
73 |     # TODO: warn_on_override for the rest here?
   |       ^^^^ TD002
74 |     if config.get("model_debug_mode", False):
75 |         set_irreps_debug(enabled=True)
   |

geom3d\models\NequIP\utils\_global_options.py:73:7: TD003 Missing issue link on the line following this TODO
   |
71 |                 )
72 | 
73 |     # TODO: warn_on_override for the rest here?
   |       ^^^^ TD003
74 |     if config.get("model_debug_mode", False):
75 |         set_irreps_debug(enabled=True)
   |

geom3d\models\NequIP\utils\_global_options.py:73:7: FIX002 Line contains TODO, consider resolving the issue
   |
71 |                 )
72 | 
73 |     # TODO: warn_on_override for the rest here?
   |       ^^^^ FIX002
74 |     if config.get("model_debug_mode", False):
75 |         set_irreps_debug(enabled=True)
   |

geom3d\models\NequIP\utils\auto_init.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\auto_init.py:8:5: PLR0913 Too many arguments in function definition (8 > 5)
   |
 8 | def instantiate_from_cls_name(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
 9 |     module,
10 |     class_name: str,
   |

geom3d\models\NequIP\utils\auto_init.py:8:5: D417 Missing argument description in the docstring for `instantiate_from_cls_name`: `prefix`
   |
 8 | def instantiate_from_cls_name(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ D417
 9 |     module,
10 |     class_name: str,
   |

geom3d\models\NequIP\utils\auto_init.py:11:13: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
 9 |     module,
10 |     class_name: str,
11 |     prefix: Optional[Union[str, List[str]]] = None,
   |             ^^^^^^^^ FA100
12 |     positional_args: Optional[dict] = None,
13 |     optional_args: Optional[dict] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:11:22: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
 9 |     module,
10 |     class_name: str,
11 |     prefix: Optional[Union[str, List[str]]] = None,
   |                      ^^^^^ FA100
12 |     positional_args: Optional[dict] = None,
13 |     optional_args: Optional[dict] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:11:33: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
 9 |     module,
10 |     class_name: str,
11 |     prefix: Optional[Union[str, List[str]]] = None,
   |                                 ^^^^ FA100
12 |     positional_args: Optional[dict] = None,
13 |     optional_args: Optional[dict] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:12:22: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
10 |     class_name: str,
11 |     prefix: Optional[Union[str, List[str]]] = None,
12 |     positional_args: Optional[dict] = None,
   |                      ^^^^^^^^ FA100
13 |     optional_args: Optional[dict] = None,
14 |     all_args: Optional[dict] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:13:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
11 |     prefix: Optional[Union[str, List[str]]] = None,
12 |     positional_args: Optional[dict] = None,
13 |     optional_args: Optional[dict] = None,
   |                    ^^^^^^^^ FA100
14 |     all_args: Optional[dict] = None,
15 |     remove_kwargs: bool = True,
   |

geom3d\models\NequIP\utils\auto_init.py:14:15: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
12 |     positional_args: Optional[dict] = None,
13 |     optional_args: Optional[dict] = None,
14 |     all_args: Optional[dict] = None,
   |               ^^^^^^^^ FA100
15 |     remove_kwargs: bool = True,
16 |     return_args_only: bool = False,
   |

geom3d\models\NequIP\utils\auto_init.py:15:5: FBT001 Boolean-typed positional argument in function definition
   |
13 |     optional_args: Optional[dict] = None,
14 |     all_args: Optional[dict] = None,
15 |     remove_kwargs: bool = True,
   |     ^^^^^^^^^^^^^ FBT001
16 |     return_args_only: bool = False,
17 | ):
   |

geom3d\models\NequIP\utils\auto_init.py:15:5: FBT002 Boolean default positional argument in function definition
   |
13 |     optional_args: Optional[dict] = None,
14 |     all_args: Optional[dict] = None,
15 |     remove_kwargs: bool = True,
   |     ^^^^^^^^^^^^^ FBT002
16 |     return_args_only: bool = False,
17 | ):
   |

geom3d\models\NequIP\utils\auto_init.py:16:5: FBT001 Boolean-typed positional argument in function definition
   |
14 |     all_args: Optional[dict] = None,
15 |     remove_kwargs: bool = True,
16 |     return_args_only: bool = False,
   |     ^^^^^^^^^^^^^^^^ FBT001
17 | ):
18 |     """Initialize a class based on a string class name.
   |

geom3d\models\NequIP\utils\auto_init.py:16:5: FBT002 Boolean default positional argument in function definition
   |
14 |     all_args: Optional[dict] = None,
15 |     remove_kwargs: bool = True,
16 |     return_args_only: bool = False,
   |     ^^^^^^^^^^^^^^^^ FBT002
17 | ):
18 |     """Initialize a class based on a string class name.
   |

geom3d\models\NequIP\utils\auto_init.py:49:9: PERF403 Use a dictionary comprehension instead of a for-loop
   |
47 |     class_dict = {}
48 |     for k, v in class_list:
49 |         class_dict[k] = v
   |         ^^^^^^^^^^^^^^^^^ PERF403
50 |     # print("class_dict", class_dict)
51 |     # print("class_name", class_name)
   |

geom3d\models\NequIP\utils\auto_init.py:50:5: ERA001 Found commented-out code
   |
48 |     for k, v in class_list:
49 |         class_dict[k] = v
50 |     # print("class_dict", class_dict)
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
51 |     # print("class_name", class_name)
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\auto_init.py:51:5: ERA001 Found commented-out code
   |
49 |         class_dict[k] = v
50 |     # print("class_dict", class_dict)
51 |     # print("class_name", class_name)
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
52 | 
53 |     # find the matching class
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\auto_init.py:70:5: C901 `instantiate` is too complex (30 > 10)
   |
70 | def instantiate(
   |     ^^^^^^^^^^^ C901
71 |     builder,
72 |     prefix: Optional[Union[str, List[str]]] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:70:5: PLR0913 Too many arguments in function definition (8 > 5)
   |
70 | def instantiate(
   |     ^^^^^^^^^^^ PLR0913
71 |     builder,
72 |     prefix: Optional[Union[str, List[str]]] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:70:5: PLR0912 Too many branches (30 > 12)
   |
70 | def instantiate(
   |     ^^^^^^^^^^^ PLR0912
71 |     builder,
72 |     prefix: Optional[Union[str, List[str]]] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:70:5: PLR0915 Too many statements (78 > 50)
   |
70 | def instantiate(
   |     ^^^^^^^^^^^ PLR0915
71 |     builder,
72 |     prefix: Optional[Union[str, List[str]]] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:70:5: D417 Missing argument description in the docstring for `instantiate`: `parent_builders`
   |
70 | def instantiate(
   |     ^^^^^^^^^^^ D417
71 |     builder,
72 |     prefix: Optional[Union[str, List[str]]] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:72:13: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
70 | def instantiate(
71 |     builder,
72 |     prefix: Optional[Union[str, List[str]]] = None,
   |             ^^^^^^^^ FA100
73 |     positional_args: Optional[dict] = None,
74 |     optional_args: Optional[dict] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:72:22: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
70 | def instantiate(
71 |     builder,
72 |     prefix: Optional[Union[str, List[str]]] = None,
   |                      ^^^^^ FA100
73 |     positional_args: Optional[dict] = None,
74 |     optional_args: Optional[dict] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:72:33: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
70 | def instantiate(
71 |     builder,
72 |     prefix: Optional[Union[str, List[str]]] = None,
   |                                 ^^^^ FA100
73 |     positional_args: Optional[dict] = None,
74 |     optional_args: Optional[dict] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:73:22: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
71 |     builder,
72 |     prefix: Optional[Union[str, List[str]]] = None,
73 |     positional_args: Optional[dict] = None,
   |                      ^^^^^^^^ FA100
74 |     optional_args: Optional[dict] = None,
75 |     all_args: Optional[dict] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:74:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
72 |     prefix: Optional[Union[str, List[str]]] = None,
73 |     positional_args: Optional[dict] = None,
74 |     optional_args: Optional[dict] = None,
   |                    ^^^^^^^^ FA100
75 |     all_args: Optional[dict] = None,
76 |     remove_kwargs: bool = True,
   |

geom3d\models\NequIP\utils\auto_init.py:75:15: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
73 |     positional_args: Optional[dict] = None,
74 |     optional_args: Optional[dict] = None,
75 |     all_args: Optional[dict] = None,
   |               ^^^^^^^^ FA100
76 |     remove_kwargs: bool = True,
77 |     return_args_only: bool = False,
   |

geom3d\models\NequIP\utils\auto_init.py:76:5: FBT001 Boolean-typed positional argument in function definition
   |
74 |     optional_args: Optional[dict] = None,
75 |     all_args: Optional[dict] = None,
76 |     remove_kwargs: bool = True,
   |     ^^^^^^^^^^^^^ FBT001
77 |     return_args_only: bool = False,
78 |     parent_builders: Optional[list] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:76:5: FBT002 Boolean default positional argument in function definition
   |
74 |     optional_args: Optional[dict] = None,
75 |     all_args: Optional[dict] = None,
76 |     remove_kwargs: bool = True,
   |     ^^^^^^^^^^^^^ FBT002
77 |     return_args_only: bool = False,
78 |     parent_builders: Optional[list] = None,
   |

geom3d\models\NequIP\utils\auto_init.py:77:5: FBT001 Boolean-typed positional argument in function definition
   |
75 |     all_args: Optional[dict] = None,
76 |     remove_kwargs: bool = True,
77 |     return_args_only: bool = False,
   |     ^^^^^^^^^^^^^^^^ FBT001
78 |     parent_builders: Optional[list] = None,
79 | ):
   |

geom3d\models\NequIP\utils\auto_init.py:77:5: FBT002 Boolean default positional argument in function definition
   |
75 |     all_args: Optional[dict] = None,
76 |     remove_kwargs: bool = True,
77 |     return_args_only: bool = False,
   |     ^^^^^^^^^^^^^^^^ FBT002
78 |     parent_builders: Optional[list] = None,
79 | ):
   |

geom3d\models\NequIP\utils\auto_init.py:78:22: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
76 |     remove_kwargs: bool = True,
77 |     return_args_only: bool = False,
78 |     parent_builders: Optional[list] = None,
   |                      ^^^^^^^^ FA100
79 | ):
80 |     """Automatic initializing class instance by matching keys in the parameter dictionary to the constructor function.
   |

geom3d\models\NequIP\utils\auto_init.py:112:9: TRY004 Prefer `TypeError` exception for invalid type
    |
110 |     else:
111 |         msg = f"prefix has the wrong type {type(prefix)}"
112 |         raise ValueError(msg)
    |         ^^^^^^^^^^^^^^^^^^^^^ TRY004
113 | 
114 |     # detect the input parameters needed from params
    |

geom3d\models\NequIP\utils\auto_init.py:221:29: G004 Logging statement uses f-string
    |
219 |             )
220 |         elif not callable(sub_builder) and not inspect.isclass(sub_builder):
221 |             logging.warning(f"subbuilder is not callable {sub_builder}")
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
222 |         elif key + "_kwargs" in positional_args:
223 |             logging.warning(
    |

geom3d\models\NequIP\utils\auto_init.py:224:17: G004 Logging statement uses f-string
    |
222 |         elif key + "_kwargs" in positional_args:
223 |             logging.warning(
224 |                 f"skip searching for nested argument because {key}_kwargs are defined in positional arguments"
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
225 |             )
    |

geom3d\models\NequIP\utils\auto_init.py:237:19: G004 Logging statement uses f-string
    |
236 |     # debug info
237 |     logging.debug(f"instantiate {builder.__name__}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
238 |     for t in key_mapping:
239 |         for k, v in key_mapping[t].items():
    |

geom3d\models\NequIP\utils\auto_init.py:244:19: G004 Logging statement uses f-string
    |
242 |                 string += f" <- {v:>50s}"
243 |             logging.debug(string)
244 |     logging.debug(f"...{builder.__name__}_param = dict(")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
245 |     logging.debug(f"...   optional_args = {final_optional_args},")
246 |     logging.debug(f"...   positional_args = {positional_args})")
    |

geom3d\models\NequIP\utils\auto_init.py:245:19: G004 Logging statement uses f-string
    |
243 |             logging.debug(string)
244 |     logging.debug(f"...{builder.__name__}_param = dict(")
245 |     logging.debug(f"...   optional_args = {final_optional_args},")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
246 |     logging.debug(f"...   positional_args = {positional_args})")
    |

geom3d\models\NequIP\utils\auto_init.py:246:19: G004 Logging statement uses f-string
    |
244 |     logging.debug(f"...{builder.__name__}_param = dict(")
245 |     logging.debug(f"...   optional_args = {final_optional_args},")
246 |     logging.debug(f"...   positional_args = {positional_args})")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
247 | 
248 |     # print(f"Start to build object with prefix `{prefix}` using builder `{builder.__name__}`")
    |

geom3d\models\NequIP\utils\auto_init.py:248:5: ERA001 Found commented-out code
    |
246 |     logging.debug(f"...   positional_args = {positional_args})")
247 | 
248 |     # print(f"Start to build object with prefix `{prefix}` using builder `{builder.__name__}`")
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
249 |     # print("positional_args", positional_args)
250 |     # print("final_optional_args", final_optional_args)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\auto_init.py:249:5: ERA001 Found commented-out code
    |
248 |     # print(f"Start to build object with prefix `{prefix}` using builder `{builder.__name__}`")
249 |     # print("positional_args", positional_args)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
250 |     # print("final_optional_args", final_optional_args)
251 |     try:
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\auto_init.py:250:5: ERA001 Found commented-out code
    |
248 |     # print(f"Start to build object with prefix `{prefix}` using builder `{builder.__name__}`")
249 |     # print("positional_args", positional_args)
250 |     # print("final_optional_args", final_optional_args)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
251 |     try:
252 |         instance = builder(**positional_args, **final_optional_args)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\auto_init.py:262:5: C901 `get_w_prefix` is too complex (14 > 10)
    |
262 | def get_w_prefix(
    |     ^^^^^^^^^^^^ C901
263 |     key: List[str],
264 |     *kwargs,
    |

geom3d\models\NequIP\utils\auto_init.py:262:5: PLR0912 Too many branches (14 > 12)
    |
262 | def get_w_prefix(
    |     ^^^^^^^^^^^^ PLR0912
263 |     key: List[str],
264 |     *kwargs,
    |

geom3d\models\NequIP\utils\auto_init.py:263:10: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
262 | def get_w_prefix(
263 |     key: List[str],
    |          ^^^^ FA100
264 |     *kwargs,
265 |     arg_dicts: Optional[List[dict]] = None,
    |

geom3d\models\NequIP\utils\auto_init.py:264:5: ANN002 Missing type annotation for `*kwargs`
    |
262 | def get_w_prefix(
263 |     key: List[str],
264 |     *kwargs,
    |     ^^^^^^^ ANN002
265 |     arg_dicts: Optional[List[dict]] = None,
266 |     prefix: Optional[Union[str, List[str]]] = None,
    |

geom3d\models\NequIP\utils\auto_init.py:265:16: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
263 |     key: List[str],
264 |     *kwargs,
265 |     arg_dicts: Optional[List[dict]] = None,
    |                ^^^^^^^^ FA100
266 |     prefix: Optional[Union[str, List[str]]] = None,
267 | ):
    |

geom3d\models\NequIP\utils\auto_init.py:265:25: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
263 |     key: List[str],
264 |     *kwargs,
265 |     arg_dicts: Optional[List[dict]] = None,
    |                         ^^^^ FA100
266 |     prefix: Optional[Union[str, List[str]]] = None,
267 | ):
    |

geom3d\models\NequIP\utils\auto_init.py:266:13: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
264 |     *kwargs,
265 |     arg_dicts: Optional[List[dict]] = None,
266 |     prefix: Optional[Union[str, List[str]]] = None,
    |             ^^^^^^^^ FA100
267 | ):
268 |     """Act as the get function and try to search for the value key from arg_dicts."""
    |

geom3d\models\NequIP\utils\auto_init.py:266:22: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
    |
264 |     *kwargs,
265 |     arg_dicts: Optional[List[dict]] = None,
266 |     prefix: Optional[Union[str, List[str]]] = None,
    |                      ^^^^^ FA100
267 | ):
268 |     """Act as the get function and try to search for the value key from arg_dicts."""
    |

geom3d\models\NequIP\utils\auto_init.py:266:33: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
264 |     *kwargs,
265 |     arg_dicts: Optional[List[dict]] = None,
266 |     prefix: Optional[Union[str, List[str]]] = None,
    |                                 ^^^^ FA100
267 | ):
268 |     """Act as the get function and try to search for the value key from arg_dicts."""
    |

geom3d\models\NequIP\utils\auto_init.py:283:9: TRY004 Prefer `TypeError` exception for invalid type
    |
281 |     else:
282 |         msg = f"prefix is with a wrong type {type(prefix)}"
283 |         raise ValueError(msg)
    |         ^^^^^^^^^^^^^^^^^^^^^ TRY004
284 | 
285 |     if not isinstance(arg_dicts, list):
    |

geom3d\models\NequIP\utils\auto_init.py:296:13: PLW2901 Outer `for` loop variable `idx` overwritten by inner `for` loop target
    |
294 |         key_mapping[idx] = {k: k for k in _keys}
295 |         # fetch paratemeters that match prefix + "_" + name
296 |         for idx, prefix_str in enumerate(prefix_list):
    |             ^^^ PLW2901
297 |             _keys = config.update_w_prefix(
298 |                 arg_dict,
    |

geom3d\models\NequIP\utils\auto_init.py:317:19: G004 Logging statement uses f-string
    |
316 |     # debug info
317 |     logging.debug(f"search for {key} with prefix {prefix}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
318 |     for t in key_mapping:
319 |         for k, v in key_mapping[t].items():
    |

geom3d\models\NequIP\utils\batch_ops.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\batch_ops.py:6:5: D103 Missing docstring in public function
  |
6 | def bincount(
  |     ^^^^^^^^ D103
7 |     input: torch.Tensor, batch: Optional[torch.Tensor] = None, minlength: int = 0
8 | ):
  |

geom3d\models\NequIP\utils\batch_ops.py:7:5: A002 Argument `input` is shadowing a Python builtin
  |
6 | def bincount(
7 |     input: torch.Tensor, batch: Optional[torch.Tensor] = None, minlength: int = 0
  |     ^^^^^ A002
8 | ):
9 |     assert input.ndim == 1
  |

geom3d\models\NequIP\utils\batch_ops.py:7:33: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
  |
6 | def bincount(
7 |     input: torch.Tensor, batch: Optional[torch.Tensor] = None, minlength: int = 0
  |                                 ^^^^^^^^ FA100
8 | ):
9 |     assert input.ndim == 1
  |

geom3d\models\NequIP\utils\batch_ops.py:9:5: S101 Use of `assert` detected
   |
 7 |     input: torch.Tensor, batch: Optional[torch.Tensor] = None, minlength: int = 0
 8 | ):
 9 |     assert input.ndim == 1
   |     ^^^^^^ S101
10 |     if batch is None:
11 |         return torch.bincount(input, minlength=minlength)
   |

geom3d\models\NequIP\utils\batch_ops.py:12:5: RET505 Unnecessary `else` after `return` statement
   |
10 |     if batch is None:
11 |         return torch.bincount(input, minlength=minlength)
12 |     else:
   |     ^^^^ RET505
13 |         assert batch.shape == input.shape
   |
   = help: Remove unnecessary `else`

geom3d\models\NequIP\utils\batch_ops.py:13:9: S101 Use of `assert` detected
   |
11 |         return torch.bincount(input, minlength=minlength)
12 |     else:
13 |         assert batch.shape == input.shape
   |         ^^^^^^ S101
14 | 
15 |         length = input.max().item() + 1
   |

geom3d\models\NequIP\utils\batch_ops.py:26:9: A001 Variable `input` is shadowing a Python builtin
   |
24 |         # Flatten indexes
25 |         # Make each "class" in input into a per-input class.
26 |         input = input + batch * minlength
   |         ^^^^^ A001
27 | 
28 |         num_batch = batch.max() + 1
   |

geom3d\models\NequIP\utils\config.py:46:7: D101 Missing docstring in public class
   |
46 | class Config:
   |       ^^^^^^ D101
47 |     def __init__(
48 |         self,
   |

geom3d\models\NequIP\utils\config.py:47:9: D107 Missing docstring in `__init__`
   |
46 | class Config:
47 |     def __init__(
   |         ^^^^^^^^ D107
48 |         self,
49 |         config: Optional[dict] = None,
   |

geom3d\models\NequIP\utils\config.py:49:17: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
47 |     def __init__(
48 |         self,
49 |         config: Optional[dict] = None,
   |                 ^^^^^^^^ FA100
50 |         allow_list: Optional[list] = None,
51 |         exclude_keys: Optional[list] = None,
   |

geom3d\models\NequIP\utils\config.py:50:21: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
48 |         self,
49 |         config: Optional[dict] = None,
50 |         allow_list: Optional[list] = None,
   |                     ^^^^^^^^ FA100
51 |         exclude_keys: Optional[list] = None,
52 |     ):
   |

geom3d\models\NequIP\utils\config.py:51:23: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
49 |         config: Optional[dict] = None,
50 |         allow_list: Optional[list] = None,
51 |         exclude_keys: Optional[list] = None,
   |                       ^^^^^^^^ FA100
52 |     ):
   |

geom3d\models\NequIP\utils\config.py:69:9: D105 Missing docstring in magic method
   |
67 |             self.update(config)
68 | 
69 |     def __repr__(self):
   |         ^^^^^^^^ D105
70 |         return str(dict(self))
   |

geom3d\models\NequIP\utils\config.py:74:9: D102 Missing docstring in public method
   |
72 |     __str__ = __repr__
73 | 
74 |     def keys(self):
   |         ^^^^ D102
75 |         return self._items.keys()
   |

geom3d\models\NequIP\utils\config.py:77:9: ANN202 Missing return type annotation for private function `_as_dict`
   |
75 |         return self._items.keys()
76 | 
77 |     def _as_dict(self):
   |         ^^^^^^^^ ANN202
78 |         return self._items
   |
   = help: Add return type annotation

geom3d\models\NequIP\utils\config.py:80:9: D102 Missing docstring in public method
   |
78 |         return self._items
79 | 
80 |     def as_dict(self):
   |         ^^^^^^^ D102
81 |         return dict(self)
   |

geom3d\models\NequIP\utils\config.py:83:9: D105 Missing docstring in magic method
   |
81 |         return dict(self)
82 | 
83 |     def __getitem__(self, key):
   |         ^^^^^^^^^^^ D105
84 |         return self._items[key]
   |

geom3d\models\NequIP\utils\config.py:87:9: D205 1 blank line required between summary line and description
   |
86 |       def get_type(self, key):
87 |           """Get Typehint from item_types dict or previous defined value
   |  _________^
88 | |         Args:
89 | | 
90 | |             key: name of the variable
91 | |         """
   | |___________^ D205
92 |           return self._item_types.get(key, None)
   |
   = help: Insert single blank line

geom3d\models\NequIP\utils\config.py:87:9: D400 First line should end with a period
   |
86 |       def get_type(self, key):
87 |           """Get Typehint from item_types dict or previous defined value
   |  _________^
88 | |         Args:
89 | | 
90 | |             key: name of the variable
91 | |         """
   | |___________^ D400
92 |           return self._item_types.get(key, None)
   |
   = help: Add period

geom3d\models\NequIP\utils\config.py:87:9: D415 First line should end with a period, question mark, or exclamation point
   |
86 |       def get_type(self, key):
87 |           """Get Typehint from item_types dict or previous defined value
   |  _________^
88 | |         Args:
89 | | 
90 | |             key: name of the variable
91 | |         """
   | |___________^ D415
92 |           return self._item_types.get(key, None)
   |
   = help: Add closing punctuation

geom3d\models\NequIP\utils\config.py:115:9: D102 Missing docstring in public method
    |
113 |         self.update(default_values)
114 | 
115 |     def allow_list(self):
    |         ^^^^^^^^^^ D102
116 |         return self._allow_list
    |

geom3d\models\NequIP\utils\config.py:118:9: D105 Missing docstring in magic method
    |
116 |         return self._allow_list
117 | 
118 |     def __setitem__(self, key, val):
    |         ^^^^^^^^^^^ D105
119 | 
120 |         # typehint
    |

geom3d\models\NequIP\utils\config.py:131:9: RET505 Unnecessary `else` after `return` statement
    |
130 |         # normal value
131 |         else:
    |         ^^^^ RET505
132 | 
133 |             if (not self._allow_all) and key not in self._allow_list:
    |
    = help: Remove unnecessary `else`

geom3d\models\NequIP\utils\config.py:141:20: BLE001 Do not catch blind exception: `Exception`
    |
139 |             try:
140 |                 val = typehint(val) if typehint is not None else val
141 |             except Exception:
    |                    ^^^^^^^^^ BLE001
142 |                 msg = (
143 |                     f"Wrong Type: Parameter {key} should be {typehint} type."
    |

geom3d\models\NequIP\utils\config.py:146:17: B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
    |
144 |                       f"But {type(val)} is given"
145 |                   )
146 |                   raise TypeError(
    |  _________________^
147 | |                     msg
148 | |                 )
    | |_________________^ B904
149 |   
150 |               self._items[key] = deepcopy(val)
    |

geom3d\models\NequIP\utils\config.py:153:9: D102 Missing docstring in public method
    |
151 |             return key
152 | 
153 |     def items(self):
    |         ^^^^^ D102
154 |         return self._items.items()
    |

geom3d\models\NequIP\utils\config.py:158:9: D105 Missing docstring in magic method
    |
156 |     __setattr__ = __setitem__
157 | 
158 |     def __getattr__(self, key):
    |         ^^^^^^^^^^^ D105
159 |         return self.__getitem__(key)
    |

geom3d\models\NequIP\utils\config.py:161:9: D105 Missing docstring in magic method
    |
159 |         return self.__getitem__(key)
160 | 
161 |     def __contains__(self, key):
    |         ^^^^^^^^^^^^ D105
162 |         return key in self._items
    |

geom3d\models\NequIP\utils\config.py:164:9: D102 Missing docstring in public method
    |
162 |         return key in self._items
163 | 
164 |     def pop(self, *args):
    |         ^^^ D102
165 |         return self._items.pop(*args)
    |

geom3d\models\NequIP\utils\config.py:164:19: ANN002 Missing type annotation for `*args`
    |
162 |         return key in self._items
163 | 
164 |     def pop(self, *args):
    |                   ^^^^^ ANN002
165 |         return self._items.pop(*args)
    |

geom3d\models\NequIP\utils\config.py:167:9: D417 Missing argument description in the docstring for `update_w_prefix`: `prefix`
    |
165 |         return self._items.pop(*args)
166 | 
167 |     def update_w_prefix(
    |         ^^^^^^^^^^^^^^^ D417
168 |         self,
169 |         dictionary: dict,
    |

geom3d\models\NequIP\utils\config.py:183:9: D414 Section has no content ("Returns")
    |
181 |             allow_val_change (None): mock for wandb.config, not used.
182 | 
183 |         Returns:
    |         ^^^^^^^ D414
184 |         -------
    |

geom3d\models\NequIP\utils\config.py:204:40: ARG002 Unused method argument: `allow_val_change`
    |
202 |         return keys
203 | 
204 |     def update(self, dictionary: dict, allow_val_change=None):
    |                                        ^^^^^^^^^^^^^^^^ ARG002
205 |         """Mock of wandb.config function.
    |

geom3d\models\NequIP\utils\config.py:234:9: D102 Missing docstring in public method
    |
232 |         return set(keys) - {None}
233 | 
234 |     def get(self, *args):
    |         ^^^ D102
235 |         return self._items.get(*args)
    |

geom3d\models\NequIP\utils\config.py:234:19: ANN002 Missing type annotation for `*args`
    |
232 |         return set(keys) - {None}
233 | 
234 |     def get(self, *args):
    |                   ^^^^^ ANN002
235 |         return self._items.get(*args)
    |

geom3d\models\NequIP\utils\config.py:246:35: A002 Argument `format` is shadowing a Python builtin
    |
244 |         """Mock wandb.config function."""
245 | 
246 |     def save(self, filename: str, format: Optional[str] = None):
    |                                   ^^^^^^ A002
247 |         """Print config to file."""
248 |         supported_formats = {"yaml": ("yml", "yaml"), "json": "json"}
    |

geom3d\models\NequIP\utils\config.py:246:43: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
244 |         """Mock wandb.config function."""
245 | 
246 |     def save(self, filename: str, format: Optional[str] = None):
    |                                           ^^^^^^^^ FA100
247 |         """Print config to file."""
248 |         supported_formats = {"yaml": ("yml", "yaml"), "json": "json"}
    |

geom3d\models\NequIP\utils\config.py:257:9: ANN205 Missing return type annotation for staticmethod `from_file`
    |
256 |     @staticmethod
257 |     def from_file(filename: str, format: Optional[str] = None, defaults: Optional[dict] = None):
    |         ^^^^^^^^^ ANN205
258 |         """Load arguments from file."""
259 |         if defaults is None:
    |
    = help: Add return type annotation

geom3d\models\NequIP\utils\config.py:257:34: A002 Argument `format` is shadowing a Python builtin
    |
256 |     @staticmethod
257 |     def from_file(filename: str, format: Optional[str] = None, defaults: Optional[dict] = None):
    |                                  ^^^^^^ A002
258 |         """Load arguments from file."""
259 |         if defaults is None:
    |

geom3d\models\NequIP\utils\config.py:257:42: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
256 |     @staticmethod
257 |     def from_file(filename: str, format: Optional[str] = None, defaults: Optional[dict] = None):
    |                                          ^^^^^^^^ FA100
258 |         """Load arguments from file."""
259 |         if defaults is None:
    |

geom3d\models\NequIP\utils\config.py:257:74: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
256 |     @staticmethod
257 |     def from_file(filename: str, format: Optional[str] = None, defaults: Optional[dict] = None):
    |                                                                          ^^^^^^^^ FA100
258 |         """Load arguments from file."""
259 |         if defaults is None:
    |

geom3d\models\NequIP\utils\config.py:270:9: ANN205 Missing return type annotation for staticmethod `from_dict`
    |
269 |     @staticmethod
270 |     def from_dict(dictionary: dict, defaults: Optional[dict] = None):
    |         ^^^^^^^^^ ANN205
271 |         if defaults is None:
272 |             defaults = {}
    |
    = help: Add return type annotation

geom3d\models\NequIP\utils\config.py:270:9: D102 Missing docstring in public method
    |
269 |     @staticmethod
270 |     def from_dict(dictionary: dict, defaults: Optional[dict] = None):
    |         ^^^^^^^^^ D102
271 |         if defaults is None:
272 |             defaults = {}
    |

geom3d\models\NequIP\utils\config.py:270:47: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
269 |     @staticmethod
270 |     def from_dict(dictionary: dict, defaults: Optional[dict] = None):
    |                                               ^^^^^^^^ FA100
271 |         if defaults is None:
272 |             defaults = {}
    |

geom3d\models\NequIP\utils\config.py:278:9: ANN205 Missing return type annotation for staticmethod `from_class`
    |
277 |     @staticmethod
278 |     def from_class(class_type, remove_kwargs: bool = False):
    |         ^^^^^^^^^^ ANN205
279 |         """Return Config class instance based on init function of the input class
280 |         the instance will only allow to store init function related variables
    |
    = help: Add return type annotation

geom3d\models\NequIP\utils\config.py:278:32: FBT001 Boolean-typed positional argument in function definition
    |
277 |     @staticmethod
278 |     def from_class(class_type, remove_kwargs: bool = False):
    |                                ^^^^^^^^^^^^^ FBT001
279 |         """Return Config class instance based on init function of the input class
280 |         the instance will only allow to store init function related variables
    |

geom3d\models\NequIP\utils\config.py:278:32: FBT002 Boolean default positional argument in function definition
    |
277 |     @staticmethod
278 |     def from_class(class_type, remove_kwargs: bool = False):
    |                                ^^^^^^^^^^^^^ FBT002
279 |         """Return Config class instance based on init function of the input class
280 |         the instance will only allow to store init function related variables
    |

geom3d\models\NequIP\utils\config.py:279:9: D205 1 blank line required between summary line and description
    |
277 |       @staticmethod
278 |       def from_class(class_type, remove_kwargs: bool = False):
279 |           """Return Config class instance based on init function of the input class
    |  _________^
280 | |         the instance will only allow to store init function related variables
281 | |         the type hints are all set to None, so no automatic format conversion is applied.
282 | | 
283 | |         class_type: torch.module children class type, i.e. .NequIP.Nequip
284 | |         remove_kwargs (optional, bool): the same as Config.from_function
285 | | 
286 | |         Returns
287 | |         -------
288 | |         config (Config):
289 | | 
290 | |         """
    | |___________^ D205
291 |           if inspect.isclass(class_type):
292 |               return Config.from_function(
    |
    = help: Insert single blank line

geom3d\models\NequIP\utils\config.py:295:9: RET505 Unnecessary `elif` after `return` statement
    |
293 |                 class_type.__init__, remove_kwargs=remove_kwargs
294 |             )
295 |         elif callable(class_type):
    |         ^^^^ RET505
296 |             return Config.from_function(class_type, remove_kwargs=remove_kwargs)
297 |         else:
    |
    = help: Remove unnecessary `elif`

geom3d\models\NequIP\utils\config.py:304:9: ANN205 Missing return type annotation for staticmethod `from_function`
    |
303 |     @staticmethod
304 |     def from_function(function, remove_kwargs=False):
    |         ^^^^^^^^^^^^^ ANN205
305 |         """Return Config class instance based on the function of the input class
306 |         the instance will only allow to store init function related variables
    |
    = help: Add return type annotation

geom3d\models\NequIP\utils\config.py:304:33: FBT002 Boolean default positional argument in function definition
    |
303 |     @staticmethod
304 |     def from_function(function, remove_kwargs=False):
    |                                 ^^^^^^^^^^^^^ FBT002
305 |         """Return Config class instance based on the function of the input class
306 |         the instance will only allow to store init function related variables
    |

geom3d\models\NequIP\utils\config.py:305:9: D205 1 blank line required between summary line and description
    |
303 |       @staticmethod
304 |       def from_function(function, remove_kwargs=False):
305 |           """Return Config class instance based on the function of the input class
    |  _________^
306 | |         the instance will only allow to store init function related variables
307 | |         the type hints are all set to None, so no automatic format conversion is applied.
308 | | 
309 | |         Args:
310 | |         ----
311 | |         function: function name
312 | |         remove_kwargs (optional, bool): if True, kwargs are removed from the keys
313 | |              and the returned instance will only takes the init params of the class_type.
314 | |              if False and kwargs exists, the config only initialized with the default param values,
315 | |              but it can take any other keys
316 | | 
317 | |         Returns:
318 | |         -------
319 | |         config (Config):
320 | | 
321 | |         """
    | |___________^ D205
322 |           sig = inspect.signature(function)
    |
    = help: Insert single blank line

geom3d\models\NequIP\utils\config.py:339:9: RET505 Unnecessary `elif` after `return` statement
    |
337 |         if "kwargs" in param_keys and not remove_kwargs:
338 |             return Config(config=default_params)
339 |         elif "kwargs" in param_keys:
    |         ^^^^ RET505
340 |             param_keys.remove("kwargs")
341 |             return Config(config=default_params, allow_list=param_keys)
    |
    = help: Remove unnecessary `elif`

geom3d\models\NequIP\utils\git.py:1:1: ERA001 Found commented-out code
  |
1 | # from typing import Optional
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
2 | 
3 | # import subprocess
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\git.py:3:1: ERA001 Found commented-out code
  |
1 | # from typing import Optional
2 | 
3 | # import subprocess
  | ^^^^^^^^^^^^^^^^^^^ ERA001
4 | # from pathlib import Path
5 | # from importlib import import_module
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:4:1: ERA001 Found commented-out code
  |
3 | # import subprocess
4 | # from pathlib import Path
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
5 | # from importlib import import_module
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:5:1: ERA001 Found commented-out code
  |
3 | # import subprocess
4 | # from pathlib import Path
5 | # from importlib import import_module
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:10:1: ERA001 Found commented-out code
   |
 8 | # def get_commit(module: str) -> Optional[str]:
 9 | 
10 | #     module = import_module(module)
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
11 | #     path = str(Path(module.__file__).parents[0] / "..")
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:11:1: ERA001 Found commented-out code
   |
10 | #     module = import_module(module)
11 | #     path = str(Path(module.__file__).parents[0] / "..")
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
12 | 
13 | #     retcode = subprocess.run(
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:13:1: ERA001 Found commented-out code
   |
11 | #     path = str(Path(module.__file__).parents[0] / "..")
12 | 
13 | #     retcode = subprocess.run(
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
14 | #         "git show --oneline --abbrev=40 -s".split(),
15 | #         cwd=path,
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:14:1: ERA001 Found commented-out code
   |
13 | #     retcode = subprocess.run(
14 | #         "git show --oneline --abbrev=40 -s".split(),
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
15 | #         cwd=path,
16 | #         stdout=subprocess.PIPE,
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:15:1: ERA001 Found commented-out code
   |
13 | #     retcode = subprocess.run(
14 | #         "git show --oneline --abbrev=40 -s".split(),
15 | #         cwd=path,
   | ^^^^^^^^^^^^^^^^^^^ ERA001
16 | #         stdout=subprocess.PIPE,
17 | #         stderr=subprocess.PIPE,
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:16:1: ERA001 Found commented-out code
   |
14 | #         "git show --oneline --abbrev=40 -s".split(),
15 | #         cwd=path,
16 | #         stdout=subprocess.PIPE,
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
17 | #         stderr=subprocess.PIPE,
18 | #     )
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:17:1: ERA001 Found commented-out code
   |
15 | #         cwd=path,
16 | #         stdout=subprocess.PIPE,
17 | #         stderr=subprocess.PIPE,
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
18 | #     )
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:18:1: ERA001 Found commented-out code
   |
16 | #         stdout=subprocess.PIPE,
17 | #         stderr=subprocess.PIPE,
18 | #     )
   | ^^^^^^^ ERA001
19 | 
20 | #     if retcode.returncode == 0:
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:21:1: ERA001 Found commented-out code
   |
20 | #     if retcode.returncode == 0:
21 | #         return retcode.stdout.decode().splitlines()[0].split()[0]
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
22 | #     else:
23 | #         return None
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:22:1: ERA001 Found commented-out code
   |
20 | #     if retcode.returncode == 0:
21 | #         return retcode.stdout.decode().splitlines()[0].split()[0]
22 | #     else:
   | ^^^^^^^^^^^ ERA001
23 | #         return None
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\git.py:23:1: ERA001 Found commented-out code
   |
21 | #         return retcode.stdout.decode().splitlines()[0].split()[0]
22 | #     else:
23 | #         return None
   | ^^^^^^^^^^^^^^^^^^^^^ ERA001
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\misc.py:1:1: ERA001 Found commented-out code
  |
1 | # import torch
  | ^^^^^^^^^^^^^^ ERA001
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\misc.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\misc.py:5:1: ERA001 Found commented-out code
  |
4 | # def dtype_from_name(name: str) -> torch.dtype:
5 | #     return {"float32": torch.float32, "float64": torch.float64}[name]
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\modules.py:1:1: ERA001 Found commented-out code
  |
1 | # from typing import Optional
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
2 | 
3 | # import torch
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\modules.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\modules.py:3:1: ERA001 Found commented-out code
  |
1 | # from typing import Optional
2 | 
3 | # import torch
  | ^^^^^^^^^^^^^^ ERA001
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\modules.py:9:1: ERA001 Found commented-out code
   |
 7 | #     """Find the first module of a given type in a module tree."""
 8 | #     if isinstance(m, kls):
 9 | #         return m
   | ^^^^^^^^^^^^^^^^^^ ERA001
10 | #     else:
11 | #         for child in m.children():
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\modules.py:10:1: ERA001 Found commented-out code
   |
 8 | #     if isinstance(m, kls):
 9 | #         return m
10 | #     else:
   | ^^^^^^^^^^^ ERA001
11 | #         for child in m.children():
12 | #             tmp = find_first_of_type(child, kls)
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\modules.py:12:1: ERA001 Found commented-out code
   |
10 | #     else:
11 | #         for child in m.children():
12 | #             tmp = find_first_of_type(child, kls)
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
13 | #             if tmp is not None:
14 | #                 return tmp
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\modules.py:14:1: ERA001 Found commented-out code
   |
12 | #             tmp = find_first_of_type(child, kls)
13 | #             if tmp is not None:
14 | #                 return tmp
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
15 | #     return None
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\modules.py:15:1: ERA001 Found commented-out code
   |
13 | #             if tmp is not None:
14 | #                 return tmp
15 | #     return None
   | ^^^^^^^^^^^^^^^^^ ERA001
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\multiprocessing.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\multiprocessing.py:6:5: D103 Missing docstring in public function
  |
6 | def num_tasks() -> int:
  |     ^^^^^^^^^ D103
7 |     # sched_getaffinity gives number of _allowed_ cores
8 |     # this is correct for SLURM jobs, for example
  |

geom3d\models\NequIP\utils\multiprocessing.py:20:5: S101 Use of `assert` detected
   |
18 |         os.environ.get("NEQUIP_NUM_TASKS", num_avail if _has_sched_getaffinity else 1)
19 |     )
20 |     assert n_proc > 0
   |     ^^^^^^ S101
21 |     assert (
22 |         n_proc <= num_avail
   |

geom3d\models\NequIP\utils\multiprocessing.py:21:5: S101 Use of `assert` detected
   |
19 |     )
20 |     assert n_proc > 0
21 |     assert (
   |     ^^^^^^ S101
22 |         n_proc <= num_avail
23 |     ), f"Asked for more worker tasks NEQUIP_NUM_TASKS={n_proc} than available CPU cores {num_avail}"
   |

geom3d\models\NequIP\utils\output.py:1:1: ERA001 Found commented-out code
  |
1 | # import inspect
  | ^^^^^^^^^^^^^^^^ ERA001
2 | # import logging
3 | # import sys
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\output.py:2:1: ERA001 Found commented-out code
  |
1 | # import inspect
2 | # import logging
  | ^^^^^^^^^^^^^^^^ ERA001
3 | # import sys
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:3:1: ERA001 Found commented-out code
  |
1 | # import inspect
2 | # import logging
3 | # import sys
  | ^^^^^^^^^^^^ ERA001
4 | 
5 | # from logging import FileHandler, StreamHandler
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:5:1: ERA001 Found commented-out code
  |
3 | # import sys
4 | 
5 | # from logging import FileHandler, StreamHandler
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
6 | # from os import makedirs
7 | # from os.path import abspath, relpath, isfile, isdir
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:6:1: ERA001 Found commented-out code
  |
5 | # from logging import FileHandler, StreamHandler
6 | # from os import makedirs
  | ^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
7 | # from os.path import abspath, relpath, isfile, isdir
8 | # from typing import Optional
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:7:1: ERA001 Found commented-out code
  |
5 | # from logging import FileHandler, StreamHandler
6 | # from os import makedirs
7 | # from os.path import abspath, relpath, isfile, isdir
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
8 | # from typing import Optional
  |
  = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:8:1: ERA001 Found commented-out code
   |
 6 | # from os import makedirs
 7 | # from os.path import abspath, relpath, isfile, isdir
 8 | # from typing import Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
 9 | 
10 | # from .config import Config
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:10:1: ERA001 Found commented-out code
   |
 8 | # from typing import Optional
 9 | 
10 | # from .config import Config
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:29:1: ERA001 Found commented-out code
   |
27 | #         root: str,
28 | #         run_name: str,
29 | #         logfile: Optional[str] = None,
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
30 | #         append: bool = False,
31 | #         screen: bool = False,
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:30:1: ERA001 Found commented-out code
   |
28 | #         run_name: str,
29 | #         logfile: Optional[str] = None,
30 | #         append: bool = False,
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
31 | #         screen: bool = False,
32 | #         verbose: str = "info",
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:31:1: ERA001 Found commented-out code
   |
29 | #         logfile: Optional[str] = None,
30 | #         append: bool = False,
31 | #         screen: bool = False,
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
32 | #         verbose: str = "info",
33 | #     ):
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:32:1: ERA001 Found commented-out code
   |
30 | #         append: bool = False,
31 | #         screen: bool = False,
32 | #         verbose: str = "info",
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
33 | #     ):
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:36:1: ERA001 Found commented-out code
   |
35 | #         # add screen output to the universal logger
36 | #         logger = logging.getLogger("")
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
37 | #         logger.setLevel(getattr(logging, verbose.upper()))
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:37:1: ERA001 Found commented-out code
   |
35 | #         # add screen output to the universal logger
36 | #         logger = logging.getLogger("")
37 | #         logger.setLevel(getattr(logging, verbose.upper()))
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
38 | 
39 | #         if len(logger.handlers) == 0 and (screen or verbose.lower() == "debug"):
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:40:1: ERA001 Found commented-out code
   |
39 | #         if len(logger.handlers) == 0 and (screen or verbose.lower() == "debug"):
40 | #             logger.addHandler(logging.StreamHandler(sys.stdout))
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
41 | 
42 | #         logging.debug("* Initialize Output")
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:42:1: ERA001 Found commented-out code
   |
40 | #             logger.addHandler(logging.StreamHandler(sys.stdout))
41 | 
42 | #         logging.debug("* Initialize Output")
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
43 | 
44 | #         FORMAT = "%(message)s"
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:44:1: ERA001 Found commented-out code
   |
42 | #         logging.debug("* Initialize Output")
43 | 
44 | #         FORMAT = "%(message)s"
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
45 | #         formatter = logging.Formatter(FORMAT)
46 | #         for handler in logger.handlers:
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:45:1: ERA001 Found commented-out code
   |
44 | #         FORMAT = "%(message)s"
45 | #         formatter = logging.Formatter(FORMAT)
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
46 | #         for handler in logger.handlers:
47 | #             handler.setFormatter(fmt=formatter)
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:47:1: ERA001 Found commented-out code
   |
45 | #         formatter = logging.Formatter(FORMAT)
46 | #         for handler in logger.handlers:
47 | #             handler.setFormatter(fmt=formatter)
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
48 | 
49 | #         self.append = append
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:49:1: ERA001 Found commented-out code
   |
47 | #             handler.setFormatter(fmt=formatter)
48 | 
49 | #         self.append = append
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
50 | #         self.screen = screen
51 | #         self.verbose = verbose
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:50:1: ERA001 Found commented-out code
   |
49 | #         self.append = append
50 | #         self.screen = screen
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
51 | #         self.verbose = verbose
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:51:1: ERA001 Found commented-out code
   |
49 | #         self.append = append
50 | #         self.screen = screen
51 | #         self.verbose = verbose
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
52 | 
53 | #         # open root folder for storing
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:55:1: ERA001 Found commented-out code
   |
53 | #         # open root folder for storing
54 | #         # if folder exists and not append, the folder name and filename will be updated
55 | #         self.root = set_if_none(root, ".")
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
56 | #         self.run_name = run_name
57 | #         self.workdir = f"{self.root}/{self.run_name}"
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:56:1: ERA001 Found commented-out code
   |
54 | #         # if folder exists and not append, the folder name and filename will be updated
55 | #         self.root = set_if_none(root, ".")
56 | #         self.run_name = run_name
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
57 | #         self.workdir = f"{self.root}/{self.run_name}"
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:57:1: ERA001 Found commented-out code
   |
55 | #         self.root = set_if_none(root, ".")
56 | #         self.run_name = run_name
57 | #         self.workdir = f"{self.root}/{self.run_name}"
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
58 | 
59 | #         assert "/" not in run_name
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:65:1: ERA001 Found commented-out code
   |
63 | #         if isdir(self.workdir) and not append:
64 | #             raise RuntimeError(
65 | #                 f"project {self.run_name} already exist under {self.root}"
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
66 | #             )
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:66:1: ERA001 Found commented-out code
   |
64 | #             raise RuntimeError(
65 | #                 f"project {self.run_name} already exist under {self.root}"
66 | #             )
   | ^^^^^^^^^^^^^^^ ERA001
67 | 
68 | #         makedirs(self.workdir, exist_ok=True)
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:68:1: ERA001 Found commented-out code
   |
66 | #             )
67 | 
68 | #         makedirs(self.workdir, exist_ok=True)
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
69 | 
70 | #         self.logfile = logfile
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:70:1: ERA001 Found commented-out code
   |
68 | #         makedirs(self.workdir, exist_ok=True)
69 | 
70 | #         self.logfile = logfile
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
71 | #         if logfile is not None:
72 | #             self.logfile = self.open_logfile(
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:73:1: ERA001 Found commented-out code
   |
71 | #         if logfile is not None:
72 | #             self.logfile = self.open_logfile(
73 | #                 file_name=logfile, screen=screen, propagate=True
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
74 | #             )
75 | #             logging.debug(f"  ...logfile {self.logfile} to")
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:74:1: ERA001 Found commented-out code
   |
72 | #             self.logfile = self.open_logfile(
73 | #                 file_name=logfile, screen=screen, propagate=True
74 | #             )
   | ^^^^^^^^^^^^^^^ ERA001
75 | #             logging.debug(f"  ...logfile {self.logfile} to")
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:75:1: ERA001 Found commented-out code
   |
73 | #                 file_name=logfile, screen=screen, propagate=True
74 | #             )
75 | #             logging.debug(f"  ...logfile {self.logfile} to")
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
76 | 
77 | #     def generate_file(self, file_name: str):
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:83:1: ERA001 Found commented-out code
   |
82 | #         if file_name.startswith("/"):
83 | #             raise ValueError("filename should be a relative path file name")
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
84 | #         file_name = f"{self.workdir}/{file_name}"
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:84:1: ERA001 Found commented-out code
   |
82 | #         if file_name.startswith("/"):
83 | #             raise ValueError("filename should be a relative path file name")
84 | #         file_name = f"{self.workdir}/{file_name}"
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
85 | 
86 | #         if isfile(file_name) and not self.append:
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:88:1: ERA001 Found commented-out code
   |
86 | #         if isfile(file_name) and not self.append:
87 | #             raise RuntimeError(
88 | #                 f"Tried to create file `{file_name}` but it already exists and either (1) append is disabled or (2) this run is not a restart"
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
89 | #             )
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:89:1: ERA001 Found commented-out code
   |
87 | #             raise RuntimeError(
88 | #                 f"Tried to create file `{file_name}` but it already exists and either (1) append is disabled or (2) this run is not a restart"
89 | #             )
   | ^^^^^^^^^^^^^^^ ERA001
90 | 
91 | #         logging.debug(f"  ...generate file name {file_name}")
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:91:1: ERA001 Found commented-out code
   |
89 | #             )
90 | 
91 | #         logging.debug(f"  ...generate file name {file_name}")
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
92 | #         return file_name
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:92:1: ERA001 Found commented-out code
   |
91 | #         logging.debug(f"  ...generate file name {file_name}")
92 | #         return file_name
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
93 | 
94 | #     def open_logfile(
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:97:1: ERA001 Found commented-out code
   |
95 | #         self,
96 | #         file_name: str,
97 | #         screen: bool = False,
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
98 | #         propagate: bool = False,
99 | #     ):
   |
   = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:98:1: ERA001 Found commented-out code
    |
 96 | #         file_name: str,
 97 | #         screen: bool = False,
 98 | #         propagate: bool = False,
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
 99 | #     ):
100 | #         """open a logger with a file and screen print
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:113:1: ERA001 Found commented-out code
    |
111 | #         """
112 | 
113 | #         file_name = self.generate_file(file_name)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
114 | 
115 | #         logger = logging.getLogger(file_name)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:115:1: ERA001 Found commented-out code
    |
113 | #         file_name = self.generate_file(file_name)
114 | 
115 | #         logger = logging.getLogger(file_name)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
116 | #         logger.propagate = propagate
117 | #         verbose = getattr(logging, self.verbose.upper())
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:116:1: ERA001 Found commented-out code
    |
115 | #         logger = logging.getLogger(file_name)
116 | #         logger.propagate = propagate
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
117 | #         verbose = getattr(logging, self.verbose.upper())
118 | #         logger.setLevel(verbose)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:117:1: ERA001 Found commented-out code
    |
115 | #         logger = logging.getLogger(file_name)
116 | #         logger.propagate = propagate
117 | #         verbose = getattr(logging, self.verbose.upper())
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
118 | #         logger.setLevel(verbose)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:118:1: ERA001 Found commented-out code
    |
116 | #         logger.propagate = propagate
117 | #         verbose = getattr(logging, self.verbose.upper())
118 | #         logger.setLevel(verbose)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
119 | 
120 | #         if len(logger.handlers) == 0:
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:122:1: ERA001 Found commented-out code
    |
120 | #         if len(logger.handlers) == 0:
121 | 
122 | #             formatter = logging.Formatter("%(message)s")
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
123 | #             fh = FileHandler(file_name, mode="a" if self.append else "w")
124 | #             fh.setLevel(logging.DEBUG)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:123:1: ERA001 Found commented-out code
    |
122 | #             formatter = logging.Formatter("%(message)s")
123 | #             fh = FileHandler(file_name, mode="a" if self.append else "w")
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
124 | #             fh.setLevel(logging.DEBUG)
125 | #             fh.setFormatter(formatter)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:124:1: ERA001 Found commented-out code
    |
122 | #             formatter = logging.Formatter("%(message)s")
123 | #             fh = FileHandler(file_name, mode="a" if self.append else "w")
124 | #             fh.setLevel(logging.DEBUG)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
125 | #             fh.setFormatter(formatter)
126 | #             logger.addHandler(fh)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:125:1: ERA001 Found commented-out code
    |
123 | #             fh = FileHandler(file_name, mode="a" if self.append else "w")
124 | #             fh.setLevel(logging.DEBUG)
125 | #             fh.setFormatter(formatter)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
126 | #             logger.addHandler(fh)
127 | #             if screen:
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:126:1: ERA001 Found commented-out code
    |
124 | #             fh.setLevel(logging.DEBUG)
125 | #             fh.setFormatter(formatter)
126 | #             logger.addHandler(fh)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
127 | #             if screen:
128 | #                 ch = StreamHandler(sys.stdout)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:128:1: ERA001 Found commented-out code
    |
126 | #             logger.addHandler(fh)
127 | #             if screen:
128 | #                 ch = StreamHandler(sys.stdout)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
129 | #                 ch.setLevel(logging.DEBUG)
130 | #                 ch.setFormatter(formatter)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:129:1: ERA001 Found commented-out code
    |
127 | #             if screen:
128 | #                 ch = StreamHandler(sys.stdout)
129 | #                 ch.setLevel(logging.DEBUG)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
130 | #                 ch.setFormatter(formatter)
131 | #                 logger.addHandler(ch)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:130:1: ERA001 Found commented-out code
    |
128 | #                 ch = StreamHandler(sys.stdout)
129 | #                 ch.setLevel(logging.DEBUG)
130 | #                 ch.setFormatter(formatter)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
131 | #                 logger.addHandler(ch)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:131:1: ERA001 Found commented-out code
    |
129 | #                 ch.setLevel(logging.DEBUG)
130 | #                 ch.setFormatter(formatter)
131 | #                 logger.addHandler(ch)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
132 | 
133 | #         logging.debug(f"  ...open log file {file_name}")
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:133:1: ERA001 Found commented-out code
    |
131 | #                 logger.addHandler(ch)
132 | 
133 | #         logging.debug(f"  ...open log file {file_name}")
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
134 | 
135 | #         return file_name
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:135:1: ERA001 Found commented-out code
    |
133 | #         logging.debug(f"  ...open log file {file_name}")
134 | 
135 | #         return file_name
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
136 | 
137 | #     def as_dict(self):
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:138:1: ERA001 Found commented-out code
    |
137 | #     def as_dict(self):
138 | #         d = inspect.signature(Output.__init__)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
139 | #         return {
140 | #             key: getattr(self, key)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:140:1: ERA001 Found commented-out code
    |
138 | #         d = inspect.signature(Output.__init__)
139 | #         return {
140 | #             key: getattr(self, key)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
141 | #             for key in list(d.parameters.keys())
142 | #             if key not in ["self", "kwargs"]
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:143:1: ERA001 Found commented-out code
    |
141 | #             for key in list(d.parameters.keys())
142 | #             if key not in ["self", "kwargs"]
143 | #         }
    | ^^^^^^^^^^^ ERA001
144 | 
145 | #     @classmethod
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:148:1: ERA001 Found commented-out code
    |
146 | #     def get_output(cls, kwargs: dict = {}):
147 | 
148 | #         d = inspect.signature(cls.__init__)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
149 | #         _kwargs = {
150 | #             key: kwargs.get(key, None)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:149:1: ERA001 Found commented-out code
    |
148 | #         d = inspect.signature(cls.__init__)
149 | #         _kwargs = {
    | ^^^^^^^^^^^^^^^^^^^^^ ERA001
150 | #             key: kwargs.get(key, None)
151 | #             for key in list(d.parameters.keys())
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:150:1: ERA001 Found commented-out code
    |
148 | #         d = inspect.signature(cls.__init__)
149 | #         _kwargs = {
150 | #             key: kwargs.get(key, None)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
151 | #             for key in list(d.parameters.keys())
152 | #             if key not in ["self", "kwargs"]
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:153:1: ERA001 Found commented-out code
    |
151 | #             for key in list(d.parameters.keys())
152 | #             if key not in ["self", "kwargs"]
153 | #         }
    | ^^^^^^^^^^^ ERA001
154 | #         return cls(**_kwargs)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:154:1: ERA001 Found commented-out code
    |
152 | #             if key not in ["self", "kwargs"]
153 | #         }
154 | #         return cls(**_kwargs)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
155 | 
156 | #     @classmethod
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:158:1: ERA001 Found commented-out code
    |
156 | #     @classmethod
157 | #     def from_config(cls, config):
158 | #         c = Config.from_class(cls)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
159 | #         c.update(config)
160 | #         return cls(**dict(c))
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:159:1: ERA001 Found commented-out code
    |
157 | #     def from_config(cls, config):
158 | #         c = Config.from_class(cls)
159 | #         c.update(config)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
160 | #         return cls(**dict(c))
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:160:1: ERA001 Found commented-out code
    |
158 | #         c = Config.from_class(cls)
159 | #         c.update(config)
160 | #         return cls(**dict(c))
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:164:1: ERA001 Found commented-out code
    |
163 | # def set_if_none(x, y):
164 | #     return y if x is None else x
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:177:1: ERA001 Found commented-out code
    |
176 | #     if relative:
177 | #         return None if path is None else relpath(path)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
178 | #     else:
179 | #         return None if path is None else abspath(path)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:178:1: ERA001 Found commented-out code
    |
176 | #     if relative:
177 | #         return None if path is None else relpath(path)
178 | #     else:
    | ^^^^^^^^^^^ ERA001
179 | #         return None if path is None else abspath(path)
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\output.py:179:1: ERA001 Found commented-out code
    |
177 | #         return None if path is None else relpath(path)
178 | #     else:
179 | #         return None if path is None else abspath(path)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
    |
    = help: Remove commented-out code

geom3d\models\NequIP\utils\regressor.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\regressor.py:10:5: D103 Missing docstring in public function
   |
10 | def solver(X, y, regressor: Optional[str] = "NormalizedGaussianProcess", **kwargs):
   |     ^^^^^^ D103
11 |     if regressor == "GaussianProcess":
12 |         return gp(X, y, **kwargs)
   |

geom3d\models\NequIP\utils\regressor.py:10:12: N803 Argument name `X` should be lowercase
   |
10 | def solver(X, y, regressor: Optional[str] = "NormalizedGaussianProcess", **kwargs):
   |            ^ N803
11 |     if regressor == "GaussianProcess":
12 |         return gp(X, y, **kwargs)
   |

geom3d\models\NequIP\utils\regressor.py:10:29: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
10 | def solver(X, y, regressor: Optional[str] = "NormalizedGaussianProcess", **kwargs):
   |                             ^^^^^^^^ FA100
11 |     if regressor == "GaussianProcess":
12 |         return gp(X, y, **kwargs)
   |

geom3d\models\NequIP\utils\regressor.py:10:74: ANN003 Missing type annotation for `**kwargs`
   |
10 | def solver(X, y, regressor: Optional[str] = "NormalizedGaussianProcess", **kwargs):
   |                                                                          ^^^^^^^^ ANN003
11 |     if regressor == "GaussianProcess":
12 |         return gp(X, y, **kwargs)
   |

geom3d\models\NequIP\utils\regressor.py:13:5: RET505 Unnecessary `elif` after `return` statement
   |
11 |     if regressor == "GaussianProcess":
12 |         return gp(X, y, **kwargs)
13 |     elif regressor == "NormalizedGaussianProcess":
   |     ^^^^ RET505
14 |         return normalized_gp(X, y, **kwargs)
15 |     else:
   |
   = help: Remove unnecessary `elif`

geom3d\models\NequIP\utils\regressor.py:20:5: D103 Missing docstring in public function
   |
20 | def normalized_gp(X, y, **kwargs):
   |     ^^^^^^^^^^^^^ D103
21 |     feature_rms = 1.0 / np.sqrt(np.average(X**2, axis=0))
22 |     feature_rms = np.nan_to_num(feature_rms, 1)
   |

geom3d\models\NequIP\utils\regressor.py:20:19: N803 Argument name `X` should be lowercase
   |
20 | def normalized_gp(X, y, **kwargs):
   |                   ^ N803
21 |     feature_rms = 1.0 / np.sqrt(np.average(X**2, axis=0))
22 |     feature_rms = np.nan_to_num(feature_rms, 1)
   |

geom3d\models\NequIP\utils\regressor.py:20:25: ANN003 Missing type annotation for `**kwargs`
   |
20 | def normalized_gp(X, y, **kwargs):
   |                         ^^^^^^^^ ANN003
21 |     feature_rms = 1.0 / np.sqrt(np.average(X**2, axis=0))
22 |     feature_rms = np.nan_to_num(feature_rms, 1)
   |

geom3d\models\NequIP\utils\regressor.py:34:5: D103 Missing docstring in public function
   |
34 | def gp(X, y, **kwargs):
   |     ^^ D103
35 |     return base_gp(
36 |         X, y, DotProduct, {"sigma_0": 0, "sigma_0_bounds": "fixed"}, **kwargs
   |

geom3d\models\NequIP\utils\regressor.py:34:8: N803 Argument name `X` should be lowercase
   |
34 | def gp(X, y, **kwargs):
   |        ^ N803
35 |     return base_gp(
36 |         X, y, DotProduct, {"sigma_0": 0, "sigma_0_bounds": "fixed"}, **kwargs
   |

geom3d\models\NequIP\utils\regressor.py:34:14: ANN003 Missing type annotation for `**kwargs`
   |
34 | def gp(X, y, **kwargs):
   |              ^^^^^^^^ ANN003
35 |     return base_gp(
36 |         X, y, DotProduct, {"sigma_0": 0, "sigma_0_bounds": "fixed"}, **kwargs
   |

geom3d\models\NequIP\utils\regressor.py:40:5: PLR0913 Too many arguments in function definition (7 > 5)
   |
40 | def base_gp(
   |     ^^^^^^^ PLR0913
41 |     X,
42 |     y,
   |

geom3d\models\NequIP\utils\regressor.py:40:5: D103 Missing docstring in public function
   |
40 | def base_gp(
   |     ^^^^^^^ D103
41 |     X,
42 |     y,
   |

geom3d\models\NequIP\utils\regressor.py:41:5: N803 Argument name `X` should be lowercase
   |
40 | def base_gp(
41 |     X,
   |     ^ N803
42 |     y,
43 |     kernel,
   |

geom3d\models\NequIP\utils\regressor.py:45:12: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
43 |     kernel,
44 |     kernel_kwargs,
45 |     alpha: Optional[float] = 0.1,
   |            ^^^^^^^^ FA100
46 |     max_iteration: int = 20,
47 |     stride: Optional[int] = None,
   |

geom3d\models\NequIP\utils\regressor.py:47:13: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
45 |     alpha: Optional[float] = 0.1,
46 |     max_iteration: int = 20,
47 |     stride: Optional[int] = None,
   |             ^^^^^^^^ FA100
48 | ):
   |

geom3d\models\NequIP\utils\regressor.py:54:9: N806 Variable `X` in function should be lowercase
   |
53 |     if stride is not None:
54 |         X = X[::stride]
   |         ^ N806
55 |         y = y[::stride]
   |

geom3d\models\NequIP\utils\regressor.py:62:23: G004 Logging statement uses f-string
   |
60 |     std = None
61 |     while not_fit:
62 |         logging.debug(f"GP fitting iteration {iteration} {alpha}")
   |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
63 |         try:
64 |             _kernel = kernel(**kernel_kwargs)
   |

geom3d\models\NequIP\utils\regressor.py:81:17: G004 Logging statement uses f-string
   |
80 |               logging.debug(
81 |                   f"GP fitting: alpha {alpha}:\n"
   |  _________________^
82 | |                 f"            residue {res}\n"
83 | |                 f"            mean {mean} std {std}\n"
84 | |                 f"            log marginal likelihood {likelihood}"
   | |___________________________________________________________________^ G004
85 |               )
86 |               not_fit = False
   |

geom3d\models\NequIP\utils\regressor.py:88:16: BLE001 Do not catch blind exception: `Exception`
   |
86 |             not_fit = False
87 | 
88 |         except Exception as e:
   |                ^^^^^^^^^ BLE001
89 |             logging.info(f"GP fitting failed for alpha={alpha} and {e.args}")
90 |             if alpha == 0 or alpha is None:
   |

geom3d\models\NequIP\utils\regressor.py:89:26: G004 Logging statement uses f-string
   |
88 |         except Exception as e:
89 |             logging.info(f"GP fitting failed for alpha={alpha} and {e.args}")
   |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
90 |             if alpha == 0 or alpha is None:
91 |                 logging.info("try a non-zero alpha")
   |

geom3d\models\NequIP\utils\regressor.py:97:17: B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
    |
 95 |                       "The dataset energy is rank deficient to be solved with GP"
 96 |                   )
 97 |                   raise ValueError(
    |  _________________^
 98 | |                     msg
 99 | |                 )
    | |_________________^ B904
100 |               else:
101 |                   alpha = alpha * 2
    |

geom3d\models\NequIP\utils\regressor.py:100:13: RET506 Unnecessary `else` after `raise` statement
    |
 98 |                     msg
 99 |                 )
100 |             else:
    |             ^^^^ RET506
101 |                 alpha = alpha * 2
102 |                 iteration += 1
    |
    = help: Remove unnecessary `else`

geom3d\models\NequIP\utils\regressor.py:103:31: G004 Logging statement uses f-string
    |
101 |                 alpha = alpha * 2
102 |                 iteration += 1
103 |                 logging.debug(f"           increase alpha to {alpha}")
    |                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
104 | 
105 |             if iteration >= max_iteration or not_fit is False:
    |

geom3d\models\NequIP\utils\regressor.py:110:17: B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
    |
108 |                       "The dataset energy is to diverge to be solved with GP"
109 |                   )
110 |                   raise ValueError(
    |  _________________^
111 | |                     msg
112 | |                 )
    | |_________________^ B904
113 |   
114 |       return mean, std
    |

geom3d\models\NequIP\utils\regressor.py:118:5: D205 1 blank line required between summary line and description
    |
117 |   class NormalizedDotProduct(Kernel):
118 |       r"""Dot-Product kernel.
    |  _____^
119 | |     .. math::
120 | |         k(x_i, x_j) = x_i \cdot A \cdot x_j.
121 | |     """
    | |_______^ D205
122 |   
123 |       def __init__(self, diagonal_elements):
    |
    = help: Insert single blank line

geom3d\models\NequIP\utils\regressor.py:123:9: D107 Missing docstring in `__init__`
    |
121 |     """
122 | 
123 |     def __init__(self, diagonal_elements):
    |         ^^^^^^^^ D107
124 |         # TO DO: check shape
125 |         self.diagonal_elements = diagonal_elements
    |

geom3d\models\NequIP\utils\regressor.py:128:24: N803 Argument name `X` should be lowercase
    |
126 |         self.A = np.diag(diagonal_elements)
127 | 
128 |     def __call__(self, X, Y=None, eval_gradient=False):
    |                        ^ N803
129 |         """Return the kernel k(X, Y) and optionally its gradient.
    |

geom3d\models\NequIP\utils\regressor.py:128:27: N803 Argument name `Y` should be lowercase
    |
126 |         self.A = np.diag(diagonal_elements)
127 | 
128 |     def __call__(self, X, Y=None, eval_gradient=False):
    |                           ^ N803
129 |         """Return the kernel k(X, Y) and optionally its gradient.
    |

geom3d\models\NequIP\utils\regressor.py:128:35: FBT002 Boolean default positional argument in function definition
    |
126 |         self.A = np.diag(diagonal_elements)
127 | 
128 |     def __call__(self, X, Y=None, eval_gradient=False):
    |                                   ^^^^^^^^^^^^^ FBT002
129 |         """Return the kernel k(X, Y) and optionally its gradient.
    |

geom3d\models\NequIP\utils\regressor.py:154:9: N806 Variable `X` in function should be lowercase
    |
153 |         """
154 |         X = np.atleast_2d(X)
    |         ^ N806
155 |         if Y is None:
156 |             K = (X.dot(self.A)).dot(X.T)
    |

geom3d\models\NequIP\utils\regressor.py:156:13: N806 Variable `K` in function should be lowercase
    |
154 |         X = np.atleast_2d(X)
155 |         if Y is None:
156 |             K = (X.dot(self.A)).dot(X.T)
    |             ^ N806
157 |         else:
158 |             if eval_gradient:
    |

geom3d\models\NequIP\utils\regressor.py:161:13: N806 Variable `K` in function should be lowercase
    |
159 |                 msg = "Gradient can only be evaluated when Y is None."
160 |                 raise ValueError(msg)
161 |             K = (X.dot(self.A)).dot(Y.T)
    |             ^ N806
162 | 
163 |         if eval_gradient:
    |

geom3d\models\NequIP\utils\regressor.py:165:9: RET505 Unnecessary `else` after `return` statement
    |
163 |         if eval_gradient:
164 |             return K, np.empty((X.shape[0], X.shape[0], 0))
165 |         else:
    |         ^^^^ RET505
166 |             return K
    |
    = help: Remove unnecessary `else`

geom3d\models\NequIP\utils\regressor.py:168:20: N803 Argument name `X` should be lowercase
    |
166 |             return K
167 | 
168 |     def diag(self, X):
    |                    ^ N803
169 |         """Returns the diagonal of the kernel k(X, X).
170 |         The result of this method is identical to np.diag(self(X)); however,
    |

geom3d\models\NequIP\utils\regressor.py:169:9: D205 1 blank line required between summary line and description
    |
168 |       def diag(self, X):
169 |           """Returns the diagonal of the kernel k(X, X).
    |  _________^
170 | |         The result of this method is identical to np.diag(self(X)); however,
171 | |         it can be evaluated more efficiently since only the diagonal is
172 | |         evaluated.
173 | | 
174 | |         Parameters
175 | |         ----------
176 | |         X : ndarray of shape (n_samples_X, n_features)
177 | |             Left argument of the returned kernel k(X, Y).
178 | | 
179 | |         Returns
180 | |         -------
181 | |         K_diag : ndarray of shape (n_samples_X,)
182 | |             Diagonal of kernel k(X, X).
183 | | 
184 | |         """
    | |___________^ D205
185 |           return np.einsum("ij,ij,jj->i", X, X, self.A)
    |
    = help: Insert single blank line

geom3d\models\NequIP\utils\regressor.py:169:9: D401 First line of docstring should be in imperative mood: "Returns the diagonal of the kernel k(X, X)."
    |
168 |       def diag(self, X):
169 |           """Returns the diagonal of the kernel k(X, X).
    |  _________^
170 | |         The result of this method is identical to np.diag(self(X)); however,
171 | |         it can be evaluated more efficiently since only the diagonal is
172 | |         evaluated.
173 | | 
174 | |         Parameters
175 | |         ----------
176 | |         X : ndarray of shape (n_samples_X, n_features)
177 | |             Left argument of the returned kernel k(X, Y).
178 | | 
179 | |         Returns
180 | |         -------
181 | |         K_diag : ndarray of shape (n_samples_X,)
182 | |             Diagonal of kernel k(X, X).
183 | | 
184 | |         """
    | |___________^ D401
185 |           return np.einsum("ij,ij,jj->i", X, X, self.A)
    |

geom3d\models\NequIP\utils\regressor.py:187:9: D105 Missing docstring in magic method
    |
185 |         return np.einsum("ij,ij,jj->i", X, X, self.A)
186 | 
187 |     def __repr__(self):
    |         ^^^^^^^^ D105
188 |         return ""
    |

geom3d\models\NequIP\utils\regressor.py:191:9: D401 First line of docstring should be in imperative mood: "Returns whether the kernel is stationary."
    |
190 |     def is_stationary(self):
191 |         """Returns whether the kernel is stationary."""
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
192 |         return False
    |

geom3d\models\NequIP\utils\regressor.py:195:9: D102 Missing docstring in public method
    |
194 |     @property
195 |     def hyperparameter_diagonal_elements(self):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
196 |         return Hyperparameter("diagonal_elements", "numeric", "fixed")
    |

geom3d\models\NequIP\utils\savenload.py:21:8: YTT203 `sys.version_info[1]` compared to integer (python4), compare `sys.version_info` to tuple
   |
19 |     # clean up
20 |     # better for python 3.8 >
21 |     if sys.version_info[1] >= 8:
   |        ^^^^^^^^^^^^^^^^^^^ YTT203
22 |         for f in paths:
23 |             f.unlink(missing_ok=True)
   |

geom3d\models\NequIP\utils\savenload.py:21:31: PLR2004 Magic value used in comparison, consider replacing `8` with a constant variable
   |
19 |     # clean up
20 |     # better for python 3.8 >
21 |     if sys.version_info[1] >= 8:
   |                               ^ PLR2004
22 |         for f in paths:
23 |             f.unlink(missing_ok=True)
   |

geom3d\models\NequIP\utils\savenload.py:31:27: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
31 | def _process_moves(moves: List[Tuple[bool, Path, Path]]) -> None:
   |                           ^^^^ FA100
32 |     """Blocking to copy (possibly across filesystems) to temp name; then atomic rename to final name."""
33 |     try:
   |

geom3d\models\NequIP\utils\savenload.py:31:32: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
   |
31 | def _process_moves(moves: List[Tuple[bool, Path, Path]]) -> None:
   |                                ^^^^^ FA100
32 |     """Blocking to copy (possibly across filesystems) to temp name; then atomic rename to final name."""
33 |     try:
   |

geom3d\models\NequIP\utils\savenload.py:46:1: S101 Use of `assert` detected
   |
44 | # allow user to enable/disable depending on their filesystem
45 | _ASYNC_ENABLED = os.environ.get("NEQUIP_ASYNC_IO", "false").lower()
46 | assert _ASYNC_ENABLED in ("true", "false")
   | ^^^^^^ S101
47 | _ASYNC_ENABLED = _ASYNC_ENABLED == "true"
   |

geom3d\models\NequIP\utils\savenload.py:63:27: G004 Logging statement uses f-string
   |
61 |             _process_moves(moves)
62 |             # logging is thread safe: https://stackoverflow.com/questions/2973900/is-pythons-logging-module-thread-safe
63 |             logging.debug(f"Finished writing {', '.join(m[2].name for m in moves)}")
   |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
64 |             queue.task_done()
   |

geom3d\models\NequIP\utils\savenload.py:66:42: FBT001 Boolean-typed positional argument in function definition
   |
64 |             queue.task_done()
65 | 
66 |     def _submit_move(from_name, to_name, blocking: bool) -> None:
   |                                          ^^^^^^^^ FBT001
67 |         global _MOVE_QUEUE
68 |         global _MOVE_THREAD
   |

geom3d\models\NequIP\utils\savenload.py:67:16: PLW0602 Using global for `_MOVE_QUEUE` but no assignment is done
   |
66 |     def _submit_move(from_name, to_name, blocking: bool) -> None:
67 |         global _MOVE_QUEUE
   |                ^^^^^^^^^^^ PLW0602
68 |         global _MOVE_THREAD
69 |         global _MOVE_SET
   |

geom3d\models\NequIP\utils\savenload.py:68:16: PLW0603 Using the global statement to update `_MOVE_THREAD` is discouraged
   |
66 |     def _submit_move(from_name, to_name, blocking: bool) -> None:
67 |         global _MOVE_QUEUE
68 |         global _MOVE_THREAD
   |                ^^^^^^^^^^^^ PLW0603
69 |         global _MOVE_SET
   |

geom3d\models\NequIP\utils\savenload.py:69:16: PLW0602 Using global for `_MOVE_SET` but no assignment is done
   |
67 |         global _MOVE_QUEUE
68 |         global _MOVE_THREAD
69 |         global _MOVE_SET
   |                ^^^^^^^^^ PLW0602
70 | 
71 |         # launch thread if its not running
   |

geom3d\models\NequIP\utils\savenload.py:97:9: D103 Missing docstring in public function
   |
96 |     @contextlib.contextmanager
97 |     def atomic_write_group():
   |         ^^^^^^^^^^^^^^^^^^ D103
98 |         global _MOVE_SET
99 |         if _MOVE_SET.get() is not None:
   |

geom3d\models\NequIP\utils\savenload.py:98:16: PLW0602 Using global for `_MOVE_SET` but no assignment is done
    |
 96 |     @contextlib.contextmanager
 97 |     def atomic_write_group():
 98 |         global _MOVE_SET
    |                ^^^^^^^^^ PLW0602
 99 |         if _MOVE_SET.get() is not None:
100 |             # nesting is a no-op
    |

geom3d\models\NequIP\utils\savenload.py:115:9: D103 Missing docstring in public function
    |
113 |         _MOVE_SET.reset(token)
114 | 
115 |     def finish_all_writes():
    |         ^^^^^^^^^^^^^^^^^ D103
116 |         global _MOVE_QUEUE
117 |         _MOVE_QUEUE.join()
    |

geom3d\models\NequIP\utils\savenload.py:116:16: PLW0602 Using global for `_MOVE_QUEUE` but no assignment is done
    |
115 |     def finish_all_writes():
116 |         global _MOVE_QUEUE
    |                ^^^^^^^^^^^ PLW0602
117 |         _MOVE_QUEUE.join()
118 |         # ^ wait for all remaining moves to be processed
    |

geom3d\models\NequIP\utils\savenload.py:122:42: FBT001 Boolean-typed positional argument in function definition
    |
120 | else:
121 | 
122 |     def _submit_move(from_name, to_name, blocking: bool) -> None:
    |                                          ^^^^^^^^ FBT001
123 |         global _MOVE_SET
124 |         obj = (blocking, from_name, to_name)
    |

geom3d\models\NequIP\utils\savenload.py:123:16: PLW0602 Using global for `_MOVE_SET` but no assignment is done
    |
122 |     def _submit_move(from_name, to_name, blocking: bool) -> None:
123 |         global _MOVE_SET
    |                ^^^^^^^^^ PLW0602
124 |         obj = (blocking, from_name, to_name)
125 |         if _MOVE_SET.get() is None:
    |

geom3d\models\NequIP\utils\savenload.py:133:9: D103 Missing docstring in public function
    |
132 |     @contextlib.contextmanager
133 |     def atomic_write_group():
    |         ^^^^^^^^^^^^^^^^^^ D103
134 |         global _MOVE_SET
135 |         if _MOVE_SET.get() is not None:
    |

geom3d\models\NequIP\utils\savenload.py:134:16: PLW0602 Using global for `_MOVE_SET` but no assignment is done
    |
132 |     @contextlib.contextmanager
133 |     def atomic_write_group():
134 |         global _MOVE_SET
    |                ^^^^^^^^^ PLW0602
135 |         if _MOVE_SET.get() is not None:
136 |             # don't nest them
    |

geom3d\models\NequIP\utils\savenload.py:144:9: D103 Missing docstring in public function
    |
142 |         _MOVE_SET.reset(token)
143 | 
144 |     def finish_all_writes():
    |         ^^^^^^^^^^^^^^^^^ D103
145 |         pass  # nothing to do since all writes blocked
    |

geom3d\models\NequIP\utils\savenload.py:149:5: D103 Missing docstring in public function
    |
148 | @contextlib.contextmanager
149 | def atomic_write(
    |     ^^^^^^^^^^^^ D103
150 |     filename: Union[Path, str, List[Union[Path, str]]],
151 |     blocking: bool = True,
    |

geom3d\models\NequIP\utils\savenload.py:150:15: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
    |
148 | @contextlib.contextmanager
149 | def atomic_write(
150 |     filename: Union[Path, str, List[Union[Path, str]]],
    |               ^^^^^ FA100
151 |     blocking: bool = True,
152 |     binary: bool = False,
    |

geom3d\models\NequIP\utils\savenload.py:150:32: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
148 | @contextlib.contextmanager
149 | def atomic_write(
150 |     filename: Union[Path, str, List[Union[Path, str]]],
    |                                ^^^^ FA100
151 |     blocking: bool = True,
152 |     binary: bool = False,
    |

geom3d\models\NequIP\utils\savenload.py:150:37: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
    |
148 | @contextlib.contextmanager
149 | def atomic_write(
150 |     filename: Union[Path, str, List[Union[Path, str]]],
    |                                     ^^^^^ FA100
151 |     blocking: bool = True,
152 |     binary: bool = False,
    |

geom3d\models\NequIP\utils\savenload.py:151:5: FBT001 Boolean-typed positional argument in function definition
    |
149 | def atomic_write(
150 |     filename: Union[Path, str, List[Union[Path, str]]],
151 |     blocking: bool = True,
    |     ^^^^^^^^ FBT001
152 |     binary: bool = False,
153 | ):
    |

geom3d\models\NequIP\utils\savenload.py:151:5: FBT002 Boolean default positional argument in function definition
    |
149 | def atomic_write(
150 |     filename: Union[Path, str, List[Union[Path, str]]],
151 |     blocking: bool = True,
    |     ^^^^^^^^ FBT002
152 |     binary: bool = False,
153 | ):
    |

geom3d\models\NequIP\utils\savenload.py:152:5: FBT001 Boolean-typed positional argument in function definition
    |
150 |     filename: Union[Path, str, List[Union[Path, str]]],
151 |     blocking: bool = True,
152 |     binary: bool = False,
    |     ^^^^^^ FBT001
153 | ):
154 |     aslist: bool = True
    |

geom3d\models\NequIP\utils\savenload.py:152:5: FBT002 Boolean default positional argument in function definition
    |
150 |     filename: Union[Path, str, List[Union[Path, str]]],
151 |     blocking: bool = True,
152 |     binary: bool = False,
    |     ^^^^^^ FBT002
153 | ):
154 |     aslist: bool = True
    |

geom3d\models\NequIP\utils\savenload.py:188:22: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
186 |     supported_formats: dict,
187 |     filename: str,
188 |     enforced_format: Optional[str] = None,
    |                      ^^^^^^^^ FA100
189 |     blocking: bool = True,
190 | ):
    |

geom3d\models\NequIP\utils\savenload.py:189:5: FBT001 Boolean-typed positional argument in function definition
    |
187 |     filename: str,
188 |     enforced_format: Optional[str] = None,
189 |     blocking: bool = True,
    |     ^^^^^^^^ FBT001
190 | ):
191 |     """Save file. It can take yaml, json, pickle, json, npz and torch save."""
    |

geom3d\models\NequIP\utils\savenload.py:189:5: FBT002 Boolean default positional argument in function definition
    |
187 |     filename: str,
188 |     enforced_format: Optional[str] = None,
189 |     blocking: bool = True,
    |     ^^^^^^^^ FBT002
190 | ):
191 |     """Save file. It can take yaml, json, pickle, json, npz and torch save."""
    |

geom3d\models\NequIP\utils\savenload.py:193:12: PTH120 `os.path.dirname()` should be replaced by `Path.parent`
    |
191 |     """Save file. It can take yaml, json, pickle, json, npz and torch save."""
192 |     # check whether folder exist
193 |     path = os.path.dirname(os.path.realpath(filename))
    |            ^^^^^^^^^^^^^^^ PTH120
194 |     if not os.path.isdir(path):
195 |         logging.debug(f"save_file make dirs {path}")
    |

geom3d\models\NequIP\utils\savenload.py:194:12: PTH112 `os.path.isdir()` should be replaced by `Path.is_dir()`
    |
192 |     # check whether folder exist
193 |     path = os.path.dirname(os.path.realpath(filename))
194 |     if not os.path.isdir(path):
    |            ^^^^^^^^^^^^^ PTH112
195 |         logging.debug(f"save_file make dirs {path}")
196 |         os.makedirs(path, exist_ok=True)
    |

geom3d\models\NequIP\utils\savenload.py:195:23: G004 Logging statement uses f-string
    |
193 |     path = os.path.dirname(os.path.realpath(filename))
194 |     if not os.path.isdir(path):
195 |         logging.debug(f"save_file make dirs {path}")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
196 |         os.makedirs(path, exist_ok=True)
    |

geom3d\models\NequIP\utils\savenload.py:196:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
    |
194 |     if not os.path.isdir(path):
195 |         logging.debug(f"save_file make dirs {path}")
196 |         os.makedirs(path, exist_ok=True)
    |         ^^^^^^^^^^^ PTH103
197 | 
198 |     format, filename = adjust_format_name(
    |

geom3d\models\NequIP\utils\savenload.py:198:5: A001 Variable `format` is shadowing a Python builtin
    |
196 |         os.makedirs(path, exist_ok=True)
197 | 
198 |     format, filename = adjust_format_name(
    |     ^^^^^^ A001
199 |         supported_formats=supported_formats,
200 |         filename=filename,
    |

geom3d\models\NequIP\utils\savenload.py:247:72: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
247 | def load_file(supported_formats: dict, filename: str, enforced_format: Optional[str] = None):
    |                                                                        ^^^^^^^^ FA100
248 |     """Load file. Current support form."""
249 |     if enforced_format is None:
    |

geom3d\models\NequIP\utils\savenload.py:250:9: A001 Variable `format` is shadowing a Python builtin
    |
248 |     """Load file. Current support form."""
249 |     if enforced_format is None:
250 |         format = match_suffix(supported_formats=supported_formats, filename=filename)
    |         ^^^^^^ A001
251 |     else:
252 |         format = enforced_format
    |

geom3d\models\NequIP\utils\savenload.py:252:9: A001 Variable `format` is shadowing a Python builtin
    |
250 |         format = match_suffix(supported_formats=supported_formats, filename=filename)
251 |     else:
252 |         format = enforced_format
    |         ^^^^^^ A001
253 | 
254 |     if not os.path.isfile(filename):
    |

geom3d\models\NequIP\utils\savenload.py:254:12: PTH113 `os.path.isfile()` should be replaced by `Path.is_file()`
    |
252 |         format = enforced_format
253 | 
254 |     if not os.path.isfile(filename):
    |            ^^^^^^^^^^^^^^ PTH113
255 |         abs_path = str(Path(filename).resolve())
256 |         msg = f"file {filename} at {abs_path} is not found"
    |

geom3d\models\NequIP\utils\savenload.py:262:14: PTH123 `open()` should be replaced by `Path.open()`
    |
260 |         import json
261 | 
262 |         with open(filename) as fin:
    |              ^^^^ PTH123
263 |             return json.load(fin)
264 |     elif format == "yaml":
    |

geom3d\models\NequIP\utils\savenload.py:267:14: PTH123 `open()` should be replaced by `Path.open()`
    |
265 |         import yaml
266 | 
267 |         with open(filename) as fin:
    |              ^^^^ PTH123
268 |             return yaml.load(fin, Loader=yaml.Loader)
269 |     elif format == "torch":
    |

geom3d\models\NequIP\utils\savenload.py:268:42: S506 Probable use of unsafe loader `Loader` with `yaml.load`. Allows instantiation of arbitrary objects. Consider `yaml.safe_load`.
    |
267 |         with open(filename) as fin:
268 |             return yaml.load(fin, Loader=yaml.Loader)
    |                                          ^^^^^^^^^^^ S506
269 |     elif format == "torch":
270 |         import torch
    |

geom3d\models\NequIP\utils\savenload.py:276:14: PTH123 `open()` should be replaced by `Path.open()`
    |
274 |         import pickle
275 | 
276 |         with open(filename, "rb") as fin:
    |              ^^^^ PTH123
277 |             return pickle.load(fin)
278 |     elif format == "npz":
    |

geom3d\models\NequIP\utils\savenload.py:277:20: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
    |
276 |         with open(filename, "rb") as fin:
277 |             return pickle.load(fin)
    |                    ^^^^^^^^^^^^^^^^ S301
278 |     elif format == "npz":
279 |         import numpy as np
    |

geom3d\models\NequIP\utils\savenload.py:289:24: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
    |
289 | def load_callable(obj: Union[str, Callable], prefix: Optional[str] = None) -> Callable:
    |                        ^^^^^ FA100
290 |     """Load a callable from a name, or pass through a callable."""
291 |     if callable(obj):
    |

geom3d\models\NequIP\utils\savenload.py:289:54: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
289 | def load_callable(obj: Union[str, Callable], prefix: Optional[str] = None) -> Callable:
    |                                                      ^^^^^^^^ FA100
290 |     """Load a callable from a name, or pass through a callable."""
291 |     if callable(obj):
    |

geom3d\models\NequIP\utils\savenload.py:303:56: S506 Probable use of unsafe loader `Loader` with `yaml.load`. Allows instantiation of arbitrary objects. Consider `yaml.safe_load`.
    |
301 |                 msg = f"Cannot load unqualified name {obj}."
302 |                 raise ValueError(msg)
303 |         obj = yaml.load(f"!!python/name:{obj}", Loader=yaml.Loader)
    |                                                        ^^^^^^^^^^^ S506
304 |     else:
305 |         raise TypeError
    |

geom3d\models\NequIP\utils\savenload.py:306:5: S101 Use of `assert` detected
    |
304 |     else:
305 |         raise TypeError
306 |     assert callable(obj), f"{obj} isn't callable"
    |     ^^^^^^ S101
307 |     return obj
    |

geom3d\models\NequIP\utils\savenload.py:311:62: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
310 | def adjust_format_name(
311 |     supported_formats: dict, filename: str, enforced_format: Optional[str] = None
    |                                                              ^^^^^^^^ FA100
312 | ):
313 |     """Recognize whether proper suffix is added to the filename.
    |

geom3d\models\NequIP\utils\savenload.py:313:5: D205 1 blank line required between summary line and description
    |
311 |       supported_formats: dict, filename: str, enforced_format: Optional[str] = None
312 |   ):
313 |       """Recognize whether proper suffix is added to the filename.
    |  _____^
314 | |     If not, add it and return the formatted file name.
315 | | 
316 | |     Args:
317 | |     ----
318 | |         supported_formats (dict): list of supported formats and corresponding suffix
319 | |         filename (str): initial filename
320 | |         enforced_format (str): default format
321 | | 
322 | |     Returns:
323 | |     -------
324 | |         newformat (str): the chosen format
325 | |         newname (str): the adjusted filename
326 | | 
327 | |     """
    | |_______^ D205
328 |       if enforced_format is None:
329 |           newformat = match_suffix(supported_formats=supported_formats, filename=filename)
    |
    = help: Insert single blank line

geom3d\models\NequIP\utils\scatter.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\scatter.py:7:5: ANN202 Missing return type annotation for private function `_broadcast`
  |
6 | # credit to https://github.com/mir-group/pytorch_runstats/blob/main/torch_runstats/scatter.py
7 | def _broadcast(src: torch.Tensor, other: torch.Tensor, dim: int):
  |     ^^^^^^^^^^ ANN202
8 |     if dim < 0:
9 |         dim = other.dim() + dim
  |
  = help: Add return type annotation

geom3d\models\NequIP\utils\scatter.py:19:5: PLR0913 Too many arguments in function definition (6 > 5)
   |
18 | @torch.jit.script
19 | def scatter(
   |     ^^^^^^^ PLR0913
20 |     src: torch.Tensor,
21 |     index: torch.Tensor,
   |

geom3d\models\NequIP\utils\scatter.py:19:5: D103 Missing docstring in public function
   |
18 | @torch.jit.script
19 | def scatter(
   |     ^^^^^^^ D103
20 |     src: torch.Tensor,
21 |     index: torch.Tensor,
   |

geom3d\models\NequIP\utils\scatter.py:23:10: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
21 |     index: torch.Tensor,
22 |     dim: int = -1,
23 |     out: Optional[torch.Tensor] = None,
   |          ^^^^^^^^ FA100
24 |     dim_size: Optional[int] = None,
25 |     reduce: str = "sum",
   |

geom3d\models\NequIP\utils\scatter.py:24:15: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
22 |     dim: int = -1,
23 |     out: Optional[torch.Tensor] = None,
24 |     dim_size: Optional[int] = None,
   |               ^^^^^^^^ FA100
25 |     reduce: str = "sum",
26 | ) -> torch.Tensor:
   |

geom3d\models\NequIP\utils\scatter.py:27:5: S101 Use of `assert` detected
   |
25 |     reduce: str = "sum",
26 | ) -> torch.Tensor:
27 |     assert reduce == "sum"  # for now, TODO
   |     ^^^^^^ S101
28 |     index = _broadcast(index, src, dim)
29 |     if out is None:
   |

geom3d\models\NequIP\utils\scatter.py:39:5: RET505 Unnecessary `else` after `return` statement
   |
37 |         out = torch.zeros(size, dtype=src.dtype, device=src.device)
38 |         return out.scatter_add_(dim, index, src)
39 |     else:
   |     ^^^^ RET505
40 |         return out.scatter_add_(dim, index, src)
   |
   = help: Remove unnecessary `else`

geom3d\models\NequIP\utils\test.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\test.py:18:5: ANN202 Missing return type annotation for private function `_inverse_permutation`
   |
17 | # https://discuss.pytorch.org/t/how-to-quickly-inverse-a-permutation-by-using-pytorch/116205/4
18 | def _inverse_permutation(perm):
   |     ^^^^^^^^^^^^^^^^^^^^ ANN202
19 |     inv = torch.empty_like(perm)
20 |     inv[perm] = torch.arange(perm.size(0), device=perm.device)
   |
   = help: Add return type annotation

geom3d\models\NequIP\utils\test.py:24:5: C901 `assert_permutation_equivariant` is too complex (22 > 10)
   |
24 | def assert_permutation_equivariant(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ C901
25 |     func: GraphModuleMixin,
26 |     data_in: AtomicDataDict.Type,
   |

geom3d\models\NequIP\utils\test.py:24:5: PLR0912 Too many branches (24 > 12)
   |
24 | def assert_permutation_equivariant(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0912
25 |     func: GraphModuleMixin,
26 |     data_in: AtomicDataDict.Type,
   |

geom3d\models\NequIP\utils\test.py:24:5: PLR0915 Too many statements (57 > 50)
   |
24 | def assert_permutation_equivariant(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0915
25 |     func: GraphModuleMixin,
26 |     data_in: AtomicDataDict.Type,
   |

geom3d\models\NequIP\utils\test.py:24:5: D417 Missing argument descriptions in the docstring for `assert_permutation_equivariant`: `raise_error`, `tolerance`
   |
24 | def assert_permutation_equivariant(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D417
25 |     func: GraphModuleMixin,
26 |     data_in: AtomicDataDict.Type,
   |

geom3d\models\NequIP\utils\test.py:27:16: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
25 |     func: GraphModuleMixin,
26 |     data_in: AtomicDataDict.Type,
27 |     tolerance: Optional[float] = None,
   |                ^^^^^^^^ FA100
28 |     raise_error: bool = True,
29 | ):
   |

geom3d\models\NequIP\utils\test.py:28:5: FBT001 Boolean-typed positional argument in function definition
   |
26 |     data_in: AtomicDataDict.Type,
27 |     tolerance: Optional[float] = None,
28 |     raise_error: bool = True,
   |     ^^^^^^^^^^^ FBT001
29 | ):
30 |     r"""Test the permutation equivariance of ``func``.
   |

geom3d\models\NequIP\utils\test.py:28:5: FBT002 Boolean default positional argument in function definition
   |
26 |     data_in: AtomicDataDict.Type,
27 |     tolerance: Optional[float] = None,
28 |     raise_error: bool = True,
   |     ^^^^^^^^^^^ FBT002
29 | ):
30 |     r"""Test the permutation equivariance of ``func``.
   |

geom3d\models\NequIP\utils\test.py:92:5: S101 Use of `assert` detected
   |
90 |     out_perm = func(perm_data_in)
91 | 
92 |     assert set(out_orig.keys()) == set(
   |     ^^^^^^ S101
93 |         out_perm.keys()
94 |     ), "Permutation changed the set of fields returned by model"
   |

geom3d\models\NequIP\utils\test.py:125:5: RET505 Unnecessary `elif` after `return` statement
    |
123 |     if len(problems) == 0:
124 |         return None
125 |     elif raise_error:
    |     ^^^^ RET505
126 |         raise AssertionError(msg)
127 |     else:
    |
    = help: Remove unnecessary `elif`

geom3d\models\NequIP\utils\test.py:131:5: N802 Function name `assert_AtomicData_equivariant` should be lowercase
    |
131 | def assert_AtomicData_equivariant(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
132 |     func: GraphModuleMixin,
133 |     data_in: Union[
    |

geom3d\models\NequIP\utils\test.py:131:5: C901 `assert_AtomicData_equivariant` is too complex (25 > 10)
    |
131 | def assert_AtomicData_equivariant(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ C901
132 |     func: GraphModuleMixin,
133 |     data_in: Union[
    |

geom3d\models\NequIP\utils\test.py:131:5: PLR0912 Too many branches (16 > 12)
    |
131 | def assert_AtomicData_equivariant(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0912
132 |     func: GraphModuleMixin,
133 |     data_in: Union[
    |

geom3d\models\NequIP\utils\test.py:131:5: PLR0915 Too many statements (59 > 50)
    |
131 | def assert_AtomicData_equivariant(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0915
132 |     func: GraphModuleMixin,
133 |     data_in: Union[
    |

geom3d\models\NequIP\utils\test.py:131:5: D417 Missing argument descriptions in the docstring for `assert_AtomicData_equivariant`: `o3_tolerance`, `permutation_tolerance`
    |
131 | def assert_AtomicData_equivariant(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D417
132 |     func: GraphModuleMixin,
133 |     data_in: Union[
    |

geom3d\models\NequIP\utils\test.py:133:14: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
    |
131 | def assert_AtomicData_equivariant(
132 |     func: GraphModuleMixin,
133 |     data_in: Union[
    |              ^^^^^ FA100
134 |         AtomicData, AtomicDataDict.Type, List[Union[AtomicData, AtomicDataDict.Type]]
135 |     ],
    |

geom3d\models\NequIP\utils\test.py:134:42: FA100 Add `from __future__ import annotations` to simplify `typing.List`
    |
132 |     func: GraphModuleMixin,
133 |     data_in: Union[
134 |         AtomicData, AtomicDataDict.Type, List[Union[AtomicData, AtomicDataDict.Type]]
    |                                          ^^^^ FA100
135 |     ],
136 |     permutation_tolerance: Optional[float] = None,
    |

geom3d\models\NequIP\utils\test.py:134:47: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
    |
132 |     func: GraphModuleMixin,
133 |     data_in: Union[
134 |         AtomicData, AtomicDataDict.Type, List[Union[AtomicData, AtomicDataDict.Type]]
    |                                               ^^^^^ FA100
135 |     ],
136 |     permutation_tolerance: Optional[float] = None,
    |

geom3d\models\NequIP\utils\test.py:136:28: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
134 |         AtomicData, AtomicDataDict.Type, List[Union[AtomicData, AtomicDataDict.Type]]
135 |     ],
136 |     permutation_tolerance: Optional[float] = None,
    |                            ^^^^^^^^ FA100
137 |     o3_tolerance: Optional[float] = None,
138 |     **kwargs,
    |

geom3d\models\NequIP\utils\test.py:137:19: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
135 |     ],
136 |     permutation_tolerance: Optional[float] = None,
137 |     o3_tolerance: Optional[float] = None,
    |                   ^^^^^^^^ FA100
138 |     **kwargs,
139 | ) -> str:
    |

geom3d\models\NequIP\utils\test.py:138:5: ANN003 Missing type annotation for `**kwargs`
    |
136 |     permutation_tolerance: Optional[float] = None,
137 |     o3_tolerance: Optional[float] = None,
138 |     **kwargs,
    |     ^^^^^^^^ ANN003
139 | ) -> str:
140 |     r"""Test the rotation, translation, parity, and permutation equivariance of ``func``.
    |

geom3d\models\NequIP\utils\test.py:186:13: S101 Use of `assert` detected
    |
184 |             # it should always have been 1o vectors
185 |             # since that's actually a valid Irreps
186 |             assert o3.Irreps(irps[AtomicDataDict.POSITIONS_KEY]) == o3.Irreps("1o")
    |             ^^^^^^ S101
187 |             irps[AtomicDataDict.POSITIONS_KEY] = "cartesian_points"
188 |         if AtomicDataDict.CELL_KEY in irps:
    |

geom3d\models\NequIP\utils\test.py:190:13: S101 Use of `assert` detected
    |
188 |         if AtomicDataDict.CELL_KEY in irps:
189 |             prev_cell_irps = irps[AtomicDataDict.CELL_KEY]
190 |             assert prev_cell_irps is None or o3.Irreps(prev_cell_irps) == o3.Irreps(
    |             ^^^^^^ S101
191 |                 "3x1o"
192 |             )
    |

geom3d\models\NequIP\utils\test.py:208:9: ANN202 Missing return type annotation for private function `wrapper`
    |
206 |             irreps_out[k] = stress_cart_tensor
207 | 
208 |     def wrapper(*args):
    |         ^^^^^^^ ANN202
209 |         arg_dict = dict(zip(irreps_in, args))
210 |         # cell is a special case
    |
    = help: Add return type annotation

geom3d\models\NequIP\utils\test.py:208:17: ANN002 Missing type annotation for `*args`
    |
206 |             irreps_out[k] = stress_cart_tensor
207 | 
208 |     def wrapper(*args):
    |                 ^^^^^ ANN002
209 |         arg_dict = dict(zip(irreps_in, args))
210 |         # cell is a special case
    |

geom3d\models\NequIP\utils\test.py:215:17: S101 Use of `assert` detected
    |
213 |                 # unflatten
214 |                 val = arg_dict[key]
215 |                 assert val.shape[-1] == 9
    |                 ^^^^^^ S101
216 |                 arg_dict[key] = val.reshape(val.shape[:-1] + (3, 3))
217 |         output = func(arg_dict)
    |

geom3d\models\NequIP\utils\test.py:215:41: PLR2004 Magic value used in comparison, consider replacing `9` with a constant variable
    |
213 |                 # unflatten
214 |                 val = arg_dict[key]
215 |                 assert val.shape[-1] == 9
    |                                         ^ PLR2004
216 |                 arg_dict[key] = val.reshape(val.shape[:-1] + (3, 3))
217 |         output = func(arg_dict)
    |

geom3d\models\NequIP\utils\test.py:223:17: S101 Use of `assert` detected
    |
221 |                 # flatten
222 |                 val = output[key]
223 |                 assert val.shape[-2:] == (3, 3)
    |                 ^^^^^^ S101
224 |                 output[key] = val.reshape(val.shape[:-2] + (9,))
225 |         # stress is also a special case,
    |

geom3d\models\NequIP\utils\test.py:238:13: S101 Use of `assert` detected
    |
236 |             # flatten
237 |             cell = d[AtomicDataDict.CELL_KEY]
238 |             assert cell.shape[-2:] == (3, 3)
    |             ^^^^^^ S101
239 |             d[AtomicDataDict.CELL_KEY] = cell.reshape(cell.shape[:-2] + (9,))
    |

geom3d\models\NequIP\utils\test.py:262:13: ANN202 Missing return type annotation for private function `_describe`
    |
260 |         problems = {k: v for k, v in errs.items() if v > o3_tolerance}
261 | 
262 |         def _describe(errors):
    |             ^^^^^^^^^ ANN202
263 |             return (
264 |                 permutation_problems + "\n" if permutation_problems is not None else ""
    |
    = help: Add return type annotation

geom3d\models\NequIP\utils\test.py:276:5: RET505 Unnecessary `else` after `return` statement
    |
275 |         return _describe(errs)
276 |     else:
    |     ^^^^ RET505
277 |         # it's newer and tells us which is which
278 |         all_errs = []
    |
    = help: Remove unnecessary `else`

geom3d\models\NequIP\utils\test.py:284:13: ANN202 Missing return type annotation for private function `_describe`
    |
282 |         problems = [e for e in all_errs if e[-1] > o3_tolerance]
283 | 
284 |         def _describe(errors):
    |             ^^^^^^^^^ ANN202
285 |             return (
286 |                 permutation_problems + "\n" if permutation_problems is not None else ""
    |
    = help: Add return type annotation

geom3d\models\NequIP\utils\test.py:303:5: C901 `set_irreps_debug` is too complex (22 > 10)
    |
303 | def set_irreps_debug(enabled: bool = False) -> None:
    |     ^^^^^^^^^^^^^^^^ C901
304 |     r"""Add debugging hooks to ``forward()`` that check data-irreps consistancy.
    |

geom3d\models\NequIP\utils\test.py:303:5: PLR0915 Too many statements (54 > 50)
    |
303 | def set_irreps_debug(enabled: bool = False) -> None:
    |     ^^^^^^^^^^^^^^^^ PLR0915
304 |     r"""Add debugging hooks to ``forward()`` that check data-irreps consistancy.
    |

geom3d\models\NequIP\utils\test.py:303:22: FBT001 Boolean-typed positional argument in function definition
    |
303 | def set_irreps_debug(enabled: bool = False) -> None:
    |                      ^^^^^^^ FBT001
304 |     r"""Add debugging hooks to ``forward()`` that check data-irreps consistancy.
    |

geom3d\models\NequIP\utils\test.py:303:22: FBT002 Boolean default positional argument in function definition
    |
303 | def set_irreps_debug(enabled: bool = False) -> None:
    |                      ^^^^^^^ FBT002
304 |     r"""Add debugging hooks to ``forward()`` that check data-irreps consistancy.
    |

geom3d\models\NequIP\utils\test.py:311:12: PLW0603 Using the global statement to update `_DEBUG_HOOKS` is discouraged
    |
310 |     """
311 |     global _DEBUG_HOOKS
    |            ^^^^^^^^^^^^ PLW0603
312 |     if _DEBUG_HOOKS is None and not enabled or _DEBUG_HOOKS is not None and enabled:
313 |         return
    |

geom3d\models\NequIP\utils\test.py:311:12: PLW0603 Using the global statement to update `_DEBUG_HOOKS` is discouraged
    |
310 |     """
311 |     global _DEBUG_HOOKS
    |            ^^^^^^^^^^^^ PLW0603
312 |     if _DEBUG_HOOKS is None and not enabled or _DEBUG_HOOKS is not None and enabled:
313 |         return
    |

geom3d\models\NequIP\utils\test.py:314:5: RET505 Unnecessary `elif` after `return` statement
    |
312 |     if _DEBUG_HOOKS is None and not enabled or _DEBUG_HOOKS is not None and enabled:
313 |         return
314 |     elif _DEBUG_HOOKS is not None and not enabled:
    |     ^^^^ RET505
315 |         for hook in _DEBUG_HOOKS:
316 |             hook.remove()
    |
    = help: Remove unnecessary `elif`

geom3d\models\NequIP\utils\test.py:335:9: RET506 Unnecessary `elif` after `raise` statement
    |
333 |                 msg
334 |             )
335 |         elif len(inp) == 0:
    |         ^^^^ RET506
336 |             msg = f"Module {mname} didn't get any arguments; this case is correctly handled with an empty dict."
337 |             raise ValueError(
    |
    = help: Remove unnecessary `elif`

geom3d\models\NequIP\utils\test.py:352:13: RET506 Unnecessary `elif` after `raise` statement
    |
350 |                     msg
351 |                 )
352 |             elif isinstance(inp[k], torch.Tensor) and isinstance(ir, o3.Irreps):
    |             ^^^^ RET506
353 |                 if inp[k].ndim == 1:
354 |                     msg = f"Field {k} in input to module {mname} has only one dimension (assumed to be batch-like); it must have a second irreps dimension even if irreps.dim == 1 (i.e. a single per atom scalar must have shape [N_at, 1], not [N_at])"
    |
    = help: Remove unnecessary `elif`

geom3d\models\NequIP\utils\test.py:358:17: RET506 Unnecessary `elif` after `raise` statement
    |
356 |                         msg
357 |                     )
358 |                 elif inp[k].shape[-1] != ir.dim:
    |                 ^^^^ RET506
359 |                     msg = f"Field {k} in input to module {mname} has last dimension {inp[k].shape[-1]} but its irreps {ir} indicate last dimension {ir.dim}"
360 |                     raise ValueError(
    |
    = help: Remove unnecessary `elif`

geom3d\models\NequIP\utils\test.py:383:13: RET506 Unnecessary `elif` after `raise` statement
    |
381 |                     msg
382 |                 )
383 |             elif isinstance(out[k], torch.Tensor) and isinstance(ir, o3.Irreps):
    |             ^^^^ RET506
384 |                 if out[k].ndim == 1:
385 |                     msg = f"Field {k} in output from module {mname} has only one dimension (assumed to be batch-like); it must have a second irreps dimension even if irreps.dim == 1 (i.e. a single per atom scalar must have shape [N_at, 1], not [N_at])"
    |
    = help: Remove unnecessary `elif`

geom3d\models\NequIP\utils\test.py:389:17: RET506 Unnecessary `elif` after `raise` statement
    |
387 |                         msg
388 |                     )
389 |                 elif out[k].shape[-1] != ir.dim:
    |                 ^^^^ RET506
390 |                     msg = f"Field {k} in output from {mname} has last dimension {out[k].shape[-1]} but its irreps {ir} indicate last dimension {ir.dim}"
391 |                     raise ValueError(
    |
    = help: Remove unnecessary `elif`

geom3d\models\NequIP\utils\tp_utils.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\tp_utils.py:4:5: D103 Missing docstring in public function
  |
4 | def tp_path_exists(irreps_in1, irreps_in2, ir_out):
  |     ^^^^^^^^^^^^^^ D103
5 |     irreps_in1 = o3.Irreps(irreps_in1).simplify()
6 |     irreps_in2 = o3.Irreps(irreps_in2).simplify()
  |

geom3d\models\NequIP\utils\versions.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\versions.py:16:5: D103 Missing docstring in public function
   |
16 | def get_config_code_versions(config) -> Tuple[dict, dict]:
   |     ^^^^^^^^^^^^^^^^^^^^^^^^ D103
17 |     code_versions = {}
18 |     for code in _DEFAULT_VERSION_CODES:
   |

geom3d\models\NequIP\utils\versions.py:16:41: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
   |
16 | def get_config_code_versions(config) -> Tuple[dict, dict]:
   |                                         ^^^^^ FA100
17 |     code_versions = {}
18 |     for code in _DEFAULT_VERSION_CODES:
   |

geom3d\models\NequIP\utils\versions.py:29:5: D103 Missing docstring in public function
   |
29 | def get_current_code_versions(config) -> Tuple[dict, dict]:
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ D103
30 |     code_versions = {}
31 |     for code in _DEFAULT_VERSION_CODES:
   |

geom3d\models\NequIP\utils\versions.py:29:42: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
   |
29 | def get_current_code_versions(config) -> Tuple[dict, dict]:
   |                                          ^^^^^ FA100
30 |     code_versions = {}
31 |     for code in _DEFAULT_VERSION_CODES:
   |

geom3d\models\NequIP\utils\versions.py:37:9: PLW2901 `for` loop variable `builder` overwritten by assignment target
   |
35 |         if not isinstance(builder, str):
36 |             continue
37 |         builder = builder.split(".")
   |         ^^^^^^^ PLW2901
38 |         if len(builder) > 1:
39 |             # it's not a single name which is from NequIP
   |

geom3d\models\NequIP\utils\versions.py:46:5: D103 Missing docstring in public function
   |
46 | def check_code_version(config, add_to_config: bool = False):
   |     ^^^^^^^^^^^^^^^^^^ D103
47 |     current_code_versions, current_code_commits = get_current_code_versions(config)
48 |     code_versions, code_commits = get_config_code_versions(config)
   |

geom3d\models\NequIP\utils\versions.py:46:32: FBT001 Boolean-typed positional argument in function definition
   |
46 | def check_code_version(config, add_to_config: bool = False):
   |                                ^^^^^^^^^^^^^ FBT001
47 |     current_code_versions, current_code_commits = get_current_code_versions(config)
48 |     code_versions, code_commits = get_config_code_versions(config)
   |

geom3d\models\NequIP\utils\versions.py:46:32: FBT002 Boolean default positional argument in function definition
   |
46 | def check_code_version(config, add_to_config: bool = False):
   |                                ^^^^^^^^^^^^^ FBT002
47 |     current_code_versions, current_code_commits = get_current_code_versions(config)
48 |     code_versions, code_commits = get_config_code_versions(config)
   |

geom3d\models\NequIP\utils\versions.py:54:17: G004 Logging statement uses f-string
   |
52 |           if version != current_code_versions.get(code, version):
53 |               logging.error(
54 |                   "Loading a saved model created with different library version(s) may cause issues."
   |  _________________^
55 | |                 f" Current {code} version: {current_code_versions[code]} "
56 | |                 f"vs  original version: {version}"
   | |__________________________________________________^ G004
57 |               )
   |

geom3d\models\NequIP\utils\versions.py:63:17: G004 Logging statement uses f-string
   |
61 |           if commit != current_code_commits.get(code, commit):
62 |               logging.error(
63 |                   "Loading a saved model created with different library git commit(s) may cause issues."
   |  _________________^
64 | |                 f" Currently {code}'s git commit: {current_code_commits[code]} "
65 | |                 f"vs  original commit: {commit}"
   | |________________________________________________^ G004
66 |               )
   |

geom3d\models\NequIP\utils\wandb.py:1:1: D100 Missing docstring in public module
geom3d\models\NequIP\utils\wandb.py:7:5: D103 Missing docstring in public function
  |
7 | def init_n_update(config):
  |     ^^^^^^^^^^^^^ D103
8 |     conf_dict = dict(config)
9 |     # wandb mangles keys (in terms of type) as well, but we can't easily correct that because there are many ambiguous edge cases. (E.g. string "-1" vs int -1 as keys, are they different config keys?)
  |

geom3d\models\NequIP\utils\wandb.py:36:26: G004 Logging statement uses f-string
   |
34 |                 skip = True
35 |         if skip:
36 |             logging.info(f"# skipping wandb update {k} from {v_old} to {v_new}")
   |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
37 |         else:
38 |             config.update({k: v_new})
   |

geom3d\models\NequIP\utils\wandb.py:39:26: G004 Logging statement uses f-string
   |
37 |         else:
38 |             config.update({k: v_new})
39 |             logging.info(f"# wandb update {k} from {v_old} to {v_new}")
   |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ G004
40 |     return config
   |

geom3d\models\NequIP\utils\wandb.py:43:5: D103 Missing docstring in public function
   |
43 | def resume(config):
   |     ^^^^^^ D103
44 |     # resume to the old wandb run
45 |     wandb.init(
   |

geom3d\models\PNA\PNA.py:1:1: N999 Invalid module name: 'PNA'
geom3d\models\PNA\PNA.py:1:1: D205 1 blank line required between summary line and description
  |
1 | / """credit to https://github.com/lukecavabarrett/PNA/blob/master/models/pytorch_geometric/PNA.py
2 | | and https://github.com/wdimmy/GNN_Molecule_Retrieval/tree/main/PNA.
3 | | """
  | |___^ D205
4 |   from typing import Dict, List, Optional
  |
  = help: Insert single blank line

geom3d\models\PNA\PNA.py:7:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
6 | import torch
7 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
8 | from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder
9 | from torch import Tensor, nn
  |

geom3d\models\PNA\PNA.py:21:7: D101 Missing docstring in public class
   |
21 | class PNAConv(MessagePassing):
   |       ^^^^^^^ D101
22 |     def __init__(self, in_channels: int, out_channels: int,
23 |                  aggregators: List[str], scalers: List[str], deg: Tensor,
   |

geom3d\models\PNA\PNA.py:22:9: PLR0913 Too many arguments in function definition (10 > 5)
   |
21 | class PNAConv(MessagePassing):
22 |     def __init__(self, in_channels: int, out_channels: int,
   |         ^^^^^^^^ PLR0913
23 |                  aggregators: List[str], scalers: List[str], deg: Tensor,
24 |                  edge_dim: Optional[int] = None, towers: int = 1,
   |

geom3d\models\PNA\PNA.py:22:9: D107 Missing docstring in `__init__`
   |
21 | class PNAConv(MessagePassing):
22 |     def __init__(self, in_channels: int, out_channels: int,
   |         ^^^^^^^^ D107
23 |                  aggregators: List[str], scalers: List[str], deg: Tensor,
24 |                  edge_dim: Optional[int] = None, towers: int = 1,
   |

geom3d\models\PNA\PNA.py:23:31: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
21 | class PNAConv(MessagePassing):
22 |     def __init__(self, in_channels: int, out_channels: int,
23 |                  aggregators: List[str], scalers: List[str], deg: Tensor,
   |                               ^^^^ FA100
24 |                  edge_dim: Optional[int] = None, towers: int = 1,
25 |                  pre_layers: int = 1, post_layers: int = 1,
   |

geom3d\models\PNA\PNA.py:23:51: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
21 | class PNAConv(MessagePassing):
22 |     def __init__(self, in_channels: int, out_channels: int,
23 |                  aggregators: List[str], scalers: List[str], deg: Tensor,
   |                                                   ^^^^ FA100
24 |                  edge_dim: Optional[int] = None, towers: int = 1,
25 |                  pre_layers: int = 1, post_layers: int = 1,
   |

geom3d\models\PNA\PNA.py:24:28: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
22 |     def __init__(self, in_channels: int, out_channels: int,
23 |                  aggregators: List[str], scalers: List[str], deg: Tensor,
24 |                  edge_dim: Optional[int] = None, towers: int = 1,
   |                            ^^^^^^^^ FA100
25 |                  pre_layers: int = 1, post_layers: int = 1,
26 |                  divide_input: bool = False, **kwargs):
   |

geom3d\models\PNA\PNA.py:26:18: FBT001 Boolean-typed positional argument in function definition
   |
24 |                  edge_dim: Optional[int] = None, towers: int = 1,
25 |                  pre_layers: int = 1, post_layers: int = 1,
26 |                  divide_input: bool = False, **kwargs):
   |                  ^^^^^^^^^^^^ FBT001
27 |         super().__init__(aggr=None, node_dim=0, **kwargs)
   |

geom3d\models\PNA\PNA.py:26:18: FBT002 Boolean default positional argument in function definition
   |
24 |                  edge_dim: Optional[int] = None, towers: int = 1,
25 |                  pre_layers: int = 1, post_layers: int = 1,
26 |                  divide_input: bool = False, **kwargs):
   |                  ^^^^^^^^^^^^ FBT002
27 |         super().__init__(aggr=None, node_dim=0, **kwargs)
   |

geom3d\models\PNA\PNA.py:26:46: ANN003 Missing type annotation for `**kwargs`
   |
24 |                  edge_dim: Optional[int] = None, towers: int = 1,
25 |                  pre_layers: int = 1, post_layers: int = 1,
26 |                  divide_input: bool = False, **kwargs):
   |                                              ^^^^^^^^ ANN003
27 |         super().__init__(aggr=None, node_dim=0, **kwargs)
   |

geom3d\models\PNA\PNA.py:30:13: S101 Use of `assert` detected
   |
29 |         if divide_input:
30 |             assert in_channels % towers == 0
   |             ^^^^^^ S101
31 |         assert out_channels % towers == 0
   |

geom3d\models\PNA\PNA.py:31:9: S101 Use of `assert` detected
   |
29 |         if divide_input:
30 |             assert in_channels % towers == 0
31 |         assert out_channels % towers == 0
   |         ^^^^^^ S101
32 | 
33 |         self.in_channels = in_channels
   |

geom3d\models\PNA\PNA.py:47:23: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
45 |         total_no_vertices = deg.sum()
46 |         bin_degrees = torch.arange(len(deg))
47 |         self.avg_deg: Dict[str, float] = {
   |                       ^^^^ FA100
48 |             "lin": ((bin_degrees * deg).sum() / total_no_vertices).item(),
49 |             "log": (((bin_degrees + 1).log() * deg).sum() / total_no_vertices).item(),
   |

geom3d\models\PNA\PNA.py:76:9: D102 Missing docstring in public method
   |
74 |         self.reset_parameters()
75 | 
76 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
77 |         for nn in self.pre_nns:
78 |             reset(nn)
   |

geom3d\models\PNA\PNA.py:77:13: F402 Import `nn` from line 9 shadowed by loop variable
   |
76 |     def reset_parameters(self):
77 |         for nn in self.pre_nns:
   |             ^^ F402
78 |             reset(nn)
79 |         for nn in self.post_nns:
   |

geom3d\models\PNA\PNA.py:83:9: D102 Missing docstring in public method
   |
81 |         self.lin.reset_parameters()
82 | 
83 |     def forward(self, x: Tensor, edge_index: Adj,
   |         ^^^^^^^ D102
84 |                 edge_attr: OptTensor = None) -> Tensor:
   |

geom3d\models\PNA\PNA.py:99:9: D102 Missing docstring in public method
    |
 97 |         return self.lin(out)
 98 | 
 99 |     def message(self, x_i: Tensor, x_j: Tensor,
    |         ^^^^^^^ D102
100 |                 edge_attr: OptTensor) -> Tensor:
    |

geom3d\models\PNA\PNA.py:114:9: D102 Missing docstring in public method
    |
112 |         return torch.stack(hs, dim=1)
113 | 
114 |     def aggregate(self, inputs: Tensor, index: Tensor,
    |         ^^^^^^^^^ D102
115 |                   dim_size: Optional[int] = None) -> Tensor:
116 |         outs = [aggr(inputs, index, dim_size) for aggr in self.aggregators]
    |

geom3d\models\PNA\PNA.py:115:29: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
114 |     def aggregate(self, inputs: Tensor, index: Tensor,
115 |                   dim_size: Optional[int] = None) -> Tensor:
    |                             ^^^^^^^^ FA100
116 |         outs = [aggr(inputs, index, dim_size) for aggr in self.aggregators]
117 |         out = torch.cat(outs, dim=-1)
    |

geom3d\models\PNA\PNA.py:124:7: D101 Missing docstring in public class
    |
124 | class PNA(nn.Module):
    |       ^^^ D101
125 |     def __init__(self, num_layer, emb_dim, dropout_ratio, deg):
126 |         super().__init__()
    |

geom3d\models\PNA\PNA.py:125:9: D107 Missing docstring in `__init__`
    |
124 | class PNA(nn.Module):
125 |     def __init__(self, num_layer, emb_dim, dropout_ratio, deg):
    |         ^^^^^^^^ D107
126 |         super().__init__()
127 |         self.atom_encoder = AtomEncoder(emb_dim)
    |

geom3d\models\PNA\PNA.py:142:9: D102 Missing docstring in public method
    |
140 |             self.batch_norms.append(BatchNorm(emb_dim))
141 | 
142 |     def get_graph_representation(self, batch):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^ D102
143 |         x = self.node_emb(batch.x)
    |

geom3d\models\PNA\PNA.py:152:9: D102 Missing docstring in public method
    |
150 |         return global_mean_pool(x, batch.batch)
151 | 
152 |     def forward(self, *argv):
    |         ^^^^^^^ D102
153 |         if len(argv) == 3:
154 |             x, edge_index, edge_attr = argv[0], argv[1], argv[2]
    |

geom3d\models\PNA\PNA.py:152:23: ANN002 Missing type annotation for `*argv`
    |
150 |         return global_mean_pool(x, batch.batch)
151 | 
152 |     def forward(self, *argv):
    |                       ^^^^^ ANN002
153 |         if len(argv) == 3:
154 |             x, edge_index, edge_attr = argv[0], argv[1], argv[2]
    |

geom3d\models\PNA\PNA.py:153:25: PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
    |
152 |     def forward(self, *argv):
153 |         if len(argv) == 3:
    |                         ^ PLR2004
154 |             x, edge_index, edge_attr = argv[0], argv[1], argv[2]
155 |         elif len(argv) == 1:
    |

geom3d\models\PNA\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\PNA\__init__.py:1:18: F401 `.PNA.PNA` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .PNA import PNA
  |                  ^^^ F401
  |
  = help: Use an explicit re-export: `PNA as PNA`

geom3d\models\PNA\aggregators.py:1:1: D100 Missing docstring in public module
geom3d\models\PNA\aggregators.py:10:5: D103 Missing docstring in public function
   |
 8 | # For an example see https://github.com/rusty1s/pytorch_geometric/blob/master/examples/PNA.py
 9 | 
10 | def aggregate_sum(src: Tensor, index: Tensor, dim_size: Optional[int]):
   |     ^^^^^^^^^^^^^ D103
11 |     return scatter(src, index, 0, None, dim_size, reduce="sum")
   |

geom3d\models\PNA\aggregators.py:10:57: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
 8 | # For an example see https://github.com/rusty1s/pytorch_geometric/blob/master/examples/PNA.py
 9 | 
10 | def aggregate_sum(src: Tensor, index: Tensor, dim_size: Optional[int]):
   |                                                         ^^^^^^^^ FA100
11 |     return scatter(src, index, 0, None, dim_size, reduce="sum")
   |

geom3d\models\PNA\aggregators.py:14:5: D103 Missing docstring in public function
   |
14 | def aggregate_mean(src: Tensor, index: Tensor, dim_size: Optional[int]):
   |     ^^^^^^^^^^^^^^ D103
15 |     return scatter(src, index, 0, None, dim_size, reduce="mean")
   |

geom3d\models\PNA\aggregators.py:14:58: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
14 | def aggregate_mean(src: Tensor, index: Tensor, dim_size: Optional[int]):
   |                                                          ^^^^^^^^ FA100
15 |     return scatter(src, index, 0, None, dim_size, reduce="mean")
   |

geom3d\models\PNA\aggregators.py:18:5: D103 Missing docstring in public function
   |
18 | def aggregate_min(src: Tensor, index: Tensor, dim_size: Optional[int]):
   |     ^^^^^^^^^^^^^ D103
19 |     return scatter(src, index, 0, None, dim_size, reduce="min")
   |

geom3d\models\PNA\aggregators.py:18:57: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
18 | def aggregate_min(src: Tensor, index: Tensor, dim_size: Optional[int]):
   |                                                         ^^^^^^^^ FA100
19 |     return scatter(src, index, 0, None, dim_size, reduce="min")
   |

geom3d\models\PNA\aggregators.py:22:5: D103 Missing docstring in public function
   |
22 | def aggregate_max(src: Tensor, index: Tensor, dim_size: Optional[int]):
   |     ^^^^^^^^^^^^^ D103
23 |     return scatter(src, index, 0, None, dim_size, reduce="max")
   |

geom3d\models\PNA\aggregators.py:22:57: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
22 | def aggregate_max(src: Tensor, index: Tensor, dim_size: Optional[int]):
   |                                                         ^^^^^^^^ FA100
23 |     return scatter(src, index, 0, None, dim_size, reduce="max")
   |

geom3d\models\PNA\aggregators.py:26:5: D103 Missing docstring in public function
   |
26 | def aggregate_var(src, index, dim_size):
   |     ^^^^^^^^^^^^^ D103
27 |     mean = aggregate_mean(src, index, dim_size)
28 |     mean_squares = aggregate_mean(src * src, index, dim_size)
   |

geom3d\models\PNA\aggregators.py:32:5: D103 Missing docstring in public function
   |
32 | def aggregate_std(src, index, dim_size):
   |     ^^^^^^^^^^^^^ D103
33 |     return torch.sqrt(torch.relu(aggregate_var(src, index, dim_size)) + 1e-5)
   |

geom3d\models\PNA\scalers.py:1:1: D100 Missing docstring in public module
geom3d\models\PNA\scalers.py:9:5: D103 Missing docstring in public function
   |
 7 | # For an example see https://github.com/rusty1s/pytorch_geometric/blob/master/examples/PNA.py
 8 | 
 9 | def scale_identity(src: Tensor, deg: Tensor, avg_deg: Dict[str, float]):
   |     ^^^^^^^^^^^^^^ D103
10 |     return src
   |

geom3d\models\PNA\scalers.py:9:33: ARG001 Unused function argument: `deg`
   |
 7 | # For an example see https://github.com/rusty1s/pytorch_geometric/blob/master/examples/PNA.py
 8 | 
 9 | def scale_identity(src: Tensor, deg: Tensor, avg_deg: Dict[str, float]):
   |                                 ^^^ ARG001
10 |     return src
   |

geom3d\models\PNA\scalers.py:9:46: ARG001 Unused function argument: `avg_deg`
   |
 7 | # For an example see https://github.com/rusty1s/pytorch_geometric/blob/master/examples/PNA.py
 8 | 
 9 | def scale_identity(src: Tensor, deg: Tensor, avg_deg: Dict[str, float]):
   |                                              ^^^^^^^ ARG001
10 |     return src
   |

geom3d\models\PNA\scalers.py:9:55: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
 7 | # For an example see https://github.com/rusty1s/pytorch_geometric/blob/master/examples/PNA.py
 8 | 
 9 | def scale_identity(src: Tensor, deg: Tensor, avg_deg: Dict[str, float]):
   |                                                       ^^^^ FA100
10 |     return src
   |

geom3d\models\PNA\scalers.py:13:5: D103 Missing docstring in public function
   |
13 | def scale_amplification(src: Tensor, deg: Tensor, avg_deg: Dict[str, float]):
   |     ^^^^^^^^^^^^^^^^^^^ D103
14 |     return src * (torch.log(deg + 1) / avg_deg["log"])
   |

geom3d\models\PNA\scalers.py:13:60: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
13 | def scale_amplification(src: Tensor, deg: Tensor, avg_deg: Dict[str, float]):
   |                                                            ^^^^ FA100
14 |     return src * (torch.log(deg + 1) / avg_deg["log"])
   |

geom3d\models\PNA\scalers.py:17:5: D103 Missing docstring in public function
   |
17 | def scale_attenuation(src: Tensor, deg: Tensor, avg_deg: Dict[str, float]):
   |     ^^^^^^^^^^^^^^^^^ D103
18 |     scale = avg_deg["log"] / torch.log(deg + 1)
19 |     scale[deg == 0] = 1
   |

geom3d\models\PNA\scalers.py:17:58: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
17 | def scale_attenuation(src: Tensor, deg: Tensor, avg_deg: Dict[str, float]):
   |                                                          ^^^^ FA100
18 |     scale = avg_deg["log"] / torch.log(deg + 1)
19 |     scale[deg == 0] = 1
   |

geom3d\models\PNA\scalers.py:23:5: D103 Missing docstring in public function
   |
23 | def scale_linear(src: Tensor, deg: Tensor, avg_deg: Dict[str, float]):
   |     ^^^^^^^^^^^^ D103
24 |     return src * (deg / avg_deg["lin"])
   |

geom3d\models\PNA\scalers.py:23:53: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
23 | def scale_linear(src: Tensor, deg: Tensor, avg_deg: Dict[str, float]):
   |                                                     ^^^^ FA100
24 |     return src * (deg / avg_deg["lin"])
   |

geom3d\models\PNA\scalers.py:27:5: D103 Missing docstring in public function
   |
27 | def scale_inverse_linear(src: Tensor, deg: Tensor, avg_deg: Dict[str, float]):
   |     ^^^^^^^^^^^^^^^^^^^^ D103
28 |     scale = avg_deg["lin"] / deg
29 |     scale[deg == 0] = 1
   |

geom3d\models\PNA\scalers.py:27:61: FA100 Add `from __future__ import annotations` to simplify `typing.Dict`
   |
27 | def scale_inverse_linear(src: Tensor, deg: Tensor, avg_deg: Dict[str, float]):
   |                                                             ^^^^ FA100
28 |     scale = avg_deg["lin"] / deg
29 |     scale[deg == 0] = 1
   |

geom3d\models\PaiNN.py:1:1: N999 Invalid module name: 'PaiNN'
geom3d\models\PaiNN.py:5:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
4 | import torch
5 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
6 | from torch import nn
7 | from torch_geometric.utils import scatter
  |

geom3d\models\PaiNN.py:23:9: D205 1 blank line required between summary line and description
   |
22 |       def __init__(self, n_atom_basis: int, activation: Callable):
23 |           """Args:
   |  _________^
24 | |         ----
25 | |             n_atom_basis: number of features to describe atomic environments.
26 | |             activation: if None, no activation function is used.
27 | |             epsilon: stability constant added in norm to prevent numerical instabilities
28 | | 
29 | |         """
   | |___________^ D205
30 |           super().__init__()
31 |           self.n_atom_basis = n_atom_basis
   |
   = help: Insert single blank line

geom3d\models\PaiNN.py:23:9: D400 First line should end with a period
   |
22 |       def __init__(self, n_atom_basis: int, activation: Callable):
23 |           """Args:
   |  _________^
24 | |         ----
25 | |             n_atom_basis: number of features to describe atomic environments.
26 | |             activation: if None, no activation function is used.
27 | |             epsilon: stability constant added in norm to prevent numerical instabilities
28 | | 
29 | |         """
   | |___________^ D400
30 |           super().__init__()
31 |           self.n_atom_basis = n_atom_basis
   |
   = help: Add period

geom3d\models\PaiNN.py:23:9: D415 First line should end with a period, question mark, or exclamation point
   |
22 |       def __init__(self, n_atom_basis: int, activation: Callable):
23 |           """Args:
   |  _________^
24 | |         ----
25 | |             n_atom_basis: number of features to describe atomic environments.
26 | |             activation: if None, no activation function is used.
27 | |             epsilon: stability constant added in norm to prevent numerical instabilities
28 | | 
29 | |         """
   | |___________^ D415
30 |           super().__init__()
31 |           self.n_atom_basis = n_atom_basis
   |
   = help: Add closing punctuation

geom3d\models\PaiNN.py:38:9: PLR0913 Too many arguments in function definition (7 > 5)
   |
36 |         )
37 | 
38 |     def forward(
   |         ^^^^^^^ PLR0913
39 |         self,
40 |         q: torch.Tensor,
   |

geom3d\models\PaiNN.py:38:9: D417 Missing argument descriptions in the docstring for `forward`: `Wij`, `dir_ij`, `idx_i`, `idx_j`, `mu`, `n_atoms`
   |
36 |         )
37 | 
38 |     def forward(
   |         ^^^^^^^ D417
39 |         self,
40 |         q: torch.Tensor,
   |

geom3d\models\PaiNN.py:42:9: N803 Argument name `Wij` should be lowercase
   |
40 |         q: torch.Tensor,
41 |         mu: torch.Tensor,
42 |         Wij: torch.Tensor,
   |         ^^^^^^^^^^^^^^^^^ N803
43 |         dir_ij: torch.Tensor,
44 |         idx_i: torch.Tensor,
   |

geom3d\models\PaiNN.py:67:13: N806 Variable `dmuR` in function should be lowercase
   |
65 |         x = Wij * xj
66 | 
67 |         dq, dmuR, dmumu = torch.split(x, self.n_atom_basis, dim=-1)
   |             ^^^^ N806
68 |         dq = scatter_add(dq, idx_i, dim_size=n_atoms)
69 |         dmu = dmuR * dir_ij[..., None] + dmumu * muj
   |

geom3d\models\PaiNN.py:82:9: D205 1 blank line required between summary line and description
   |
81 |       def __init__(self, n_atom_basis: int, activation: Callable, epsilon: float = 1e-8):
82 |           """Args:
   |  _________^
83 | |         ----
84 | |             n_atom_basis: number of features to describe atomic environments.
85 | |             activation: if None, no activation function is used.
86 | |             epsilon: stability constant added in norm to prevent numerical instabilities
87 | | 
88 | |         """
   | |___________^ D205
89 |           super().__init__()
90 |           self.n_atom_basis = n_atom_basis
   |
   = help: Insert single blank line

geom3d\models\PaiNN.py:82:9: D400 First line should end with a period
   |
81 |       def __init__(self, n_atom_basis: int, activation: Callable, epsilon: float = 1e-8):
82 |           """Args:
   |  _________^
83 | |         ----
84 | |             n_atom_basis: number of features to describe atomic environments.
85 | |             activation: if None, no activation function is used.
86 | |             epsilon: stability constant added in norm to prevent numerical instabilities
87 | | 
88 | |         """
   | |___________^ D400
89 |           super().__init__()
90 |           self.n_atom_basis = n_atom_basis
   |
   = help: Add period

geom3d\models\PaiNN.py:82:9: D415 First line should end with a period, question mark, or exclamation point
   |
81 |       def __init__(self, n_atom_basis: int, activation: Callable, epsilon: float = 1e-8):
82 |           """Args:
   |  _________^
83 | |         ----
84 | |             n_atom_basis: number of features to describe atomic environments.
85 | |             activation: if None, no activation function is used.
86 | |             epsilon: stability constant added in norm to prevent numerical instabilities
87 | | 
88 | |         """
   | |___________^ D415
89 |           super().__init__()
90 |           self.n_atom_basis = n_atom_basis
   |
   = help: Add closing punctuation

geom3d\models\PaiNN.py:101:9: D417 Missing argument description in the docstring for `forward`: `mu`
    |
 99 |         self.epsilon = epsilon
100 | 
101 |     def forward(self, q: torch.Tensor, mu: torch.Tensor):
    |         ^^^^^^^ D417
102 |         """Compute intraatomic mixing.
    |

geom3d\models\PaiNN.py:114:9: N806 Variable `mu_V` in function should be lowercase
    |
112 |         ## intra-atomic
113 |         mu_mix = self.mu_channel_mix(mu)
114 |         mu_V, mu_W = torch.split(mu_mix, self.n_atom_basis, dim=-1)
    |         ^^^^ N806
115 |         mu_Vn = torch.sqrt(torch.sum(mu_V ** 2, dim=-2, keepdim=True) + self.epsilon)
    |

geom3d\models\PaiNN.py:114:15: N806 Variable `mu_W` in function should be lowercase
    |
112 |         ## intra-atomic
113 |         mu_mix = self.mu_channel_mix(mu)
114 |         mu_V, mu_W = torch.split(mu_mix, self.n_atom_basis, dim=-1)
    |               ^^^^ N806
115 |         mu_Vn = torch.sqrt(torch.sum(mu_V ** 2, dim=-2, keepdim=True) + self.epsilon)
    |

geom3d\models\PaiNN.py:115:9: N806 Variable `mu_Vn` in function should be lowercase
    |
113 |         mu_mix = self.mu_channel_mix(mu)
114 |         mu_V, mu_W = torch.split(mu_mix, self.n_atom_basis, dim=-1)
115 |         mu_Vn = torch.sqrt(torch.sum(mu_V ** 2, dim=-2, keepdim=True) + self.epsilon)
    |         ^^^^^ N806
116 | 
117 |         ctx = torch.cat([q, mu_Vn], dim=-1)
    |

geom3d\models\PaiNN.py:131:5: D205 1 blank line required between summary line and description
    |
130 |   class PaiNN(nn.Module):
131 |       """PaiNN - polarizable interaction neural network
    |  _____^
132 | |     References:
133 | |     .. [#PaiNN1] Schütt, Unke, Gastegger:
134 | |        Equivariant message passing for the prediction of tensorial properties and molecular spectra.
135 | |        ICML 2021, http://proceedings.mlr.press/v139/schutt21a.html.
136 | |     """
    | |_______^ D205
137 |   
138 |       def __init__(
    |
    = help: Insert single blank line

geom3d\models\PaiNN.py:138:9: PLR0913 Too many arguments in function definition (14 > 5)
    |
136 |     """
137 | 
138 |     def __init__(
    |         ^^^^^^^^ PLR0913
139 |         self,
140 |         n_atom_basis: int,
    |

geom3d\models\PaiNN.py:146:16: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
144 |         n_out: int,
145 |         readout: str,
146 |         gamma: Optional[float]=None,
    |                ^^^^^^^^ FA100
147 |         n_out_hidden: Optional[int]=None,
148 |         n_out_layers: int = 2,
    |

geom3d\models\PaiNN.py:147:23: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
145 |         readout: str,
146 |         gamma: Optional[float]=None,
147 |         n_out_hidden: Optional[int]=None,
    |                       ^^^^^^^^ FA100
148 |         n_out_layers: int = 2,
149 |         activation: Optional[Callable] = F.silu,
    |

geom3d\models\PaiNN.py:149:21: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
147 |         n_out_hidden: Optional[int]=None,
148 |         n_out_layers: int = 2,
149 |         activation: Optional[Callable] = F.silu,
    |                     ^^^^^^^^ FA100
150 |         max_z: int = 100,
151 |         shared_interactions: bool = False,
    |

geom3d\models\PaiNN.py:151:9: FBT001 Boolean-typed positional argument in function definition
    |
149 |         activation: Optional[Callable] = F.silu,
150 |         max_z: int = 100,
151 |         shared_interactions: bool = False,
    |         ^^^^^^^^^^^^^^^^^^^ FBT001
152 |         shared_filters: bool = False,
153 |         epsilon: float = 1e-8,
    |

geom3d\models\PaiNN.py:151:9: FBT002 Boolean default positional argument in function definition
    |
149 |         activation: Optional[Callable] = F.silu,
150 |         max_z: int = 100,
151 |         shared_interactions: bool = False,
    |         ^^^^^^^^^^^^^^^^^^^ FBT002
152 |         shared_filters: bool = False,
153 |         epsilon: float = 1e-8,
    |

geom3d\models\PaiNN.py:152:9: FBT001 Boolean-typed positional argument in function definition
    |
150 |         max_z: int = 100,
151 |         shared_interactions: bool = False,
152 |         shared_filters: bool = False,
    |         ^^^^^^^^^^^^^^ FBT001
153 |         epsilon: float = 1e-8,
154 |     ):
    |

geom3d\models\PaiNN.py:152:9: FBT002 Boolean default positional argument in function definition
    |
150 |         max_z: int = 100,
151 |         shared_interactions: bool = False,
152 |         shared_filters: bool = False,
    |         ^^^^^^^^^^^^^^ FBT002
153 |         epsilon: float = 1e-8,
154 |     ):
    |

geom3d\models\PaiNN.py:155:9: D205 1 blank line required between summary line and description
    |
153 |           epsilon: float = 1e-8,
154 |       ):
155 |           """Args:
    |  _________^
156 | |         ----
157 | |             n_atom_basis: number of features to describe atomic environments.
158 | |                 This determines the size of each embedding vector; i.e. embeddings_dim.
159 | |             n_interactions: number of interaction blocks.
160 | |             radial_basis: layer for expanding interatomic distances in a basis set
161 | |             cutoff_fn: cutoff function
162 | |             activation: activation function
163 | |             shared_interactions: if True, share the weights across
164 | |                 interaction blocks.
165 | |             shared_interactions: if True, share the weights across
166 | |                 filter-generating networks.
167 | |             epsilon: stability constant added in norm to prevent numerical instabilities
168 | | 
169 | |         """
    | |___________^ D205
170 |           super().__init__()
    |
    = help: Insert single blank line

geom3d\models\PaiNN.py:155:9: D400 First line should end with a period
    |
153 |           epsilon: float = 1e-8,
154 |       ):
155 |           """Args:
    |  _________^
156 | |         ----
157 | |             n_atom_basis: number of features to describe atomic environments.
158 | |                 This determines the size of each embedding vector; i.e. embeddings_dim.
159 | |             n_interactions: number of interaction blocks.
160 | |             radial_basis: layer for expanding interatomic distances in a basis set
161 | |             cutoff_fn: cutoff function
162 | |             activation: activation function
163 | |             shared_interactions: if True, share the weights across
164 | |                 interaction blocks.
165 | |             shared_interactions: if True, share the weights across
166 | |                 filter-generating networks.
167 | |             epsilon: stability constant added in norm to prevent numerical instabilities
168 | | 
169 | |         """
    | |___________^ D400
170 |           super().__init__()
    |
    = help: Add period

geom3d\models\PaiNN.py:155:9: D415 First line should end with a period, question mark, or exclamation point
    |
153 |           epsilon: float = 1e-8,
154 |       ):
155 |           """Args:
    |  _________^
156 | |         ----
157 | |             n_atom_basis: number of features to describe atomic environments.
158 | |                 This determines the size of each embedding vector; i.e. embeddings_dim.
159 | |             n_interactions: number of interaction blocks.
160 | |             radial_basis: layer for expanding interatomic distances in a basis set
161 | |             cutoff_fn: cutoff function
162 | |             activation: activation function
163 | |             shared_interactions: if True, share the weights across
164 | |                 interaction blocks.
165 | |             shared_interactions: if True, share the weights across
166 | |                 filter-generating networks.
167 | |             epsilon: stability constant added in norm to prevent numerical instabilities
168 | | 
169 | |         """
    | |___________^ D415
170 |           super().__init__()
    |
    = help: Add closing punctuation

geom3d\models\PaiNN.py:217:9: D102 Missing docstring in public method
    |
215 |         )
216 | 
217 |     def create_output_layers(self):
    |         ^^^^^^^^^^^^^^^^^^^^ D102
218 |         return build_mlp(
219 |             n_in=self.n_atom_basis,
    |

geom3d\models\PaiNN.py:226:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
224 |         )
225 | 
226 |     def forward(self, x, positions, radius_edge_index, batch, return_latent=False, return_vector=False):
    |         ^^^^^^^ PLR0913
227 |         """Compute atomic representations/embeddings.
    |

geom3d\models\PaiNN.py:226:9: D417 Missing argument descriptions in the docstring for `forward`: `batch`, `positions`, `radius_edge_index`, `return_latent`, `return_vector`, `x`
    |
224 |         )
225 | 
226 |     def forward(self, x, positions, radius_edge_index, batch, return_latent=False, return_vector=False):
    |         ^^^^^^^ D417
227 |         """Compute atomic representations/embeddings.
    |

geom3d\models\PaiNN.py:226:63: FBT002 Boolean default positional argument in function definition
    |
224 |         )
225 | 
226 |     def forward(self, x, positions, radius_edge_index, batch, return_latent=False, return_vector=False):
    |                                                               ^^^^^^^^^^^^^ FBT002
227 |         """Compute atomic representations/embeddings.
    |

geom3d\models\PaiNN.py:226:84: FBT002 Boolean default positional argument in function definition
    |
224 |         )
225 | 
226 |     def forward(self, x, positions, radius_edge_index, batch, return_latent=False, return_vector=False):
    |                                                                                    ^^^^^^^^^^^^^ FBT002
227 |         """Compute atomic representations/embeddings.
    |

geom3d\models\PaiNN.py:240:48: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
239 |         """
240 |         atomic_numbers = x[:, 0] if x.dim() == 2 else x
    |                                                ^ PLR2004
241 |         n_atoms = atomic_numbers.size()[0]
    |

geom3d\models\PaiNN.py:278:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
276 |         return h
277 | 
278 |     def forward_with_gathered_index(self, gathered_x, positions, radius_edge_index, gathered_batch, periodic_index_mapping, return_latent=False, return_vector=False):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
279 |         idx_i, idx_j = radius_edge_index[0], radius_edge_index[1]
280 |         r_ij = positions[idx_i] - positions[idx_j]
    |

geom3d\models\PaiNN.py:278:9: D102 Missing docstring in public method
    |
276 |         return h
277 | 
278 |     def forward_with_gathered_index(self, gathered_x, positions, radius_edge_index, gathered_batch, periodic_index_mapping, return_latent=False, return_vector=False):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
279 |         idx_i, idx_j = radius_edge_index[0], radius_edge_index[1]
280 |         r_ij = positions[idx_i] - positions[idx_j]
    |

geom3d\models\PaiNN.py:278:125: FBT002 Boolean default positional argument in function definition
    |
276 |         return h
277 | 
278 |     def forward_with_gathered_index(self, gathered_x, positions, radius_edge_index, gathered_batch, periodic_index_mapping, return_latent=False, return_vector=False):
    |                                                                                                                             ^^^^^^^^^^^^^ FBT002
279 |         idx_i, idx_j = radius_edge_index[0], radius_edge_index[1]
280 |         r_ij = positions[idx_i] - positions[idx_j]
    |

geom3d\models\PaiNN.py:278:146: FBT002 Boolean default positional argument in function definition
    |
276 |         return h
277 | 
278 |     def forward_with_gathered_index(self, gathered_x, positions, radius_edge_index, gathered_batch, periodic_index_mapping, return_latent=False, return_vector=False):
    |                                                                                                                                                  ^^^^^^^^^^^^^ FBT002
279 |         idx_i, idx_j = radius_edge_index[0], radius_edge_index[1]
280 |         r_ij = positions[idx_i] - positions[idx_j]
    |

geom3d\models\PaiNN_utils.py:1:1: N999 Invalid module name: 'PaiNN_utils'
geom3d\models\PaiNN_utils.py:1:1: D100 Missing docstring in public module
geom3d\models\PaiNN_utils.py:5:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
4 | import torch
5 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
6 | from torch import nn
7 | from torch.nn.init import xavier_uniform_, zeros_
  |

geom3d\models\PaiNN_utils.py:10:7: D101 Missing docstring in public class
   |
10 | class Dense(nn.Linear):
   |       ^^^^^ D101
11 |     def __init__(
12 |         self,
   |

geom3d\models\PaiNN_utils.py:11:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
10 | class Dense(nn.Linear):
11 |     def __init__(
   |         ^^^^^^^^ PLR0913
12 |         self,
13 |         in_features: int,
   |

geom3d\models\PaiNN_utils.py:11:9: D107 Missing docstring in `__init__`
   |
10 | class Dense(nn.Linear):
11 |     def __init__(
   |         ^^^^^^^^ D107
12 |         self,
13 |         in_features: int,
   |

geom3d\models\PaiNN_utils.py:15:9: FBT001 Boolean-typed positional argument in function definition
   |
13 |         in_features: int,
14 |         out_features: int,
15 |         bias: bool = True,
   |         ^^^^ FBT001
16 |         activation: Union[Callable, nn.Module] = None,
17 |         weight_init: Callable = xavier_uniform_,
   |

geom3d\models\PaiNN_utils.py:15:9: FBT002 Boolean default positional argument in function definition
   |
13 |         in_features: int,
14 |         out_features: int,
15 |         bias: bool = True,
   |         ^^^^ FBT002
16 |         activation: Union[Callable, nn.Module] = None,
17 |         weight_init: Callable = xavier_uniform_,
   |

geom3d\models\PaiNN_utils.py:16:21: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
14 |         out_features: int,
15 |         bias: bool = True,
16 |         activation: Union[Callable, nn.Module] = None,
   |                     ^^^^^ FA100
17 |         weight_init: Callable = xavier_uniform_,
18 |         bias_init: Callable = zeros_,
   |

geom3d\models\PaiNN_utils.py:28:9: D102 Missing docstring in public method
   |
26 |             self.activation = nn.Identity()
27 | 
28 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
29 |         self.weight_init(self.weight)
30 |         if self.bias is not None:
   |

geom3d\models\PaiNN_utils.py:33:9: D102 Missing docstring in public method
   |
31 |             self.bias_init(self.bias)
32 | 
33 |     def forward(self, input: torch.Tensor):
   |         ^^^^^^^ D102
34 |         y = F.linear(input, self.weight, self.bias)
35 |         return self.activation(y)
   |

geom3d\models\PaiNN_utils.py:33:23: A002 Argument `input` is shadowing a Python builtin
   |
31 |             self.bias_init(self.bias)
32 | 
33 |     def forward(self, input: torch.Tensor):
   |                       ^^^^^ A002
34 |         y = F.linear(input, self.weight, self.bias)
35 |         return self.activation(y)
   |

geom3d\models\PaiNN_utils.py:38:5: D103 Missing docstring in public function
   |
38 | def build_mlp(
   |     ^^^^^^^^^ D103
39 |     n_in: int,
40 |     n_out: int,
   |

geom3d\models\PaiNN_utils.py:41:15: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
39 |     n_in: int,
40 |     n_out: int,
41 |     n_hidden: Optional[Union[int, Sequence[int]]] = None,
   |               ^^^^^^^^ FA100
42 |     n_layers: int = 2,
43 |     activation: Callable = F.silu,
   |

geom3d\models\PaiNN_utils.py:41:24: FA100 Add `from __future__ import annotations` to simplify `typing.Union`
   |
39 |     n_in: int,
40 |     n_out: int,
41 |     n_hidden: Optional[Union[int, Sequence[int]]] = None,
   |                        ^^^^^ FA100
42 |     n_layers: int = 2,
43 |     activation: Callable = F.silu,
   |

geom3d\models\PaiNN_utils.py:72:5: D103 Missing docstring in public function
   |
72 | def scatter_add(
   |     ^^^^^^^^^^^ D103
73 |     x: torch.Tensor, idx_i: torch.Tensor, dim_size: int, dim: int = 0
74 | ) -> torch.Tensor:
   |

geom3d\models\PaiNN_utils.py:87:5: D103 Missing docstring in public function
   |
87 | def replicate_module(
   |     ^^^^^^^^^^^^^^^^ D103
88 |     module_factory: Callable[[], nn.Module], n: int, share_params: bool
89 | ):
   |

geom3d\models\PaiNN_utils.py:88:54: FBT001 Boolean-typed positional argument in function definition
   |
87 | def replicate_module(
88 |     module_factory: Callable[[], nn.Module], n: int, share_params: bool
   |                                                      ^^^^^^^^^^^^ FBT001
89 | ):
90 |     if share_params:
   |

geom3d\models\PaiNN_utils.py:100:69: FBT001 Boolean-typed positional argument in function definition
    |
 98 |     r"""Gaussian radial basis functions."""
 99 | 
100 |     def __init__(self, n_rbf: int, cutoff: float, start: float=0.0, trainable: bool=False, gamma: Optional[float]=None):
    |                                                                     ^^^^^^^^^ FBT001
101 |         r"""Args:
102 |         ----
    |

geom3d\models\PaiNN_utils.py:100:69: FBT002 Boolean default positional argument in function definition
    |
 98 |     r"""Gaussian radial basis functions."""
 99 | 
100 |     def __init__(self, n_rbf: int, cutoff: float, start: float=0.0, trainable: bool=False, gamma: Optional[float]=None):
    |                                                                     ^^^^^^^^^ FBT002
101 |         r"""Args:
102 |         ----
    |

geom3d\models\PaiNN_utils.py:100:99: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
 98 |     r"""Gaussian radial basis functions."""
 99 | 
100 |     def __init__(self, n_rbf: int, cutoff: float, start: float=0.0, trainable: bool=False, gamma: Optional[float]=None):
    |                                                                                                   ^^^^^^^^ FA100
101 |         r"""Args:
102 |         ----
    |

geom3d\models\PaiNN_utils.py:101:9: D205 1 blank line required between summary line and description
    |
100 |       def __init__(self, n_rbf: int, cutoff: float, start: float=0.0, trainable: bool=False, gamma: Optional[float]=None):
101 |           r"""Args:
    |  _________^
102 | |         ----
103 | |             n_rbf: total number of Gaussian functions, :math:`N_g`.
104 | |             cutoff: center of last Gaussian function, :math:`\mu_{N_g}`
105 | |             start: center of first Gaussian function, :math:`\mu_0`.
106 | |             trainable: If True, widths and offset of Gaussian functions
107 | |                 are adjusted during training process.
108 | | 
109 | |         """
    | |___________^ D205
110 |           super().__init__()
111 |           self.n_rbf = n_rbf
    |
    = help: Insert single blank line

geom3d\models\PaiNN_utils.py:101:9: D400 First line should end with a period
    |
100 |       def __init__(self, n_rbf: int, cutoff: float, start: float=0.0, trainable: bool=False, gamma: Optional[float]=None):
101 |           r"""Args:
    |  _________^
102 | |         ----
103 | |             n_rbf: total number of Gaussian functions, :math:`N_g`.
104 | |             cutoff: center of last Gaussian function, :math:`\mu_{N_g}`
105 | |             start: center of first Gaussian function, :math:`\mu_0`.
106 | |             trainable: If True, widths and offset of Gaussian functions
107 | |                 are adjusted during training process.
108 | | 
109 | |         """
    | |___________^ D400
110 |           super().__init__()
111 |           self.n_rbf = n_rbf
    |
    = help: Add period

geom3d\models\PaiNN_utils.py:101:9: D415 First line should end with a period, question mark, or exclamation point
    |
100 |       def __init__(self, n_rbf: int, cutoff: float, start: float=0.0, trainable: bool=False, gamma: Optional[float]=None):
101 |           r"""Args:
    |  _________^
102 | |         ----
103 | |             n_rbf: total number of Gaussian functions, :math:`N_g`.
104 | |             cutoff: center of last Gaussian function, :math:`\mu_{N_g}`
105 | |             start: center of first Gaussian function, :math:`\mu_0`.
106 | |             trainable: If True, widths and offset of Gaussian functions
107 | |                 are adjusted during training process.
108 | | 
109 | |         """
    | |___________^ D415
110 |           super().__init__()
111 |           self.n_rbf = n_rbf
    |
    = help: Add closing punctuation

geom3d\models\PaiNN_utils.py:126:9: D102 Missing docstring in public method
    |
124 |             self.register_buffer("offsets", offset)
125 | 
126 |     def forward(self, inputs: torch.Tensor):
    |         ^^^^^^^ D102
127 |         if self.gamma is not None:
128 |             coeff = - self.gamma
    |

geom3d\models\PaiNN_utils.py:134:5: D103 Missing docstring in public function
    |
134 | def gaussian_rbf(coeff, inputs, offsets):
    |     ^^^^^^^^^^^^ D103
135 |     diff = inputs[..., None] - offsets
136 |     return torch.exp(coeff * torch.pow(diff, 2))
    |

geom3d\models\PaiNN_utils.py:139:5: D417 Missing argument description in the docstring for `cosine_cutoff`: `input`
    |
139 | def cosine_cutoff(input: torch.Tensor, cutoff: torch.Tensor):
    |     ^^^^^^^^^^^^^ D417
140 |     r"""Behler-style cosine cutoff.
141 |     .. math::
    |

geom3d\models\PaiNN_utils.py:139:19: A002 Argument `input` is shadowing a Python builtin
    |
139 | def cosine_cutoff(input: torch.Tensor, cutoff: torch.Tensor):
    |                   ^^^^^ A002
140 |     r"""Behler-style cosine cutoff.
141 |     .. math::
    |

geom3d\models\PaiNN_utils.py:140:5: D205 1 blank line required between summary line and description
    |
139 |   def cosine_cutoff(input: torch.Tensor, cutoff: torch.Tensor):
140 |       r"""Behler-style cosine cutoff.
    |  _____^
141 | |     .. math::
142 | |        f(r) = \begin{cases}
143 | |         0.5 \times \\left[1 + \\cos\\left(\frac{\\pi r}{r_\text{cutoff}}\right)\right]
144 | |           & r < r_\text{cutoff} \\
145 | |             0 & r \\geqslant r_\text{cutoff} \\
146 | |             \\end{cases}.
147 | | 
148 | |     Args:
149 | |     ----
150 | |         cutoff (float, optional): cutoff radius.
151 | | 
152 | |     """
    | |_______^ D205
153 |       # Compute values of cutoff function
154 |       input_cut = 0.5 * (torch.cos(input * math.pi / cutoff) + 1.0)
    |
    = help: Insert single blank line

geom3d\models\PaiNN_utils.py:161:5: D205 1 blank line required between summary line and description
    |
160 |   class CosineCutoff(nn.Module):
161 |       r"""Behler-style cosine cutoff module.
    |  _____^
162 | |     .. math::
163 | |        f(r) = \begin{cases}
164 | |         0.5 \times \left[1 + \cos\left(\frac{\pi r}{r_\text{cutoff}}\right)\right]
165 | |           & r < r_\text{cutoff} \\
166 | |         0 & r \geqslant r_\text{cutoff} \\
167 | |         \end{cases}.
168 | |     """
    | |_______^ D205
169 |   
170 |       def __init__(self, cutoff: float):
    |
    = help: Insert single blank line

geom3d\models\PaiNN_utils.py:171:9: D205 1 blank line required between summary line and description
    |
170 |       def __init__(self, cutoff: float):
171 |           """Args:
    |  _________^
172 | |         ----
173 | |             cutoff (float, optional): cutoff radius.
174 | | 
175 | |         """
    | |___________^ D205
176 |           super().__init__()
177 |           self.register_buffer("cutoff", torch.FloatTensor([cutoff]))
    |
    = help: Insert single blank line

geom3d\models\PaiNN_utils.py:171:9: D400 First line should end with a period
    |
170 |       def __init__(self, cutoff: float):
171 |           """Args:
    |  _________^
172 | |         ----
173 | |             cutoff (float, optional): cutoff radius.
174 | | 
175 | |         """
    | |___________^ D400
176 |           super().__init__()
177 |           self.register_buffer("cutoff", torch.FloatTensor([cutoff]))
    |
    = help: Add period

geom3d\models\PaiNN_utils.py:171:9: D415 First line should end with a period, question mark, or exclamation point
    |
170 |       def __init__(self, cutoff: float):
171 |           """Args:
    |  _________^
172 | |         ----
173 | |             cutoff (float, optional): cutoff radius.
174 | | 
175 | |         """
    | |___________^ D415
176 |           super().__init__()
177 |           self.register_buffer("cutoff", torch.FloatTensor([cutoff]))
    |
    = help: Add closing punctuation

geom3d\models\PaiNN_utils.py:179:9: D102 Missing docstring in public method
    |
177 |         self.register_buffer("cutoff", torch.FloatTensor([cutoff]))
178 | 
179 |     def forward(self, input: torch.Tensor):
    |         ^^^^^^^ D102
180 |         return cosine_cutoff(input, self.cutoff)
    |

geom3d\models\PaiNN_utils.py:179:23: A002 Argument `input` is shadowing a Python builtin
    |
177 |         self.register_buffer("cutoff", torch.FloatTensor([cutoff]))
178 | 
179 |     def forward(self, input: torch.Tensor):
    |                       ^^^^^ A002
180 |         return cosine_cutoff(input, self.cutoff)
    |

geom3d\models\ProNet\ProNet.py:1:1: N999 Invalid module name: 'ProNet'
geom3d\models\ProNet\ProNet.py:5:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
3 | import numpy as np
4 | import torch
5 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
6 | from torch import nn
7 | from torch.nn import Embedding
  |

geom3d\models\ProNet\ProNet.py:19:5: D103 Missing docstring in public function
   |
17 | num_bb_embs = 6
18 | 
19 | def swish(x):
   |     ^^^^^ D103
20 |     return x * torch.sigmoid(x)
   |

geom3d\models\ProNet\ProNet.py:35:9: D107 Missing docstring in `__init__`
   |
33 |     """
34 | 
35 |     def __init__(self, in_channels, out_channels, bias=True, weight_initializer="glorot"):
   |         ^^^^^^^^ D107
36 | 
37 |         super().__init__()
   |

geom3d\models\ProNet\ProNet.py:35:51: FBT002 Boolean default positional argument in function definition
   |
33 |     """
34 | 
35 |     def __init__(self, in_channels, out_channels, bias=True, weight_initializer="glorot"):
   |                                                   ^^^^ FBT002
36 | 
37 |         super().__init__()
   |

geom3d\models\ProNet\ProNet.py:51:9: D102 Missing docstring in public method
   |
49 |         self.reset_parameters()
50 | 
51 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
52 |         if self.weight_initializer == "glorot":
53 |             inits.glorot(self.weight)
   |

geom3d\models\ProNet\ProNet.py:60:9: D419 Docstring is empty
   |
59 |     def forward(self, x):
60 |         """"""
   |         ^^^^^^ D419
61 |         return F.linear(x, self.weight, self.bias)
   |

geom3d\models\ProNet\ProNet.py:77:9: D107 Missing docstring in `__init__`
   |
75 |     """
76 | 
77 |     def __init__(
   |         ^^^^^^^^ D107
78 |             self,
79 |             in_channels,
   |

geom3d\models\ProNet\ProNet.py:82:13: FBT002 Boolean default positional argument in function definition
   |
80 |             middle_channels,
81 |             out_channels,
82 |             bias=False,
   |             ^^^^ FBT002
83 |             act=False
84 |     ):
   |

geom3d\models\ProNet\ProNet.py:83:13: FBT002 Boolean default positional argument in function definition
   |
81 |             out_channels,
82 |             bias=False,
83 |             act=False
   |             ^^^ FBT002
84 |     ):
85 |         super().__init__()
   |

geom3d\models\ProNet\ProNet.py:90:9: D102 Missing docstring in public method
   |
88 |         self.act = act
89 | 
90 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
91 |         self.lin1.reset_parameters()
92 |         self.lin2.reset_parameters()
   |

geom3d\models\ProNet\ProNet.py:94:9: D102 Missing docstring in public method
   |
92 |         self.lin2.reset_parameters()
93 | 
94 |     def forward(self, x):
   |         ^^^^^^^ D102
95 |         x = self.lin1(x)
96 |         if self.act:
   |

geom3d\models\ProNet\ProNet.py:116:9: D107 Missing docstring in `__init__`
    |
114 |     """
115 | 
116 |     def __init__(self, in_channels, out_channels):
    |         ^^^^^^^^ D107
117 |         super().__init__()
    |

geom3d\models\ProNet\ProNet.py:127:9: D102 Missing docstring in public method
    |
125 |         self.reset_parameters()
126 | 
127 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
128 |         self.lin_l.reset_parameters()
129 |         self.lin_r.reset_parameters()
    |

geom3d\models\ProNet\ProNet.py:131:9: D102 Missing docstring in public method
    |
129 |         self.lin_r.reset_parameters()
130 | 
131 |     def forward(self, x, edge_index, edge_weight, size=None):
    |         ^^^^^^^ D102
132 |         x = (x, x)
133 |         out = self.propagate(edge_index, x=x, edge_weight=edge_weight, size=size)
    |

geom3d\models\ProNet\ProNet.py:137:9: D102 Missing docstring in public method
    |
135 |         return out + self.lin_r(x[1])
136 | 
137 |     def message(self, x_j, edge_weight):
    |         ^^^^^^^ D102
138 |         return edge_weight * x_j
    |

geom3d\models\ProNet\ProNet.py:140:9: D102 Missing docstring in public method
    |
138 |         return edge_weight * x_j
139 | 
140 |     def message_and_aggregate(self, adj_t, x):
    |         ^^^^^^^^^^^^^^^^^^^^^ D102
141 |         return matmul(adj_t, x[0], reduce=self.aggr)
    |

geom3d\models\ProNet\ProNet.py:144:7: D101 Missing docstring in public class
    |
144 | class InteractionBlock(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^ D101
145 |     def __init__(
146 |             self,
    |

geom3d\models\ProNet\ProNet.py:145:9: PLR0913 Too many arguments in function definition (10 > 5)
    |
144 | class InteractionBlock(torch.nn.Module):
145 |     def __init__(
    |         ^^^^^^^^ PLR0913
146 |             self,
147 |             hidden_channels,
    |

geom3d\models\ProNet\ProNet.py:145:9: D107 Missing docstring in `__init__`
    |
144 | class InteractionBlock(torch.nn.Module):
145 |     def __init__(
    |         ^^^^^^^^ D107
146 |             self,
147 |             hidden_channels,
    |

geom3d\models\ProNet\ProNet.py:192:9: D102 Missing docstring in public method
    |
190 |         self.reset_parameters()
191 | 
192 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
193 |         self.conv0.reset_parameters()
194 |         self.conv1.reset_parameters()
    |

geom3d\models\ProNet\ProNet.py:216:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
216 |     def forward(self, x, feature0, feature1, pos_emb, edge_index, batch):
    |         ^^^^^^^ PLR0913
217 |         x_lin_1 = self.act(self.lin_1(x))
218 |         x_lin_2 = self.act(self.lin_2(x))
    |

geom3d\models\ProNet\ProNet.py:216:9: D102 Missing docstring in public method
    |
216 |     def forward(self, x, feature0, feature1, pos_emb, edge_index, batch):
    |         ^^^^^^^ D102
217 |         x_lin_1 = self.act(self.lin_1(x))
218 |         x_lin_2 = self.act(self.lin_2(x))
    |

geom3d\models\ProNet\ProNet.py:216:67: ARG002 Unused method argument: `batch`
    |
216 |     def forward(self, x, feature0, feature1, pos_emb, edge_index, batch):
    |                                                                   ^^^^^ ARG002
217 |         x_lin_1 = self.act(self.lin_1(x))
218 |         x_lin_2 = self.act(self.lin_2(x))
    |

geom3d\models\ProNet\ProNet.py:272:9: PLR0913 Too many arguments in function definition (15 > 5)
    |
270 |     """
271 | 
272 |     def __init__(
    |         ^^^^^^^^ PLR0913
273 |             self,
274 |             level="aminoacid",
    |

geom3d\models\ProNet\ProNet.py:272:9: D107 Missing docstring in `__init__`
    |
270 |     """
271 | 
272 |     def __init__(
    |         ^^^^^^^^ D107
273 |             self,
274 |             level="aminoacid",
    |

geom3d\models\ProNet\ProNet.py:287:13: FBT002 Boolean default positional argument in function definition
    |
285 |             num_pos_emb=16,
286 |             dropout=0,
287 |             data_augment_eachlayer=False,
    |             ^^^^^^^^^^^^^^^^^^^^^^ FBT002
288 |             euler_noise = False,
289 |     ):
    |

geom3d\models\ProNet\ProNet.py:288:13: FBT002 Boolean default positional argument in function definition
    |
286 |             dropout=0,
287 |             data_augment_eachlayer=False,
288 |             euler_noise = False,
    |             ^^^^^^^^^^^ FBT002
289 |     ):
290 |         super().__init__()
    |

geom3d\models\ProNet\ProNet.py:339:9: D102 Missing docstring in public method
    |
337 |         self.reset_parameters()
338 | 
339 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
340 |         self.embedding.reset_parameters()
341 |         for interaction in self.interaction_blocks:
    |

geom3d\models\ProNet\ProNet.py:347:9: D102 Missing docstring in public method
    |
345 |         self.lin_out.reset_parameters()
346 | 
347 |     def pos_emb(self, edge_index, num_pos_emb=16):
    |         ^^^^^^^ D102
348 |         # From https://github.com/jingraham/neurips19-graph-protein-design
349 |         d = edge_index[0] - edge_index[1]
    |

geom3d\models\ProNet\ProNet.py:358:9: PLR0915 Too many statements (71 > 50)
    |
356 |         return torch.cat((torch.cos(angles), torch.sin(angles)), -1)
357 | 
358 |     def forward(self, batch_data):
    |         ^^^^^^^ PLR0915
359 | 
360 |         z, pos, batch = torch.squeeze(batch_data.x.long()), batch_data.coords_ca, batch_data.batch
    |

geom3d\models\ProNet\ProNet.py:358:9: D102 Missing docstring in public method
    |
356 |         return torch.cat((torch.cos(angles), torch.sin(angles)), -1)
357 | 
358 |     def forward(self, batch_data):
    |         ^^^^^^^ D102
359 | 
360 |         z, pos, batch = torch.squeeze(batch_data.x.long()), batch_data.coords_ca, batch_data.batch
    |

geom3d\models\ProNet\ProNet.py:406:13: N806 Variable `Or1_x` in function should be lowercase
    |
404 |         if self.level in ("backbone", "allatom"):
405 |             # Calculate Euler angles.
406 |             Or1_x = pos_n[i] - pos[i]
    |             ^^^^^ N806
407 |             Or1_z = torch.cross(Or1_x, torch.cross(Or1_x, pos_c[i] - pos[i]))
408 |             Or1_z_length = Or1_z.norm(dim=1) + 1e-7
    |

geom3d\models\ProNet\ProNet.py:407:13: N806 Variable `Or1_z` in function should be lowercase
    |
405 |             # Calculate Euler angles.
406 |             Or1_x = pos_n[i] - pos[i]
407 |             Or1_z = torch.cross(Or1_x, torch.cross(Or1_x, pos_c[i] - pos[i]))
    |             ^^^^^ N806
408 |             Or1_z_length = Or1_z.norm(dim=1) + 1e-7
    |

geom3d\models\ProNet\ProNet.py:408:13: N806 Variable `Or1_z_length` in function should be lowercase
    |
406 |             Or1_x = pos_n[i] - pos[i]
407 |             Or1_z = torch.cross(Or1_x, torch.cross(Or1_x, pos_c[i] - pos[i]))
408 |             Or1_z_length = Or1_z.norm(dim=1) + 1e-7
    |             ^^^^^^^^^^^^ N806
409 | 
410 |             Or2_x = pos_n[j] - pos[j]
    |

geom3d\models\ProNet\ProNet.py:410:13: N806 Variable `Or2_x` in function should be lowercase
    |
408 |             Or1_z_length = Or1_z.norm(dim=1) + 1e-7
409 | 
410 |             Or2_x = pos_n[j] - pos[j]
    |             ^^^^^ N806
411 |             Or2_z = torch.cross(Or2_x, torch.cross(Or2_x, pos_c[j] - pos[j]))
412 |             Or2_z_length = Or2_z.norm(dim=1) + 1e-7
    |

geom3d\models\ProNet\ProNet.py:411:13: N806 Variable `Or2_z` in function should be lowercase
    |
410 |             Or2_x = pos_n[j] - pos[j]
411 |             Or2_z = torch.cross(Or2_x, torch.cross(Or2_x, pos_c[j] - pos[j]))
    |             ^^^^^ N806
412 |             Or2_z_length = Or2_z.norm(dim=1) + 1e-7
    |

geom3d\models\ProNet\ProNet.py:412:13: N806 Variable `Or2_z_length` in function should be lowercase
    |
410 |             Or2_x = pos_n[j] - pos[j]
411 |             Or2_z = torch.cross(Or2_x, torch.cross(Or2_x, pos_c[j] - pos[j]))
412 |             Or2_z_length = Or2_z.norm(dim=1) + 1e-7
    |             ^^^^^^^^^^^^ N806
413 | 
414 |             Or1_Or2_N = torch.cross(Or1_z, Or2_z)
    |

geom3d\models\ProNet\ProNet.py:414:13: N806 Variable `Or1_Or2_N` in function should be lowercase
    |
412 |             Or2_z_length = Or2_z.norm(dim=1) + 1e-7
413 | 
414 |             Or1_Or2_N = torch.cross(Or1_z, Or2_z)
    |             ^^^^^^^^^ N806
415 | 
416 |             angle1 = torch.atan2((torch.cross(Or1_x, Or1_Or2_N) * Or1_z).sum(dim=-1)/Or1_z_length, (Or1_x * Or1_Or2_N).sum(dim=-1))
    |

geom3d\models\ProNet\ProNet.py:464:9: D102 Missing docstring in public method
    |
463 |     @property
464 |     def num_params(self):
    |         ^^^^^^^^^^ D102
465 |         return sum(p.numel() for p in self.parameters())
    |

geom3d\models\ProNet\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\ProNet\features.py:1:1: D100 Missing docstring in public module
geom3d\models\ProNet\features.py:12:5: N802 Function name `Jn` should be lowercase
   |
12 | def Jn(r, n):
   |     ^^ N802
13 |     """Numerical spherical bessel functions of order n."""
14 |     return sp.spherical_jn(n, r)
   |

geom3d\models\ProNet\features.py:17:5: N802 Function name `Jn_zeros` should be lowercase
   |
17 | def Jn_zeros(n, k):
   |     ^^^^^^^^ N802
18 |     """Compute the first k zeros of the spherical bessel functions up to order n (excluded)."""
19 |     zerosj = np.zeros((n, k), dtype="float32")
   |

geom3d\models\ProNet\features.py:34:5: D401 First line of docstring should be in imperative mood: "Computes the sympy formulas for the spherical bessel functions up to order n (excluded)."
   |
33 | def spherical_bessel_formulas(n):
34 |     """Computes the sympy formulas for the spherical bessel functions up to order n (excluded)."""
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
35 |     x = sym.symbols("x")
36 |     # j_i = (-x)^i * (1/x * d/dx)^î * sin(x)/x
   |

geom3d\models\ProNet\features.py:36:5: ERA001 Found commented-out code
   |
34 |     """Computes the sympy formulas for the spherical bessel functions up to order n (excluded)."""
35 |     x = sym.symbols("x")
36 |     # j_i = (-x)^i * (1/x * d/dx)^î * sin(x)/x
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
37 |     j = [sym.sin(x) / x]  # j_0
38 |     a = sym.sin(x) / x
   |
   = help: Remove commented-out code

geom3d\models\ProNet\features.py:47:5: D205 1 blank line required between summary line and description
   |
46 |   def bessel_basis(n, k):
47 |       """Compute the sympy formulas for the normalized and rescaled spherical bessel functions up to
   |  _____^
48 | |     order n (excluded) and maximum frequency k (excluded).
49 | | 
50 | |     Returns
51 | |     -------
52 | |         bess_basis: list
53 | |             Bessel basis formulas taking in a single argument x.
54 | |             Has length n where each element has length k. -> In total n*k many.
55 | | 
56 | |     """
   | |_______^ D205
57 |       zeros = Jn_zeros(n, k)
58 |       normalizer = []
   |
   = help: Insert single blank line

geom3d\models\ProNet\features.py:83:5: D417 Missing argument descriptions in the docstring for `sph_harm_prefactor`: `l`, `m`
   |
83 | def sph_harm_prefactor(l, m):
   |     ^^^^^^^^^^^^^^^^^^ D417
84 |     """Computes the constant pre-factor for the spherical harmonic of degree l and order m.
   |

geom3d\models\ProNet\features.py:83:24: E741 Ambiguous variable name: `l`
   |
83 | def sph_harm_prefactor(l, m):
   |                        ^ E741
84 |     """Computes the constant pre-factor for the spherical harmonic of degree l and order m.
   |

geom3d\models\ProNet\features.py:84:5: D401 First line of docstring should be in imperative mood: "Computes the constant pre-factor for the spherical harmonic of degree l and order m."
   |
83 |   def sph_harm_prefactor(l, m):
84 |       """Computes the constant pre-factor for the spherical harmonic of degree l and order m.
   |  _____^
85 | | 
86 | |     Parameters
87 | |     ----------
88 | |         l: int
89 | |             Degree of the spherical harmonic. l >= 0
90 | |         m: int
91 | |             Order of the spherical harmonic. -l <= m <= l
92 | | 
93 | |     Returns
94 | |     -------
95 | |         factor: float
96 | | 
97 | |     """
   | |_______^ D401
98 |       # sqrt((2*l+1)/4*pi * (l-m)!/(l+m)! )
99 |       return (
   |

geom3d\models\ProNet\features.py:107:5: C901 `associated_legendre_polynomials` is too complex (11 > 10)
    |
107 | def associated_legendre_polynomials(L, zero_m_only=True, pos_m_only=True):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ C901
108 |     """Computes string formulas of the associated legendre polynomials up to degree L (excluded).
    |

geom3d\models\ProNet\features.py:107:5: D417 Missing argument descriptions in the docstring for `associated_legendre_polynomials`: `L`, `pos_m_only`, `zero_m_only`
    |
107 | def associated_legendre_polynomials(L, zero_m_only=True, pos_m_only=True):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D417
108 |     """Computes string formulas of the associated legendre polynomials up to degree L (excluded).
    |

geom3d\models\ProNet\features.py:107:37: N803 Argument name `L` should be lowercase
    |
107 | def associated_legendre_polynomials(L, zero_m_only=True, pos_m_only=True):
    |                                     ^ N803
108 |     """Computes string formulas of the associated legendre polynomials up to degree L (excluded).
    |

geom3d\models\ProNet\features.py:107:40: FBT002 Boolean default positional argument in function definition
    |
107 | def associated_legendre_polynomials(L, zero_m_only=True, pos_m_only=True):
    |                                        ^^^^^^^^^^^ FBT002
108 |     """Computes string formulas of the associated legendre polynomials up to degree L (excluded).
    |

geom3d\models\ProNet\features.py:107:58: FBT002 Boolean default positional argument in function definition
    |
107 | def associated_legendre_polynomials(L, zero_m_only=True, pos_m_only=True):
    |                                                          ^^^^^^^^^^ FBT002
108 |     """Computes string formulas of the associated legendre polynomials up to degree L (excluded).
    |

geom3d\models\ProNet\features.py:108:5: D401 First line of docstring should be in imperative mood: "Computes string formulas of the associated legendre polynomials up to degree L (excluded)."
    |
107 |   def associated_legendre_polynomials(L, zero_m_only=True, pos_m_only=True):
108 |       """Computes string formulas of the associated legendre polynomials up to degree L (excluded).
    |  _____^
109 | | 
110 | |     Parameters
111 | |     ----------
112 | |         L: int
113 | |             Degree up to which to calculate the associated legendre polynomials (degree L is excluded).
114 | |         zero_m_only: bool
115 | |             If True only calculate the polynomials for the polynomials where m=0.
116 | |         pos_m_only: bool
117 | |             If True only calculate the polynomials for the polynomials where m>=0. Overwritten by zero_m_only.
118 | | 
119 | |     Returns
120 | |     -------
121 | |         polynomials: list
122 | |             Contains the sympy functions of the polynomials (in total L many if zero_m_only is True else L^2 many).
123 | | 
124 | |     """
    | |_______^ D401
125 |       # calculations from http://web.cmb.usc.edu/people/alber/Software/tomominer/docs/cpp/group__legendre__polynomials.html
126 |       z = sym.symbols("z")
    |

geom3d\models\ProNet\features.py:127:5: N806 Variable `P_l_m` in function should be lowercase
    |
125 |     # calculations from http://web.cmb.usc.edu/people/alber/Software/tomominer/docs/cpp/group__legendre__polynomials.html
126 |     z = sym.symbols("z")
127 |     P_l_m = [[0] * (2 * l + 1) for l in range(L)]  # for order l: -l <= m <= l
    |     ^^^^^ N806
128 | 
129 |     P_l_m[0][0] = 1
    |

geom3d\models\ProNet\features.py:127:36: E741 Ambiguous variable name: `l`
    |
125 |     # calculations from http://web.cmb.usc.edu/people/alber/Software/tomominer/docs/cpp/group__legendre__polynomials.html
126 |     z = sym.symbols("z")
127 |     P_l_m = [[0] * (2 * l + 1) for l in range(L)]  # for order l: -l <= m <= l
    |                                    ^ E741
128 | 
129 |     P_l_m[0][0] = 1
    |

geom3d\models\ProNet\features.py:132:13: ERA001 Found commented-out code
    |
130 |     if L > 0:
131 |         if zero_m_only:
132 |             # m = 0
    |             ^^^^^^^ ERA001
133 |             P_l_m[1][0] = z
134 |             for l in range(2, L):
    |
    = help: Remove commented-out code

geom3d\models\ProNet\features.py:134:17: E741 Ambiguous variable name: `l`
    |
132 |             # m = 0
133 |             P_l_m[1][0] = z
134 |             for l in range(2, L):
    |                 ^ E741
135 |                 P_l_m[l][0] = sym.simplify(
136 |                     ((2 * l - 1) * z * P_l_m[l - 1][0] - (l - 1) * P_l_m[l - 2][0]) / l
    |

geom3d\models\ProNet\features.py:139:9: RET505 Unnecessary `else` after `return` statement
    |
137 |                 )
138 |             return P_l_m
139 |         else:
    |         ^^^^ RET505
140 |             # for m >= 0
141 |             for l in range(1, L):
    |
    = help: Remove unnecessary `else`

geom3d\models\ProNet\features.py:141:17: E741 Ambiguous variable name: `l`
    |
139 |         else:
140 |             # for m >= 0
141 |             for l in range(1, L):
    |                 ^ E741
142 |                 P_l_m[l][l] = sym.simplify(
143 |                     (1 - 2 * l) * (1 - z ** 2) ** 0.5 * P_l_m[l - 1][l - 1]
    |

geom3d\models\ProNet\features.py:151:17: E741 Ambiguous variable name: `l`
    |
149 |                 )  # P_10, P_21, P_32, P_43
150 | 
151 |             for l in range(2, L):
    |                 ^ E741
152 |                 for m in range(l - 1):  # P_20, P_30, P_31
153 |                     P_l_m[l][m] = sym.simplify(
    |

geom3d\models\ProNet\features.py:163:21: E741 Ambiguous variable name: `l`
    |
161 |             if not pos_m_only:
162 |                 # for m < 0: P_l(-m) = (-1)^m * (l-m)!/(l+m)! * P_lm
163 |                 for l in range(1, L):
    |                     ^ E741
164 |                     for m in range(1, l + 1):  # P_1(-1), P_2(-1) P_2(-2)
165 |                         P_l_m[l][-m] = sym.simplify(
    |

geom3d\models\ProNet\features.py:176:5: C901 `real_sph_harm` is too complex (14 > 10)
    |
176 | def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
    |     ^^^^^^^^^^^^^ C901
177 |     """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
178 |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
    |

geom3d\models\ProNet\features.py:176:5: PLR0912 Too many branches (14 > 12)
    |
176 | def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
    |     ^^^^^^^^^^^^^ PLR0912
177 |     """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
178 |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
    |

geom3d\models\ProNet\features.py:176:5: D417 Missing argument descriptions in the docstring for `real_sph_harm`: `L`, `spherical_coordinates`, `zero_m_only`
    |
176 | def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
    |     ^^^^^^^^^^^^^ D417
177 |     """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
178 |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
    |

geom3d\models\ProNet\features.py:176:19: N803 Argument name `L` should be lowercase
    |
176 | def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
    |                   ^ N803
177 |     """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
178 |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
    |

geom3d\models\ProNet\features.py:176:45: FBT002 Boolean default positional argument in function definition
    |
176 | def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
    |                                             ^^^^^^^^^^^ FBT002
177 |     """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
178 |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
    |

geom3d\models\ProNet\features.py:177:5: D205 1 blank line required between summary line and description
    |
176 |   def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
177 |       """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
    |  _____^
178 | |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
179 | | 
180 | |     Parameters
181 | |     ----------
182 | |         L: int
183 | |             Degree up to which to calculate the spherical harmonics (degree L is excluded).
184 | |         spherical_coordinates: bool
185 | |             - True: Expects the input of the formula strings to be phi and theta.
186 | |             - False: Expects the input of the formula strings to be x, y and z.
187 | |         zero_m_only: bool
188 | |             If True only calculate the harmonics where m=0.
189 | | 
190 | |     Returns
191 | |     -------
192 | |         Y_lm_real: list
193 | |             Computes formula strings of the the real part of the spherical harmonics up
194 | |             to degree L (where degree L is not excluded).
195 | |             In total L^2 many sph harm exist up to degree L (excluded). However, if zero_m_only only is True then
196 | |             the total count is reduced to be only L many.
197 | | 
198 | |     """
    | |_______^ D205
199 |       z = sym.symbols("z")
200 |       P_l_m = associated_legendre_polynomials(L, zero_m_only)
    |
    = help: Insert single blank line

geom3d\models\ProNet\features.py:177:5: D401 First line of docstring should be in imperative mood: "Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded)."
    |
176 |   def real_sph_harm(L, spherical_coordinates, zero_m_only=True):
177 |       """Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).
    |  _____^
178 | |     Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.
179 | | 
180 | |     Parameters
181 | |     ----------
182 | |         L: int
183 | |             Degree up to which to calculate the spherical harmonics (degree L is excluded).
184 | |         spherical_coordinates: bool
185 | |             - True: Expects the input of the formula strings to be phi and theta.
186 | |             - False: Expects the input of the formula strings to be x, y and z.
187 | |         zero_m_only: bool
188 | |             If True only calculate the harmonics where m=0.
189 | | 
190 | |     Returns
191 | |     -------
192 | |         Y_lm_real: list
193 | |             Computes formula strings of the the real part of the spherical harmonics up
194 | |             to degree L (where degree L is not excluded).
195 | |             In total L^2 many sph harm exist up to degree L (excluded). However, if zero_m_only only is True then
196 | |             the total count is reduced to be only L many.
197 | | 
198 | |     """
    | |_______^ D401
199 |       z = sym.symbols("z")
200 |       P_l_m = associated_legendre_polynomials(L, zero_m_only)
    |

geom3d\models\ProNet\features.py:200:5: N806 Variable `P_l_m` in function should be lowercase
    |
198 |     """
199 |     z = sym.symbols("z")
200 |     P_l_m = associated_legendre_polynomials(L, zero_m_only)
    |     ^^^^^ N806
201 |     if zero_m_only:
202 |         # for all m != 0: Y_lm = 0
    |

geom3d\models\ProNet\features.py:203:9: N806 Variable `Y_l_m` in function should be lowercase
    |
201 |     if zero_m_only:
202 |         # for all m != 0: Y_lm = 0
203 |         Y_l_m = [[0] for l in range(L)]
    |         ^^^^^ N806
204 |     else:
205 |         Y_l_m = [[0] * (2 * l + 1) for l in range(L)]  # for order l: -l <= m <= l
    |

geom3d\models\ProNet\features.py:203:26: E741 Ambiguous variable name: `l`
    |
201 |     if zero_m_only:
202 |         # for all m != 0: Y_lm = 0
203 |         Y_l_m = [[0] for l in range(L)]
    |                          ^ E741
204 |     else:
205 |         Y_l_m = [[0] * (2 * l + 1) for l in range(L)]  # for order l: -l <= m <= l
    |

geom3d\models\ProNet\features.py:205:9: N806 Variable `Y_l_m` in function should be lowercase
    |
203 |         Y_l_m = [[0] for l in range(L)]
204 |     else:
205 |         Y_l_m = [[0] * (2 * l + 1) for l in range(L)]  # for order l: -l <= m <= l
    |         ^^^^^ N806
206 | 
207 |     # convert expressions to spherical coordiantes
    |

geom3d\models\ProNet\features.py:205:40: E741 Ambiguous variable name: `l`
    |
203 |         Y_l_m = [[0] for l in range(L)]
204 |     else:
205 |         Y_l_m = [[0] * (2 * l + 1) for l in range(L)]  # for order l: -l <= m <= l
    |                                        ^ E741
206 | 
207 |     # convert expressions to spherical coordiantes
    |

geom3d\models\ProNet\features.py:211:13: E741 Ambiguous variable name: `l`
    |
209 |         # replace z by cos(theta)
210 |         theta = sym.symbols("theta")
211 |         for l in range(L):
    |             ^ E741
212 |             for m in range(len(P_l_m[l])):
213 |                 if not isinstance(P_l_m[l][m], int):
    |

geom3d\models\ProNet\features.py:217:5: ERA001 Found commented-out code
    |
216 |     ## calculate Y_lm
217 |     # Y_lm = N * P_lm(cos(theta)) * exp(i*m*phi)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
218 |     #             { sqrt(2) * (-1)^m * N * P_l|m| * sin(|m|*phi)   if m < 0
219 |     # Y_lm_real = { Y_lm                                           if m = 0
    |
    = help: Remove commented-out code

geom3d\models\ProNet\features.py:222:9: E741 Ambiguous variable name: `l`
    |
220 |     #             { sqrt(2) * (-1)^m * N * P_lm * cos(m*phi)       if m > 0
221 | 
222 |     for l in range(L):
    |         ^ E741
223 |         Y_l_m[l][0] = sym.simplify(sph_harm_prefactor(l, 0) * P_l_m[l][0])  # Y_l0
    |

geom3d\models\ProNet\features.py:227:13: E741 Ambiguous variable name: `l`
    |
225 |     if not zero_m_only:
226 |         phi = sym.symbols("phi")
227 |         for l in range(1, L):
    |             ^ E741
228 |             # m > 0
229 |             for m in range(1, l + 1):
    |

geom3d\models\ProNet\features.py:252:17: E741 Ambiguous variable name: `l`
    |
250 |             x = sym.symbols("x")
251 |             y = sym.symbols("y")
252 |             for l in range(L):
    |                 ^ E741
253 |                 for m in range(len(Y_l_m[l])):
254 |                     Y_l_m[l][m] = sym.simplify(Y_l_m[l][m].subs(phi, sym.atan2(y, x)))
    |

geom3d\models\ProNet\features.py:258:7: N801 Class name `d_angle_emb` should use CapWords convention
    |
258 | class d_angle_emb(torch.nn.Module):
    |       ^^^^^^^^^^^ N801
259 |     def __init__(self, num_radial, num_spherical, cutoff=8.0):
260 |         super().__init__()
    |

geom3d\models\ProNet\features.py:258:7: D101 Missing docstring in public class
    |
258 | class d_angle_emb(torch.nn.Module):
    |       ^^^^^^^^^^^ D101
259 |     def __init__(self, num_radial, num_spherical, cutoff=8.0):
260 |         super().__init__()
    |

geom3d\models\ProNet\features.py:259:9: D107 Missing docstring in `__init__`
    |
258 | class d_angle_emb(torch.nn.Module):
259 |     def __init__(self, num_radial, num_spherical, cutoff=8.0):
    |         ^^^^^^^^ D107
260 |         super().__init__()
261 |         assert num_radial <= 64
    |

geom3d\models\ProNet\features.py:261:9: S101 Use of `assert` detected
    |
259 |     def __init__(self, num_radial, num_spherical, cutoff=8.0):
260 |         super().__init__()
261 |         assert num_radial <= 64
    |         ^^^^^^ S101
262 |         self.num_spherical = num_spherical
263 |         self.num_radial = num_radial
    |

geom3d\models\ProNet\features.py:261:30: PLR2004 Magic value used in comparison, consider replacing `64` with a constant variable
    |
259 |     def __init__(self, num_radial, num_spherical, cutoff=8.0):
260 |         super().__init__()
261 |         assert num_radial <= 64
    |                              ^^ PLR2004
262 |         self.num_spherical = num_spherical
263 |         self.num_radial = num_radial
    |

geom3d\models\ProNet\features.py:267:9: N806 Variable `Y_lm` in function should be lowercase
    |
266 |         bessel_formulas = bessel_basis(num_spherical, num_radial)
267 |         Y_lm = real_sph_harm(
    |         ^^^^ N806
268 |             num_spherical, spherical_coordinates=True, zero_m_only=True
269 |         )
    |

geom3d\models\ProNet\features.py:277:13: E741 Ambiguous variable name: `l`
    |
275 |         modules = {"sin": torch.sin, "cos": torch.cos, "sqrt": torch.sqrt}
276 |         m = 0
277 |         for l in range(len(Y_lm)):
    |             ^ E741
278 |             if l == 0:
279 |                 first_sph = sym.lambdify([theta], Y_lm[l][m], modules)
    |

geom3d\models\ProNet\features.py:281:61: B023 Function definition does not bind loop variable `first_sph`
    |
279 |                 first_sph = sym.lambdify([theta], Y_lm[l][m], modules)
280 |                 self.sph_funcs.append(
281 |                     lambda theta: torch.zeros_like(theta) + first_sph(theta)
    |                                                             ^^^^^^^^^ B023
282 |                 )
283 |             else:
    |

geom3d\models\ProNet\features.py:290:9: D102 Missing docstring in public method
    |
288 |                 )
289 | 
290 |     def forward(self, dist, angle):
    |         ^^^^^^^ D102
291 |         dist = dist / self.cutoff
292 |         rbf = torch.stack([f(dist) for f in self.bessel_funcs], dim=1)
    |

geom3d\models\ProNet\features.py:298:7: N801 Class name `d_theta_phi_emb` should use CapWords convention
    |
298 | class d_theta_phi_emb(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^ N801
299 |     def __init__(self, num_radial, num_spherical, cutoff=8.0):
300 |         super().__init__()
    |

geom3d\models\ProNet\features.py:298:7: D101 Missing docstring in public class
    |
298 | class d_theta_phi_emb(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^ D101
299 |     def __init__(self, num_radial, num_spherical, cutoff=8.0):
300 |         super().__init__()
    |

geom3d\models\ProNet\features.py:299:9: D107 Missing docstring in `__init__`
    |
298 | class d_theta_phi_emb(torch.nn.Module):
299 |     def __init__(self, num_radial, num_spherical, cutoff=8.0):
    |         ^^^^^^^^ D107
300 |         super().__init__()
301 |         assert num_radial <= 64
    |

geom3d\models\ProNet\features.py:301:9: S101 Use of `assert` detected
    |
299 |     def __init__(self, num_radial, num_spherical, cutoff=8.0):
300 |         super().__init__()
301 |         assert num_radial <= 64
    |         ^^^^^^ S101
302 |         self.num_radial = num_radial
303 |         self.num_spherical = num_spherical
    |

geom3d\models\ProNet\features.py:301:30: PLR2004 Magic value used in comparison, consider replacing `64` with a constant variable
    |
299 |     def __init__(self, num_radial, num_spherical, cutoff=8.0):
300 |         super().__init__()
301 |         assert num_radial <= 64
    |                              ^^ PLR2004
302 |         self.num_radial = num_radial
303 |         self.num_spherical = num_spherical
    |

geom3d\models\ProNet\features.py:307:9: N806 Variable `Y_lm` in function should be lowercase
    |
306 |         bessel_formulas = bessel_basis(num_spherical, num_radial)
307 |         Y_lm = real_sph_harm(
    |         ^^^^ N806
308 |             num_spherical, spherical_coordinates=True, zero_m_only=False
309 |         )
    |

geom3d\models\ProNet\features.py:317:13: E741 Ambiguous variable name: `l`
    |
315 |         phi = sym.symbols("phi")
316 |         modules = {"sin": torch.sin, "cos": torch.cos, "sqrt": torch.sqrt}
317 |         for l in range(len(Y_lm)):
    |             ^ E741
318 |             for m in range(len(Y_lm[l])):
319 |                 if (
    |

geom3d\models\ProNet\features.py:325:46: B023 Function definition does not bind loop variable `first_sph`
    |
323 |                     self.sph_funcs.append(
324 |                         lambda theta, phi: torch.zeros_like(theta)
325 |                                            + first_sph(theta, phi)
    |                                              ^^^^^^^^^ B023
326 |                     )
327 |                 else:
    |

geom3d\models\ProNet\features.py:340:9: D102 Missing docstring in public method
    |
338 |         )
339 | 
340 |     def forward(self, dist, theta, phi):
    |         ^^^^^^^ D102
341 |         dist = dist / self.cutoff
342 |         rbf = torch.stack([f(dist) for f in self.bessel_funcs], dim=1)
    |

geom3d\models\SE3_Transformer.py:1:1: N999 Invalid module name: 'SE3_Transformer'
geom3d\models\SE3_Transformer.py:1:1: D100 Missing docstring in public module
geom3d\models\SE3_Transformer.py:13:9: PLR0913 Too many arguments in function definition (8 > 5)
   |
11 |     """SE(3) equivariant GCN with attention."""
12 | 
13 |     def __init__(
   |         ^^^^^^^^ PLR0913
14 |         self,
15 |         num_layers,
   |

geom3d\models\SE3_Transformer.py:13:9: D107 Missing docstring in `__init__`
   |
11 |     """SE(3) equivariant GCN with attention."""
12 | 
13 |     def __init__(
   |         ^^^^^^^^ D107
14 |         self,
15 |         num_layers,
   |

geom3d\models\SE3_Transformer.py:65:9: D102 Missing docstring in public method
   |
63 |         self.layers = nn.ModuleList(layers)
64 | 
65 |     def forward(self, x, positions, edge_index, edge_feat=None):
   |         ^^^^^^^ D102
66 |         # Compute equivariant weight basis from relative positions
67 |         row, col = edge_index
   |

geom3d\models\SE3_Transformer_utils.py:1:1: N999 Invalid module name: 'SE3_Transformer_utils'
geom3d\models\SE3_Transformer_utils.py:1:1: D100 Missing docstring in public module
geom3d\models\SE3_Transformer_utils.py:3:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | import numpy as np
2 | import torch
3 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
4 | from torch import nn
5 | from torch_scatter import scatter_add
  |

geom3d\models\SE3_Transformer_utils.py:14:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
12 |     """Graph attention block with SE(3)-equivariance and skip connection."""
13 | 
14 |     def __init__(
   |         ^^^^^^^^ PLR0913
15 |         self,
16 |         f_in,
   |

geom3d\models\SE3_Transformer_utils.py:14:9: D107 Missing docstring in `__init__`
   |
12 |     """Graph attention block with SE(3)-equivariance and skip connection."""
13 | 
14 |     def __init__(
   |         ^^^^^^^^ D107
15 |         self,
16 |         f_in,
   |

geom3d\models\SE3_Transformer_utils.py:21:9: FBT002 Boolean default positional argument in function definition
   |
19 |         div=4,
20 |         n_heads=1,
21 |         learnable_skip=True,
   |         ^^^^^^^^^^^^^^ FBT002
22 |         skip="cat",
23 |         selfint="1x1",
   |

geom3d\models\SE3_Transformer_utils.py:74:17: S101 Use of `assert` detected
   |
72 |                 # more channels than the ouput (for at least one degree); this would
73 |                 # then cause a (hard to debug) error in the next layer
74 |                 assert (
   |                 ^^^^^^ S101
75 |                     self.add.f_out.structure_dict == f_out.structure_dict
76 |                 ), "skip connection would change output structure"
   |

geom3d\models\SE3_Transformer_utils.py:78:9: D102 Missing docstring in public method
   |
76 |                 ), "skip connection would change output structure"
77 | 
78 |     def forward(self, h, edge_index, **kwargs):
   |         ^^^^^^^ D102
79 |         # Embeddings
80 |         v = self.GMAB["v"](h, edge_index=edge_index, **kwargs)
   |

geom3d\models\SE3_Transformer_utils.py:78:38: ANN003 Missing type annotation for `**kwargs`
   |
76 |                 ), "skip connection would change output structure"
77 | 
78 |     def forward(self, h, edge_index, **kwargs):
   |                                      ^^^^^^^^ ANN003
79 |         # Embeddings
80 |         v = self.GMAB["v"](h, edge_index=edge_index, **kwargs)
   |

geom3d\models\SE3_Transformer_utils.py:100:9: D417 Missing argument descriptions in the docstring for `__init__`: `edge_dim`, `x_ij`
    |
 98 |     """Graph SE(3)-equivariant node -> edge layer."""
 99 | 
100 |     def __init__(self, f_in, f_out, edge_dim: int = 0, x_ij=None):
    |         ^^^^^^^^ D417
101 |         """SE(3)-equivariant partial convolution.
102 |         A partial convolution computes the inner product between a kernel and
    |

geom3d\models\SE3_Transformer_utils.py:101:9: D205 1 blank line required between summary line and description
    |
100 |       def __init__(self, f_in, f_out, edge_dim: int = 0, x_ij=None):
101 |           """SE(3)-equivariant partial convolution.
    |  _________^
102 | |         A partial convolution computes the inner product between a kernel and
103 | |         each input channel, without summing over the result from each input
104 | |         channel. This unfolded structure makes it amenable to be used for
105 | |         computing the value-embeddings of the attention mechanism.
106 | | 
107 | |         Args:
108 | |         ----
109 | |             f_in: list of tuples [(multiplicities, type),...]
110 | |             f_out: list of tuples [(multiplicities, type),...]
111 | | 
112 | |         """
    | |___________^ D205
113 |           super().__init__()
114 |           self.f_out = f_out
    |
    = help: Insert single blank line

geom3d\models\SE3_Transformer_utils.py:120:9: S101 Use of `assert` detected
    |
118 |         # 'cat' concatenates relative position & existing feature vector
119 |         # 'add' adds it, but only if multiplicity > 1
120 |         assert x_ij in [None, "cat", "add"]
    |         ^^^^^^ S101
121 |         self.x_ij = x_ij
122 |         if x_ij == "cat":
    |

geom3d\models\SE3_Transformer_utils.py:135:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
133 |                 )
134 | 
135 |     def forward(self, h, positions, r, basis, edge_index, edge_feat=None):
    |         ^^^^^^^ PLR0913
136 |         """Forward pass of the linear layer
137 |         Args:
    |

geom3d\models\SE3_Transformer_utils.py:136:9: D205 1 blank line required between summary line and description
    |
135 |       def forward(self, h, positions, r, basis, edge_index, edge_feat=None):
136 |           """Forward pass of the linear layer
    |  _________^
137 | |         Args:
138 | |             h: dict of node-features
139 | |             G: minibatch of (homo)graphs
140 | |             r: inter-atomic distances
141 | |             basis: pre-computed Q * Y
142 | |         Returns:
143 | |             tensor with new features [B, n_points, n_features_out].
144 | |         """
    | |___________^ D205
145 |           # Add node features to local graph scope
146 |           G = {}
    |
    = help: Insert single blank line

geom3d\models\SE3_Transformer_utils.py:146:9: N806 Variable `G` in function should be lowercase
    |
144 |         """
145 |         # Add node features to local graph scope
146 |         G = {}
    |         ^ N806
147 |         for k, v in h.items():
148 |             G[k] = v
    |

geom3d\models\SE3_Transformer_utils.py:148:13: PERF403 Use a dictionary comprehension instead of a for-loop
    |
146 |         G = {}
147 |         for k, v in h.items():
148 |             G[k] = v
    |             ^^^^^^^^ PERF403
149 | 
150 |         feat = torch.cat([edge_feat, r], -1) if edge_feat is not None else r
    |

geom3d\models\SE3_Transformer_utils.py:166:23: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
164 |                 # if type 1 and flag set, add relative position as feature
165 |                 if self.x_ij == "cat" and d_in == 1:
166 |                     # TODO: double-check
    |                       ^^^^ TD002
167 |                     # relative positions
168 |                     rel = (positions[row] - positions[col]).view(-1, 3, 1)
    |

geom3d\models\SE3_Transformer_utils.py:166:23: TD003 Missing issue link on the line following this TODO
    |
164 |                 # if type 1 and flag set, add relative position as feature
165 |                 if self.x_ij == "cat" and d_in == 1:
166 |                     # TODO: double-check
    |                       ^^^^ TD003
167 |                     # relative positions
168 |                     rel = (positions[row] - positions[col]).view(-1, 3, 1)
    |

geom3d\models\SE3_Transformer_utils.py:166:23: FIX002 Line contains TODO, consider resolving the issue
    |
164 |                 # if type 1 and flag set, add relative position as feature
165 |                 if self.x_ij == "cat" and d_in == 1:
166 |                     # TODO: double-check
    |                       ^^^^ FIX002
167 |                     # relative positions
168 |                     rel = (positions[row] - positions[col]).view(-1, 3, 1)
    |

geom3d\models\SE3_Transformer_utils.py:175:27: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
173 |                         src = rel
174 |                     else:
175 |                         # TODO: double-check
    |                           ^^^^ TD002
176 |                         h_ = G[f"{d_in}"]
177 |                         # features of src node, shape [edges, m_in*(2l+1), 1]
    |

geom3d\models\SE3_Transformer_utils.py:175:27: TD003 Missing issue link on the line following this TODO
    |
173 |                         src = rel
174 |                     else:
175 |                         # TODO: double-check
    |                           ^^^^ TD003
176 |                         h_ = G[f"{d_in}"]
177 |                         # features of src node, shape [edges, m_in*(2l+1), 1]
    |

geom3d\models\SE3_Transformer_utils.py:175:27: FIX002 Line contains TODO, consider resolving the issue
    |
173 |                         src = rel
174 |                     else:
175 |                         # TODO: double-check
    |                           ^^^^ FIX002
176 |                         h_ = G[f"{d_in}"]
177 |                         # features of src node, shape [edges, m_in*(2l+1), 1]
    |

geom3d\models\SE3_Transformer_utils.py:182:23: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
180 |                         src = torch.cat([src, rel], dim=1)
181 |                 elif self.x_ij == "add" and d_in == 1 and m_in > 1:
182 |                     # TODO: double-check
    |                       ^^^^ TD002
183 |                     h_ = G[f"{d_in}"]
184 |                     src = h_[row].view(-1, m_in * (2 * d_in + 1), 1)
    |

geom3d\models\SE3_Transformer_utils.py:182:23: TD003 Missing issue link on the line following this TODO
    |
180 |                         src = torch.cat([src, rel], dim=1)
181 |                 elif self.x_ij == "add" and d_in == 1 and m_in > 1:
182 |                     # TODO: double-check
    |                       ^^^^ TD003
183 |                     h_ = G[f"{d_in}"]
184 |                     src = h_[row].view(-1, m_in * (2 * d_in + 1), 1)
    |

geom3d\models\SE3_Transformer_utils.py:182:23: FIX002 Line contains TODO, consider resolving the issue
    |
180 |                         src = torch.cat([src, rel], dim=1)
181 |                 elif self.x_ij == "add" and d_in == 1 and m_in > 1:
182 |                     # TODO: double-check
    |                       ^^^^ FIX002
183 |                     h_ = G[f"{d_in}"]
184 |                     src = h_[row].view(-1, m_in * (2 * d_in + 1), 1)
    |

geom3d\models\SE3_Transformer_utils.py:199:9: D105 Missing docstring in magic method
    |
197 |         return result
198 | 
199 |     def __repr__(self):
    |         ^^^^^^^^ D105
200 |         return f"GConvSE3Partial(structure={self.f_out})"
    |

geom3d\models\SE3_Transformer_utils.py:204:5: D205 1 blank line required between summary line and description
    |
203 |   class G1x1SE3(nn.Module):
204 |       """Graph Linear SE(3)-equivariant layer, equivalent to a 1x1 convolution.
    |  _____^
205 | |     This is equivalent to a self-interaction layer in TensorField Networks.
206 | |     """
    | |_______^ D205
207 |   
208 |       def __init__(self, f_in, f_out, learnable=True):
    |
    = help: Insert single blank line

geom3d\models\SE3_Transformer_utils.py:208:9: D417 Missing argument description in the docstring for `__init__`: `learnable`
    |
206 |     """
207 | 
208 |     def __init__(self, f_in, f_out, learnable=True):
    |         ^^^^^^^^ D417
209 |         """SE(3)-equivariant 1x1 convolution.
    |

geom3d\models\SE3_Transformer_utils.py:208:37: FBT002 Boolean default positional argument in function definition
    |
206 |     """
207 | 
208 |     def __init__(self, f_in, f_out, learnable=True):
    |                                     ^^^^^^^^^ FBT002
209 |         """SE(3)-equivariant 1x1 convolution.
    |

geom3d\models\SE3_Transformer_utils.py:229:9: D102 Missing docstring in public method
    |
227 |             )
228 | 
229 |     def forward(self, features, **kwargs):
    |         ^^^^^^^ D102
230 |         output = {}
231 |         for k, v in features.items():
    |

geom3d\models\SE3_Transformer_utils.py:229:33: ANN003 Missing type annotation for `**kwargs`
    |
227 |             )
228 | 
229 |     def forward(self, features, **kwargs):
    |                                 ^^^^^^^^ ANN003
230 |         output = {}
231 |         for k, v in features.items():
    |

geom3d\models\SE3_Transformer_utils.py:229:35: ARG002 Unused method argument: `kwargs`
    |
227 |             )
228 | 
229 |     def forward(self, features, **kwargs):
    |                                   ^^^^^^ ARG002
230 |         output = {}
231 |         for k, v in features.items():
    |

geom3d\models\SE3_Transformer_utils.py:236:9: D105 Missing docstring in magic method
    |
234 |         return output
235 | 
236 |     def __repr__(self):
    |         ^^^^^^^^ D105
237 |         return f"G1x1SE3(structure={self.f_out})"
    |

geom3d\models\SE3_Transformer_utils.py:258:44: ANN003 Missing type annotation for `**kwargs`
    |
256 |         self.n_heads = n_heads
257 | 
258 |     def forward(self, v, k, q, edge_index, **kwargs):
    |                                            ^^^^^^^^ ANN003
259 |         """Forward pass of the linear layer
260 |         Args:
    |

geom3d\models\SE3_Transformer_utils.py:258:46: ARG002 Unused method argument: `kwargs`
    |
256 |         self.n_heads = n_heads
257 | 
258 |     def forward(self, v, k, q, edge_index, **kwargs):
    |                                              ^^^^^^ ARG002
259 |         """Forward pass of the linear layer
260 |         Args:
    |

geom3d\models\SE3_Transformer_utils.py:259:9: D205 1 blank line required between summary line and description
    |
258 |       def forward(self, v, k, q, edge_index, **kwargs):
259 |           """Forward pass of the linear layer
    |  _________^
260 | |         Args:
261 | |             G: minibatch of (homo)graphs
262 | |             v: dict of value edge-features
263 | |             k: dict of key edge-features
264 | |             q: dict of query node-features
265 | |         Returns:
266 | |             tensor with new features [B, n_points, n_features_out].
267 | |         """
    | |___________^ D205
268 |           # Add node features to local graph scope
269 |           ## We use the stacked tensor representation for attention
    |
    = help: Insert single blank line

geom3d\models\SE3_Transformer_utils.py:270:9: N806 Variable `G` in function should be lowercase
    |
268 |         # Add node features to local graph scope
269 |         ## We use the stacked tensor representation for attention
270 |         G = {}
    |         ^ N806
271 |         for m, d in self.f_value.structure:
272 |             G[f"v{d}"] = v[f"{d}"].view(-1, self.n_heads, m // self.n_heads, 2 * d + 1)
    |

geom3d\models\SE3_Transformer_utils.py:279:9: N806 Variable `N` in function should be lowercase
    |
277 |             q, self.n_heads, self.f_key, squeeze=True
278 |         )  # [nodes, heads, channels](?)
279 |         N = G["q"].size()[0]
    |         ^ N806
280 | 
281 |         # Compute attention weights
    |

geom3d\models\SE3_Transformer_utils.py:286:11: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
284 |         e = (G["k"] * G["q"][col]).sum(2)
285 | 
286 |         # TODO: need double-check
    |           ^^^^ TD002
287 |         e = e / np.sqrt(self.f_key.n_features)
288 |         e = e.exp()
    |

geom3d\models\SE3_Transformer_utils.py:286:11: TD003 Missing issue link on the line following this TODO
    |
284 |         e = (G["k"] * G["q"][col]).sum(2)
285 | 
286 |         # TODO: need double-check
    |           ^^^^ TD003
287 |         e = e / np.sqrt(self.f_key.n_features)
288 |         e = e.exp()
    |

geom3d\models\SE3_Transformer_utils.py:286:11: FIX002 Line contains TODO, consider resolving the issue
    |
284 |         e = (G["k"] * G["q"][col]).sum(2)
285 | 
286 |         # TODO: need double-check
    |           ^^^^ FIX002
287 |         e = e / np.sqrt(self.f_key.n_features)
288 |         e = e.exp()
    |

geom3d\models\SE3_Transformer_utils.py:299:15: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
297 |             msg = attn * value
298 | 
299 |             # TODO: row or col?
    |               ^^^^ TD002
300 |             G[f"out{d_out}"] = scatter_add(msg, col, dim=0, dim_size=N)
    |

geom3d\models\SE3_Transformer_utils.py:299:15: TD003 Missing issue link on the line following this TODO
    |
297 |             msg = attn * value
298 | 
299 |             # TODO: row or col?
    |               ^^^^ TD003
300 |             G[f"out{d_out}"] = scatter_add(msg, col, dim=0, dim_size=N)
    |

geom3d\models\SE3_Transformer_utils.py:299:15: FIX002 Line contains TODO, consider resolving the issue
    |
297 |             msg = attn * value
298 | 
299 |             # TODO: row or col?
    |               ^^^^ FIX002
300 |             G[f"out{d_out}"] = scatter_add(msg, col, dim=0, dim_size=N)
    |

geom3d\models\SE3_Transformer_utils.py:308:9: D105 Missing docstring in magic method
    |
306 |         return result
307 | 
308 |     def __repr__(self):
    |         ^^^^^^^^ D105
309 |         return f"GMABSE3(n_heads={self.n_heads}, structure={self.f_value})"
    |

geom3d\models\SE3_Transformer_utils.py:312:7: D101 Missing docstring in public class
    |
312 | class GAttentiveSelfInt(nn.Module):
    |       ^^^^^^^^^^^^^^^^^ D101
313 |     def __init__(self, f_in, f_out):
314 |         """SE(3)-equivariant 1x1 convolution.
    |

geom3d\models\SE3_Transformer_utils.py:335:9: ANN202 Missing return type annotation for private function `_build_net`
    |
333 |             self.transform[str(o)] = self._build_net(m_in, m_out)
334 | 
335 |     def _build_net(self, m_in: int, m_out):
    |         ^^^^^^^^^^ ANN202
336 |         n_hidden = m_in * m_out
337 |         cur_inpt = m_in * m_in
    |
    = help: Add return type annotation

geom3d\models\SE3_Transformer_utils.py:342:15: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
340 |             net.append(nn.LayerNorm(int(cur_inpt)))
341 |             net.append(self.nonlin)
342 |             # TODO: implement cleaner init
    |               ^^^^ TD002
343 |             net.append(nn.Linear(cur_inpt, n_hidden, bias=(i == self.num_layers - 1)))
344 |             nn.init.kaiming_uniform_(net[-1].weight)
    |

geom3d\models\SE3_Transformer_utils.py:342:15: TD003 Missing issue link on the line following this TODO
    |
340 |             net.append(nn.LayerNorm(int(cur_inpt)))
341 |             net.append(self.nonlin)
342 |             # TODO: implement cleaner init
    |               ^^^^ TD003
343 |             net.append(nn.Linear(cur_inpt, n_hidden, bias=(i == self.num_layers - 1)))
344 |             nn.init.kaiming_uniform_(net[-1].weight)
    |

geom3d\models\SE3_Transformer_utils.py:342:15: FIX002 Line contains TODO, consider resolving the issue
    |
340 |             net.append(nn.LayerNorm(int(cur_inpt)))
341 |             net.append(self.nonlin)
342 |             # TODO: implement cleaner init
    |               ^^^^ FIX002
343 |             net.append(nn.Linear(cur_inpt, n_hidden, bias=(i == self.num_layers - 1)))
344 |             nn.init.kaiming_uniform_(net[-1].weight)
    |

geom3d\models\SE3_Transformer_utils.py:348:9: D102 Missing docstring in public method
    |
346 |         return nn.Sequential(*net)
347 | 
348 |     def forward(self, features, **kwargs):
    |         ^^^^^^^ D102
349 |         output = {}
350 |         for k, v in features.items():
    |

geom3d\models\SE3_Transformer_utils.py:348:33: ANN003 Missing type annotation for `**kwargs`
    |
346 |         return nn.Sequential(*net)
347 | 
348 |     def forward(self, features, **kwargs):
    |                                 ^^^^^^^^ ANN003
349 |         output = {}
350 |         for k, v in features.items():
    |

geom3d\models\SE3_Transformer_utils.py:348:35: ARG002 Unused method argument: `kwargs`
    |
346 |         return nn.Sequential(*net)
347 | 
348 |     def forward(self, features, **kwargs):
    |                                   ^^^^^^ ARG002
349 |         output = {}
350 |         for k, v in features.items():
    |

geom3d\models\SE3_Transformer_utils.py:355:13: S101 Use of `assert` detected
    |
353 |             m_in = self.f_in.structure_dict[int(k)]
354 |             m_out = self.f_out.structure_dict[int(k)]
355 |             assert v.shape[-2] == m_in
    |             ^^^^^^ S101
356 |             assert v.shape[-1] == 2 * int(k) + 1
    |

geom3d\models\SE3_Transformer_utils.py:356:13: S101 Use of `assert` detected
    |
354 |             m_out = self.f_out.structure_dict[int(k)]
355 |             assert v.shape[-2] == m_in
356 |             assert v.shape[-1] == 2 * int(k) + 1
    |             ^^^^^^ S101
357 | 
358 |             # Compute the norms and normalized features
    |

geom3d\models\SE3_Transformer_utils.py:359:13: ERA001 Found commented-out code
    |
358 |             # Compute the norms and normalized features
359 |             # norm = v.norm(p=2, dim=-1, keepdim=True).clamp_min(self.eps).expand_as(v)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
360 |             # phase = v / norm # [..., m, 2*k+1]
361 |             scalars = torch.einsum("...ac,...bc->...ab", [v, v])  # [..., m_in, m_in]
    |
    = help: Remove commented-out code

geom3d\models\SE3_Transformer_utils.py:360:13: ERA001 Found commented-out code
    |
358 |             # Compute the norms and normalized features
359 |             # norm = v.norm(p=2, dim=-1, keepdim=True).clamp_min(self.eps).expand_as(v)
360 |             # phase = v / norm # [..., m, 2*k+1]
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
361 |             scalars = torch.einsum("...ac,...bc->...ab", [v, v])  # [..., m_in, m_in]
362 |             scalars = scalars.view(*first_dims, m_in * m_in)  # [..., m_in*m_in]
    |
    = help: Remove commented-out code

geom3d\models\SE3_Transformer_utils.py:373:13: ERA001 Found commented-out code
    |
371 |             )  # [..., m_out, m_in]
372 |             att_weights = F.softmax(input=att_weights, dim=-1)
373 |             # shape [..., m_out, 2*k+1]
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
374 |             # output[k] = torch.einsum('...nm,...md->...nd', [att_weights, phase])
375 |             output[k] = torch.einsum("...nm,...md->...nd", [att_weights, v])
    |
    = help: Remove commented-out code

geom3d\models\SE3_Transformer_utils.py:374:13: ERA001 Found commented-out code
    |
372 |             att_weights = F.softmax(input=att_weights, dim=-1)
373 |             # shape [..., m_out, 2*k+1]
374 |             # output[k] = torch.einsum('...nm,...md->...nd', [att_weights, phase])
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
375 |             output[k] = torch.einsum("...nm,...md->...nd", [att_weights, v])
    |
    = help: Remove commented-out code

geom3d\models\SE3_Transformer_utils.py:379:9: D105 Missing docstring in magic method
    |
377 |         return output
378 | 
379 |     def __repr__(self):
    |         ^^^^^^^^ D105
380 |         return f"AttentiveSelfInteractionSE3(in={self.f_in}, out={self.f_out})"
    |

geom3d\models\SE3_Transformer_utils.py:400:9: D105 Missing docstring in magic method
    |
398 |         self.f_out = Fiber.combine_max(f_x, f_y)
399 | 
400 |     def __repr__(self):
    |         ^^^^^^^^ D105
401 |         return f"GSum(structure={self.f_out})"
    |

geom3d\models\SE3_Transformer_utils.py:403:9: D102 Missing docstring in public method
    |
401 |         return f"GSum(structure={self.f_out})"
402 | 
403 |     def forward(self, x, y):
    |         ^^^^^^^ D102
404 |         out = {}
405 |         for k in self.f_out.degrees:
    |

geom3d\models\SE3_Transformer_utils.py:406:13: PLW2901 `for` loop variable `k` overwritten by assignment target
    |
404 |         out = {}
405 |         for k in self.f_out.degrees:
406 |             k = str(k)
    |             ^ PLW2901
407 |             if (k in x) and (k in y):
408 |                 if x[k].shape[1] > y[k].shape[1]:
    |

geom3d\models\SE3_Transformer_utils.py:432:9: D107 Missing docstring in `__init__`
    |
430 |     """Concat only degrees which are in f_x."""
431 | 
432 |     def __init__(self, f_x: Fiber, f_y: Fiber):
    |         ^^^^^^^^ D107
433 |         super().__init__()
434 |         self.f_x = f_x
    |

geom3d\models\SE3_Transformer_utils.py:443:9: D102 Missing docstring in public method
    |
441 |         self.f_out = Fiber(dictionary=f_out)
442 | 
443 |     def forward(self, x, y):
    |         ^^^^^^^ D102
444 |         out = {}
445 |         for k in self.f_out.degrees:
    |

geom3d\models\SE3_Transformer_utils.py:446:13: PLW2901 `for` loop variable `k` overwritten by assignment target
    |
444 |         out = {}
445 |         for k in self.f_out.degrees:
446 |             k = str(k)
    |             ^ PLW2901
447 |             if k in y:
448 |                 out[k] = torch.cat([x[k], y[k]], 1)
    |

geom3d\models\SE3_Transformer_utils.py:453:9: D105 Missing docstring in magic method
    |
451 |         return out
452 | 
453 |     def __repr__(self):
    |         ^^^^^^^^ D105
454 |         return f"GCat(structure={self.f_out})"
    |

geom3d\models\SEGNN\SEGNN.py:1:1: N999 Invalid module name: 'SEGNN'
geom3d\models\SEGNN\SEGNN.py:1:1: D100 Missing docstring in public module
geom3d\models\SEGNN\SEGNN.py:3:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | import numpy as np
2 | import torch
3 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
4 | from e3nn.nn import BatchNorm
5 | from e3nn.o3 import Irreps, spherical_harmonics
  |

geom3d\models\SEGNN\SEGNN.py:20:7: D101 Missing docstring in public class
   |
20 | class SEGNNModel(nn.Module):
   |       ^^^^^^^^^^ D101
21 |     def __init__(self, input_features, output_features, hidden_features, N, norm, lmax_h, lmax_pos=None, pool="avg", edge_inference=False):
22 |         super().__init__()
   |

geom3d\models\SEGNN\SEGNN.py:21:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
20 | class SEGNNModel(nn.Module):
21 |     def __init__(self, input_features, output_features, hidden_features, N, norm, lmax_h, lmax_pos=None, pool="avg", edge_inference=False):
   |         ^^^^^^^^ PLR0913
22 |         super().__init__()
23 |         self.num_classes = input_features
   |

geom3d\models\SEGNN\SEGNN.py:21:9: D107 Missing docstring in `__init__`
   |
20 | class SEGNNModel(nn.Module):
21 |     def __init__(self, input_features, output_features, hidden_features, N, norm, lmax_h, lmax_pos=None, pool="avg", edge_inference=False):
   |         ^^^^^^^^ D107
22 |         super().__init__()
23 |         self.num_classes = input_features
   |

geom3d\models\SEGNN\SEGNN.py:21:74: N803 Argument name `N` should be lowercase
   |
20 | class SEGNNModel(nn.Module):
21 |     def __init__(self, input_features, output_features, hidden_features, N, norm, lmax_h, lmax_pos=None, pool="avg", edge_inference=False):
   |                                                                          ^ N803
22 |         super().__init__()
23 |         self.num_classes = input_features
   |

geom3d\models\SEGNN\SEGNN.py:21:118: FBT002 Boolean default positional argument in function definition
   |
20 | class SEGNNModel(nn.Module):
21 |     def __init__(self, input_features, output_features, hidden_features, N, norm, lmax_h, lmax_pos=None, pool="avg", edge_inference=False):
   |                                                                                                                      ^^^^^^^^^^^^^^ FBT002
22 |         super().__init__()
23 |         self.num_classes = input_features
   |

geom3d\models\SEGNN\SEGNN.py:40:53: FBT003 Boolean positional value in function call
   |
38 |         # Irreps for the hidden activations (s.t. the nr of weights in the TP approx that of a standard linear layer)
39 |         node_hidden_irreps = WeightBalancedIrreps(
40 |             node_hidden_irreps_scalar, attr_irreps, True, lmax=lmax_h)  # True: copies of sh
   |                                                     ^^^^ FBT003
41 |         self.node_hidden_irreps = node_hidden_irreps
42 |         # Network for computing the node attributes
   |

geom3d\models\SEGNN\SEGNN.py:75:9: D102 Missing docstring in public method
   |
73 |                                                       node_out_irreps_scalar)
74 | 
75 |     def forward(self, *argv):
   |         ^^^^^^^ D102
76 |         if len(argv) == 4:
77 |             x, pos, edge_index, batch = argv[0], argv[1], argv[2], argv[3]
   |

geom3d\models\SEGNN\SEGNN.py:75:23: ANN002 Missing type annotation for `*argv`
   |
73 |                                                       node_out_irreps_scalar)
74 | 
75 |     def forward(self, *argv):
   |                       ^^^^^ ANN002
76 |         if len(argv) == 4:
77 |             x, pos, edge_index, batch = argv[0], argv[1], argv[2], argv[3]
   |

geom3d\models\SEGNN\SEGNN.py:76:25: PLR2004 Magic value used in comparison, consider replacing `4` with a constant variable
   |
75 |     def forward(self, *argv):
76 |         if len(argv) == 4:
   |                         ^ PLR2004
77 |             x, pos, edge_index, batch = argv[0], argv[1], argv[2], argv[3]
78 |             graph = Data(x=x, pos=pos, radius_edge_index=edge_index, batch=batch)
   |

geom3d\models\SEGNN\SEGNN.py:97:9: S101 Use of `assert` detected
   |
95 |         edge_index_max = edge_index.max().item()
96 |         num_nodes = graph.num_nodes
97 |         assert num_nodes == x.size()[0]
   |         ^^^^^^ S101
98 |         if (graph.has_isolated_nodes() and edge_index_max + 1 != num_nodes):
99 |             nr_add_attr = num_nodes - (edge_index_max + 1)
   |

geom3d\models\SEGNN\SEGNN.py:126:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
124 |         return self.head_post_pool_layer_2(x)
125 | 
126 |     def forward_with_gathered_index(self, x, pos, edge_index, batch, periodic_index_mapping, graph):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
127 | 
128 |         if x.dim() > 1:
    |

geom3d\models\SEGNN\SEGNN.py:126:9: D102 Missing docstring in public method
    |
124 |         return self.head_post_pool_layer_2(x)
125 | 
126 |     def forward_with_gathered_index(self, x, pos, edge_index, batch, periodic_index_mapping, graph):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
127 | 
128 |         if x.dim() > 1:
    |

geom3d\models\SEGNN\SEGNN.py:178:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
176 |     """E(3) equivariant message passing layer."""
177 | 
178 |     def __init__(self, node_in_irreps, node_hidden_irreps, node_out_irreps, attr_irreps, norm, edge_inference):
    |         ^^^^^^^^ PLR0913
179 |         super().__init__(node_dim=-2, aggr="add")
    |

geom3d\models\SEGNN\SEGNN.py:178:9: D107 Missing docstring in `__init__`
    |
176 |     """E(3) equivariant message passing layer."""
177 | 
178 |     def __init__(self, node_in_irreps, node_hidden_irreps, node_out_irreps, attr_irreps, norm, edge_inference):
    |         ^^^^^^^^ D107
179 |         super().__init__(node_dim=-2, aggr="add")
    |

geom3d\models\SEGNN\SEGNN.py:214:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
212 |             self.inference_layer = O3TensorProduct(node_hidden_irreps, Irreps("1x0e"), attr_irreps)
213 | 
214 |     def forward(self, x, pos, edge_index, edge_dist, edge_attr, node_attr, batch):
    |         ^^^^^^^ PLR0913
215 |         """Propagate messages along edges."""
216 |         x, pos = self.propagate(edge_index, x=x, pos=pos, edge_dist=edge_dist,
    |

geom3d\models\SEGNN\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\SEGNN\__init__.py:1:20: F401 `.SEGNN.SEGNNModel` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .SEGNN import SEGNNModel
  |                    ^^^^^^^^^^ F401
  |
  = help: Use an explicit re-export: `SEGNNModel as SEGNNModel`

geom3d\models\SEGNN\balanced_irreps.py:1:1: D100 Missing docstring in public module
geom3d\models\SEGNN\balanced_irreps.py:4:5: N802 Function name `BalancedIrreps` should be lowercase
  |
4 | def BalancedIrreps(lmax, vec_dim, sh_type=True):
  |     ^^^^^^^^^^^^^^ N802
5 |     """Allocates irreps equally along channel budget, resulting
6 |         in unequal numbers of irreps in ratios of 2l_i + 1 to 2l_j + 1.
  |

geom3d\models\SEGNN\balanced_irreps.py:4:35: FBT002 Boolean default positional argument in function definition
  |
4 | def BalancedIrreps(lmax, vec_dim, sh_type=True):
  |                                   ^^^^^^^ FBT002
5 |     """Allocates irreps equally along channel budget, resulting
6 |         in unequal numbers of irreps in ratios of 2l_i + 1 to 2l_j + 1.
  |

geom3d\models\SEGNN\balanced_irreps.py:5:5: D205 1 blank line required between summary line and description
   |
 4 |   def BalancedIrreps(lmax, vec_dim, sh_type=True):
 5 |       """Allocates irreps equally along channel budget, resulting
   |  _____^
 6 | |         in unequal numbers of irreps in ratios of 2l_i + 1 to 2l_j + 1.
 7 | | 
 8 | |     Parameters
 9 | |     ----------
10 | |     lmax : int
11 | |         Maximum order of irreps.
12 | |     vec_dim : int
13 | |         Dim of feature vector.
14 | |     sh_type : bool
15 | |         if true, use spherical harmonics. Else the full set of irreps (with redundance).
16 | | 
17 | |     Returns
18 | |     -------
19 | |     Irreps
20 | |         Resulting irreps for feature vectors.
21 | | 
22 | |     """
   | |_______^ D205
23 |       irrep_spec = "0e"
24 |       for l in range(1, lmax + 1):
   |
   = help: Insert single blank line

geom3d\models\SEGNN\balanced_irreps.py:24:9: E741 Ambiguous variable name: `l`
   |
22 |     """
23 |     irrep_spec = "0e"
24 |     for l in range(1, lmax + 1):
   |         ^ E741
25 |         if sh_type:
26 |             irrep_spec += f" + {l}" + ("e" if (l % 2) == 0 else "o")
   |

geom3d\models\SEGNN\balanced_irreps.py:50:5: N802 Function name `WeightBalancedIrreps` should be lowercase
   |
50 | def WeightBalancedIrreps(irreps_in1_scalar, irreps_in2, sh=True, lmax=None):
   |     ^^^^^^^^^^^^^^^^^^^^ N802
51 |     """Determines an irreps_in1 type of order irreps_in2.lmax that when used in a tensor product
52 |     irreps_in1 x irreps_in2 -> irreps_in1
   |

geom3d\models\SEGNN\balanced_irreps.py:50:57: FBT002 Boolean default positional argument in function definition
   |
50 | def WeightBalancedIrreps(irreps_in1_scalar, irreps_in2, sh=True, lmax=None):
   |                                                         ^^ FBT002
51 |     """Determines an irreps_in1 type of order irreps_in2.lmax that when used in a tensor product
52 |     irreps_in1 x irreps_in2 -> irreps_in1
   |

geom3d\models\SEGNN\balanced_irreps.py:51:5: D205 1 blank line required between summary line and description
   |
50 |   def WeightBalancedIrreps(irreps_in1_scalar, irreps_in2, sh=True, lmax=None):
51 |       """Determines an irreps_in1 type of order irreps_in2.lmax that when used in a tensor product
   |  _____^
52 | |     irreps_in1 x irreps_in2 -> irreps_in1
53 | |     would have the same number of weights as for a standard linear layer, e.g. a tensor product
54 | |     irreps_in1_scalar x "1x0e" -> irreps_in1_scalar.
55 | | 
56 | |     Parameters
57 | |     ----------
58 | |     irreps_in1_scalar : o3.Irreps
59 | |         Number of hidden features, represented by zeroth order irreps.
60 | |     irreps_in2 : o3.Irreps
61 | |         Irreps related to edge attributes.
62 | |     sh : bool
63 | |         if true, yields equal number of every order. Else returns balanced irrep.
64 | |     lmax : int
65 | |         Maximum order irreps to be considered.
66 | | 
67 | |     Returns
68 | |     -------
69 | |     o3.Irreps
70 | |         Irreps for hidden feaure vectors. 
71 | | 
72 | |     """
   | |_______^ D205
73 |       n = 1
74 |       if lmax is None:
   |
   = help: Insert single blank line

geom3d\models\SEGNN\balanced_irreps.py:51:5: D401 First line of docstring should be in imperative mood: "Determines an irreps_in1 type of order irreps_in2.lmax that when used in a tensor product"
   |
50 |   def WeightBalancedIrreps(irreps_in1_scalar, irreps_in2, sh=True, lmax=None):
51 |       """Determines an irreps_in1 type of order irreps_in2.lmax that when used in a tensor product
   |  _____^
52 | |     irreps_in1 x irreps_in2 -> irreps_in1
53 | |     would have the same number of weights as for a standard linear layer, e.g. a tensor product
54 | |     irreps_in1_scalar x "1x0e" -> irreps_in1_scalar.
55 | | 
56 | |     Parameters
57 | |     ----------
58 | |     irreps_in1_scalar : o3.Irreps
59 | |         Number of hidden features, represented by zeroth order irreps.
60 | |     irreps_in2 : o3.Irreps
61 | |         Irreps related to edge attributes.
62 | |     sh : bool
63 | |         if true, yields equal number of every order. Else returns balanced irrep.
64 | |     lmax : int
65 | |         Maximum order irreps to be considered.
66 | | 
67 | |     Returns
68 | |     -------
69 | |     o3.Irreps
70 | |         Irreps for hidden feaure vectors. 
71 | | 
72 | |     """
   | |_______^ D401
73 |       n = 1
74 |       if lmax is None:
   |

geom3d\models\SEGNN\balanced_irreps.py:79:51: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
77 |     weight_numel1 = FullyConnectedTensorProduct(irreps_in1, irreps_in2, irreps_in1).weight_numel
78 |     weight_numel_scalar = FullyConnectedTensorProduct(irreps_in1_scalar, Irreps("1x0e"), irreps_in1_scalar).weight_numel
79 |     while weight_numel1 < weight_numel_scalar:  # TODO: somewhat suboptimal implementation...
   |                                                   ^^^^ TD002
80 |         n += 1
81 |         irreps_in1 = (Irreps.spherical_harmonics(lmax) * n).sort().irreps.simplify() if sh else BalancedIrreps(lmax, n)
   |

geom3d\models\SEGNN\balanced_irreps.py:79:51: TD003 Missing issue link on the line following this TODO
   |
77 |     weight_numel1 = FullyConnectedTensorProduct(irreps_in1, irreps_in2, irreps_in1).weight_numel
78 |     weight_numel_scalar = FullyConnectedTensorProduct(irreps_in1_scalar, Irreps("1x0e"), irreps_in1_scalar).weight_numel
79 |     while weight_numel1 < weight_numel_scalar:  # TODO: somewhat suboptimal implementation...
   |                                                   ^^^^ TD003
80 |         n += 1
81 |         irreps_in1 = (Irreps.spherical_harmonics(lmax) * n).sort().irreps.simplify() if sh else BalancedIrreps(lmax, n)
   |

geom3d\models\SEGNN\balanced_irreps.py:79:51: FIX002 Line contains TODO, consider resolving the issue
   |
77 |     weight_numel1 = FullyConnectedTensorProduct(irreps_in1, irreps_in2, irreps_in1).weight_numel
78 |     weight_numel_scalar = FullyConnectedTensorProduct(irreps_in1_scalar, Irreps("1x0e"), irreps_in1_scalar).weight_numel
79 |     while weight_numel1 < weight_numel_scalar:  # TODO: somewhat suboptimal implementation...
   |                                                   ^^^^ FIX002
80 |         n += 1
81 |         irreps_in1 = (Irreps.spherical_harmonics(lmax) * n).sort().irreps.simplify() if sh else BalancedIrreps(lmax, n)
   |

geom3d\models\SEGNN\instance_norm.py:1:1: D100 Missing docstring in public module
geom3d\models\SEGNN\instance_norm.py:8:5: D205 1 blank line required between summary line and description
   |
 7 |   class InstanceNorm(nn.Module):
 8 |       """Instance normalization for orthonormal representations
   |  _____^
 9 | |     It normalizes by the norm of the representations.
10 | |     Note that the norm is invariant only for orthonormal representations.
11 | |     Irreducible representations `wigner_D` are orthonormal.
12 | | 
13 | |     Parameters
14 | |     ----------
15 | |     irreps : `Irreps`
16 | |         representation
17 | |     eps : float
18 | |         avoid division by zero when we normalize by the variance
19 | |     affine : bool
20 | |         do we have weight and bias parameters
21 | |     reduce : {'mean', 'max'}
22 | |         method used to reduce
23 | | 
24 | |     """
   | |_______^ D205
25 |   
26 |       def __init__(self, irreps, eps=1e-5, affine=True, reduce="mean", normalization="component"):
   |
   = help: Insert single blank line

geom3d\models\SEGNN\instance_norm.py:26:9: D107 Missing docstring in `__init__`
   |
24 |     """
25 | 
26 |     def __init__(self, irreps, eps=1e-5, affine=True, reduce="mean", normalization="component"):
   |         ^^^^^^^^ D107
27 |         super().__init__()
   |

geom3d\models\SEGNN\instance_norm.py:26:42: FBT002 Boolean default positional argument in function definition
   |
24 |     """
25 | 
26 |     def __init__(self, irreps, eps=1e-5, affine=True, reduce="mean", normalization="component"):
   |                                          ^^^^^^ FBT002
27 |         super().__init__()
   |

geom3d\models\SEGNN\instance_norm.py:43:9: S101 Use of `assert` detected
   |
41 |             self.register_parameter("bias", None)
42 | 
43 |         assert isinstance(reduce, str), "reduce should be passed as a string value"
   |         ^^^^^^ S101
44 |         assert reduce in ["mean", "max"], "reduce needs to be 'mean' or 'max'"
45 |         self.reduce = reduce
   |

geom3d\models\SEGNN\instance_norm.py:44:9: S101 Use of `assert` detected
   |
43 |         assert isinstance(reduce, str), "reduce should be passed as a string value"
44 |         assert reduce in ["mean", "max"], "reduce needs to be 'mean' or 'max'"
   |         ^^^^^^ S101
45 |         self.reduce = reduce
   |

geom3d\models\SEGNN\instance_norm.py:47:9: S101 Use of `assert` detected
   |
45 |         self.reduce = reduce
46 | 
47 |         assert normalization in ["norm", "component"], "normalization needs to be 'norm' or 'component'"
   |         ^^^^^^ S101
48 |         self.normalization = normalization
   |

geom3d\models\SEGNN\instance_norm.py:50:9: D105 Missing docstring in magic method
   |
48 |         self.normalization = normalization
49 | 
50 |     def __repr__(self):
   |         ^^^^^^^^ D105
51 |         return f"{self.__class__.__name__} ({self.irreps}, eps={self.eps})"
   |

geom3d\models\SEGNN\instance_norm.py:53:9: D417 Missing argument description in the docstring for `forward`: `batch`
   |
51 |         return f"{self.__class__.__name__} ({self.irreps}, eps={self.eps})"
52 | 
53 |     def forward(self, input, batch):
   |         ^^^^^^^ D417
54 |         """evaluate.
   |

geom3d\models\SEGNN\instance_norm.py:53:23: A002 Argument `input` is shadowing a Python builtin
   |
51 |         return f"{self.__class__.__name__} ({self.irreps}, eps={self.eps})"
52 | 
53 |     def forward(self, input, batch):
   |                       ^^^^^ A002
54 |         """evaluate.
   |

geom3d\models\SEGNN\instance_norm.py:67:9: ERA001 Found commented-out code
   |
66 |         """
67 |         # batch, *size, dim = input.shape  # TODO: deal with batch
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
68 |         # input = input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
69 |         # input has shape [batch * nodes, dim], but with variable nr of nodes.
   |
   = help: Remove commented-out code

geom3d\models\SEGNN\instance_norm.py:67:46: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
66 |         """
67 |         # batch, *size, dim = input.shape  # TODO: deal with batch
   |                                              ^^^^ TD002
68 |         # input = input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
69 |         # input has shape [batch * nodes, dim], but with variable nr of nodes.
   |

geom3d\models\SEGNN\instance_norm.py:67:46: TD003 Missing issue link on the line following this TODO
   |
66 |         """
67 |         # batch, *size, dim = input.shape  # TODO: deal with batch
   |                                              ^^^^ TD003
68 |         # input = input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
69 |         # input has shape [batch * nodes, dim], but with variable nr of nodes.
   |

geom3d\models\SEGNN\instance_norm.py:67:46: FIX002 Line contains TODO, consider resolving the issue
   |
66 |         """
67 |         # batch, *size, dim = input.shape  # TODO: deal with batch
   |                                              ^^^^ FIX002
68 |         # input = input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
69 |         # input has shape [batch * nodes, dim], but with variable nr of nodes.
   |

geom3d\models\SEGNN\instance_norm.py:68:9: ERA001 Found commented-out code
   |
66 |         """
67 |         # batch, *size, dim = input.shape  # TODO: deal with batch
68 |         # input = input.reshape(batch, -1, dim)  # [batch, sample, stacked features]
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
69 |         # input has shape [batch * nodes, dim], but with variable nr of nodes.
70 |         # the input batch slices this into separate graphs
   |
   = help: Remove commented-out code

geom3d\models\SEGNN\instance_norm.py:83:13: ERA001 Found commented-out code
   |
81 |             ix += mul * d
82 | 
83 |             # [batch * sample, mul, repr]
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
84 |             field = field.reshape(-1, mul, d)
   |
   = help: Remove commented-out code

geom3d\models\SEGNN\node_attribute_network.py:1:1: D100 Missing docstring in public module
geom3d\models\SEGNN\node_attribute_network.py:7:9: D107 Missing docstring in `__init__`
  |
5 |     """Computes the node and edge attributes based on relative positions."""
6 | 
7 |     def __init__(self):
  |         ^^^^^^^^ D107
8 |         super().__init__(node_dim=-2, aggr="mean")  # <---- Mean of all edge features
  |

geom3d\models\SEGNN\node_attribute_network.py:12:67: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
10 |     def forward(self, edge_index, edge_attr):
11 |         """Simply sums the edge attributes."""
12 |         return self.propagate(edge_index, edge_attr=edge_attr)  # TODO: continue here!
   |                                                                   ^^^^ TD002
13 | 
14 |     def message(self, edge_attr):
   |

geom3d\models\SEGNN\node_attribute_network.py:12:67: TD003 Missing issue link on the line following this TODO
   |
10 |     def forward(self, edge_index, edge_attr):
11 |         """Simply sums the edge attributes."""
12 |         return self.propagate(edge_index, edge_attr=edge_attr)  # TODO: continue here!
   |                                                                   ^^^^ TD003
13 | 
14 |     def message(self, edge_attr):
   |

geom3d\models\SEGNN\node_attribute_network.py:12:67: FIX002 Line contains TODO, consider resolving the issue
   |
10 |     def forward(self, edge_index, edge_attr):
11 |         """Simply sums the edge attributes."""
12 |         return self.propagate(edge_index, edge_attr=edge_attr)  # TODO: continue here!
   |                                                                   ^^^^ FIX002
13 | 
14 |     def message(self, edge_attr):
   |

geom3d\models\SEGNN\node_attribute_network.py:15:9: D401 First line of docstring should be in imperative mood: "The message is the edge attribute."
   |
14 |     def message(self, edge_attr):
15 |         """The message is the edge attribute."""
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
16 |         return edge_attr
   |

geom3d\models\SEGNN\node_attribute_network.py:19:9: D401 First line of docstring should be in imperative mood: "The input to update is the aggregated messages, and thus the node attribute."
   |
18 |     def update(self, node_attr):
19 |         """The input to update is the aggregated messages, and thus the node attribute."""
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
20 |         return node_attr
   |

geom3d\models\SEGNN\o3_building_blocks.py:1:1: D100 Missing docstring in public module
geom3d\models\SEGNN\o3_building_blocks.py:10:7: D101 Missing docstring in public class
   |
10 | class O3TensorProduct(torch.nn.Module):
   |       ^^^^^^^^^^^^^^^ D101
11 |     def __init__(self, irreps_in1, irreps_out, irreps_in2=None, tp_rescale=True) -> None:
12 |         super().__init__()
   |

geom3d\models\SEGNN\o3_building_blocks.py:11:9: D107 Missing docstring in `__init__`
   |
10 | class O3TensorProduct(torch.nn.Module):
11 |     def __init__(self, irreps_in1, irreps_out, irreps_in2=None, tp_rescale=True) -> None:
   |         ^^^^^^^^ D107
12 |         super().__init__()
   |

geom3d\models\SEGNN\o3_building_blocks.py:11:65: FBT002 Boolean default positional argument in function definition
   |
10 | class O3TensorProduct(torch.nn.Module):
11 |     def __init__(self, irreps_in1, irreps_out, irreps_in2=None, tp_rescale=True) -> None:
   |                                                                 ^^^^^^^^^^ FBT002
12 |         super().__init__()
   |

geom3d\models\SEGNN\o3_building_blocks.py:56:9: D102 Missing docstring in public method
   |
54 |         self.tensor_product_init()
55 | 
56 |     def tensor_product_init(self) -> None:
   |         ^^^^^^^^^^^^^^^^^^^ D102
57 |         with torch.no_grad():
58 |             # Determine fan_in for each slice, it could be that each output slice is updated via several instructions
   |

geom3d\models\SEGNN\o3_building_blocks.py:85:9: D102 Missing docstring in public method
   |
83 |                 out_bias.uniform_(-sqrt_k, sqrt_k)
84 | 
85 |     def forward_tp_rescale_bias(self, data_in1, data_in2=None) -> torch.Tensor:
   |         ^^^^^^^^^^^^^^^^^^^^^^^ D102
86 |         if data_in2 is None:
87 |             data_in2 = torch.ones_like(data_in1[:, 0:1])
   |

geom3d\models\SEGNN\o3_building_blocks.py:92:18: A001 Variable `slice` is shadowing a Python builtin
   |
90 |         # Apply corrections
91 |         if self.tp_rescale:
92 |             for (slice, slice_sqrt_k) in self.slices_sqrt_k.values():
   |                  ^^^^^ A001
93 |                 data_out[:, slice] /= slice_sqrt_k
94 |         # Add the biases
   |

geom3d\models\SEGNN\o3_building_blocks.py:95:17: A001 Variable `slice` is shadowing a Python builtin
   |
93 |                 data_out[:, slice] /= slice_sqrt_k
94 |         # Add the biases
95 |         for (_, slice, bias) in zip(self.biases_slice_idx, self.biases_slices, self.biases):
   |                 ^^^^^ A001
96 |             data_out[:, slice] += bias
97 |         # Return result
   |

geom3d\models\SEGNN\o3_building_blocks.py:100:9: D102 Missing docstring in public method
    |
 98 |         return data_out
 99 | 
100 |     def forward(self, data_in1, data_in2=None) -> torch.Tensor:
    |         ^^^^^^^ D102
101 |         # Apply the tensor product, the rescaling and the bias
102 |         return self.forward_tp_rescale_bias(data_in1, data_in2)
    |

geom3d\models\SEGNN\o3_building_blocks.py:105:7: D101 Missing docstring in public class
    |
105 | class O3TensorProductSwishGate(O3TensorProduct):
    |       ^^^^^^^^^^^^^^^^^^^^^^^^ D101
106 |     def __init__(self, irreps_in1, irreps_out, irreps_in2=None) -> None:
107 |         # For the gate the output of the linear needs to have an extra number of scalar irreps equal to the amount of
    |

geom3d\models\SEGNN\o3_building_blocks.py:106:9: D107 Missing docstring in `__init__`
    |
105 | class O3TensorProductSwishGate(O3TensorProduct):
106 |     def __init__(self, irreps_in1, irreps_out, irreps_in2=None) -> None:
    |         ^^^^^^^^ D107
107 |         # For the gate the output of the linear needs to have an extra number of scalar irreps equal to the amount of
108 |         # non scalar irreps:
    |

geom3d\models\SEGNN\o3_building_blocks.py:124:9: D102 Missing docstring in public method
    |
122 |             self.gate = nn.SiLU()
123 | 
124 |     def forward(self, data_in1, data_in2=None) -> torch.Tensor:
    |         ^^^^^^^ D102
125 |         # Apply the tensor product, the rescaling and the bias
126 |         data_out = self.forward_tp_rescale_bias(data_in1, data_in2)
    |

geom3d\models\SchNet.py:1:1: N999 Invalid module name: 'SchNet'
geom3d\models\SchNet.py:1:1: D100 Missing docstring in public module
geom3d\models\SchNet.py:4:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
2 | import ase
3 | import torch
4 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
5 | from torch.nn import Embedding, Linear, ModuleList, Sequential
6 | from torch_cluster import radius_graph
  |

geom3d\models\SchNet.py:11:7: D101 Missing docstring in public class
   |
11 | class SchNet(torch.nn.Module):
   |       ^^^^^^ D101
12 |     def __init__(
13 |         self,
   |

geom3d\models\SchNet.py:12:9: PLR0913 Too many arguments in function definition (12 > 5)
   |
11 | class SchNet(torch.nn.Module):
12 |     def __init__(
   |         ^^^^^^^^ PLR0913
13 |         self,
14 |         hidden_channels=128,
   |

geom3d\models\SchNet.py:12:9: D107 Missing docstring in `__init__`
   |
11 | class SchNet(torch.nn.Module):
12 |     def __init__(
   |         ^^^^^^^^ D107
13 |         self,
14 |         hidden_channels=128,
   |

geom3d\models\SchNet.py:21:9: FBT002 Boolean default positional argument in function definition
   |
19 |         node_class=None,
20 |         readout="mean",
21 |         dipole=False,
   |         ^^^^^^ FBT002
22 |         mean=None,
23 |         std=None,
   |

geom3d\models\SchNet.py:29:9: S101 Use of `assert` detected
   |
27 |         super().__init__()
28 | 
29 |         assert readout in ["add", "sum", "mean"]
   |         ^^^^^^ S101
30 | 
31 |         self.hidden_channels = hidden_channels
   |

geom3d\models\SchNet.py:46:9: ERA001 Found commented-out code
   |
44 |         self.register_buffer("atomic_mass", atomic_mass)
45 | 
46 |         # self.embedding = Embedding(100, hidden_channels)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
47 |         self.embedding = Embedding(node_class, hidden_channels)
48 |         self.distance_expansion = GaussianSmearing(0.0, cutoff, num_gaussians, gamma=gamma)
   |
   = help: Remove commented-out code

geom3d\models\SchNet.py:57:11: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
   |
55 |             self.interactions.append(block)
56 | 
57 |         # TODO: double-check hidden size
   |           ^^^^ TD002
58 |         self.lin1 = Linear(hidden_channels, hidden_channels)
59 |         self.act = ShiftedSoftplus()
   |

geom3d\models\SchNet.py:57:11: TD003 Missing issue link on the line following this TODO
   |
55 |             self.interactions.append(block)
56 | 
57 |         # TODO: double-check hidden size
   |           ^^^^ TD003
58 |         self.lin1 = Linear(hidden_channels, hidden_channels)
59 |         self.act = ShiftedSoftplus()
   |

geom3d\models\SchNet.py:57:11: FIX002 Line contains TODO, consider resolving the issue
   |
55 |             self.interactions.append(block)
56 | 
57 |         # TODO: double-check hidden size
   |           ^^^^ FIX002
58 |         self.lin1 = Linear(hidden_channels, hidden_channels)
59 |         self.act = ShiftedSoftplus()
   |

geom3d\models\SchNet.py:70:9: D102 Missing docstring in public method
   |
68 |         self.reset_parameters()
69 | 
70 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
71 |         self.embedding.reset_parameters()
72 |         for interaction in self.interactions:
   |

geom3d\models\SchNet.py:81:9: D102 Missing docstring in public method
   |
79 |             self.atomref.weight.data.copy_(self.initial_atomref)
80 | 
81 |     def forward(self, z, pos, batch=None, edge_index=None, return_latent=False):
   |         ^^^^^^^ D102
82 |         if z.dim() == 1:
83 |             assert z.dim() == 1
   |

geom3d\models\SchNet.py:81:60: FBT002 Boolean default positional argument in function definition
   |
79 |             self.atomref.weight.data.copy_(self.initial_atomref)
80 | 
81 |     def forward(self, z, pos, batch=None, edge_index=None, return_latent=False):
   |                                                            ^^^^^^^^^^^^^ FBT002
82 |         if z.dim() == 1:
83 |             assert z.dim() == 1
   |

geom3d\models\SchNet.py:83:13: S101 Use of `assert` detected
   |
81 |     def forward(self, z, pos, batch=None, edge_index=None, return_latent=False):
82 |         if z.dim() == 1:
83 |             assert z.dim() == 1
   |             ^^^^^^ S101
84 |             assert z.dtype == torch.long
85 |             h = self.embedding(z)
   |

geom3d\models\SchNet.py:84:13: S101 Use of `assert` detected
   |
82 |         if z.dim() == 1:
83 |             assert z.dim() == 1
84 |             assert z.dtype == torch.long
   |             ^^^^^^ S101
85 |             h = self.embedding(z)
86 |         else:  # When the input z is one-hot
   |

geom3d\models\SchNet.py:87:13: S101 Use of `assert` detected
   |
85 |             h = self.embedding(z)
86 |         else:  # When the input z is one-hot
87 |             assert z.dim() == 2
   |             ^^^^^^ S101
88 |             h = torch.matmul(z, self.embedding.weight)
89 |         batch = torch.zeros_like(z) if batch is None else batch
   |

geom3d\models\SchNet.py:87:31: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   |
85 |             h = self.embedding(z)
86 |         else:  # When the input z is one-hot
87 |             assert z.dim() == 2
   |                               ^ PLR2004
88 |             h = torch.matmul(z, self.embedding.weight)
89 |         batch = torch.zeros_like(z) if batch is None else batch
   |

geom3d\models\SchNet.py:129:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
127 |         return out
128 | 
129 |     def forward_with_gathered_index(self, gathered_z, pos, batch, edge_index, gathered_batch, periodic_index_mapping, return_latent=False):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
130 |         gathered_h = self.embedding(gathered_z)
131 |         batch = torch.zeros_like(gathered_z) if batch is None else batch
    |

geom3d\models\SchNet.py:129:9: D102 Missing docstring in public method
    |
127 |         return out
128 | 
129 |     def forward_with_gathered_index(self, gathered_z, pos, batch, edge_index, gathered_batch, periodic_index_mapping, return_latent=False):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
130 |         gathered_h = self.embedding(gathered_z)
131 |         batch = torch.zeros_like(gathered_z) if batch is None else batch
    |

geom3d\models\SchNet.py:129:119: FBT002 Boolean default positional argument in function definition
    |
127 |         return out
128 | 
129 |     def forward_with_gathered_index(self, gathered_z, pos, batch, edge_index, gathered_batch, periodic_index_mapping, return_latent=False):
    |                                                                                                                       ^^^^^^^^^^^^^ FBT002
130 |         gathered_h = self.embedding(gathered_z)
131 |         batch = torch.zeros_like(gathered_z) if batch is None else batch
    |

geom3d\models\SchNet.py:156:9: D105 Missing docstring in magic method
    |
154 |         return out
155 | 
156 |     def __repr__(self):
    |         ^^^^^^^^ D105
157 |         return (
158 |             f"{self.__class__.__name__}("
    |

geom3d\models\SchNet.py:167:7: D101 Missing docstring in public class
    |
167 | class InteractionBlock(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^ D101
168 |     def __init__(self, hidden_channels, num_gaussians, num_filters, cutoff):
169 |         super().__init__()
    |

geom3d\models\SchNet.py:168:9: D107 Missing docstring in `__init__`
    |
167 | class InteractionBlock(torch.nn.Module):
168 |     def __init__(self, hidden_channels, num_gaussians, num_filters, cutoff):
    |         ^^^^^^^^ D107
169 |         super().__init__()
170 |         self.mlp = Sequential(
    |

geom3d\models\SchNet.py:183:9: D102 Missing docstring in public method
    |
181 |         self.reset_parameters()
182 | 
183 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
184 |         torch.nn.init.xavier_uniform_(self.mlp[0].weight)
185 |         self.mlp[0].bias.data.fill_(0)
    |

geom3d\models\SchNet.py:192:9: D102 Missing docstring in public method
    |
190 |         self.lin.bias.data.fill_(0)
191 | 
192 |     def forward(self, x, edge_index, edge_weight, edge_attr):
    |         ^^^^^^^ D102
193 |         x = self.conv(x, edge_index, edge_weight, edge_attr)
194 |         x = self.act(x)
    |

geom3d\models\SchNet.py:198:7: D101 Missing docstring in public class
    |
198 | class CFConv(MessagePassing):
    |       ^^^^^^ D101
199 |     def __init__(self, in_channels, out_channels, num_filters, nn, cutoff):
200 |         super().__init__(aggr="add")
    |

geom3d\models\SchNet.py:199:9: D107 Missing docstring in `__init__`
    |
198 | class CFConv(MessagePassing):
199 |     def __init__(self, in_channels, out_channels, num_filters, nn, cutoff):
    |         ^^^^^^^^ D107
200 |         super().__init__(aggr="add")
201 |         self.lin1 = Linear(in_channels, num_filters, bias=False)
    |

geom3d\models\SchNet.py:208:9: D102 Missing docstring in public method
    |
206 |         self.reset_parameters()
207 | 
208 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
209 |         torch.nn.init.xavier_uniform_(self.lin1.weight)
210 |         torch.nn.init.xavier_uniform_(self.lin2.weight)
    |

geom3d\models\SchNet.py:213:9: D102 Missing docstring in public method
    |
211 |         self.lin2.bias.data.fill_(0)
212 | 
213 |     def forward(self, x, edge_index, edge_weight, edge_attr):
    |         ^^^^^^^ D102
214 |         C = 0.5 * (torch.cos(edge_weight * 3.14 / self.cutoff) + 1.0)
    |

geom3d\models\SchNet.py:214:9: N806 Variable `C` in function should be lowercase
    |
213 |     def forward(self, x, edge_index, edge_weight, edge_attr):
214 |         C = 0.5 * (torch.cos(edge_weight * 3.14 / self.cutoff) + 1.0)
    |         ^ N806
215 | 
216 |         W = self.nn(edge_attr) * C.view(-1, 1)
    |

geom3d\models\SchNet.py:216:9: N806 Variable `W` in function should be lowercase
    |
214 |         C = 0.5 * (torch.cos(edge_weight * 3.14 / self.cutoff) + 1.0)
215 | 
216 |         W = self.nn(edge_attr) * C.view(-1, 1)
    |         ^ N806
217 |         x = self.lin1(x)
218 |         # propagate_type: ( x: Tensor, W: Tensor )
    |

geom3d\models\SchNet.py:222:9: D102 Missing docstring in public method
    |
220 |         return self.lin2(x)
221 | 
222 |     def message(self, x_j, W):
    |         ^^^^^^^ D102
223 |         return x_j * W
    |

geom3d\models\SchNet.py:222:28: N803 Argument name `W` should be lowercase
    |
220 |         return self.lin2(x)
221 | 
222 |     def message(self, x_j, W):
    |                            ^ N803
223 |         return x_j * W
    |

geom3d\models\SchNet.py:226:7: D101 Missing docstring in public class
    |
226 | class GaussianSmearing(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^ D101
227 |     def __init__(self, start=0.0, stop=5.0, num_gaussians=50, gamma=None):
228 |         super().__init__()
    |

geom3d\models\SchNet.py:227:9: D107 Missing docstring in `__init__`
    |
226 | class GaussianSmearing(torch.nn.Module):
227 |     def __init__(self, start=0.0, stop=5.0, num_gaussians=50, gamma=None):
    |         ^^^^^^^^ D107
228 |         super().__init__()
229 |         offset = torch.linspace(start, stop, num_gaussians)
    |

geom3d\models\SchNet.py:236:9: D102 Missing docstring in public method
    |
234 |         self.register_buffer("offset", offset)
235 | 
236 |     def forward(self, dist):
    |         ^^^^^^^ D102
237 |         dist = dist.view(-1, 1) - self.offset.view(1, -1)
238 |         return torch.exp(self.coeff * torch.pow(dist, 2))
    |

geom3d\models\SchNet.py:241:7: D101 Missing docstring in public class
    |
241 | class ShiftedSoftplus(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^ D101
242 |     def __init__(self):
243 |         super().__init__()
    |

geom3d\models\SchNet.py:242:9: D107 Missing docstring in `__init__`
    |
241 | class ShiftedSoftplus(torch.nn.Module):
242 |     def __init__(self):
    |         ^^^^^^^^ D107
243 |         super().__init__()
244 |         self.shift = torch.log(torch.tensor(2.0)).item()
    |

geom3d\models\SchNet.py:246:9: D102 Missing docstring in public method
    |
244 |         self.shift = torch.log(torch.tensor(2.0)).item()
245 | 
246 |     def forward(self, x):
    |         ^^^^^^^ D102
247 |         return F.softplus(x) - self.shift
    |

geom3d\models\SphereNet.py:1:1: N999 Invalid module name: 'SphereNet'
geom3d\models\SphereNet.py:1:1: D100 Missing docstring in public module
geom3d\models\SphereNet.py:1:18: N812 Lowercase `pi` imported as non-lowercase `PI`
  |
1 | from math import pi as PI
  |                  ^^^^^^^^ N812
2 | from math import sqrt
  |

geom3d\models\SphereNet.py:18:7: N801 Class name `emb` should use CapWords convention
   |
18 | class emb(torch.nn.Module):
   |       ^^^ N801
19 |     def __init__(self, num_spherical, num_radial, cutoff, envelope_exponent):
20 |         super().__init__()
   |

geom3d\models\SphereNet.py:18:7: D101 Missing docstring in public class
   |
18 | class emb(torch.nn.Module):
   |       ^^^ D101
19 |     def __init__(self, num_spherical, num_radial, cutoff, envelope_exponent):
20 |         super().__init__()
   |

geom3d\models\SphereNet.py:19:9: D107 Missing docstring in `__init__`
   |
18 | class emb(torch.nn.Module):
19 |     def __init__(self, num_spherical, num_radial, cutoff, envelope_exponent):
   |         ^^^^^^^^ D107
20 |         super().__init__()
21 |         self.dist_emb = dist_emb(num_radial, cutoff, envelope_exponent)
   |

geom3d\models\SphereNet.py:28:9: D102 Missing docstring in public method
   |
26 |         self.reset_parameters()
27 | 
28 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
29 |         self.dist_emb.reset_parameters()
   |

geom3d\models\SphereNet.py:31:9: D102 Missing docstring in public method
   |
29 |         self.dist_emb.reset_parameters()
30 | 
31 |     def forward(self, dist, angle, torsion, idx_kj):
   |         ^^^^^^^ D102
32 |         dist_emb = self.dist_emb(dist)
33 |         angle_emb = self.angle_emb(dist, angle, idx_kj)
   |

geom3d\models\SphereNet.py:38:7: N801 Class name `init` should use CapWords convention
   |
38 | class init(torch.nn.Module):
   |       ^^^^ N801
39 |     def __init__(self, num_radial, hidden_channels, act="swish"):
40 |         super().__init__()
   |

geom3d\models\SphereNet.py:38:7: D101 Missing docstring in public class
   |
38 | class init(torch.nn.Module):
   |       ^^^^ D101
39 |     def __init__(self, num_radial, hidden_channels, act="swish"):
40 |         super().__init__()
   |

geom3d\models\SphereNet.py:39:9: D107 Missing docstring in `__init__`
   |
38 | class init(torch.nn.Module):
39 |     def __init__(self, num_radial, hidden_channels, act="swish"):
   |         ^^^^^^^^ D107
40 |         super().__init__()
41 |         self.act = act
   |

geom3d\models\SphereNet.py:48:9: D102 Missing docstring in public method
   |
46 |         self.reset_parameters()
47 | 
48 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
49 |         self.emb.weight.data.uniform_(-sqrt(3), sqrt(3))
50 |         self.lin_rbf_0.reset_parameters()
   |

geom3d\models\SphereNet.py:54:9: D102 Missing docstring in public method
   |
52 |         glorot_orthogonal(self.lin_rbf_1.weight, scale=2.0)
53 | 
54 |     def forward(self, x, emb, i, j):
   |         ^^^^^^^ D102
55 |         rbf, _, _ = emb
56 |         x = self.emb(x)
   |

geom3d\models\SphereNet.py:64:7: N801 Class name `update_e` should use CapWords convention
   |
64 | class update_e(torch.nn.Module):
   |       ^^^^^^^^ N801
65 |     def __init__(
66 |         self,
   |

geom3d\models\SphereNet.py:64:7: D101 Missing docstring in public class
   |
64 | class update_e(torch.nn.Module):
   |       ^^^^^^^^ D101
65 |     def __init__(
66 |         self,
   |

geom3d\models\SphereNet.py:65:9: PLR0913 Too many arguments in function definition (10 > 5)
   |
64 | class update_e(torch.nn.Module):
65 |     def __init__(
   |         ^^^^^^^^ PLR0913
66 |         self,
67 |         hidden_channels,
   |

geom3d\models\SphereNet.py:65:9: D107 Missing docstring in `__init__`
   |
64 | class update_e(torch.nn.Module):
65 |     def __init__(
   |         ^^^^^^^^ D107
66 |         self,
67 |         hidden_channels,
   |

geom3d\models\SphereNet.py:110:9: D102 Missing docstring in public method
    |
108 |         self.reset_parameters()
109 | 
110 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
111 |         glorot_orthogonal(self.lin_rbf1.weight, scale=2.0)
112 |         glorot_orthogonal(self.lin_rbf2.weight, scale=2.0)
    |

geom3d\models\SphereNet.py:135:9: D102 Missing docstring in public method
    |
133 |         glorot_orthogonal(self.lin_rbf.weight, scale=2.0)
134 | 
135 |     def forward(self, x, emb, idx_kj, idx_ji):
    |         ^^^^^^^ D102
136 |         rbf0, sbf, t = emb
137 |         x1, _ = x
    |

geom3d\models\SphereNet.py:170:7: N801 Class name `update_v` should use CapWords convention
    |
170 | class update_v(torch.nn.Module):
    |       ^^^^^^^^ N801
171 |     def __init__(
172 |         self,
    |

geom3d\models\SphereNet.py:170:7: D101 Missing docstring in public class
    |
170 | class update_v(torch.nn.Module):
    |       ^^^^^^^^ D101
171 |     def __init__(
172 |         self,
    |

geom3d\models\SphereNet.py:171:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
170 | class update_v(torch.nn.Module):
171 |     def __init__(
    |         ^^^^^^^^ PLR0913
172 |         self,
173 |         hidden_channels,
    |

geom3d\models\SphereNet.py:171:9: D107 Missing docstring in `__init__`
    |
170 | class update_v(torch.nn.Module):
171 |     def __init__(
    |         ^^^^^^^^ D107
172 |         self,
173 |         hidden_channels,
    |

geom3d\models\SphereNet.py:192:9: D102 Missing docstring in public method
    |
190 |         self.reset_parameters()
191 | 
192 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
193 |         glorot_orthogonal(self.lin_up.weight, scale=2.0)
194 |         for lin in self.lins:
    |

geom3d\models\SphereNet.py:202:9: D102 Missing docstring in public method
    |
200 |             glorot_orthogonal(self.lin.weight, scale=2.0)
201 | 
202 |     def forward(self, e, i):
    |         ^^^^^^^ D102
203 |         _, e2 = e
204 |         v = scatter(e2, i, dim=0)
    |

geom3d\models\SphereNet.py:211:7: N801 Class name `update_u` should use CapWords convention
    |
211 | class update_u(torch.nn.Module):
    |       ^^^^^^^^ N801
212 |     def __init__(self):
213 |         super().__init__()
    |

geom3d\models\SphereNet.py:211:7: D101 Missing docstring in public class
    |
211 | class update_u(torch.nn.Module):
    |       ^^^^^^^^ D101
212 |     def __init__(self):
213 |         super().__init__()
    |

geom3d\models\SphereNet.py:212:9: D107 Missing docstring in `__init__`
    |
211 | class update_u(torch.nn.Module):
212 |     def __init__(self):
    |         ^^^^^^^^ D107
213 |         super().__init__()
    |

geom3d\models\SphereNet.py:215:9: D102 Missing docstring in public method
    |
213 |         super().__init__()
214 | 
215 |     def forward(self, u, v, batch):
    |         ^^^^^^^ D102
216 |         u += scatter(v, batch, dim=0)
217 |         return u
    |

geom3d\models\SphereNet.py:246:9: PLR0913 Too many arguments in function definition (18 > 5)
    |
244 |     """
245 | 
246 |     def __init__(
    |         ^^^^^^^^ PLR0913
247 |         self,
248 |         energy_and_force=False,
    |

geom3d\models\SphereNet.py:246:9: D107 Missing docstring in `__init__`
    |
244 |     """
245 | 
246 |     def __init__(
    |         ^^^^^^^^ D107
247 |         self,
248 |         energy_and_force=False,
    |

geom3d\models\SphereNet.py:248:9: FBT002 Boolean default positional argument in function definition
    |
246 |     def __init__(
247 |         self,
248 |         energy_and_force=False,
    |         ^^^^^^^^^^^^^^^^ FBT002
249 |         cutoff=5.0,
250 |         num_layers=4,
    |

geom3d\models\SphereNet.py:320:9: D102 Missing docstring in public method
    |
318 |         self.reset_parameters()
319 | 
320 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
321 |         self.init_e.reset_parameters()
322 |         self.init_v.reset_parameters()
    |

geom3d\models\SphereNet.py:329:9: D417 Missing argument descriptions in the docstring for `triplets`: `edge_index`, `num_nodes`
    |
327 |             update_v.reset_parameters()
328 | 
329 |     def triplets(self, pos, edge_index, num_nodes, use_torsion=False):
    |         ^^^^^^^^ D417
330 |         """Compute the diatance, angle, and torsion from geometric information.
    |

geom3d\models\SphereNet.py:329:52: FBT002 Boolean default positional argument in function definition
    |
327 |             update_v.reset_parameters()
328 | 
329 |     def triplets(self, pos, edge_index, num_nodes, use_torsion=False):
    |                                                    ^^^^^^^^^^^ FBT002
330 |         """Compute the diatance, angle, and torsion from geometric information.
    |

geom3d\models\SphereNet.py:374:9: ERA001 Found commented-out code
    |
372 |         repeat = num_triplets - 1
373 |         num_triplets_t = num_triplets.repeat_interleave(repeat)
374 |         #num_triplets_t = num_triplets.repeat_interleave(num_triplets) - 1
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
375 | 
376 |         #debug
    |
    = help: Remove commented-out code

geom3d\models\SphereNet.py:407:9: RET505 Unnecessary `else` after `return` statement
    |
405 |             return dist, angle, torsion, i, j, idx_kj, idx_ji
406 | 
407 |         else:
    |         ^^^^ RET505
408 |             return dist, angle, i, j, idx_kj, idx_ji
    |
    = help: Remove unnecessary `else`

geom3d\models\SphereNet.py:410:9: D102 Missing docstring in public method
    |
408 |             return dist, angle, i, j, idx_kj, idx_ji
409 | 
410 |     def forward(self, z, pos, batch):
    |         ^^^^^^^ D102
411 |         if self.energy_and_force:
412 |             pos.requires_grad_()
    |

geom3d\models\SphereNet_periodic.py:1:1: N999 Invalid module name: 'SphereNet_periodic'
geom3d\models\SphereNet_periodic.py:1:1: D100 Missing docstring in public module
geom3d\models\SphereNet_periodic.py:1:18: N812 Lowercase `pi` imported as non-lowercase `PI`
  |
1 | from math import pi as PI
  |                  ^^^^^^^^ N812
2 | from math import sqrt
  |

geom3d\models\SphereNet_periodic.py:18:7: N801 Class name `emb` should use CapWords convention
   |
18 | class emb(torch.nn.Module):
   |       ^^^ N801
19 |     def __init__(self, num_spherical, num_radial, cutoff, envelope_exponent):
20 |         super().__init__()
   |

geom3d\models\SphereNet_periodic.py:18:7: D101 Missing docstring in public class
   |
18 | class emb(torch.nn.Module):
   |       ^^^ D101
19 |     def __init__(self, num_spherical, num_radial, cutoff, envelope_exponent):
20 |         super().__init__()
   |

geom3d\models\SphereNet_periodic.py:19:9: D107 Missing docstring in `__init__`
   |
18 | class emb(torch.nn.Module):
19 |     def __init__(self, num_spherical, num_radial, cutoff, envelope_exponent):
   |         ^^^^^^^^ D107
20 |         super().__init__()
21 |         self.dist_emb = dist_emb(num_radial, cutoff, envelope_exponent)
   |

geom3d\models\SphereNet_periodic.py:28:9: D102 Missing docstring in public method
   |
26 |         self.reset_parameters()
27 | 
28 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
29 |         self.dist_emb.reset_parameters()
   |

geom3d\models\SphereNet_periodic.py:31:9: D102 Missing docstring in public method
   |
29 |         self.dist_emb.reset_parameters()
30 | 
31 |     def forward(self, dist, angle, torsion, idx_kj):
   |         ^^^^^^^ D102
32 |         dist_emb = self.dist_emb(dist)
33 |         angle_emb = self.angle_emb(dist, angle, idx_kj)
   |

geom3d\models\SphereNet_periodic.py:38:7: N801 Class name `init` should use CapWords convention
   |
38 | class init(torch.nn.Module):
   |       ^^^^ N801
39 |     def __init__(self, num_radial, hidden_channels, act="swish"):
40 |         super().__init__()
   |

geom3d\models\SphereNet_periodic.py:38:7: D101 Missing docstring in public class
   |
38 | class init(torch.nn.Module):
   |       ^^^^ D101
39 |     def __init__(self, num_radial, hidden_channels, act="swish"):
40 |         super().__init__()
   |

geom3d\models\SphereNet_periodic.py:39:9: D107 Missing docstring in `__init__`
   |
38 | class init(torch.nn.Module):
39 |     def __init__(self, num_radial, hidden_channels, act="swish"):
   |         ^^^^^^^^ D107
40 |         super().__init__()
41 |         self.act = act
   |

geom3d\models\SphereNet_periodic.py:48:9: D102 Missing docstring in public method
   |
46 |         self.reset_parameters()
47 | 
48 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
49 |         self.emb.weight.data.uniform_(-sqrt(3), sqrt(3))
50 |         self.lin_rbf_0.reset_parameters()
   |

geom3d\models\SphereNet_periodic.py:54:9: D102 Missing docstring in public method
   |
52 |         glorot_orthogonal(self.lin_rbf_1.weight, scale=2.0)
53 | 
54 |     def forward(self, x, emb, i, j):
   |         ^^^^^^^ D102
55 |         rbf, _, _ = emb
56 |         x = self.emb(x)
   |

geom3d\models\SphereNet_periodic.py:64:7: N801 Class name `update_e` should use CapWords convention
   |
64 | class update_e(torch.nn.Module):
   |       ^^^^^^^^ N801
65 |     def __init__(
66 |         self,
   |

geom3d\models\SphereNet_periodic.py:64:7: D101 Missing docstring in public class
   |
64 | class update_e(torch.nn.Module):
   |       ^^^^^^^^ D101
65 |     def __init__(
66 |         self,
   |

geom3d\models\SphereNet_periodic.py:65:9: PLR0913 Too many arguments in function definition (10 > 5)
   |
64 | class update_e(torch.nn.Module):
65 |     def __init__(
   |         ^^^^^^^^ PLR0913
66 |         self,
67 |         hidden_channels,
   |

geom3d\models\SphereNet_periodic.py:65:9: D107 Missing docstring in `__init__`
   |
64 | class update_e(torch.nn.Module):
65 |     def __init__(
   |         ^^^^^^^^ D107
66 |         self,
67 |         hidden_channels,
   |

geom3d\models\SphereNet_periodic.py:110:9: D102 Missing docstring in public method
    |
108 |         self.reset_parameters()
109 | 
110 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
111 |         glorot_orthogonal(self.lin_rbf1.weight, scale=2.0)
112 |         glorot_orthogonal(self.lin_rbf2.weight, scale=2.0)
    |

geom3d\models\SphereNet_periodic.py:135:9: D102 Missing docstring in public method
    |
133 |         glorot_orthogonal(self.lin_rbf.weight, scale=2.0)
134 | 
135 |     def forward(self, x, emb, idx_kj, idx_ji):
    |         ^^^^^^^ D102
136 |         rbf0, sbf, t = emb
137 |         x1, _ = x
    |

geom3d\models\SphereNet_periodic.py:170:7: N801 Class name `update_v` should use CapWords convention
    |
170 | class update_v(torch.nn.Module):
    |       ^^^^^^^^ N801
171 |     def __init__(
172 |         self,
    |

geom3d\models\SphereNet_periodic.py:170:7: D101 Missing docstring in public class
    |
170 | class update_v(torch.nn.Module):
    |       ^^^^^^^^ D101
171 |     def __init__(
172 |         self,
    |

geom3d\models\SphereNet_periodic.py:171:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
170 | class update_v(torch.nn.Module):
171 |     def __init__(
    |         ^^^^^^^^ PLR0913
172 |         self,
173 |         hidden_channels,
    |

geom3d\models\SphereNet_periodic.py:171:9: D107 Missing docstring in `__init__`
    |
170 | class update_v(torch.nn.Module):
171 |     def __init__(
    |         ^^^^^^^^ D107
172 |         self,
173 |         hidden_channels,
    |

geom3d\models\SphereNet_periodic.py:192:9: D102 Missing docstring in public method
    |
190 |         self.reset_parameters()
191 | 
192 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
193 |         glorot_orthogonal(self.lin_up.weight, scale=2.0)
194 |         for lin in self.lins:
    |

geom3d\models\SphereNet_periodic.py:202:9: D102 Missing docstring in public method
    |
200 |             glorot_orthogonal(self.lin.weight, scale=2.0)
201 | 
202 |     def forward(self, e, i, dim_size=None):
    |         ^^^^^^^ D102
203 |         if dim_size is None:
204 |             dim_size = i.max().item() + 1
    |

geom3d\models\SphereNet_periodic.py:213:7: N801 Class name `update_u` should use CapWords convention
    |
213 | class update_u(torch.nn.Module):
    |       ^^^^^^^^ N801
214 |     def __init__(self):
215 |         super().__init__()
    |

geom3d\models\SphereNet_periodic.py:213:7: D101 Missing docstring in public class
    |
213 | class update_u(torch.nn.Module):
    |       ^^^^^^^^ D101
214 |     def __init__(self):
215 |         super().__init__()
    |

geom3d\models\SphereNet_periodic.py:214:9: D107 Missing docstring in `__init__`
    |
213 | class update_u(torch.nn.Module):
214 |     def __init__(self):
    |         ^^^^^^^^ D107
215 |         super().__init__()
    |

geom3d\models\SphereNet_periodic.py:217:9: D102 Missing docstring in public method
    |
215 |         super().__init__()
216 | 
217 |     def forward(self, u, v, batch):
    |         ^^^^^^^ D102
218 |         u += scatter(v, batch, dim=0, reduce=REDUCE)
219 |         return u
    |

geom3d\models\SphereNet_periodic.py:248:9: PLR0913 Too many arguments in function definition (18 > 5)
    |
246 |     """
247 | 
248 |     def __init__(
    |         ^^^^^^^^ PLR0913
249 |         self,
250 |         energy_and_force=False,
    |

geom3d\models\SphereNet_periodic.py:248:9: D107 Missing docstring in `__init__`
    |
246 |     """
247 | 
248 |     def __init__(
    |         ^^^^^^^^ D107
249 |         self,
250 |         energy_and_force=False,
    |

geom3d\models\SphereNet_periodic.py:250:9: FBT002 Boolean default positional argument in function definition
    |
248 |     def __init__(
249 |         self,
250 |         energy_and_force=False,
    |         ^^^^^^^^^^^^^^^^ FBT002
251 |         cutoff=5.0,
252 |         num_layers=4,
    |

geom3d\models\SphereNet_periodic.py:322:9: D102 Missing docstring in public method
    |
320 |         self.reset_parameters()
321 | 
322 |     def reset_parameters(self):
    |         ^^^^^^^^^^^^^^^^ D102
323 |         self.init_e.reset_parameters()
324 |         self.init_v.reset_parameters()
    |

geom3d\models\SphereNet_periodic.py:331:9: D417 Missing argument descriptions in the docstring for `triplets`: `edge_index`, `num_nodes`
    |
329 |             update_v.reset_parameters()
330 | 
331 |     def triplets(self, pos, edge_index, num_nodes, use_torsion=False):
    |         ^^^^^^^^ D417
332 |         """Compute the diatance, angle, and torsion from geometric information.
    |

geom3d\models\SphereNet_periodic.py:331:52: FBT002 Boolean default positional argument in function definition
    |
329 |             update_v.reset_parameters()
330 | 
331 |     def triplets(self, pos, edge_index, num_nodes, use_torsion=False):
    |                                                    ^^^^^^^^^^^ FBT002
332 |         """Compute the diatance, angle, and torsion from geometric information.
    |

geom3d\models\SphereNet_periodic.py:405:9: RET505 Unnecessary `else` after `return` statement
    |
403 |             return dist, angle, torsion, i, j, idx_kj, idx_ji
404 | 
405 |         else:
    |         ^^^^ RET505
406 |             return dist, angle, i, j, idx_kj, idx_ji
    |
    = help: Remove unnecessary `else`

geom3d\models\SphereNet_periodic.py:408:9: D102 Missing docstring in public method
    |
406 |             return dist, angle, i, j, idx_kj, idx_ji
407 | 
408 |     def forward(self, z, pos, edge_index, batch):
    |         ^^^^^^^ D102
409 |         if self.energy_and_force:
410 |             pos.requires_grad_()
    |

geom3d\models\SphereNet_periodic.py:431:9: D102 Missing docstring in public method
    |
429 |         return u
430 | 
431 |     def forward_with_gathered_index(self, z, pos, edge_index, batch, periodic_index_mapping):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
432 |         if self.energy_and_force:
433 |             pos.requires_grad_()
    |

geom3d\models\SphereNet_utils.py:1:1: N999 Invalid module name: 'SphereNet_utils'
geom3d\models\SphereNet_utils.py:1:1: D100 Missing docstring in public module
geom3d\models\SphereNet_utils.py:1:18: N812 Lowercase `pi` imported as non-lowercase `PI`
  |
1 | from math import pi as PI
  |                  ^^^^^^^^ N812
2 | 
3 | import sympy as sym
  |

geom3d\models\SphereNet_utils.py:14:5: C901 `real_sph_harm` is too complex (16 > 10)
   |
14 | def real_sph_harm(l, zero_m_only=False, spherical_coordinates=True):
   |     ^^^^^^^^^^^^^ C901
15 |     """Computes formula strings of the the real part of the spherical harmonics up to order l (excluded).
16 |     Variables are either cartesian coordinates x,y,z on the unit sphere or spherical coordinates phi and theta.
   |

geom3d\models\SphereNet_utils.py:14:5: PLR0912 Too many branches (15 > 12)
   |
14 | def real_sph_harm(l, zero_m_only=False, spherical_coordinates=True):
   |     ^^^^^^^^^^^^^ PLR0912
15 |     """Computes formula strings of the the real part of the spherical harmonics up to order l (excluded).
16 |     Variables are either cartesian coordinates x,y,z on the unit sphere or spherical coordinates phi and theta.
   |

geom3d\models\SphereNet_utils.py:14:19: E741 Ambiguous variable name: `l`
   |
14 | def real_sph_harm(l, zero_m_only=False, spherical_coordinates=True):
   |                   ^ E741
15 |     """Computes formula strings of the the real part of the spherical harmonics up to order l (excluded).
16 |     Variables are either cartesian coordinates x,y,z on the unit sphere or spherical coordinates phi and theta.
   |

geom3d\models\SphereNet_utils.py:14:22: FBT002 Boolean default positional argument in function definition
   |
14 | def real_sph_harm(l, zero_m_only=False, spherical_coordinates=True):
   |                      ^^^^^^^^^^^ FBT002
15 |     """Computes formula strings of the the real part of the spherical harmonics up to order l (excluded).
16 |     Variables are either cartesian coordinates x,y,z on the unit sphere or spherical coordinates phi and theta.
   |

geom3d\models\SphereNet_utils.py:14:41: FBT002 Boolean default positional argument in function definition
   |
14 | def real_sph_harm(l, zero_m_only=False, spherical_coordinates=True):
   |                                         ^^^^^^^^^^^^^^^^^^^^^ FBT002
15 |     """Computes formula strings of the the real part of the spherical harmonics up to order l (excluded).
16 |     Variables are either cartesian coordinates x,y,z on the unit sphere or spherical coordinates phi and theta.
   |

geom3d\models\SphereNet_utils.py:15:5: D205 1 blank line required between summary line and description
   |
14 |   def real_sph_harm(l, zero_m_only=False, spherical_coordinates=True):
15 |       """Computes formula strings of the the real part of the spherical harmonics up to order l (excluded).
   |  _____^
16 | |     Variables are either cartesian coordinates x,y,z on the unit sphere or spherical coordinates phi and theta.
17 | |     """
   | |_______^ D205
18 |       if not zero_m_only:
19 |           x = sym.symbols("x")
   |
   = help: Insert single blank line

geom3d\models\SphereNet_utils.py:15:5: D401 First line of docstring should be in imperative mood: "Computes formula strings of the the real part of the spherical harmonics up to order l (excluded)."
   |
14 |   def real_sph_harm(l, zero_m_only=False, spherical_coordinates=True):
15 |       """Computes formula strings of the the real part of the spherical harmonics up to order l (excluded).
   |  _____^
16 | |     Variables are either cartesian coordinates x,y,z on the unit sphere or spherical coordinates phi and theta.
17 | |     """
   | |_______^ D401
18 |       if not zero_m_only:
19 |           x = sym.symbols("x")
   |

geom3d\models\SphereNet_utils.py:21:9: N806 Variable `S_m` in function should be lowercase
   |
19 |         x = sym.symbols("x")
20 |         y = sym.symbols("y")
21 |         S_m = [x * 0]
   |         ^^^ N806
22 |         C_m = [1 + 0 * x]
23 |         # S_m = [0]
   |

geom3d\models\SphereNet_utils.py:22:9: N806 Variable `C_m` in function should be lowercase
   |
20 |         y = sym.symbols("y")
21 |         S_m = [x * 0]
22 |         C_m = [1 + 0 * x]
   |         ^^^ N806
23 |         # S_m = [0]
24 |         # C_m = [1]
   |

geom3d\models\SphereNet_utils.py:23:9: ERA001 Found commented-out code
   |
21 |         S_m = [x * 0]
22 |         C_m = [1 + 0 * x]
23 |         # S_m = [0]
   |         ^^^^^^^^^^^ ERA001
24 |         # C_m = [1]
25 |         for i in range(1, l):
   |
   = help: Remove commented-out code

geom3d\models\SphereNet_utils.py:24:9: ERA001 Found commented-out code
   |
22 |         C_m = [1 + 0 * x]
23 |         # S_m = [0]
24 |         # C_m = [1]
   |         ^^^^^^^^^^^ ERA001
25 |         for i in range(1, l):
26 |             x = sym.symbols("x")
   |
   = help: Remove commented-out code

geom3d\models\SphereNet_utils.py:28:13: N806 Variable `S_m` in function should be lowercase
   |
26 |             x = sym.symbols("x")
27 |             y = sym.symbols("y")
28 |             S_m += [x * S_m[i - 1] + y * C_m[i - 1]]
   |             ^^^ N806
29 |             C_m += [x * C_m[i - 1] - y * S_m[i - 1]]
   |

geom3d\models\SphereNet_utils.py:29:13: N806 Variable `C_m` in function should be lowercase
   |
27 |             y = sym.symbols("y")
28 |             S_m += [x * S_m[i - 1] + y * C_m[i - 1]]
29 |             C_m += [x * C_m[i - 1] - y * S_m[i - 1]]
   |             ^^^ N806
30 | 
31 |     P_l_m = associated_legendre_polynomials(l, zero_m_only)
   |

geom3d\models\SphereNet_utils.py:31:5: N806 Variable `P_l_m` in function should be lowercase
   |
29 |             C_m += [x * C_m[i - 1] - y * S_m[i - 1]]
30 | 
31 |     P_l_m = associated_legendre_polynomials(l, zero_m_only)
   |     ^^^^^ N806
32 |     if spherical_coordinates:
33 |         theta = sym.symbols("theta")
   |

geom3d\models\SphereNet_utils.py:37:20: E721 Use `is` and `is not` for type comparisons, or `isinstance()` for isinstance checks
   |
35 |         for i in range(len(P_l_m)):
36 |             for j in range(len(P_l_m[i])):
37 |                 if type(P_l_m[i][j]) != int:
   |                    ^^^^^^^^^^^^^^^^^^^^^^^^ E721
38 |                     P_l_m[i][j] = P_l_m[i][j].subs(z, sym.cos(theta))
39 |         if not zero_m_only:
   |

geom3d\models\SphereNet_utils.py:54:5: N806 Variable `Y_func_l_m` in function should be lowercase
   |
52 |                 )
53 | 
54 |     Y_func_l_m = [["0"] * (2 * j + 1) for j in range(l)]
   |     ^^^^^^^^^^ N806
55 |     for i in range(l):
56 |         Y_func_l_m[i][0] = sym.simplify(sph_harm_prefactor(i, 0) * P_l_m[i][0])
   |

geom3d\models\SphereNet_utils.py:73:7: N801 Class name `dist_emb` should use CapWords convention
   |
73 | class dist_emb(torch.nn.Module):
   |       ^^^^^^^^ N801
74 |     def __init__(self, num_radial, cutoff=5.0, envelope_exponent=5):
75 |         super().__init__()
   |

geom3d\models\SphereNet_utils.py:73:7: D101 Missing docstring in public class
   |
73 | class dist_emb(torch.nn.Module):
   |       ^^^^^^^^ D101
74 |     def __init__(self, num_radial, cutoff=5.0, envelope_exponent=5):
75 |         super().__init__()
   |

geom3d\models\SphereNet_utils.py:74:9: D107 Missing docstring in `__init__`
   |
73 | class dist_emb(torch.nn.Module):
74 |     def __init__(self, num_radial, cutoff=5.0, envelope_exponent=5):
   |         ^^^^^^^^ D107
75 |         super().__init__()
76 |         self.cutoff = cutoff
   |

geom3d\models\SphereNet_utils.py:83:9: D102 Missing docstring in public method
   |
81 |         self.reset_parameters()
82 | 
83 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
84 |         with torch.no_grad(): torch.arange(1, self.freq.numel() + 1, out=self.freq).mul_(PI)
   |

geom3d\models\SphereNet_utils.py:84:29: E701 Multiple statements on one line (colon)
   |
83 |     def reset_parameters(self):
84 |         with torch.no_grad(): torch.arange(1, self.freq.numel() + 1, out=self.freq).mul_(PI)
   |                             ^ E701
85 | 
86 |     def forward(self, dist):
   |

geom3d\models\SphereNet_utils.py:86:9: D102 Missing docstring in public method
   |
84 |         with torch.no_grad(): torch.arange(1, self.freq.numel() + 1, out=self.freq).mul_(PI)
85 | 
86 |     def forward(self, dist):
   |         ^^^^^^^ D102
87 |         dist = dist.unsqueeze(-1) / self.cutoff
88 |         return self.envelope(dist) * (self.freq * dist).sin()
   |

geom3d\models\SphereNet_utils.py:91:7: N801 Class name `angle_emb` should use CapWords convention
   |
91 | class angle_emb(torch.nn.Module):
   |       ^^^^^^^^^ N801
92 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
93 |         super().__init__()
   |

geom3d\models\SphereNet_utils.py:91:7: D101 Missing docstring in public class
   |
91 | class angle_emb(torch.nn.Module):
   |       ^^^^^^^^^ D101
92 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
93 |         super().__init__()
   |

geom3d\models\SphereNet_utils.py:92:9: D107 Missing docstring in `__init__`
   |
91 | class angle_emb(torch.nn.Module):
92 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
   |         ^^^^^^^^ D107
93 |         super().__init__()
94 |         assert num_radial <= 64
   |

geom3d\models\SphereNet_utils.py:92:63: ARG002 Unused method argument: `envelope_exponent`
   |
91 | class angle_emb(torch.nn.Module):
92 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
   |                                                               ^^^^^^^^^^^^^^^^^ ARG002
93 |         super().__init__()
94 |         assert num_radial <= 64
   |

geom3d\models\SphereNet_utils.py:94:9: S101 Use of `assert` detected
   |
92 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
93 |         super().__init__()
94 |         assert num_radial <= 64
   |         ^^^^^^ S101
95 |         self.num_spherical = num_spherical
96 |         self.num_radial = num_radial
   |

geom3d\models\SphereNet_utils.py:94:30: PLR2004 Magic value used in comparison, consider replacing `64` with a constant variable
   |
92 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
93 |         super().__init__()
94 |         assert num_radial <= 64
   |                              ^^ PLR2004
95 |         self.num_spherical = num_spherical
96 |         self.num_radial = num_radial
   |

geom3d\models\SphereNet_utils.py:98:9: ERA001 Found commented-out code
    |
 96 |         self.num_radial = num_radial
 97 |         self.cutoff = cutoff
 98 |         # self.envelope = Envelope(envelope_exponent)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
 99 | 
100 |         bessel_forms = bessel_basis(num_spherical, num_radial)
    |
    = help: Remove commented-out code

geom3d\models\SphereNet_utils.py:110:71: B023 Function definition does not bind loop variable `sph1`
    |
108 |             if i == 0:
109 |                 sph1 = sym.lambdify([theta], sph_harm_forms[i][0], modules)(0)
110 |                 self.sph_funcs.append(lambda x: torch.zeros_like(x) + sph1)
    |                                                                       ^^^^ B023
111 |             else:
112 |                 sph = sym.lambdify([theta], sph_harm_forms[i][0], modules)
    |

geom3d\models\SphereNet_utils.py:118:9: D102 Missing docstring in public method
    |
116 |                 self.bessel_funcs.append(bessel)
117 | 
118 |     def forward(self, dist, angle, idx_kj):
    |         ^^^^^^^ D102
119 |         dist = dist / self.cutoff
120 |         rbf = torch.stack([f(dist) for f in self.bessel_funcs], dim=1)
    |

geom3d\models\SphereNet_utils.py:121:9: ERA001 Found commented-out code
    |
119 |         dist = dist / self.cutoff
120 |         rbf = torch.stack([f(dist) for f in self.bessel_funcs], dim=1)
121 |         # rbf = self.envelope(dist).unsqueeze(-1) * rbf
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
122 | 
123 |         cbf = torch.stack([f(angle) for f in self.sph_funcs], dim=1)
    |
    = help: Remove commented-out code

geom3d\models\SphereNet_utils.py:129:7: N801 Class name `torsion_emb` should use CapWords convention
    |
129 | class torsion_emb(torch.nn.Module):
    |       ^^^^^^^^^^^ N801
130 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
131 |         super().__init__()
    |

geom3d\models\SphereNet_utils.py:129:7: D101 Missing docstring in public class
    |
129 | class torsion_emb(torch.nn.Module):
    |       ^^^^^^^^^^^ D101
130 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
131 |         super().__init__()
    |

geom3d\models\SphereNet_utils.py:130:9: D107 Missing docstring in `__init__`
    |
129 | class torsion_emb(torch.nn.Module):
130 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
    |         ^^^^^^^^ D107
131 |         super().__init__()
132 |         assert num_radial <= 64
    |

geom3d\models\SphereNet_utils.py:130:63: ARG002 Unused method argument: `envelope_exponent`
    |
129 | class torsion_emb(torch.nn.Module):
130 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
    |                                                               ^^^^^^^^^^^^^^^^^ ARG002
131 |         super().__init__()
132 |         assert num_radial <= 64
    |

geom3d\models\SphereNet_utils.py:132:9: S101 Use of `assert` detected
    |
130 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
131 |         super().__init__()
132 |         assert num_radial <= 64
    |         ^^^^^^ S101
133 |         self.num_spherical = num_spherical
134 |         self.num_radial = num_radial
    |

geom3d\models\SphereNet_utils.py:132:30: PLR2004 Magic value used in comparison, consider replacing `64` with a constant variable
    |
130 |     def __init__(self, num_spherical, num_radial, cutoff=5.0, envelope_exponent=5):
131 |         super().__init__()
132 |         assert num_radial <= 64
    |                              ^^ PLR2004
133 |         self.num_spherical = num_spherical
134 |         self.num_radial = num_radial
    |

geom3d\models\SphereNet_utils.py:136:9: ERA001 Found commented-out code
    |
134 |         self.num_radial = num_radial
135 |         self.cutoff = cutoff
136 |         # self.envelope = Envelope(envelope_exponent)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
137 | 
138 |         bessel_forms = bessel_basis(num_spherical, num_radial)
    |
    = help: Remove commented-out code

geom3d\models\SphereNet_utils.py:151:78: B023 Function definition does not bind loop variable `sph1`
    |
149 |                 sph1 = sym.lambdify([theta, phi], sph_harm_forms[i][0], modules)
150 |                 self.sph_funcs.append(
151 |                     lambda x, y: torch.zeros_like(x) + torch.zeros_like(y) + sph1(0, 0)
    |                                                                              ^^^^ B023
152 |                 )  # torch.zeros_like(x) + torch.zeros_like(y)
153 |             else:
    |

geom3d\models\SphereNet_utils.py:161:9: D102 Missing docstring in public method
    |
159 |                 self.bessel_funcs.append(bessel)
160 | 
161 |     def forward(self, dist, angle, phi, idx_kj):
    |         ^^^^^^^ D102
162 |         dist = dist / self.cutoff
163 |         rbf = torch.stack([f(dist) for f in self.bessel_funcs], dim=1)
    |

geom3d\models\TFN.py:1:1: N999 Invalid module name: 'TFN'
geom3d\models\TFN.py:1:1: D100 Missing docstring in public module
geom3d\models\TFN.py:10:7: D101 Missing docstring in public class
   |
10 | class TFN(nn.Module):
   |       ^^^ D101
11 |     def __init__(
12 |         self,
   |

geom3d\models\TFN.py:11:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
10 | class TFN(nn.Module):
11 |     def __init__(
   |         ^^^^^^^^ PLR0913
12 |         self,
13 |         num_layers,
   |

geom3d\models\TFN.py:11:9: D107 Missing docstring in `__init__`
   |
10 | class TFN(nn.Module):
11 |     def __init__(
   |         ^^^^^^^^ D107
12 |         self,
13 |         num_layers,
   |

geom3d\models\TFN.py:58:9: D102 Missing docstring in public method
   |
58 |     def forward(self, x, positions, edge_index, edge_feat=None):
   |         ^^^^^^^ D102
59 |         # Compute equivariant weight basis from relative positions
60 |         row, col = edge_index
   |

geom3d\models\TFN_utils.py:1:1: N999 Invalid module name: 'TFN_utils'
geom3d\models\TFN_utils.py:1:1: D100 Missing docstring in public module
geom3d\models\TFN_utils.py:20:9: D102 Missing docstring in public method
   |
18 |         self.bn = nn.LayerNorm(m)
19 | 
20 |     def forward(self, x):
   |         ^^^^^^^ D102
21 |         return self.bn(x)
   |

geom3d\models\TFN_utils.py:59:9: D102 Missing docstring in public method
   |
57 |         nn.init.kaiming_uniform_(self.net[6].weight)
58 | 
59 |     def forward(self, x):
   |         ^^^^^^^ D102
60 |         y = self.net(x)
61 |         return y.view(-1, self.out_dim, 1, self.in_dim, 1, self.num_freq)
   |

geom3d\models\TFN_utils.py:63:9: D105 Missing docstring in magic method
   |
61 |         return y.view(-1, self.out_dim, 1, self.in_dim, 1, self.num_freq)
62 | 
63 |     def __repr__(self):
   |         ^^^^^^^^ D105
64 |         return f"RadialFunc(edge_dim={self.edge_dim}, in_dim={self.in_dim}, out_dim={self.out_dim})"
   |

geom3d\models\TFN_utils.py:107:9: D102 Missing docstring in public method
    |
105 |         self.rp = RadialFunc(self.num_freq, nc_in, nc_out, self.edge_dim)
106 | 
107 |     def forward(self, feat, basis):
    |         ^^^^^^^ D102
108 |         # Get radial weights
109 |         R = self.rp(feat)
    |

geom3d\models\TFN_utils.py:109:9: N806 Variable `R` in function should be lowercase
    |
107 |     def forward(self, feat, basis):
108 |         # Get radial weights
109 |         R = self.rp(feat)
    |         ^ N806
110 |         kernel = torch.sum(R * basis[f"{self.degree_in},{self.degree_out}"], -1)
111 |         return kernel.view(kernel.shape[0], self.d_out * self.nc_out, -1)
    |

geom3d\models\TFN_utils.py:113:9: D105 Missing docstring in magic method
    |
111 |         return kernel.view(kernel.shape[0], self.d_out * self.nc_out, -1)
112 | 
113 |     def __repr__(self):
    |         ^^^^^^^^ D105
114 |         return f"PairwiseConv(edge_dim={self.edge_dim}, degree_in={self.degree_in}, degree_out={self.degree_out})"
    |

geom3d\models\TFN_utils.py:118:5: D205 1 blank line required between summary line and description
    |
117 |   class GConvSE3(nn.Module):
118 |       """A tensor field network layer as a DGL module.
    |  _____^
119 | |     GConvSE3 stands for a Graph Convolution SE(3)-equivariant layer. It is the
120 | |     equivalent of a linear layer in an MLP, a conv layer in a CNN, or a graph
121 | |     conv layer in a GCN.
122 | |     At each node, the activations are split into different "feature types",
123 | |     indexed by the SE(3) representation type: non-negative integers 0, 1, 2, ..
124 | |     """
    | |_______^ D205
125 |   
126 |       def __init__(self, f_in, f_out, self_interaction=False, edge_dim=0, flavor="skip"):
    |
    = help: Insert single blank line

geom3d\models\TFN_utils.py:126:37: FBT002 Boolean default positional argument in function definition
    |
124 |     """
125 | 
126 |     def __init__(self, f_in, f_out, self_interaction=False, edge_dim=0, flavor="skip"):
    |                                     ^^^^^^^^^^^^^^^^ FBT002
127 |         """SE(3)-equivariant Graph Conv Layer
128 |         Args:
    |

geom3d\models\TFN_utils.py:127:9: D205 1 blank line required between summary line and description
    |
126 |       def __init__(self, f_in, f_out, self_interaction=False, edge_dim=0, flavor="skip"):
127 |           """SE(3)-equivariant Graph Conv Layer
    |  _________^
128 | |         Args:
129 | |             f_in: list of tuples [(multiplicities, type),...]
130 | |             f_out: list of tuples [(multiplicities, type),...]
131 | |             self_interaction: include self-interaction in convolution
132 | |             edge_dim: number of dimensions for edge embedding
133 | |             flavor: allows ['TFN', 'skip'], where 'skip' adds a skip connection.
134 | |         """
    | |___________^ D205
135 |           super().__init__()
136 |           self.f_in = f_in
    |
    = help: Insert single blank line

geom3d\models\TFN_utils.py:153:13: S101 Use of `assert` detected
    |
151 |         self.kernel_self = nn.ParameterDict()
152 |         if self_interaction:
153 |             assert self.flavor in ["TFN", "skip"]
    |             ^^^^^^ S101
154 |             if self.flavor == "TFN":
155 |                 for m_out, d_out in self.f_out.structure:
    |

geom3d\models\TFN_utils.py:156:21: N806 Variable `W` in function should be lowercase
    |
154 |             if self.flavor == "TFN":
155 |                 for m_out, d_out in self.f_out.structure:
156 |                     W = nn.Parameter(torch.randn(1, m_out, m_out) / np.sqrt(m_out))
    |                     ^ N806
157 |                     self.kernel_self[f"{d_out}"] = W
158 |             elif self.flavor == "skip":
    |

geom3d\models\TFN_utils.py:162:25: N806 Variable `W` in function should be lowercase
    |
160 |                     if d_in in self.f_out.degrees:
161 |                         m_out = self.f_out.structure_dict[d_in]
162 |                         W = nn.Parameter(torch.randn(1, m_out, m_in) / np.sqrt(m_in))
    |                         ^ N806
163 |                         self.kernel_self[f"{d_in}"] = W
    |

geom3d\models\TFN_utils.py:166:64: ANN003 Missing type annotation for `**kwargs`
    |
165 |     # def forward(self, h, G=None, r=None, basis=None, **kwargs):
166 |     def forward(self, h, r, basis, edge_index, edge_feat=None, **kwargs):
    |                                                                ^^^^^^^^ ANN003
167 |         """Forward pass of the linear layer
168 |         Args:
    |

geom3d\models\TFN_utils.py:166:66: ARG002 Unused method argument: `kwargs`
    |
165 |     # def forward(self, h, G=None, r=None, basis=None, **kwargs):
166 |     def forward(self, h, r, basis, edge_index, edge_feat=None, **kwargs):
    |                                                                  ^^^^^^ ARG002
167 |         """Forward pass of the linear layer
168 |         Args:
    |

geom3d\models\TFN_utils.py:167:9: D205 1 blank line required between summary line and description
    |
165 |       # def forward(self, h, G=None, r=None, basis=None, **kwargs):
166 |       def forward(self, h, r, basis, edge_index, edge_feat=None, **kwargs):
167 |           """Forward pass of the linear layer
    |  _________^
168 | |         Args:
169 | |             G: minibatch of (homo)graphs
170 | |             h: dict of features
171 | |             r: inter-atomic distances
172 | |             basis: pre-computed Q * Y
173 | |         Returns:
174 | |             tensor with new features [B, n_points, n_features_out].
175 | |         """
    | |___________^ D205
176 |           # Add node features to local graph scope
177 |           G = {}
    |
    = help: Insert single blank line

geom3d\models\TFN_utils.py:177:9: N806 Variable `G` in function should be lowercase
    |
175 |         """
176 |         # Add node features to local graph scope
177 |         G = {}
    |         ^ N806
178 |         N = h["0"].size()[0]
179 |         for k, v in h.items():
    |

geom3d\models\TFN_utils.py:178:9: N806 Variable `N` in function should be lowercase
    |
176 |         # Add node features to local graph scope
177 |         G = {}
178 |         N = h["0"].size()[0]
    |         ^ N806
179 |         for k, v in h.items():
180 |             G[k] = v
    |

geom3d\models\TFN_utils.py:180:13: PERF403 Use a dictionary comprehension instead of a for-loop
    |
178 |         N = h["0"].size()[0]
179 |         for k, v in h.items():
180 |             G[k] = v
    |             ^^^^^^^^ PERF403
181 | 
182 |         feat = torch.cat([edge_feat, r], -1) if edge_feat is not None else r
    |

geom3d\models\TFN_utils.py:204:13: SIM102 Use a single `if` statement instead of nested `if` statements
    |
203 |               # Center -> center messages
204 |               if self.self_interaction:
    |  _____________^
205 | |                 if f"{d_out}" in self.kernel_self:
    | |__________________________________________________^ SIM102
206 |                       if self.flavor == "TFN":
207 |                           W = self.kernel_self[f"{d_out}"]
    |
    = help: Combine `if` statements using `and`

geom3d\models\TFN_utils.py:207:25: N806 Variable `W` in function should be lowercase
    |
205 |                 if f"{d_out}" in self.kernel_self:
206 |                     if self.flavor == "TFN":
207 |                         W = self.kernel_self[f"{d_out}"]
    |                         ^ N806
208 |                         msg = torch.matmul(W, msg)
209 |                     if self.flavor == "skip":
    |

geom3d\models\TFN_utils.py:212:25: N806 Variable `W` in function should be lowercase
    |
210 |                         h_ = G[f"{d_out}"]
211 |                         dst = h_[col]
212 |                         W = self.kernel_self[f"{d_out}"]
    |                         ^ N806
213 |                         msg = msg + torch.matmul(W, dst)
214 |             msg = msg.view(msg.shape[0], -1, 2 * d_out + 1)
    |

geom3d\models\TFN_utils.py:216:15: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
214 |             msg = msg.view(msg.shape[0], -1, 2 * d_out + 1)
215 | 
216 |             # TODO: row or col?
    |               ^^^^ TD002
217 |             result[f"{d_out}"] = scatter_mean(msg, col, dim=0, dim_size=N)
218 |         return result
    |

geom3d\models\TFN_utils.py:216:15: TD003 Missing issue link on the line following this TODO
    |
214 |             msg = msg.view(msg.shape[0], -1, 2 * d_out + 1)
215 | 
216 |             # TODO: row or col?
    |               ^^^^ TD003
217 |             result[f"{d_out}"] = scatter_mean(msg, col, dim=0, dim_size=N)
218 |         return result
    |

geom3d\models\TFN_utils.py:216:15: FIX002 Line contains TODO, consider resolving the issue
    |
214 |             msg = msg.view(msg.shape[0], -1, 2 * d_out + 1)
215 | 
216 |             # TODO: row or col?
    |               ^^^^ FIX002
217 |             result[f"{d_out}"] = scatter_mean(msg, col, dim=0, dim_size=N)
218 |         return result
    |

geom3d\models\TFN_utils.py:217:34: F821 Undefined name `scatter_mean`
    |
216 |             # TODO: row or col?
217 |             result[f"{d_out}"] = scatter_mean(msg, col, dim=0, dim_size=N)
    |                                  ^^^^^^^^^^^^ F821
218 |         return result
    |

geom3d\models\TFN_utils.py:220:9: D105 Missing docstring in magic method
    |
218 |         return result
219 | 
220 |     def __repr__(self):
    |         ^^^^^^^^ D105
221 |         return f"GConvSE3(structure={self.f_out}, self_interaction={self.self_interaction})"
    |

geom3d\models\TFN_utils.py:225:5: D205 1 blank line required between summary line and description
    |
224 |   class GNormSE3(nn.Module):
225 |       """Graph Norm-based SE(3)-equivariant nonlinearity.
    |  _____^
226 | |     Nonlinearities are important in SE(3) equivariant GCNs. They are also quite
227 | |     expensive to compute, so it is convenient for them to share resources with
228 | |     other layers, such as normalization. The general workflow is as follows:
229 | |     > for feature type in features:
230 | |     >    norm, phase <- feature
231 | |     >    output = fnc(norm) * phase
232 | |     where fnc: {R+}^m -> R^m is a learnable map from m norms to m scalars.
233 | |     """
    | |_______^ D205
234 |   
235 |       def __init__(self, fiber, nonlin=nn.ReLU(inplace=True), num_layers: int = 0):
    |
    = help: Insert single blank line

geom3d\models\TFN_utils.py:235:38: B008 Do not perform function call `nn.ReLU` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
    |
233 |     """
234 | 
235 |     def __init__(self, fiber, nonlin=nn.ReLU(inplace=True), num_layers: int = 0):
    |                                      ^^^^^^^^^^^^^^^^^^^^^ B008
236 |         """Initializer.
    |

geom3d\models\TFN_utils.py:236:9: D401 First line of docstring should be in imperative mood: "Initializer."
    |
235 |       def __init__(self, fiber, nonlin=nn.ReLU(inplace=True), num_layers: int = 0):
236 |           """Initializer.
    |  _________^
237 | | 
238 | |         Args:
239 | |         ----
240 | |             fiber: Fiber() of feature multiplicities and types
241 | |             nonlin: nonlinearity to use everywhere
242 | |             num_layers: non-negative number of linear layers in fnc
243 | | 
244 | |         """
    | |___________^ D401
245 |           super().__init__()
246 |           self.fiber = fiber
    |

geom3d\models\TFN_utils.py:258:9: ANN202 Missing return type annotation for private function `_build_net`
    |
256 |             self.transform[str(d)] = self._build_net(int(m))
257 | 
258 |     def _build_net(self, m: int):
    |         ^^^^^^^^^^ ANN202
259 |         net = []
260 |         for i in range(self.num_layers):
    |
    = help: Add return type annotation

geom3d\models\TFN_utils.py:263:15: TD002 Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
    |
261 |             net.append(BN(int(m)))
262 |             net.append(self.nonlin)
263 |             # TODO: implement cleaner init
    |               ^^^^ TD002
264 |             net.append(nn.Linear(m, m, bias=(i == self.num_layers - 1)))
265 |             nn.init.kaiming_uniform_(net[-1].weight)
    |

geom3d\models\TFN_utils.py:263:15: TD003 Missing issue link on the line following this TODO
    |
261 |             net.append(BN(int(m)))
262 |             net.append(self.nonlin)
263 |             # TODO: implement cleaner init
    |               ^^^^ TD003
264 |             net.append(nn.Linear(m, m, bias=(i == self.num_layers - 1)))
265 |             nn.init.kaiming_uniform_(net[-1].weight)
    |

geom3d\models\TFN_utils.py:263:15: FIX002 Line contains TODO, consider resolving the issue
    |
261 |             net.append(BN(int(m)))
262 |             net.append(self.nonlin)
263 |             # TODO: implement cleaner init
    |               ^^^^ FIX002
264 |             net.append(nn.Linear(m, m, bias=(i == self.num_layers - 1)))
265 |             nn.init.kaiming_uniform_(net[-1].weight)
    |

geom3d\models\TFN_utils.py:271:9: D102 Missing docstring in public method
    |
269 |         return nn.Sequential(*net)
270 | 
271 |     def forward(self, features, **kwargs):
    |         ^^^^^^^ D102
272 |         output = {}
273 |         for k, v in features.items():
    |

geom3d\models\TFN_utils.py:271:33: ANN003 Missing type annotation for `**kwargs`
    |
269 |         return nn.Sequential(*net)
270 | 
271 |     def forward(self, features, **kwargs):
    |                                 ^^^^^^^^ ANN003
272 |         output = {}
273 |         for k, v in features.items():
    |

geom3d\models\TFN_utils.py:271:35: ARG002 Unused method argument: `kwargs`
    |
269 |         return nn.Sequential(*net)
270 | 
271 |     def forward(self, features, **kwargs):
    |                                   ^^^^^^ ARG002
272 |         output = {}
273 |         for k, v in features.items():
    |

geom3d\models\TFN_utils.py:287:9: D105 Missing docstring in magic method
    |
285 |         return output
286 | 
287 |     def __repr__(self):
    |         ^^^^^^^^ D105
288 |         return f"GNormSE3(num_layers={self.num_layers}, nonlin={self.nonlin})"
    |

geom3d\models\TransformerM\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\TransformerM\__init__.py:1:28: F401 `.transformer_m.TransformerM` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .transformer_m import TransformerM
  |                            ^^^^^^^^^^^^ F401
2 | from .transformer_m_encoder import TransformerMEncoder, init_params
  |
  = help: Use an explicit re-export: `TransformerM as TransformerM`

geom3d\models\TransformerM\__init__.py:2:36: F401 `.transformer_m_encoder.TransformerMEncoder` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .transformer_m import TransformerM
2 | from .transformer_m_encoder import TransformerMEncoder, init_params
  |                                    ^^^^^^^^^^^^^^^^^^^ F401
  |
  = help: Use an explicit re-export: `TransformerMEncoder as TransformerMEncoder`

geom3d\models\TransformerM\__init__.py:2:57: F401 `.transformer_m_encoder.init_params` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .transformer_m import TransformerM
2 | from .transformer_m_encoder import TransformerMEncoder, init_params
  |                                                         ^^^^^^^^^^^ F401
  |
  = help: Use an explicit re-export: `init_params as init_params`

geom3d\models\TransformerM\layers\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\TransformerM\layers\__init__.py:1:34: F401 `.multihead_attention.MultiheadAttention` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .multihead_attention import MultiheadAttention
  |                                  ^^^^^^^^^^^^^^^^^^ F401
2 | from .transformer_m_encoder_layer import TransformerMEncoderLayer
3 | from .transformer_m_layers import AtomFeature, Molecule3DBias, MoleculeAttnBias
  |
  = help: Use an explicit re-export: `MultiheadAttention as MultiheadAttention`

geom3d\models\TransformerM\layers\__init__.py:2:42: F401 `.transformer_m_encoder_layer.TransformerMEncoderLayer` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .multihead_attention import MultiheadAttention
2 | from .transformer_m_encoder_layer import TransformerMEncoderLayer
  |                                          ^^^^^^^^^^^^^^^^^^^^^^^^ F401
3 | from .transformer_m_layers import AtomFeature, Molecule3DBias, MoleculeAttnBias
  |
  = help: Use an explicit re-export: `TransformerMEncoderLayer as TransformerMEncoderLayer`

geom3d\models\TransformerM\layers\__init__.py:3:35: F401 `.transformer_m_layers.AtomFeature` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .multihead_attention import MultiheadAttention
2 | from .transformer_m_encoder_layer import TransformerMEncoderLayer
3 | from .transformer_m_layers import AtomFeature, Molecule3DBias, MoleculeAttnBias
  |                                   ^^^^^^^^^^^ F401
  |
  = help: Use an explicit re-export: `AtomFeature as AtomFeature`

geom3d\models\TransformerM\layers\__init__.py:3:48: F401 `.transformer_m_layers.Molecule3DBias` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .multihead_attention import MultiheadAttention
2 | from .transformer_m_encoder_layer import TransformerMEncoderLayer
3 | from .transformer_m_layers import AtomFeature, Molecule3DBias, MoleculeAttnBias
  |                                                ^^^^^^^^^^^^^^ F401
  |
  = help: Use an explicit re-export: `Molecule3DBias as Molecule3DBias`

geom3d\models\TransformerM\layers\__init__.py:3:64: F401 `.transformer_m_layers.MoleculeAttnBias` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .multihead_attention import MultiheadAttention
2 | from .transformer_m_encoder_layer import TransformerMEncoderLayer
3 | from .transformer_m_layers import AtomFeature, Molecule3DBias, MoleculeAttnBias
  |                                                                ^^^^^^^^^^^^^^^^ F401
  |
  = help: Use an explicit re-export: `MoleculeAttnBias as MoleculeAttnBias`

geom3d\models\TransformerM\layers\multihead_attention.py:1:1: D100 Missing docstring in public module
geom3d\models\TransformerM\layers\multihead_attention.py:19:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
17 |     """
18 | 
19 |     def __init__(
   |         ^^^^^^^^ PLR0913
20 |         self,
21 |         embed_dim,
   |

geom3d\models\TransformerM\layers\multihead_attention.py:19:9: D107 Missing docstring in `__init__`
   |
17 |     """
18 | 
19 |     def __init__(
   |         ^^^^^^^^ D107
20 |         self,
21 |         embed_dim,
   |

geom3d\models\TransformerM\layers\multihead_attention.py:26:9: FBT002 Boolean default positional argument in function definition
   |
24 |         vdim=None,
25 |         dropout=0.0,
26 |         bias=True,
   |         ^^^^ FBT002
27 |         self_attention=False,
28 |         q_noise=0.0,
   |

geom3d\models\TransformerM\layers\multihead_attention.py:27:9: FBT002 Boolean default positional argument in function definition
   |
25 |         dropout=0.0,
26 |         bias=True,
27 |         self_attention=False,
   |         ^^^^^^^^^^^^^^ FBT002
28 |         q_noise=0.0,
29 |         qn_block_size=8,
   |

geom3d\models\TransformerM\layers\multihead_attention.py:43:9: S101 Use of `assert` detected
   |
42 |         self.head_dim = embed_dim // num_heads
43 |         assert (
   |         ^^^^^^ S101
44 |             self.head_dim * num_heads == self.embed_dim
45 |         ), "embed_dim must be divisible by num_heads"
   |

geom3d\models\TransformerM\layers\multihead_attention.py:50:9: S101 Use of `assert` detected
   |
48 |         self.self_attention = self_attention
49 | 
50 |         assert self.self_attention, "Only support self attention"
   |         ^^^^^^ S101
51 | 
52 |         assert not self.self_attention or self.qkv_same_dim, (
   |

geom3d\models\TransformerM\layers\multihead_attention.py:52:9: S101 Use of `assert` detected
   |
50 |         assert self.self_attention, "Only support self attention"
51 | 
52 |         assert not self.self_attention or self.qkv_same_dim, (
   |         ^^^^^^ S101
53 |             "Self-attention requires query, key and " "value to be of the same size"
54 |         )
   |

geom3d\models\TransformerM\layers\multihead_attention.py:74:9: D102 Missing docstring in public method
   |
72 |         self.onnx_trace = False
73 | 
74 |     def prepare_for_onnx_export_(self):
   |         ^^^^^^^^^^^^^^^^^^^^^^^^ D102
75 |         raise NotImplementedError
   |

geom3d\models\TransformerM\layers\multihead_attention.py:77:9: D102 Missing docstring in public method
   |
75 |         raise NotImplementedError
76 | 
77 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
78 |         if self.qkv_same_dim:
79 |             # Empirically observed the convergence to be much better with
   |

geom3d\models\TransformerM\layers\multihead_attention.py:93:9: C901 `forward` is too complex (14 > 10)
   |
91 |             nn.init.constant_(self.out_proj.bias, 0.0)
92 | 
93 |     def forward(
   |         ^^^^^^^ C901
94 |         self,
95 |         query,
   |

geom3d\models\TransformerM\layers\multihead_attention.py:93:9: PLR0913 Too many arguments in function definition (9 > 5)
   |
91 |             nn.init.constant_(self.out_proj.bias, 0.0)
92 | 
93 |     def forward(
   |         ^^^^^^^ PLR0913
94 |         self,
95 |         query,
   |

geom3d\models\TransformerM\layers\multihead_attention.py:93:9: PLR0912 Too many branches (13 > 12)
   |
91 |             nn.init.constant_(self.out_proj.bias, 0.0)
92 | 
93 |     def forward(
   |         ^^^^^^^ PLR0912
94 |         self,
95 |         query,
   |

geom3d\models\TransformerM\layers\multihead_attention.py:93:9: PLR0915 Too many statements (55 > 50)
   |
91 |             nn.init.constant_(self.out_proj.bias, 0.0)
92 | 
93 |     def forward(
   |         ^^^^^^^ PLR0915
94 |         self,
95 |         query,
   |

geom3d\models\TransformerM\layers\multihead_attention.py:93:9: D417 Missing argument descriptions in the docstring for `forward`: `attn_bias`, `key`, `query`, `value`
   |
91 |             nn.init.constant_(self.out_proj.bias, 0.0)
92 | 
93 |     def forward(
   |         ^^^^^^^ D417
94 |         self,
95 |         query,
   |

geom3d\models\TransformerM\layers\multihead_attention.py:96:14: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
94 |         self,
95 |         query,
96 |         key: Optional[Tensor],
   |              ^^^^^^^^ FA100
97 |         value: Optional[Tensor],
98 |         attn_bias: Optional[Tensor],
   |

geom3d\models\TransformerM\layers\multihead_attention.py:97:16: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
95 |         query,
96 |         key: Optional[Tensor],
97 |         value: Optional[Tensor],
   |                ^^^^^^^^ FA100
98 |         attn_bias: Optional[Tensor],
99 |         key_padding_mask: Optional[Tensor] = None,
   |

geom3d\models\TransformerM\layers\multihead_attention.py:98:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
 96 |         key: Optional[Tensor],
 97 |         value: Optional[Tensor],
 98 |         attn_bias: Optional[Tensor],
    |                    ^^^^^^^^ FA100
 99 |         key_padding_mask: Optional[Tensor] = None,
100 |         need_weights: bool = True,
    |

geom3d\models\TransformerM\layers\multihead_attention.py:99:27: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
 97 |         value: Optional[Tensor],
 98 |         attn_bias: Optional[Tensor],
 99 |         key_padding_mask: Optional[Tensor] = None,
    |                           ^^^^^^^^ FA100
100 |         need_weights: bool = True,
101 |         attn_mask: Optional[Tensor] = None,
    |

geom3d\models\TransformerM\layers\multihead_attention.py:100:9: FBT001 Boolean-typed positional argument in function definition
    |
 98 |         attn_bias: Optional[Tensor],
 99 |         key_padding_mask: Optional[Tensor] = None,
100 |         need_weights: bool = True,
    |         ^^^^^^^^^^^^ FBT001
101 |         attn_mask: Optional[Tensor] = None,
102 |         before_softmax: bool = False,
    |

geom3d\models\TransformerM\layers\multihead_attention.py:100:9: FBT002 Boolean default positional argument in function definition
    |
 98 |         attn_bias: Optional[Tensor],
 99 |         key_padding_mask: Optional[Tensor] = None,
100 |         need_weights: bool = True,
    |         ^^^^^^^^^^^^ FBT002
101 |         attn_mask: Optional[Tensor] = None,
102 |         before_softmax: bool = False,
    |

geom3d\models\TransformerM\layers\multihead_attention.py:101:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
 99 |         key_padding_mask: Optional[Tensor] = None,
100 |         need_weights: bool = True,
101 |         attn_mask: Optional[Tensor] = None,
    |                    ^^^^^^^^ FA100
102 |         before_softmax: bool = False,
103 |         need_head_weights: bool = False,
    |

geom3d\models\TransformerM\layers\multihead_attention.py:102:9: FBT001 Boolean-typed positional argument in function definition
    |
100 |         need_weights: bool = True,
101 |         attn_mask: Optional[Tensor] = None,
102 |         before_softmax: bool = False,
    |         ^^^^^^^^^^^^^^ FBT001
103 |         need_head_weights: bool = False,
104 |     ) -> Tuple[Tensor, Optional[Tensor]]:
    |

geom3d\models\TransformerM\layers\multihead_attention.py:102:9: FBT002 Boolean default positional argument in function definition
    |
100 |         need_weights: bool = True,
101 |         attn_mask: Optional[Tensor] = None,
102 |         before_softmax: bool = False,
    |         ^^^^^^^^^^^^^^ FBT002
103 |         need_head_weights: bool = False,
104 |     ) -> Tuple[Tensor, Optional[Tensor]]:
    |

geom3d\models\TransformerM\layers\multihead_attention.py:103:9: FBT001 Boolean-typed positional argument in function definition
    |
101 |         attn_mask: Optional[Tensor] = None,
102 |         before_softmax: bool = False,
103 |         need_head_weights: bool = False,
    |         ^^^^^^^^^^^^^^^^^ FBT001
104 |     ) -> Tuple[Tensor, Optional[Tensor]]:
105 |         """Input shape: Time x Batch x Channel.
    |

geom3d\models\TransformerM\layers\multihead_attention.py:103:9: FBT002 Boolean default positional argument in function definition
    |
101 |         attn_mask: Optional[Tensor] = None,
102 |         before_softmax: bool = False,
103 |         need_head_weights: bool = False,
    |         ^^^^^^^^^^^^^^^^^ FBT002
104 |     ) -> Tuple[Tensor, Optional[Tensor]]:
105 |         """Input shape: Time x Batch x Channel.
    |

geom3d\models\TransformerM\layers\multihead_attention.py:104:10: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
    |
102 |         before_softmax: bool = False,
103 |         need_head_weights: bool = False,
104 |     ) -> Tuple[Tensor, Optional[Tensor]]:
    |          ^^^^^ FA100
105 |         """Input shape: Time x Batch x Channel.
    |

geom3d\models\TransformerM\layers\multihead_attention.py:104:24: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
102 |         before_softmax: bool = False,
103 |         need_head_weights: bool = False,
104 |     ) -> Tuple[Tensor, Optional[Tensor]]:
    |                        ^^^^^^^^ FA100
105 |         """Input shape: Time x Batch x Channel.
    |

geom3d\models\TransformerM\layers\multihead_attention.py:129:9: S101 Use of `assert` detected
    |
127 |         tgt_len, bsz, embed_dim = query.size()
128 |         src_len = tgt_len
129 |         assert embed_dim == self.embed_dim, f"query dim {embed_dim} != {self.embed_dim}"
    |         ^^^^^^ S101
130 |         assert list(query.size()) == [tgt_len, bsz, embed_dim]
131 |         if key is not None:
    |

geom3d\models\TransformerM\layers\multihead_attention.py:130:9: S101 Use of `assert` detected
    |
128 |         src_len = tgt_len
129 |         assert embed_dim == self.embed_dim, f"query dim {embed_dim} != {self.embed_dim}"
130 |         assert list(query.size()) == [tgt_len, bsz, embed_dim]
    |         ^^^^^^ S101
131 |         if key is not None:
132 |             src_len, key_bsz, _ = key.size()
    |

geom3d\models\TransformerM\layers\multihead_attention.py:134:17: S101 Use of `assert` detected
    |
132 |             src_len, key_bsz, _ = key.size()
133 |             if not torch.jit.is_scripting():
134 |                 assert key_bsz == bsz
    |                 ^^^^^^ S101
135 |                 assert value is not None
136 |                 assert src_len, bsz == value.shape[:2]
    |

geom3d\models\TransformerM\layers\multihead_attention.py:135:17: S101 Use of `assert` detected
    |
133 |             if not torch.jit.is_scripting():
134 |                 assert key_bsz == bsz
135 |                 assert value is not None
    |                 ^^^^^^ S101
136 |                 assert src_len, bsz == value.shape[:2]
    |

geom3d\models\TransformerM\layers\multihead_attention.py:136:17: S101 Use of `assert` detected
    |
134 |                 assert key_bsz == bsz
135 |                 assert value is not None
136 |                 assert src_len, bsz == value.shape[:2]
    |                 ^^^^^^ S101
137 | 
138 |         q = self.q_proj(query)
    |

geom3d\models\TransformerM\layers\multihead_attention.py:161:9: S101 Use of `assert` detected
    |
159 |             )
160 | 
161 |         assert k is not None
    |         ^^^^^^ S101
162 |         assert k.size(1) == src_len
    |

geom3d\models\TransformerM\layers\multihead_attention.py:162:9: S101 Use of `assert` detected
    |
161 |         assert k is not None
162 |         assert k.size(1) == src_len
    |         ^^^^^^ S101
163 | 
164 |         # This is part of a workaround to get around fork/join parallelism
    |

geom3d\models\TransformerM\layers\multihead_attention.py:170:13: S101 Use of `assert` detected
    |
169 |         if key_padding_mask is not None:
170 |             assert key_padding_mask.size(0) == bsz
    |             ^^^^^^ S101
171 |             assert key_padding_mask.size(1) == src_len
172 |         attn_weights = torch.bmm(q, k.transpose(1, 2))
    |

geom3d\models\TransformerM\layers\multihead_attention.py:171:13: S101 Use of `assert` detected
    |
169 |         if key_padding_mask is not None:
170 |             assert key_padding_mask.size(0) == bsz
171 |             assert key_padding_mask.size(1) == src_len
    |             ^^^^^^ S101
172 |         attn_weights = torch.bmm(q, k.transpose(1, 2))
173 |         attn_weights = self.apply_sparse_mask(attn_weights, tgt_len, src_len, bsz)
    |

geom3d\models\TransformerM\layers\multihead_attention.py:175:9: S101 Use of `assert` detected
    |
173 |         attn_weights = self.apply_sparse_mask(attn_weights, tgt_len, src_len, bsz)
174 | 
175 |         assert list(attn_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]
    |         ^^^^^^ S101
176 | 
177 |         if attn_bias is not None:
    |

geom3d\models\TransformerM\layers\multihead_attention.py:202:9: S101 Use of `assert` detected
    |
200 |         attn_probs = self.dropout_module(attn_weights)
201 | 
202 |         assert v is not None
    |         ^^^^^^ S101
203 |         attn = torch.bmm(attn_probs, v)
204 |         assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]
    |

geom3d\models\TransformerM\layers\multihead_attention.py:204:9: S101 Use of `assert` detected
    |
202 |         assert v is not None
203 |         attn = torch.bmm(attn_probs, v)
204 |         assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]
    |         ^^^^^^ S101
205 | 
206 |         attn = attn.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)
    |

geom3d\models\TransformerM\layers\multihead_attention.py:209:23: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
207 |         attn = self.out_proj(attn)
208 | 
209 |         attn_weights: Optional[Tensor] = None
    |                       ^^^^^^^^ FA100
210 |         if need_weights:
211 |             attn_weights = attn_weights_float.view(
    |

geom3d\models\TransformerM\layers\multihead_attention.py:220:9: D102 Missing docstring in public method
    |
218 |         return attn, attn_weights
219 | 
220 |     def apply_sparse_mask(self, attn_weights, tgt_len: int, src_len: int, bsz: int):
    |         ^^^^^^^^^^^^^^^^^ D102
221 |         return attn_weights
    |

geom3d\models\TransformerM\layers\multihead_attention.py:220:47: ARG002 Unused method argument: `tgt_len`
    |
218 |         return attn, attn_weights
219 | 
220 |     def apply_sparse_mask(self, attn_weights, tgt_len: int, src_len: int, bsz: int):
    |                                               ^^^^^^^ ARG002
221 |         return attn_weights
    |

geom3d\models\TransformerM\layers\multihead_attention.py:220:61: ARG002 Unused method argument: `src_len`
    |
218 |         return attn, attn_weights
219 | 
220 |     def apply_sparse_mask(self, attn_weights, tgt_len: int, src_len: int, bsz: int):
    |                                                             ^^^^^^^ ARG002
221 |         return attn_weights
    |

geom3d\models\TransformerM\layers\multihead_attention.py:220:75: ARG002 Unused method argument: `bsz`
    |
218 |         return attn, attn_weights
219 | 
220 |     def apply_sparse_mask(self, attn_weights, tgt_len: int, src_len: int, bsz: int):
    |                                                                           ^^^ ARG002
221 |         return attn_weights
    |

geom3d\models\TransformerM\layers\multihead_attention.py:223:9: D102 Missing docstring in public method
    |
221 |         return attn_weights
222 | 
223 |     def upgrade_state_dict_named(self, state_dict, name):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^ D102
224 |         prefix = name + "." if name != "" else ""
225 |         items_to_add = {}
    |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:1:1: D100 Missing docstring in public module
geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:19:9: PLR0913 Too many arguments in function definition (13 > 5)
   |
17 |     """Implements a Transformer-M Encoder Layer."""
18 | 
19 |     def __init__(
   |         ^^^^^^^^ PLR0913
20 |         self,
21 |         embedding_dim: int = 768,
   |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:19:9: D107 Missing docstring in `__init__`
   |
17 |     """Implements a Transformer-M Encoder Layer."""
18 | 
19 |     def __init__(
   |         ^^^^^^^^ D107
20 |         self,
21 |         embedding_dim: int = 768,
   |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:28:9: FBT001 Boolean-typed positional argument in function definition
   |
26 |         activation_dropout: float = 0.1,
27 |         activation_fn: str = "relu",
28 |         export: bool = False,
   |         ^^^^^^ FBT001
29 |         q_noise: float = 0.0,
30 |         qn_block_size: int = 8,
   |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:28:9: FBT002 Boolean default positional argument in function definition
   |
26 |         activation_dropout: float = 0.1,
27 |         activation_fn: str = "relu",
28 |         export: bool = False,
   |         ^^^^^^ FBT002
29 |         q_noise: float = 0.0,
30 |         qn_block_size: int = 8,
   |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:31:18: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
29 |         q_noise: float = 0.0,
30 |         qn_block_size: int = 8,
31 |         init_fn: Optional[Callable] = None,
   |                  ^^^^^^^^ FA100
32 |         sandwich_ln: bool = False,
33 |         droppath_prob: float = 0.0,
   |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:32:9: FBT001 Boolean-typed positional argument in function definition
   |
30 |         qn_block_size: int = 8,
31 |         init_fn: Optional[Callable] = None,
32 |         sandwich_ln: bool = False,
   |         ^^^^^^^^^^^ FBT001
33 |         droppath_prob: float = 0.0,
34 |     ) -> None:
   |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:32:9: FBT002 Boolean default positional argument in function definition
   |
30 |         qn_block_size: int = 8,
31 |         init_fn: Optional[Callable] = None,
32 |         sandwich_ln: bool = False,
   |         ^^^^^^^^^^^ FBT002
33 |         droppath_prob: float = 0.0,
34 |     ) -> None:
   |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:95:9: D102 Missing docstring in public method
   |
93 |         self.final_sandwich_layer_norm = LayerNorm(self.embedding_dim, export=export) if self.sandwich_ln else None
94 | 
95 |     def build_fc1(self, input_dim, output_dim, q_noise, qn_block_size):
   |         ^^^^^^^^^ D102
96 |         return quant_noise(nn.Linear(input_dim, output_dim), q_noise, qn_block_size)
   |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:98:9: D102 Missing docstring in public method
   |
96 |         return quant_noise(nn.Linear(input_dim, output_dim), q_noise, qn_block_size)
97 | 
98 |     def build_fc2(self, input_dim, output_dim, q_noise, qn_block_size):
   |         ^^^^^^^^^ D102
99 |         return quant_noise(nn.Linear(input_dim, output_dim), q_noise, qn_block_size)
   |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:101:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
 99 |         return quant_noise(nn.Linear(input_dim, output_dim), q_noise, qn_block_size)
100 | 
101 |     def build_self_attention(
    |         ^^^^^^^^^^^^^^^^^^^^ PLR0913
102 |         self,
103 |         embed_dim,
    |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:101:9: D102 Missing docstring in public method
    |
 99 |         return quant_noise(nn.Linear(input_dim, output_dim), q_noise, qn_block_size)
100 | 
101 |     def build_self_attention(
    |         ^^^^^^^^^^^^^^^^^^^^ D102
102 |         self,
103 |         embed_dim,
    |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:106:9: ARG002 Unused method argument: `self_attention`
    |
104 |         num_attention_heads,
105 |         dropout,
106 |         self_attention,
    |         ^^^^^^^^^^^^^^ ARG002
107 |         q_noise,
108 |         qn_block_size,
    |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:122:25: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
120 |         self,
121 |         x: torch.Tensor,
122 |         self_attn_bias: Optional[torch.Tensor] = None,
    |                         ^^^^^^^^ FA100
123 |         self_attn_mask: Optional[torch.Tensor] = None,
124 |         self_attn_padding_mask: Optional[torch.Tensor] = None,
    |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:123:25: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
121 |         x: torch.Tensor,
122 |         self_attn_bias: Optional[torch.Tensor] = None,
123 |         self_attn_mask: Optional[torch.Tensor] = None,
    |                         ^^^^^^^^ FA100
124 |         self_attn_padding_mask: Optional[torch.Tensor] = None,
125 |     ):
    |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:124:33: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
122 |         self_attn_bias: Optional[torch.Tensor] = None,
123 |         self_attn_mask: Optional[torch.Tensor] = None,
124 |         self_attn_padding_mask: Optional[torch.Tensor] = None,
    |                                 ^^^^^^^^ FA100
125 |     ):
126 |         """LayerNorm is applied either before or after the self-attention/ffn
    |

geom3d\models\TransformerM\layers\transformer_m_encoder_layer.py:126:9: D205 1 blank line required between summary line and description
    |
124 |           self_attn_padding_mask: Optional[torch.Tensor] = None,
125 |       ):
126 |           """LayerNorm is applied either before or after the self-attention/ffn
    |  _________^
127 | |         modules similar to the original Transformer implementation.
128 | |         """
    | |___________^ D205
129 |           # x: T x B x C
130 |           residual = x
    |
    = help: Insert single blank line

geom3d\models\TransformerM\layers\transformer_m_layers.py:1:1: D100 Missing docstring in public module
geom3d\models\TransformerM\layers\transformer_m_layers.py:5:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
4 | import torch
5 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
6 | from stk_search.geom3d.models.TransformerM.modules import FairseqDropout, utils
7 | from torch import Tensor, nn
  |

geom3d\models\TransformerM\layers\transformer_m_layers.py:10:5: D103 Missing docstring in public function
   |
10 | def init_params(module, n_layers):
   |     ^^^^^^^^^^^ D103
11 |     if isinstance(module, nn.Linear):
12 |         module.weight.data.normal_(mean=0.0, std=0.02 / math.sqrt(n_layers))
   |

geom3d\models\TransformerM\layers\transformer_m_layers.py:22:9: PLR0913 Too many arguments in function definition (7 > 5)
   |
20 |     """Compute atom features for each atom in the molecule."""
21 | 
22 |     def __init__(self, num_heads, num_atoms, num_in_degree, num_out_degree, hidden_dim, n_layers, no_2d=False):
   |         ^^^^^^^^ PLR0913
23 |         super().__init__()
24 |         self.num_heads = num_heads
   |

geom3d\models\TransformerM\layers\transformer_m_layers.py:22:9: D107 Missing docstring in `__init__`
   |
20 |     """Compute atom features for each atom in the molecule."""
21 | 
22 |     def __init__(self, num_heads, num_atoms, num_in_degree, num_out_degree, hidden_dim, n_layers, no_2d=False):
   |         ^^^^^^^^ D107
23 |         super().__init__()
24 |         self.num_heads = num_heads
   |

geom3d\models\TransformerM\layers\transformer_m_layers.py:22:99: FBT002 Boolean default positional argument in function definition
   |
20 |     """Compute atom features for each atom in the molecule."""
21 | 
22 |     def __init__(self, num_heads, num_atoms, num_in_degree, num_out_degree, hidden_dim, n_layers, no_2d=False):
   |                                                                                                   ^^^^^ FBT002
23 |         super().__init__()
24 |         self.num_heads = num_heads
   |

geom3d\models\TransformerM\layers\transformer_m_layers.py:37:9: D102 Missing docstring in public method
   |
35 |         self.apply(lambda module: init_params(module, n_layers=n_layers))
36 | 
37 |     def forward(self, batched_data, mask_2d=None):
   |         ^^^^^^^ D102
38 |         x, in_degree, out_degree = batched_data["x"],batched_data["in_degree"], batched_data["out_degree"]
39 |         n_graph, n_node = x.size()[:2]
   |

geom3d\models\TransformerM\layers\transformer_m_layers.py:59:9: PLR0913 Too many arguments in function definition (10 > 5)
   |
57 |     """Compute attention bias for each head."""
58 | 
59 |     def __init__(self, num_heads, num_atoms, num_edges, num_spatial, num_edge_dis, hidden_dim, edge_type, multi_hop_max_dist, n_layers, no_2d=False):
   |         ^^^^^^^^ PLR0913
60 |         super().__init__()
61 |         self.num_heads = num_heads
   |

geom3d\models\TransformerM\layers\transformer_m_layers.py:59:9: D107 Missing docstring in `__init__`
   |
57 |     """Compute attention bias for each head."""
58 | 
59 |     def __init__(self, num_heads, num_atoms, num_edges, num_spatial, num_edge_dis, hidden_dim, edge_type, multi_hop_max_dist, n_layers, no_2d=False):
   |         ^^^^^^^^ D107
60 |         super().__init__()
61 |         self.num_heads = num_heads
   |

geom3d\models\TransformerM\layers\transformer_m_layers.py:59:35: ARG002 Unused method argument: `num_atoms`
   |
57 |     """Compute attention bias for each head."""
58 | 
59 |     def __init__(self, num_heads, num_atoms, num_edges, num_spatial, num_edge_dis, hidden_dim, edge_type, multi_hop_max_dist, n_layers, no_2d=False):
   |                                   ^^^^^^^^^ ARG002
60 |         super().__init__()
61 |         self.num_heads = num_heads
   |

geom3d\models\TransformerM\layers\transformer_m_layers.py:59:84: ARG002 Unused method argument: `hidden_dim`
   |
57 |     """Compute attention bias for each head."""
58 | 
59 |     def __init__(self, num_heads, num_atoms, num_edges, num_spatial, num_edge_dis, hidden_dim, edge_type, multi_hop_max_dist, n_layers, no_2d=False):
   |                                                                                    ^^^^^^^^^^ ARG002
60 |         super().__init__()
61 |         self.num_heads = num_heads
   |

geom3d\models\TransformerM\layers\transformer_m_layers.py:59:137: FBT002 Boolean default positional argument in function definition
   |
57 |     """Compute attention bias for each head."""
58 | 
59 |     def __init__(self, num_heads, num_atoms, num_edges, num_spatial, num_edge_dis, hidden_dim, edge_type, multi_hop_max_dist, n_layers, no_2d=False):
   |                                                                                                                                         ^^^^^ FBT002
60 |         super().__init__()
61 |         self.num_heads = num_heads
   |

geom3d\models\TransformerM\layers\transformer_m_layers.py:77:9: D102 Missing docstring in public method
   |
75 |         self.apply(lambda module: init_params(module, n_layers=n_layers))
76 | 
77 |     def forward(self, batched_data, mask_2d=None):
   |         ^^^^^^^ D102
78 |         attn_bias, spatial_pos, x = batched_data["attn_bias"], batched_data["spatial_pos"], batched_data["x"]
79 |         edge_input, attn_edge_type = batched_data["edge_input"], batched_data["attn_edge_type"]
   |

geom3d\models\TransformerM\layers\transformer_m_layers.py:110:17: ERA001 Found commented-out code
    |
108 |                     spatial_pos_ = spatial_pos_.clamp(0, self.multi_hop_max_dist)
109 |                     edge_input = edge_input[:, :, :, :self.multi_hop_max_dist, :]
110 |                 # [n_graph, n_node, n_node, max_dist, n_head]
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
111 |                 edge_input = self.edge_encoder(edge_input).mean(-2)
112 |                 max_dist = edge_input.size(-2)
    |
    = help: Remove commented-out code

geom3d\models\TransformerM\layers\transformer_m_layers.py:139:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
137 |     """Compute 3D attention bias according to the position information for each head."""
138 | 
139 |     def __init__(self, num_heads, num_edges, n_layers, embed_dim, num_kernel, no_share_rpe=False):
    |         ^^^^^^^^ PLR0913
140 |         super().__init__()
141 |         self.num_heads = num_heads
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:139:9: D107 Missing docstring in `__init__`
    |
137 |     """Compute 3D attention bias according to the position information for each head."""
138 | 
139 |     def __init__(self, num_heads, num_edges, n_layers, embed_dim, num_kernel, no_share_rpe=False):
    |         ^^^^^^^^ D107
140 |         super().__init__()
141 |         self.num_heads = num_heads
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:139:79: FBT002 Boolean default positional argument in function definition
    |
137 |     """Compute 3D attention bias according to the position information for each head."""
138 | 
139 |     def __init__(self, num_heads, num_edges, n_layers, embed_dim, num_kernel, no_share_rpe=False):
    |                                                                               ^^^^^^^^^^^^ FBT002
140 |         super().__init__()
141 |         self.num_heads = num_heads
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:158:9: D102 Missing docstring in public method
    |
156 |             self.edge_proj = None
157 | 
158 |     def forward(self, batched_data):
    |         ^^^^^^^ D102
159 | 
160 |         pos, x, node_type_edge = batched_data["pos"], batched_data["x"], batched_data["node_type_edge"] # pos shape: [n_graphs, n_nodes, 3]
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:161:9: ERA001 Found commented-out code
    |
160 |         pos, x, node_type_edge = batched_data["pos"], batched_data["x"], batched_data["node_type_edge"] # pos shape: [n_graphs, n_nodes, 3]
161 |         # pos.requires_grad_(True)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
162 | 
163 |         padding_mask = x.eq(0).all(dim=-1)
    |
    = help: Remove commented-out code

geom3d\models\TransformerM\layers\transformer_m_layers.py:189:5: D103 Missing docstring in public function
    |
188 | @torch.jit.script
189 | def gaussian(x, mean, std):
    |     ^^^^^^^^ D103
190 |     pi = 3.14159
191 |     a = (2*pi) ** 0.5
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:194:7: D101 Missing docstring in public class
    |
192 |     return torch.exp(-0.5 * (((x - mean) / std) ** 2)) / (a * std)
193 | 
194 | class GaussianLayer(nn.Module):
    |       ^^^^^^^^^^^^^ D101
195 |     def __init__(self, K=128, edge_types=512*3):
196 |         super().__init__()
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:195:9: D107 Missing docstring in `__init__`
    |
194 | class GaussianLayer(nn.Module):
195 |     def __init__(self, K=128, edge_types=512*3):
    |         ^^^^^^^^ D107
196 |         super().__init__()
197 |         self.K = K
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:195:24: N803 Argument name `K` should be lowercase
    |
194 | class GaussianLayer(nn.Module):
195 |     def __init__(self, K=128, edge_types=512*3):
    |                        ^ N803
196 |         super().__init__()
197 |         self.K = K
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:207:9: D102 Missing docstring in public method
    |
205 |         nn.init.constant_(self.mul.weight, 1)
206 | 
207 |     def forward(self, x, edge_types):
    |         ^^^^^^^ D102
208 |         mul = self.mul(edge_types).sum(dim=-2)
209 |         bias = self.bias(edge_types).sum(dim=-2)
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:216:7: D101 Missing docstring in public class
    |
214 |         return gaussian(x.float(), mean, std).type_as(self.means.weight)
215 | 
216 | class NonLinear(nn.Module):
    |       ^^^^^^^^^ D101
217 |     def __init__(self, input, output_size, hidden=None):
218 |         super().__init__()
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:217:9: D107 Missing docstring in `__init__`
    |
216 | class NonLinear(nn.Module):
217 |     def __init__(self, input, output_size, hidden=None):
    |         ^^^^^^^^ D107
218 |         super().__init__()
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:217:24: A002 Argument `input` is shadowing a Python builtin
    |
216 | class NonLinear(nn.Module):
217 |     def __init__(self, input, output_size, hidden=None):
    |                        ^^^^^ A002
218 |         super().__init__()
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:225:9: D102 Missing docstring in public method
    |
223 |         self.layer2 = nn.Linear(hidden, output_size)
224 | 
225 |     def forward(self, x):
    |         ^^^^^^^ D102
226 |         x = self.layer1(x)
227 |         x = F.gelu(x)
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:231:7: D101 Missing docstring in public class
    |
231 | class AtomTaskHead(nn.Module):
    |       ^^^^^^^^^^^^ D101
232 |     def __init__(
233 |         self,
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:232:9: D107 Missing docstring in `__init__`
    |
231 | class AtomTaskHead(nn.Module):
232 |     def __init__(
    |         ^^^^^^^^ D107
233 |         self,
234 |         embed_dim: int,
    |

geom3d\models\TransformerM\layers\transformer_m_layers.py:252:9: D102 Missing docstring in public method
    |
250 |         )
251 | 
252 |     def forward(
    |         ^^^^^^^ D102
253 |         self,
254 |         query: Tensor,
    |

geom3d\models\TransformerM\modules\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\TransformerM\modules\__init__.py:1:23: F401 `.droppath.DropPath` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .droppath import DropPath
  |                       ^^^^^^^^ F401
2 | from .fairseq_dropout import FairseqDropout
3 | from .layer_drop import LayerDropModuleList
  |
  = help: Use an explicit re-export: `DropPath as DropPath`

geom3d\models\TransformerM\modules\__init__.py:2:30: F401 `.fairseq_dropout.FairseqDropout` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .droppath import DropPath
2 | from .fairseq_dropout import FairseqDropout
  |                              ^^^^^^^^^^^^^^ F401
3 | from .layer_drop import LayerDropModuleList
4 | from .layer_norm import LayerNorm
  |
  = help: Use an explicit re-export: `FairseqDropout as FairseqDropout`

geom3d\models\TransformerM\modules\__init__.py:3:25: F401 `.layer_drop.LayerDropModuleList` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | from .droppath import DropPath
2 | from .fairseq_dropout import FairseqDropout
3 | from .layer_drop import LayerDropModuleList
  |                         ^^^^^^^^^^^^^^^^^^^ F401
4 | from .layer_norm import LayerNorm
5 | from .quant_noise import quant_noise
  |
  = help: Use an explicit re-export: `LayerDropModuleList as LayerDropModuleList`

geom3d\models\TransformerM\modules\__init__.py:4:25: F401 `.layer_norm.LayerNorm` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
2 | from .fairseq_dropout import FairseqDropout
3 | from .layer_drop import LayerDropModuleList
4 | from .layer_norm import LayerNorm
  |                         ^^^^^^^^^ F401
5 | from .quant_noise import quant_noise
  |
  = help: Use an explicit re-export: `LayerNorm as LayerNorm`

geom3d\models\TransformerM\modules\__init__.py:5:26: F401 `.quant_noise.quant_noise` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
3 | from .layer_drop import LayerDropModuleList
4 | from .layer_norm import LayerNorm
5 | from .quant_noise import quant_noise
  |                          ^^^^^^^^^^^ F401
  |
  = help: Use an explicit re-export: `quant_noise as quant_noise`

geom3d\models\TransformerM\modules\droppath.py:1:1: D100 Missing docstring in public module
geom3d\models\TransformerM\modules\droppath.py:7:9: D107 Missing docstring in `__init__`
  |
5 |     """Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks)."""
6 | 
7 |     def __init__(self, prob=None):
  |         ^^^^^^^^ D107
8 |         super().__init__()
9 |         self.drop_prob = prob
  |

geom3d\models\TransformerM\modules\droppath.py:11:9: D102 Missing docstring in public method
   |
 9 |         self.drop_prob = prob
10 | 
11 |     def forward(self, x):
   |         ^^^^^^^ D102
12 |         if self.drop_prob == 0.0 or not self.training:
13 |             return x
   |

geom3d\models\TransformerM\modules\droppath.py:22:9: D102 Missing docstring in public method
   |
20 |         return x.div(keep_prob) * random_tensor
21 | 
22 |     def extra_repr(self) -> str:
   |         ^^^^^^^^^^ D102
23 |         return f"prob={self.drop_prob}"
   |

geom3d\models\TransformerM\modules\fairseq_dropout.py:1:1: D100 Missing docstring in public module
geom3d\models\TransformerM\modules\fairseq_dropout.py:3:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | from typing import List, Optional
2 | 
3 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
4 | from torch import nn
  |

geom3d\models\TransformerM\modules\fairseq_dropout.py:7:7: D101 Missing docstring in public class
  |
7 | class FairseqDropout(nn.Module):
  |       ^^^^^^^^^^^^^^ D101
8 |     def __init__(self, p, module_name=None):
9 |         super().__init__()
  |

geom3d\models\TransformerM\modules\fairseq_dropout.py:8:9: D107 Missing docstring in `__init__`
   |
 7 | class FairseqDropout(nn.Module):
 8 |     def __init__(self, p, module_name=None):
   |         ^^^^^^^^ D107
 9 |         super().__init__()
10 |         self.p = p
   |

geom3d\models\TransformerM\modules\fairseq_dropout.py:14:9: D102 Missing docstring in public method
   |
12 |         self.apply_during_inference = False
13 | 
14 |     def forward(self, x, inplace: bool = False):
   |         ^^^^^^^ D102
15 |         if self.p > 0 and (self.training or self.apply_during_inference):
16 |             return F.dropout(x, p=self.p, training=True, inplace=inplace)
   |

geom3d\models\TransformerM\modules\fairseq_dropout.py:14:26: FBT001 Boolean-typed positional argument in function definition
   |
12 |         self.apply_during_inference = False
13 | 
14 |     def forward(self, x, inplace: bool = False):
   |                          ^^^^^^^ FBT001
15 |         if self.p > 0 and (self.training or self.apply_during_inference):
16 |             return F.dropout(x, p=self.p, training=True, inplace=inplace)
   |

geom3d\models\TransformerM\modules\fairseq_dropout.py:14:26: FBT002 Boolean default positional argument in function definition
   |
12 |         self.apply_during_inference = False
13 | 
14 |     def forward(self, x, inplace: bool = False):
   |                          ^^^^^^^ FBT002
15 |         if self.p > 0 and (self.training or self.apply_during_inference):
16 |             return F.dropout(x, p=self.p, training=True, inplace=inplace)
   |

geom3d\models\TransformerM\modules\fairseq_dropout.py:17:9: RET505 Unnecessary `else` after `return` statement
   |
15 |         if self.p > 0 and (self.training or self.apply_during_inference):
16 |             return F.dropout(x, p=self.p, training=True, inplace=inplace)
17 |         else:
   |         ^^^^ RET505
18 |             return x
   |
   = help: Remove unnecessary `else`

geom3d\models\TransformerM\modules\fairseq_dropout.py:20:9: D102 Missing docstring in public method
   |
18 |             return x
19 | 
20 |     def make_generation_fast_(
   |         ^^^^^^^^^^^^^^^^^^^^^ D102
21 |         self,
22 |         name: str,
   |

geom3d\models\TransformerM\modules\fairseq_dropout.py:22:9: ARG002 Unused method argument: `name`
   |
20 |     def make_generation_fast_(
21 |         self,
22 |         name: str,
   |         ^^^^ ARG002
23 |         retain_dropout: bool = False,
24 |         retain_dropout_modules: Optional[List[str]] = None,
   |

geom3d\models\TransformerM\modules\fairseq_dropout.py:23:9: FBT001 Boolean-typed positional argument in function definition
   |
21 |         self,
22 |         name: str,
23 |         retain_dropout: bool = False,
   |         ^^^^^^^^^^^^^^ FBT001
24 |         retain_dropout_modules: Optional[List[str]] = None,
25 |         **kwargs
   |

geom3d\models\TransformerM\modules\fairseq_dropout.py:23:9: FBT002 Boolean default positional argument in function definition
   |
21 |         self,
22 |         name: str,
23 |         retain_dropout: bool = False,
   |         ^^^^^^^^^^^^^^ FBT002
24 |         retain_dropout_modules: Optional[List[str]] = None,
25 |         **kwargs
   |

geom3d\models\TransformerM\modules\fairseq_dropout.py:24:33: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
22 |         name: str,
23 |         retain_dropout: bool = False,
24 |         retain_dropout_modules: Optional[List[str]] = None,
   |                                 ^^^^^^^^ FA100
25 |         **kwargs
26 |     ):
   |

geom3d\models\TransformerM\modules\fairseq_dropout.py:24:42: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
22 |         name: str,
23 |         retain_dropout: bool = False,
24 |         retain_dropout_modules: Optional[List[str]] = None,
   |                                          ^^^^ FA100
25 |         **kwargs
26 |     ):
   |

geom3d\models\TransformerM\modules\fairseq_dropout.py:25:9: ANN003 Missing type annotation for `**kwargs`
   |
23 |         retain_dropout: bool = False,
24 |         retain_dropout_modules: Optional[List[str]] = None,
25 |         **kwargs
   |         ^^^^^^^^ ANN003
26 |     ):
27 |         if retain_dropout:
   |

geom3d\models\TransformerM\modules\fairseq_dropout.py:25:11: ARG002 Unused method argument: `kwargs`
   |
23 |         retain_dropout: bool = False,
24 |         retain_dropout_modules: Optional[List[str]] = None,
25 |         **kwargs
   |           ^^^^^^ ARG002
26 |     ):
27 |         if retain_dropout:
   |

geom3d\models\TransformerM\modules\layer_drop.py:1:1: D100 Missing docstring in public module
geom3d\models\TransformerM\modules\layer_drop.py:7:5: D205 1 blank line required between summary line and description
   |
 6 |   class LayerDropModuleList(nn.ModuleList):
 7 |       """A LayerDrop implementation based on :class:`torch.nn.ModuleList`.
   |  _____^
 8 | |     We refresh the choice of which layers to drop every time we iterate
 9 | |     over the LayerDropModuleList instance. During evaluation we always
10 | |     iterate over all layers.
11 | |     Usage::
12 | |         layers = LayerDropList(p=0.5, modules=[layer1, layer2, layer3])
13 | |         for layer in layers:  # this might iterate over layers 1 and 3
14 | |             x = layer(x)
15 | |         for layer in layers:  # this might iterate over all layers
16 | |             x = layer(x)
17 | |         for layer in layers:  # this might not iterate over any layers
18 | |             x = layer(x).
19 | | 
20 | |     Args:
21 | |     ----
22 | |         p (float): probability of dropping out each layer
23 | |         modules (iterable, optional): an iterable of modules to add
24 | | 
25 | |     """
   | |_______^ D205
26 |   
27 |       def __init__(self, p, modules=None):
   |
   = help: Insert single blank line

geom3d\models\TransformerM\modules\layer_drop.py:27:9: D107 Missing docstring in `__init__`
   |
25 |     """
26 | 
27 |     def __init__(self, p, modules=None):
   |         ^^^^^^^^ D107
28 |         super().__init__(modules)
29 |         self.p = p
   |

geom3d\models\TransformerM\modules\layer_drop.py:31:9: D105 Missing docstring in magic method
   |
29 |         self.p = p
30 | 
31 |     def __iter__(self):
   |         ^^^^^^^^ D105
32 |         dropout_probs = torch.empty(len(self)).uniform_()
33 |         for i, m in enumerate(super().__iter__()):
   |

geom3d\models\TransformerM\modules\layer_norm.py:1:1: D100 Missing docstring in public module
geom3d\models\TransformerM\modules\layer_norm.py:9:11: D101 Missing docstring in public class
   |
 7 |     has_fused_layernorm = True
 8 | 
 9 |     class FusedLayerNorm(_FusedLayerNorm):
   |           ^^^^^^^^^^^^^^ D101
10 |         @torch.jit.unused
11 |         def forward(self, x):
   |

geom3d\models\TransformerM\modules\layer_norm.py:11:13: D102 Missing docstring in public method
   |
 9 |     class FusedLayerNorm(_FusedLayerNorm):
10 |         @torch.jit.unused
11 |         def forward(self, x):
   |             ^^^^^^^ D102
12 |             if not x.is_cuda:
13 |                 return super().forward(x)
   |

geom3d\models\TransformerM\modules\layer_norm.py:14:13: RET505 Unnecessary `else` after `return` statement
   |
12 |             if not x.is_cuda:
13 |                 return super().forward(x)
14 |             else:
   |             ^^^^ RET505
15 |                 with torch.cuda.device(x.device):
16 |                     return super().forward(x)
   |
   = help: Remove unnecessary `else`

geom3d\models\TransformerM\modules\layer_norm.py:22:5: N802 Function name `LayerNorm` should be lowercase
   |
22 | def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):
   |     ^^^^^^^^^ N802
23 |     if torch.jit.is_scripting() or torch.jit.is_tracing():
24 |         export = True
   |

geom3d\models\TransformerM\modules\layer_norm.py:22:5: D103 Missing docstring in public function
   |
22 | def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):
   |     ^^^^^^^^^ D103
23 |     if torch.jit.is_scripting() or torch.jit.is_tracing():
24 |         export = True
   |

geom3d\models\TransformerM\modules\layer_norm.py:22:43: FBT002 Boolean default positional argument in function definition
   |
22 | def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):
   |                                           ^^^^^^^^^^^^^^^^^^ FBT002
23 |     if torch.jit.is_scripting() or torch.jit.is_tracing():
24 |         export = True
   |

geom3d\models\TransformerM\modules\layer_norm.py:22:68: FBT002 Boolean default positional argument in function definition
   |
22 | def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):
   |                                                                    ^^^^^^ FBT002
23 |     if torch.jit.is_scripting() or torch.jit.is_tracing():
24 |         export = True
   |

geom3d\models\TransformerM\modules\quant_noise.py:1:1: D100 Missing docstring in public module
geom3d\models\TransformerM\modules\quant_noise.py:7:5: D205 1 blank line required between summary line and description
   |
 6 |   def quant_noise(module, p, block_size):
 7 |       """Wraps modules and applies quantization noise to the weights for
   |  _____^
 8 | |     subsequent quantization with Iterative Product Quantization as
 9 | |     described in "Training with Quantization Noise for Extreme Model Compression"
10 | |     Args:
11 | |         - module: nn.Module
12 | |         - p: amount of Quantization Noise
13 | |         - block_size: size of the blocks for subsequent quantization with iPQ
14 | |     Remarks:
15 | |         - Module weights must have the right sizes wrt the block size
16 | |         - Only Linear, Embedding and Conv2d modules are supported for the moment
17 | |         - For more detail on how to quantize by blocks with convolutional weights,
18 | |           see "And the Bit Goes Down: Revisiting the Quantization of Neural Networks"
19 | |         - We implement the simplest form of noise here as stated in the paper
20 | |           which consists in randomly dropping blocks.
21 | |     """
   | |_______^ D205
22 |       # if no quantization noise, don't register hook
23 |       if p <= 0:
   |
   = help: Insert single blank line

geom3d\models\TransformerM\modules\quant_noise.py:7:5: D401 First line of docstring should be in imperative mood: "Wraps modules and applies quantization noise to the weights for"
   |
 6 |   def quant_noise(module, p, block_size):
 7 |       """Wraps modules and applies quantization noise to the weights for
   |  _____^
 8 | |     subsequent quantization with Iterative Product Quantization as
 9 | |     described in "Training with Quantization Noise for Extreme Model Compression"
10 | |     Args:
11 | |         - module: nn.Module
12 | |         - p: amount of Quantization Noise
13 | |         - block_size: size of the blocks for subsequent quantization with iPQ
14 | |     Remarks:
15 | |         - Module weights must have the right sizes wrt the block size
16 | |         - Only Linear, Embedding and Conv2d modules are supported for the moment
17 | |         - For more detail on how to quantize by blocks with convolutional weights,
18 | |           see "And the Bit Goes Down: Revisiting the Quantization of Neural Networks"
19 | |         - We implement the simplest form of noise here as stated in the paper
20 | |           which consists in randomly dropping blocks.
21 | |     """
   | |_______^ D401
22 |       # if no quantization noise, don't register hook
23 |       if p <= 0:
   |

geom3d\models\TransformerM\modules\quant_noise.py:27:5: S101 Use of `assert` detected
   |
26 |     # supported modules
27 |     assert isinstance(module, (nn.Linear, nn.Embedding, nn.Conv2d))
   |     ^^^^^^ S101
28 | 
29 |     # test whether module.weight has the right sizes wrt block_size
   |

geom3d\models\TransformerM\modules\quant_noise.py:30:37: PLR2004 Magic value used in comparison, consider replacing `4` with a constant variable
   |
29 |     # test whether module.weight has the right sizes wrt block_size
30 |     is_conv = module.weight.ndim == 4
   |                                     ^ PLR2004
31 | 
32 |     # 2D matrix
   |

geom3d\models\TransformerM\modules\quant_noise.py:34:9: S101 Use of `assert` detected
   |
32 |     # 2D matrix
33 |     if not is_conv:
34 |         assert (
   |         ^^^^^^ S101
35 |             module.weight.size(1) % block_size == 0
36 |         ), "Input features must be a multiple of block sizes"
   |

geom3d\models\TransformerM\modules\quant_noise.py:40:9: S101 Use of `assert` detected
   |
38 |     # 4D matrix
39 |     elif module.kernel_size == (1, 1):
40 |         assert (
   |         ^^^^^^ S101
41 |             module.in_channels % block_size == 0
42 |         ), "Input channels must be a multiple of block sizes"
   |

geom3d\models\TransformerM\modules\quant_noise.py:46:9: S101 Use of `assert` detected
   |
44 |     else:
45 |         k = module.kernel_size[0] * module.kernel_size[1]
46 |         assert k % block_size == 0, "Kernel size must be a multiple of block size"
   |         ^^^^^^ S101
47 | 
48 |     def _forward_pre_hook(mod, input) -> None:
   |

geom3d\models\TransformerM\modules\quant_noise.py:48:32: A002 Argument `input` is shadowing a Python builtin
   |
46 |         assert k % block_size == 0, "Kernel size must be a multiple of block size"
47 | 
48 |     def _forward_pre_hook(mod, input) -> None:
   |                                ^^^^^ A002
49 |         # no noise for evaluation
50 |         if mod.training:
   |

geom3d\models\TransformerM\modules\quant_noise.py:48:32: ARG001 Unused function argument: `input`
   |
46 |         assert k % block_size == 0, "Kernel size must be a multiple of block size"
47 | 
48 |     def _forward_pre_hook(mod, input) -> None:
   |                                ^^^^^ ARG001
49 |         # no noise for evaluation
50 |         if mod.training:
   |

geom3d\models\TransformerM\modules\utils.py:1:1: D100 Missing docstring in public module
geom3d\models\TransformerM\modules\utils.py:5:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
4 | import torch
5 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
  |

geom3d\models\TransformerM\modules\utils.py:8:5: D103 Missing docstring in public function
   |
 8 | def softmax(x, dim: int, onnx_trace: bool = False):
   |     ^^^^^^^ D103
 9 |     if onnx_trace:
10 |         return F.softmax(x.float(), dim=dim)
   |

geom3d\models\TransformerM\modules\utils.py:8:26: FBT001 Boolean-typed positional argument in function definition
   |
 8 | def softmax(x, dim: int, onnx_trace: bool = False):
   |                          ^^^^^^^^^^ FBT001
 9 |     if onnx_trace:
10 |         return F.softmax(x.float(), dim=dim)
   |

geom3d\models\TransformerM\modules\utils.py:8:26: FBT002 Boolean default positional argument in function definition
   |
 8 | def softmax(x, dim: int, onnx_trace: bool = False):
   |                          ^^^^^^^^^^ FBT002
 9 |     if onnx_trace:
10 |         return F.softmax(x.float(), dim=dim)
   |

geom3d\models\TransformerM\modules\utils.py:11:5: RET505 Unnecessary `else` after `return` statement
   |
 9 |     if onnx_trace:
10 |         return F.softmax(x.float(), dim=dim)
11 |     else:
   |     ^^^^ RET505
12 |         return F.softmax(x, dim=dim, dtype=torch.float32)
   |
   = help: Remove unnecessary `else`

geom3d\models\TransformerM\modules\utils.py:16:5: D401 First line of docstring should be in imperative mood: "Returns the activation function corresponding to `activation`."
   |
15 | def get_activation_fn(activation: str) -> Callable:
16 |     """Returns the activation function corresponding to `activation`."""
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
17 |     # from fairseq.modules import gelu, gelu_accurate
   |

geom3d\models\TransformerM\modules\utils.py:17:5: ERA001 Found commented-out code
   |
15 | def get_activation_fn(activation: str) -> Callable:
16 |     """Returns the activation function corresponding to `activation`."""
17 |     # from fairseq.modules import gelu, gelu_accurate
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
18 | 
19 |     if activation == "relu":
   |
   = help: Remove commented-out code

geom3d\models\TransformerM\modules\utils.py:21:5: ERA001 Found commented-out code
   |
19 |     if activation == "relu":
20 |         return F.relu
21 |     # elif activation == "relu_squared":
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
22 |     #     return relu_squared
23 |     # elif activation == "gelu":
   |
   = help: Remove commented-out code

geom3d\models\TransformerM\modules\utils.py:22:5: ERA001 Found commented-out code
   |
20 |         return F.relu
21 |     # elif activation == "relu_squared":
22 |     #     return relu_squared
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
23 |     # elif activation == "gelu":
24 |     #     return gelu
   |
   = help: Remove commented-out code

geom3d\models\TransformerM\modules\utils.py:23:5: ERA001 Found commented-out code
   |
21 |     # elif activation == "relu_squared":
22 |     #     return relu_squared
23 |     # elif activation == "gelu":
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
24 |     #     return gelu
25 |     # elif activation == "gelu_fast":
   |
   = help: Remove commented-out code

geom3d\models\TransformerM\modules\utils.py:24:5: ERA001 Found commented-out code
   |
22 |     #     return relu_squared
23 |     # elif activation == "gelu":
24 |     #     return gelu
   |     ^^^^^^^^^^^^^^^^^ ERA001
25 |     # elif activation == "gelu_fast":
26 |     #     deprecation_warning(
   |
   = help: Remove commented-out code

geom3d\models\TransformerM\modules\utils.py:25:5: ERA001 Found commented-out code
   |
23 |     # elif activation == "gelu":
24 |     #     return gelu
25 |     # elif activation == "gelu_fast":
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
26 |     #     deprecation_warning(
27 |     #         "--activation-fn=gelu_fast has been renamed to gelu_accurate"
   |
   = help: Remove commented-out code

geom3d\models\TransformerM\modules\utils.py:27:5: ERA001 Found commented-out code
   |
25 |     # elif activation == "gelu_fast":
26 |     #     deprecation_warning(
27 |     #         "--activation-fn=gelu_fast has been renamed to gelu_accurate"
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
28 |     #     )
29 |     #     return gelu_accurate
   |
   = help: Remove commented-out code

geom3d\models\TransformerM\modules\utils.py:28:5: ERA001 Found commented-out code
   |
26 |     #     deprecation_warning(
27 |     #         "--activation-fn=gelu_fast has been renamed to gelu_accurate"
28 |     #     )
   |     ^^^^^^^ ERA001
29 |     #     return gelu_accurate
30 |     # elif activation == "gelu_accurate":
   |
   = help: Remove commented-out code

geom3d\models\TransformerM\modules\utils.py:29:5: ERA001 Found commented-out code
   |
27 |     #         "--activation-fn=gelu_fast has been renamed to gelu_accurate"
28 |     #     )
29 |     #     return gelu_accurate
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
30 |     # elif activation == "gelu_accurate":
31 |     #     return gelu_accurate
   |
   = help: Remove commented-out code

geom3d\models\TransformerM\modules\utils.py:30:5: ERA001 Found commented-out code
   |
28 |     #     )
29 |     #     return gelu_accurate
30 |     # elif activation == "gelu_accurate":
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
31 |     #     return gelu_accurate
32 |     elif activation == "tanh":
   |
   = help: Remove commented-out code

geom3d\models\TransformerM\modules\utils.py:31:5: ERA001 Found commented-out code
   |
29 |     #     return gelu_accurate
30 |     # elif activation == "gelu_accurate":
31 |     #     return gelu_accurate
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
32 |     elif activation == "tanh":
33 |         return torch.tanh
   |
   = help: Remove commented-out code

geom3d\models\TransformerM\modules\utils.py:32:5: RET505 Unnecessary `elif` after `return` statement
   |
30 |     # elif activation == "gelu_accurate":
31 |     #     return gelu_accurate
32 |     elif activation == "tanh":
   |     ^^^^ RET505
33 |         return torch.tanh
34 |     elif activation == "linear":
   |
   = help: Remove unnecessary `elif`

geom3d\models\TransformerM\transformer_m.py:1:1: D100 Missing docstring in public module
geom3d\models\TransformerM\transformer_m.py:8:7: D101 Missing docstring in public class
   |
 8 | class TransformerM(nn.Module):
   |       ^^^^^^^^^^^^ D101
 9 | 
10 |     def __init__(self, args):
   |

geom3d\models\TransformerM\transformer_m.py:10:9: D107 Missing docstring in `__init__`
   |
 8 | class TransformerM(nn.Module):
 9 | 
10 |     def __init__(self, args):
   |         ^^^^^^^^ D107
11 |         super().__init__()
12 |         self.max_nodes = args.max_nodes
   |

geom3d\models\TransformerM\transformer_m.py:60:9: D102 Missing docstring in public method
   |
58 |         )
59 | 
60 |     def forward(self, batched_data, perturb=None, segment_labels=None, masked_tokens=None, **unused):
   |         ^^^^^^^ D102
61 | 
62 |         inner_states, atom_output = self.molecule_encoder(
   |

geom3d\models\TransformerM\transformer_m.py:60:72: ARG002 Unused method argument: `masked_tokens`
   |
58 |         )
59 | 
60 |     def forward(self, batched_data, perturb=None, segment_labels=None, masked_tokens=None, **unused):
   |                                                                        ^^^^^^^^^^^^^ ARG002
61 | 
62 |         inner_states, atom_output = self.molecule_encoder(
   |

geom3d\models\TransformerM\transformer_m.py:60:92: ANN003 Missing type annotation for `**unused`
   |
58 |         )
59 | 
60 |     def forward(self, batched_data, perturb=None, segment_labels=None, masked_tokens=None, **unused):
   |                                                                                            ^^^^^^^^ ANN003
61 | 
62 |         inner_states, atom_output = self.molecule_encoder(
   |

geom3d\models\TransformerM\transformer_m.py:60:94: ARG002 Unused method argument: `unused`
   |
58 |         )
59 | 
60 |     def forward(self, batched_data, perturb=None, segment_labels=None, masked_tokens=None, **unused):
   |                                                                                              ^^^^^^ ARG002
61 | 
62 |         inner_states, atom_output = self.molecule_encoder(
   |

geom3d\models\TransformerM\transformer_m.py:80:9: D102 Missing docstring in public method
   |
78 |         return self.max_nodes
79 | 
80 |     def upgrade_state_dict_named(self, state_dict, name):
   |         ^^^^^^^^^^^^^^^^^^^^^^^^ D102
81 |         return state_dict
   |

geom3d\models\TransformerM\transformer_m.py:80:52: ARG002 Unused method argument: `name`
   |
78 |         return self.max_nodes
79 | 
80 |     def upgrade_state_dict_named(self, state_dict, name):
   |                                                    ^^^^ ARG002
81 |         return state_dict
   |

geom3d\models\TransformerM\transformer_m.py:84:5: D103 Missing docstring in public function
   |
83 | # only for reference
84 | def base_architecture(args):
   |     ^^^^^^^^^^^^^^^^^ D103
85 |     args.dropout = getattr(args, "dropout", 0.1)
86 |     args.attention_dropout = getattr(args, "attention_dropout", 0.1)
   |

geom3d\models\TransformerM\transformer_m.py:117:5: D103 Missing docstring in public function
    |
116 | # only for reference
117 | def bert_base_architecture(args):
    |     ^^^^^^^^^^^^^^^^^^^^^^ D103
118 |     args.encoder_embed_dim = getattr(args, "encoder_embed_dim", 768)
119 |     args.share_encoder_input_output_embed = getattr(
    |

geom3d\models\TransformerM\transformer_m_encoder.py:1:1: D100 Missing docstring in public module
geom3d\models\TransformerM\transformer_m_encoder.py:19:5: D103 Missing docstring in public function
   |
19 | def init_params(module):
   |     ^^^^^^^^^^^ D103
20 | 
21 |     def normal_(data) -> None:
   |

geom3d\models\TransformerM\transformer_m_encoder.py:42:7: D101 Missing docstring in public class
   |
42 | class TransformerMEncoder(nn.Module):
   |       ^^^^^^^^^^^^^^^^^^^ D101
43 | 
44 |     def __init__(
   |

geom3d\models\TransformerM\transformer_m_encoder.py:44:9: PLR0913 Too many arguments in function definition (34 > 5)
   |
42 | class TransformerMEncoder(nn.Module):
43 | 
44 |     def __init__(
   |         ^^^^^^^^ PLR0913
45 |         self,
46 |         num_atoms: int,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:44:9: D107 Missing docstring in `__init__`
   |
42 | class TransformerMEncoder(nn.Module):
43 | 
44 |     def __init__(
   |         ^^^^^^^^ D107
45 |         self,
46 |         num_atoms: int,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:64:9: FBT001 Boolean-typed positional argument in function definition
   |
62 |         max_seq_len: int = 256,
63 |         num_segments: int = 2,
64 |         use_position_embeddings: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^^^ FBT001
65 |         encoder_normalize_before: bool = False,
66 |         apply_init: bool = False,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:64:9: FBT002 Boolean default positional argument in function definition
   |
62 |         max_seq_len: int = 256,
63 |         num_segments: int = 2,
64 |         use_position_embeddings: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^^^ FBT002
65 |         encoder_normalize_before: bool = False,
66 |         apply_init: bool = False,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:65:9: FBT001 Boolean-typed positional argument in function definition
   |
63 |         num_segments: int = 2,
64 |         use_position_embeddings: bool = True,
65 |         encoder_normalize_before: bool = False,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^ FBT001
66 |         apply_init: bool = False,
67 |         activation_fn: str = "relu",
   |

geom3d\models\TransformerM\transformer_m_encoder.py:65:9: FBT002 Boolean default positional argument in function definition
   |
63 |         num_segments: int = 2,
64 |         use_position_embeddings: bool = True,
65 |         encoder_normalize_before: bool = False,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^ FBT002
66 |         apply_init: bool = False,
67 |         activation_fn: str = "relu",
   |

geom3d\models\TransformerM\transformer_m_encoder.py:66:9: FBT001 Boolean-typed positional argument in function definition
   |
64 |         use_position_embeddings: bool = True,
65 |         encoder_normalize_before: bool = False,
66 |         apply_init: bool = False,
   |         ^^^^^^^^^^ FBT001
67 |         activation_fn: str = "relu",
68 |         learned_pos_embedding: bool = True,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:66:9: FBT002 Boolean default positional argument in function definition
   |
64 |         use_position_embeddings: bool = True,
65 |         encoder_normalize_before: bool = False,
66 |         apply_init: bool = False,
   |         ^^^^^^^^^^ FBT002
67 |         activation_fn: str = "relu",
68 |         learned_pos_embedding: bool = True,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:68:9: FBT001 Boolean-typed positional argument in function definition
   |
66 |         apply_init: bool = False,
67 |         activation_fn: str = "relu",
68 |         learned_pos_embedding: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^ FBT001
69 |         embed_scale: Optional[float] = None,
70 |         export: bool = False,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:68:9: FBT002 Boolean default positional argument in function definition
   |
66 |         apply_init: bool = False,
67 |         activation_fn: str = "relu",
68 |         learned_pos_embedding: bool = True,
   |         ^^^^^^^^^^^^^^^^^^^^^ FBT002
69 |         embed_scale: Optional[float] = None,
70 |         export: bool = False,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:69:22: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
67 |         activation_fn: str = "relu",
68 |         learned_pos_embedding: bool = True,
69 |         embed_scale: Optional[float] = None,
   |                      ^^^^^^^^ FA100
70 |         export: bool = False,
71 |         traceable: bool = False,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:70:9: FBT001 Boolean-typed positional argument in function definition
   |
68 |         learned_pos_embedding: bool = True,
69 |         embed_scale: Optional[float] = None,
70 |         export: bool = False,
   |         ^^^^^^ FBT001
71 |         traceable: bool = False,
72 |         q_noise: float = 0.0,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:70:9: FBT002 Boolean default positional argument in function definition
   |
68 |         learned_pos_embedding: bool = True,
69 |         embed_scale: Optional[float] = None,
70 |         export: bool = False,
   |         ^^^^^^ FBT002
71 |         traceable: bool = False,
72 |         q_noise: float = 0.0,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:71:9: FBT001 Boolean-typed positional argument in function definition
   |
69 |         embed_scale: Optional[float] = None,
70 |         export: bool = False,
71 |         traceable: bool = False,
   |         ^^^^^^^^^ FBT001
72 |         q_noise: float = 0.0,
73 |         qn_block_size: int = 8,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:71:9: FBT002 Boolean default positional argument in function definition
   |
69 |         embed_scale: Optional[float] = None,
70 |         export: bool = False,
71 |         traceable: bool = False,
   |         ^^^^^^^^^ FBT002
72 |         q_noise: float = 0.0,
73 |         qn_block_size: int = 8,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:74:9: FBT001 Boolean-typed positional argument in function definition
   |
72 |         q_noise: float = 0.0,
73 |         qn_block_size: int = 8,
74 |         sandwich_ln: bool = False,
   |         ^^^^^^^^^^^ FBT001
75 |         droppath_prob: float = 0.0,
76 |         add_3d: bool = False,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:74:9: FBT002 Boolean default positional argument in function definition
   |
72 |         q_noise: float = 0.0,
73 |         qn_block_size: int = 8,
74 |         sandwich_ln: bool = False,
   |         ^^^^^^^^^^^ FBT002
75 |         droppath_prob: float = 0.0,
76 |         add_3d: bool = False,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:76:9: FBT001 Boolean-typed positional argument in function definition
   |
74 |         sandwich_ln: bool = False,
75 |         droppath_prob: float = 0.0,
76 |         add_3d: bool = False,
   |         ^^^^^^ FBT001
77 |         num_3d_bias_kernel: int = 128,
78 |         no_2d: bool = False,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:76:9: FBT002 Boolean default positional argument in function definition
   |
74 |         sandwich_ln: bool = False,
75 |         droppath_prob: float = 0.0,
76 |         add_3d: bool = False,
   |         ^^^^^^ FBT002
77 |         num_3d_bias_kernel: int = 128,
78 |         no_2d: bool = False,
   |

geom3d\models\TransformerM\transformer_m_encoder.py:78:9: FBT001 Boolean-typed positional argument in function definition
   |
76 |         add_3d: bool = False,
77 |         num_3d_bias_kernel: int = 128,
78 |         no_2d: bool = False,
   |         ^^^^^ FBT001
79 |         mode_prob: str = "0.2,0.2,0.6",
80 |     ) -> None:
   |

geom3d\models\TransformerM\transformer_m_encoder.py:78:9: FBT002 Boolean default positional argument in function definition
   |
76 |         add_3d: bool = False,
77 |         num_3d_bias_kernel: int = 128,
78 |         no_2d: bool = False,
   |         ^^^^^ FBT002
79 |         mode_prob: str = "0.2,0.2,0.6",
80 |     ) -> None:
   |

geom3d\models\TransformerM\transformer_m_encoder.py:98:13: S101 Use of `assert` detected
    |
 96 |         try:
 97 |             mode_prob = [float(item) for item in mode_prob.split(",")]
 98 |             assert len(mode_prob) == 3
    |             ^^^^^^ S101
 99 |             assert sum(mode_prob) == 1.0
100 |         except:
    |

geom3d\models\TransformerM\transformer_m_encoder.py:98:38: PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
    |
 96 |         try:
 97 |             mode_prob = [float(item) for item in mode_prob.split(",")]
 98 |             assert len(mode_prob) == 3
    |                                      ^ PLR2004
 99 |             assert sum(mode_prob) == 1.0
100 |         except:
    |

geom3d\models\TransformerM\transformer_m_encoder.py:99:13: S101 Use of `assert` detected
    |
 97 |             mode_prob = [float(item) for item in mode_prob.split(",")]
 98 |             assert len(mode_prob) == 3
 99 |             assert sum(mode_prob) == 1.0
    |             ^^^^^^ S101
100 |         except:
101 |             mode_prob = [0.2, 0.2, 0.6]
    |

geom3d\models\TransformerM\transformer_m_encoder.py:100:9: E722 Do not use bare `except`
    |
 98 |             assert len(mode_prob) == 3
 99 |             assert sum(mode_prob) == 1.0
100 |         except:
    |         ^^^^^^ E722
101 |             mode_prob = [0.2, 0.2, 0.6]
102 |         self.mode_prob = mode_prob
    |

geom3d\models\TransformerM\transformer_m_encoder.py:188:9: PLR0913 Too many arguments in function definition (12 > 5)
    |
186 |             self.apply(init_params)
187 | 
188 |     def build_transformer_m_encoder_layer(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
189 |         self,
190 |         embedding_dim,
    |

geom3d\models\TransformerM\transformer_m_encoder.py:188:9: D102 Missing docstring in public method
    |
186 |             self.apply(init_params)
187 | 
188 |     def build_transformer_m_encoder_layer(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D102
189 |         self,
190 |         embedding_dim,
    |

geom3d\models\TransformerM\transformer_m_encoder.py:218:9: C901 `forward` is too complex (16 > 10)
    |
216 |         )
217 | 
218 |     def forward(
    |         ^^^^^^^ C901
219 |         self,
220 |         batched_data,
    |

geom3d\models\TransformerM\transformer_m_encoder.py:218:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
216 |         )
217 | 
218 |     def forward(
    |         ^^^^^^^ PLR0913
219 |         self,
220 |         batched_data,
    |

geom3d\models\TransformerM\transformer_m_encoder.py:218:9: PLR0912 Too many branches (17 > 12)
    |
216 |         )
217 | 
218 |     def forward(
    |         ^^^^^^^ PLR0912
219 |         self,
220 |         batched_data,
    |

geom3d\models\TransformerM\transformer_m_encoder.py:218:9: PLR0915 Too many statements (51 > 50)
    |
216 |         )
217 | 
218 |     def forward(
    |         ^^^^^^^ PLR0915
219 |         self,
220 |         batched_data,
    |

geom3d\models\TransformerM\transformer_m_encoder.py:218:9: D102 Missing docstring in public method
    |
216 |         )
217 | 
218 |     def forward(
    |         ^^^^^^^ D102
219 |         self,
220 |         batched_data,
    |

geom3d\models\TransformerM\transformer_m_encoder.py:222:9: ARG002 Unused method argument: `segment_labels`
    |
220 |         batched_data,
221 |         perturb=None,
222 |         segment_labels: torch.Tensor = None,
    |         ^^^^^^^^^^^^^^ ARG002
223 |         last_state_only: bool = False,
224 |         positions: Optional[torch.Tensor] = None,
    |

geom3d\models\TransformerM\transformer_m_encoder.py:223:9: FBT001 Boolean-typed positional argument in function definition
    |
221 |         perturb=None,
222 |         segment_labels: torch.Tensor = None,
223 |         last_state_only: bool = False,
    |         ^^^^^^^^^^^^^^^ FBT001
224 |         positions: Optional[torch.Tensor] = None,
225 |         token_embeddings: Optional[torch.Tensor] = None,
    |

geom3d\models\TransformerM\transformer_m_encoder.py:223:9: FBT002 Boolean default positional argument in function definition
    |
221 |         perturb=None,
222 |         segment_labels: torch.Tensor = None,
223 |         last_state_only: bool = False,
    |         ^^^^^^^^^^^^^^^ FBT002
224 |         positions: Optional[torch.Tensor] = None,
225 |         token_embeddings: Optional[torch.Tensor] = None,
    |

geom3d\models\TransformerM\transformer_m_encoder.py:224:9: ARG002 Unused method argument: `positions`
    |
222 |         segment_labels: torch.Tensor = None,
223 |         last_state_only: bool = False,
224 |         positions: Optional[torch.Tensor] = None,
    |         ^^^^^^^^^ ARG002
225 |         token_embeddings: Optional[torch.Tensor] = None,
226 |         attn_mask: Optional[torch.Tensor] = None,
    |

geom3d\models\TransformerM\transformer_m_encoder.py:224:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
222 |         segment_labels: torch.Tensor = None,
223 |         last_state_only: bool = False,
224 |         positions: Optional[torch.Tensor] = None,
    |                    ^^^^^^^^ FA100
225 |         token_embeddings: Optional[torch.Tensor] = None,
226 |         attn_mask: Optional[torch.Tensor] = None,
    |

geom3d\models\TransformerM\transformer_m_encoder.py:225:27: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
223 |         last_state_only: bool = False,
224 |         positions: Optional[torch.Tensor] = None,
225 |         token_embeddings: Optional[torch.Tensor] = None,
    |                           ^^^^^^^^ FA100
226 |         attn_mask: Optional[torch.Tensor] = None,
227 |     ) -> Tuple[torch.Tensor, torch.Tensor]:
    |

geom3d\models\TransformerM\transformer_m_encoder.py:226:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
    |
224 |         positions: Optional[torch.Tensor] = None,
225 |         token_embeddings: Optional[torch.Tensor] = None,
226 |         attn_mask: Optional[torch.Tensor] = None,
    |                    ^^^^^^^^ FA100
227 |     ) -> Tuple[torch.Tensor, torch.Tensor]:
228 |         # compute padding mask. This is needed for multi-head attention
    |

geom3d\models\TransformerM\transformer_m_encoder.py:227:10: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
    |
225 |         token_embeddings: Optional[torch.Tensor] = None,
226 |         attn_mask: Optional[torch.Tensor] = None,
227 |     ) -> Tuple[torch.Tensor, torch.Tensor]:
    |          ^^^^^ FA100
228 |         # compute padding mask. This is needed for multi-head attention
    |

geom3d\models\TransformerM\transformer_m_encoder.py:239:27: NPY002 Replace legacy `np.random.choice` call with `np.random.Generator`
    |
237 |         mask_2d = mask_3d = None
238 |         if self.training:
239 |             mask_choice = np.random.choice(np.arange(3), n_mol, p=self.mode_prob)
    |                           ^^^^^^^^^^^^^^^^ NPY002
240 |             mask = torch.tensor([mask_dict[i] for i in mask_choice]).to(batched_data["pos"])
241 |             mask_2d = mask[:, 0]
    |

geom3d\models\TransformerM\transformer_m_encoder.py:302:9: RET505 Unnecessary `else` after `return` statement
    |
300 |         if self.traceable:
301 |             return torch.stack(inner_states), atom_output
302 |         else:
    |         ^^^^ RET505
303 |             return inner_states, atom_output
    |
    = help: Remove unnecessary `else`

geom3d\models\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\__init__.py:1:8: F401 `torch` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | import torch
  |        ^^^^^ F401
2 | import torch.nn.functional as F
3 | from torch import nn
  |
  = help: Remove unused import: `torch`

geom3d\models\__init__.py:2:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | import torch
2 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
3 | from torch import nn
4 | from torch_geometric.nn import GATConv, GCNConv
  |

geom3d\models\__init__.py:2:31: F401 `torch.nn.functional` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | import torch
2 | import torch.nn.functional as F
  |                               ^ F401
3 | from torch import nn
4 | from torch_geometric.nn import GATConv, GCNConv
  |
  = help: Remove unused import: `torch.nn.functional`

geom3d\models\__init__.py:3:19: F401 `torch.nn` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
1 | import torch
2 | import torch.nn.functional as F
3 | from torch import nn
  |                   ^^ F401
4 | from torch_geometric.nn import GATConv, GCNConv
  |
  = help: Remove unused import: `torch.nn`

geom3d\models\__init__.py:4:32: F401 `torch_geometric.nn.GATConv` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
2 | import torch.nn.functional as F
3 | from torch import nn
4 | from torch_geometric.nn import GATConv, GCNConv
  |                                ^^^^^^^ F401
5 | 
6 | from .AutoEncoder import AutoEncoder, VariationalAutoEncoder
  |
  = help: Remove unused import

geom3d\models\__init__.py:4:41: F401 `torch_geometric.nn.GCNConv` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
2 | import torch.nn.functional as F
3 | from torch import nn
4 | from torch_geometric.nn import GATConv, GCNConv
  |                                         ^^^^^^^ F401
5 | 
6 | from .AutoEncoder import AutoEncoder, VariationalAutoEncoder
  |
  = help: Remove unused import

geom3d\models\__init__.py:6:26: F401 `.AutoEncoder.AutoEncoder` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
4 | from torch_geometric.nn import GATConv, GCNConv
5 | 
6 | from .AutoEncoder import AutoEncoder, VariationalAutoEncoder
  |                          ^^^^^^^^^^^ F401
7 | from .AWARE import AWARE
8 | from .BERT import BertForSequenceRegression
  |
  = help: Use an explicit re-export: `AutoEncoder as AutoEncoder`

geom3d\models\__init__.py:6:39: F401 `.AutoEncoder.VariationalAutoEncoder` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
4 | from torch_geometric.nn import GATConv, GCNConv
5 | 
6 | from .AutoEncoder import AutoEncoder, VariationalAutoEncoder
  |                                       ^^^^^^^^^^^^^^^^^^^^^^ F401
7 | from .AWARE import AWARE
8 | from .BERT import BertForSequenceRegression
  |
  = help: Use an explicit re-export: `VariationalAutoEncoder as VariationalAutoEncoder`

geom3d\models\__init__.py:7:20: F401 `.AWARE.AWARE` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  |
6 | from .AutoEncoder import AutoEncoder, VariationalAutoEncoder
7 | from .AWARE import AWARE
  |                    ^^^^^ F401
8 | from .BERT import BertForSequenceRegression
9 | from .ClofNet import ClofNet
  |
  = help: Use an explicit re-export: `AWARE as AWARE`

geom3d\models\__init__.py:8:19: F401 `.BERT.BertForSequenceRegression` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
 6 | from .AutoEncoder import AutoEncoder, VariationalAutoEncoder
 7 | from .AWARE import AWARE
 8 | from .BERT import BertForSequenceRegression
   |                   ^^^^^^^^^^^^^^^^^^^^^^^^^ F401
 9 | from .ClofNet import ClofNet
10 | from .CNN import CNN
   |
   = help: Use an explicit re-export: `BertForSequenceRegression as BertForSequenceRegression`

geom3d\models\__init__.py:9:22: F401 `.ClofNet.ClofNet` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
 7 | from .AWARE import AWARE
 8 | from .BERT import BertForSequenceRegression
 9 | from .ClofNet import ClofNet
   |                      ^^^^^^^ F401
10 | from .CNN import CNN
11 | from .DimeNet import DimeNet
   |
   = help: Use an explicit re-export: `ClofNet as ClofNet`

geom3d\models\__init__.py:10:18: F401 `.CNN.CNN` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
 8 | from .BERT import BertForSequenceRegression
 9 | from .ClofNet import ClofNet
10 | from .CNN import CNN
   |                  ^^^ F401
11 | from .DimeNet import DimeNet
12 | from .DimeNetPlusPlus import DimeNetPlusPlus
   |
   = help: Use an explicit re-export: `CNN as CNN`

geom3d\models\__init__.py:11:22: F401 `.DimeNet.DimeNet` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
 9 | from .ClofNet import ClofNet
10 | from .CNN import CNN
11 | from .DimeNet import DimeNet
   |                      ^^^^^^^ F401
12 | from .DimeNetPlusPlus import DimeNetPlusPlus
13 | from .DMPNN import DMPNN
   |
   = help: Use an explicit re-export: `DimeNet as DimeNet`

geom3d\models\__init__.py:12:30: F401 `.DimeNetPlusPlus.DimeNetPlusPlus` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
10 | from .CNN import CNN
11 | from .DimeNet import DimeNet
12 | from .DimeNetPlusPlus import DimeNetPlusPlus
   |                              ^^^^^^^^^^^^^^^ F401
13 | from .DMPNN import DMPNN
14 | from .EGNN import EGNN
   |
   = help: Use an explicit re-export: `DimeNetPlusPlus as DimeNetPlusPlus`

geom3d\models\__init__.py:13:20: F401 `.DMPNN.DMPNN` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
11 | from .DimeNet import DimeNet
12 | from .DimeNetPlusPlus import DimeNetPlusPlus
13 | from .DMPNN import DMPNN
   |                    ^^^^^ F401
14 | from .EGNN import EGNN
15 | from .ENN import ENN_S2S
   |
   = help: Use an explicit re-export: `DMPNN as DMPNN`

geom3d\models\__init__.py:14:19: F401 `.EGNN.EGNN` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
12 | from .DimeNetPlusPlus import DimeNetPlusPlus
13 | from .DMPNN import DMPNN
14 | from .EGNN import EGNN
   |                   ^^^^ F401
15 | from .ENN import ENN_S2S
16 | from .Equiformer import (
   |
   = help: Use an explicit re-export: `EGNN as EGNN`

geom3d\models\__init__.py:15:18: F401 `.ENN.ENN_S2S` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
13 | from .DMPNN import DMPNN
14 | from .EGNN import EGNN
15 | from .ENN import ENN_S2S
   |                  ^^^^^^^ F401
16 | from .Equiformer import (
17 |     EquiformerEnergy,
   |
   = help: Use an explicit re-export: `ENN_S2S as ENN_S2S`

geom3d\models\__init__.py:17:5: F401 `.Equiformer.EquiformerEnergy` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
15 | from .ENN import ENN_S2S
16 | from .Equiformer import (
17 |     EquiformerEnergy,
   |     ^^^^^^^^^^^^^^^^ F401
18 |     EquiformerEnergyForce,
19 |     EquiformerEnergyPeriodic,
   |
   = help: Use an explicit re-export: `EquiformerEnergy as EquiformerEnergy`

geom3d\models\__init__.py:18:5: F401 `.Equiformer.EquiformerEnergyForce` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
16 | from .Equiformer import (
17 |     EquiformerEnergy,
18 |     EquiformerEnergyForce,
   |     ^^^^^^^^^^^^^^^^^^^^^ F401
19 |     EquiformerEnergyPeriodic,
20 | )
   |
   = help: Use an explicit re-export: `EquiformerEnergyForce as EquiformerEnergyForce`

geom3d\models\__init__.py:19:5: F401 `.Equiformer.EquiformerEnergyPeriodic` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
17 |     EquiformerEnergy,
18 |     EquiformerEnergyForce,
19 |     EquiformerEnergyPeriodic,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^ F401
20 | )
21 | from .GearNet import GearNet
   |
   = help: Use an explicit re-export: `EquiformerEnergyPeriodic as EquiformerEnergyPeriodic`

geom3d\models\__init__.py:21:22: F401 `.GearNet.GearNet` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
19 |     EquiformerEnergyPeriodic,
20 | )
21 | from .GearNet import GearNet
   |                      ^^^^^^^ F401
22 | from .GemNet import GemNet
23 | from .GeoSSL_DDM import GeoSSL_DDM
   |
   = help: Use an explicit re-export: `GearNet as GearNet`

geom3d\models\__init__.py:22:21: F401 `.GemNet.GemNet` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
20 | )
21 | from .GearNet import GearNet
22 | from .GemNet import GemNet
   |                     ^^^^^^ F401
23 | from .GeoSSL_DDM import GeoSSL_DDM
24 | from .GeoSSL_PDM import GeoSSL_PDM
   |
   = help: Use an explicit re-export: `GemNet as GemNet`

geom3d\models\__init__.py:23:25: F401 `.GeoSSL_DDM.GeoSSL_DDM` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
21 | from .GearNet import GearNet
22 | from .GemNet import GemNet
23 | from .GeoSSL_DDM import GeoSSL_DDM
   |                         ^^^^^^^^^^ F401
24 | from .GeoSSL_PDM import GeoSSL_PDM
25 | from .GPS import GPSModel
   |
   = help: Use an explicit re-export: `GeoSSL_DDM as GeoSSL_DDM`

geom3d\models\__init__.py:24:25: F401 `.GeoSSL_PDM.GeoSSL_PDM` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
22 | from .GemNet import GemNet
23 | from .GeoSSL_DDM import GeoSSL_DDM
24 | from .GeoSSL_PDM import GeoSSL_PDM
   |                         ^^^^^^^^^^ F401
25 | from .GPS import GPSModel
26 | from .Graphormer import Graphormer
   |
   = help: Use an explicit re-export: `GeoSSL_PDM as GeoSSL_PDM`

geom3d\models\__init__.py:25:18: F401 `.GPS.GPSModel` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
23 | from .GeoSSL_DDM import GeoSSL_DDM
24 | from .GeoSSL_PDM import GeoSSL_PDM
25 | from .GPS import GPSModel
   |                  ^^^^^^^^ F401
26 | from .Graphormer import Graphormer
27 | from .GVP import GVP_GNN
   |
   = help: Use an explicit re-export: `GPSModel as GPSModel`

geom3d\models\__init__.py:26:25: F401 `.Graphormer.Graphormer` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
24 | from .GeoSSL_PDM import GeoSSL_PDM
25 | from .GPS import GPSModel
26 | from .Graphormer import Graphormer
   |                         ^^^^^^^^^^ F401
27 | from .GVP import GVP_GNN
28 | from .MLP import MLP
   |
   = help: Use an explicit re-export: `Graphormer as Graphormer`

geom3d\models\__init__.py:27:18: F401 `.GVP.GVP_GNN` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
25 | from .GPS import GPSModel
26 | from .Graphormer import Graphormer
27 | from .GVP import GVP_GNN
   |                  ^^^^^^^ F401
28 | from .MLP import MLP
29 | from .molecule_gnn_model import GNN, GNN_graphpred
   |
   = help: Use an explicit re-export: `GVP_GNN as GVP_GNN`

geom3d\models\__init__.py:28:18: F401 `.MLP.MLP` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
26 | from .Graphormer import Graphormer
27 | from .GVP import GVP_GNN
28 | from .MLP import MLP
   |                  ^^^ F401
29 | from .molecule_gnn_model import GNN, GNN_graphpred
30 | from .molecule_gnn_model_simplified import GNNSimplified
   |
   = help: Use an explicit re-export: `MLP as MLP`

geom3d\models\__init__.py:29:33: F401 `.molecule_gnn_model.GNN` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
27 | from .GVP import GVP_GNN
28 | from .MLP import MLP
29 | from .molecule_gnn_model import GNN, GNN_graphpred
   |                                 ^^^ F401
30 | from .molecule_gnn_model_simplified import GNNSimplified
31 | from .PaiNN import PaiNN
   |
   = help: Use an explicit re-export: `GNN as GNN`

geom3d\models\__init__.py:29:38: F401 `.molecule_gnn_model.GNN_graphpred` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
27 | from .GVP import GVP_GNN
28 | from .MLP import MLP
29 | from .molecule_gnn_model import GNN, GNN_graphpred
   |                                      ^^^^^^^^^^^^^ F401
30 | from .molecule_gnn_model_simplified import GNNSimplified
31 | from .PaiNN import PaiNN
   |
   = help: Use an explicit re-export: `GNN_graphpred as GNN_graphpred`

geom3d\models\__init__.py:30:44: F401 `.molecule_gnn_model_simplified.GNNSimplified` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
28 | from .MLP import MLP
29 | from .molecule_gnn_model import GNN, GNN_graphpred
30 | from .molecule_gnn_model_simplified import GNNSimplified
   |                                            ^^^^^^^^^^^^^ F401
31 | from .PaiNN import PaiNN
32 | from .PNA import PNA
   |
   = help: Use an explicit re-export: `GNNSimplified as GNNSimplified`

geom3d\models\__init__.py:31:20: F401 `.PaiNN.PaiNN` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
29 | from .molecule_gnn_model import GNN, GNN_graphpred
30 | from .molecule_gnn_model_simplified import GNNSimplified
31 | from .PaiNN import PaiNN
   |                    ^^^^^ F401
32 | from .PNA import PNA
33 | from .ProNet import ProNet
   |
   = help: Use an explicit re-export: `PaiNN as PaiNN`

geom3d\models\__init__.py:32:18: F401 `.PNA.PNA` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
30 | from .molecule_gnn_model_simplified import GNNSimplified
31 | from .PaiNN import PaiNN
32 | from .PNA import PNA
   |                  ^^^ F401
33 | from .ProNet import ProNet
34 | from .SchNet import SchNet
   |
   = help: Use an explicit re-export: `PNA as PNA`

geom3d\models\__init__.py:33:21: F401 `.ProNet.ProNet` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
31 | from .PaiNN import PaiNN
32 | from .PNA import PNA
33 | from .ProNet import ProNet
   |                     ^^^^^^ F401
34 | from .SchNet import SchNet
35 | from .SE3_Transformer import SE3Transformer
   |
   = help: Use an explicit re-export: `ProNet as ProNet`

geom3d\models\__init__.py:34:21: F401 `.SchNet.SchNet` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
32 | from .PNA import PNA
33 | from .ProNet import ProNet
34 | from .SchNet import SchNet
   |                     ^^^^^^ F401
35 | from .SE3_Transformer import SE3Transformer
36 | from .SEGNN import SEGNNModel as SEGNN
   |
   = help: Use an explicit re-export: `SchNet as SchNet`

geom3d\models\__init__.py:35:30: F401 `.SE3_Transformer.SE3Transformer` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
33 | from .ProNet import ProNet
34 | from .SchNet import SchNet
35 | from .SE3_Transformer import SE3Transformer
   |                              ^^^^^^^^^^^^^^ F401
36 | from .SEGNN import SEGNNModel as SEGNN
37 | from .SphereNet import SphereNet
   |
   = help: Use an explicit re-export: `SE3Transformer as SE3Transformer`

geom3d\models\__init__.py:36:20: N814 Camelcase `SEGNNModel` imported as constant `SEGNN`
   |
34 | from .SchNet import SchNet
35 | from .SE3_Transformer import SE3Transformer
36 | from .SEGNN import SEGNNModel as SEGNN
   |                    ^^^^^^^^^^^^^^^^^^^ N814
37 | from .SphereNet import SphereNet
38 | from .SphereNet_periodic import SphereNetPeriodic
   |

geom3d\models\__init__.py:36:34: F401 `.SEGNN.SEGNNModel` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
34 | from .SchNet import SchNet
35 | from .SE3_Transformer import SE3Transformer
36 | from .SEGNN import SEGNNModel as SEGNN
   |                                  ^^^^^ F401
37 | from .SphereNet import SphereNet
38 | from .SphereNet_periodic import SphereNetPeriodic
   |
   = help: Use an explicit re-export: `SEGNNModel as SEGNNModel`

geom3d\models\__init__.py:37:24: F401 `.SphereNet.SphereNet` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
35 | from .SE3_Transformer import SE3Transformer
36 | from .SEGNN import SEGNNModel as SEGNN
37 | from .SphereNet import SphereNet
   |                        ^^^^^^^^^ F401
38 | from .SphereNet_periodic import SphereNetPeriodic
39 | from .TFN import TFN
   |
   = help: Use an explicit re-export: `SphereNet as SphereNet`

geom3d\models\__init__.py:38:33: F401 `.SphereNet_periodic.SphereNetPeriodic` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
36 | from .SEGNN import SEGNNModel as SEGNN
37 | from .SphereNet import SphereNet
38 | from .SphereNet_periodic import SphereNetPeriodic
   |                                 ^^^^^^^^^^^^^^^^^ F401
39 | from .TFN import TFN
40 | from .TransformerM import TransformerM
   |
   = help: Use an explicit re-export: `SphereNetPeriodic as SphereNetPeriodic`

geom3d\models\__init__.py:39:18: F401 `.TFN.TFN` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
37 | from .SphereNet import SphereNet
38 | from .SphereNet_periodic import SphereNetPeriodic
39 | from .TFN import TFN
   |                  ^^^ F401
40 | from .TransformerM import TransformerM
   |
   = help: Use an explicit re-export: `TFN as TFN`

geom3d\models\__init__.py:40:27: F401 `.TransformerM.TransformerM` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
38 | from .SphereNet_periodic import SphereNetPeriodic
39 | from .TFN import TFN
40 | from .TransformerM import TransformerM
   |                           ^^^^^^^^^^^^ F401
   |
   = help: Use an explicit re-export: `TransformerM as TransformerM`

geom3d\models\fibers.py:1:1: D100 Missing docstring in public module
geom3d\models\fibers.py:13:22: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
11 |     def __init__(
12 |         self,
13 |         num_degrees: Optional[int] = None,
   |                      ^^^^^^^^ FA100
14 |         num_channels: Optional[int] = None,
15 |         structure: Optional[List[Tuple[int, int]]] = None,
   |

geom3d\models\fibers.py:14:23: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
12 |         self,
13 |         num_degrees: Optional[int] = None,
14 |         num_channels: Optional[int] = None,
   |                       ^^^^^^^^ FA100
15 |         structure: Optional[List[Tuple[int, int]]] = None,
16 |         dictionary=None,
   |

geom3d\models\fibers.py:15:20: FA100 Add `from __future__ import annotations` to simplify `typing.Optional`
   |
13 |         num_degrees: Optional[int] = None,
14 |         num_channels: Optional[int] = None,
15 |         structure: Optional[List[Tuple[int, int]]] = None,
   |                    ^^^^^^^^ FA100
16 |         dictionary=None,
17 |     ):
   |

geom3d\models\fibers.py:15:29: FA100 Add `from __future__ import annotations` to simplify `typing.List`
   |
13 |         num_degrees: Optional[int] = None,
14 |         num_channels: Optional[int] = None,
15 |         structure: Optional[List[Tuple[int, int]]] = None,
   |                             ^^^^ FA100
16 |         dictionary=None,
17 |     ):
   |

geom3d\models\fibers.py:15:34: FA100 Add `from __future__ import annotations` to simplify `typing.Tuple`
   |
13 |         num_degrees: Optional[int] = None,
14 |         num_channels: Optional[int] = None,
15 |         structure: Optional[List[Tuple[int, int]]] = None,
   |                                  ^^^^^ FA100
16 |         dictionary=None,
17 |     ):
   |

geom3d\models\fibers.py:18:9: D205 1 blank line required between summary line and description
   |
16 |           dictionary=None,
17 |       ):
18 |           """Define fiber structure; use one num_degrees & num_channels OR structure
   |  _________^
19 | |         OR dictionary.
20 | | 
21 | |         :param num_degrees: degrees will be [0, ..., num_degrees-1]
22 | |         :param num_channels: number of channels, same for each degree
23 | |         :param structure: e.g. [(32, 0),(16, 1),(16,2)]
24 | |         :param dictionary: e.g. {0:32, 1:16, 2:16}
25 | |         """
   | |___________^ D205
26 |           if structure:
27 |               self.structure = structure
   |
   = help: Insert single blank line

geom3d\models\fibers.py:40:9: ANN205 Missing return type annotation for staticmethod `combine`
   |
39 |     @staticmethod
40 |     def combine(f1, f2):
   |         ^^^^^^^ ANN205
41 |         new_dict = copy.deepcopy(f1.structure_dict)
42 |         for k, m in f2.structure_dict.items():
   |
   = help: Add return type annotation

geom3d\models\fibers.py:40:9: D102 Missing docstring in public method
   |
39 |     @staticmethod
40 |     def combine(f1, f2):
   |         ^^^^^^^ D102
41 |         new_dict = copy.deepcopy(f1.structure_dict)
42 |         for k, m in f2.structure_dict.items():
   |

geom3d\models\fibers.py:51:9: ANN205 Missing return type annotation for staticmethod `combine_max`
   |
50 |     @staticmethod
51 |     def combine_max(f1, f2):
   |         ^^^^^^^^^^^ ANN205
52 |         new_dict = copy.deepcopy(f1.structure_dict)
53 |         for k, m in f2.structure_dict.items():
   |
   = help: Add return type annotation

geom3d\models\fibers.py:51:9: D102 Missing docstring in public method
   |
50 |     @staticmethod
51 |     def combine_max(f1, f2):
   |         ^^^^^^^^^^^ D102
52 |         new_dict = copy.deepcopy(f1.structure_dict)
53 |         for k, m in f2.structure_dict.items():
   |

geom3d\models\fibers.py:61:9: D105 Missing docstring in magic method
   |
59 |         return Fiber(structure=structure)
60 | 
61 |     def __repr__(self):
   |         ^^^^^^^^ D105
62 |         return f"{self.structure}"
   |

geom3d\models\fibers.py:65:5: D103 Missing docstring in public function
   |
65 | def fiber2head(F, h, structure, squeeze=False):
   |     ^^^^^^^^^^ D103
66 |     if squeeze:
67 |         fibers = [
   |

geom3d\models\fibers.py:65:16: N803 Argument name `F` should be lowercase
   |
65 | def fiber2head(F, h, structure, squeeze=False):
   |                ^ N803
66 |     if squeeze:
67 |         fibers = [
   |

geom3d\models\fibers.py:65:33: FBT002 Boolean default positional argument in function definition
   |
65 | def fiber2head(F, h, structure, squeeze=False):
   |                                 ^^^^^^^ FBT002
66 |     if squeeze:
67 |         fibers = [
   |

geom3d\models\from_se3cnn\SO3.py:1:1: N999 Invalid module name: 'SO3'
geom3d\models\from_se3cnn\SO3.py:11:7: N801 Class name `torch_default_dtype` should use CapWords convention
   |
11 | class torch_default_dtype:
   |       ^^^^^^^^^^^^^^^^^^^ N801
12 |     def __init__(self, dtype):
13 |         self.saved_dtype = None
   |

geom3d\models\from_se3cnn\SO3.py:11:7: D101 Missing docstring in public class
   |
11 | class torch_default_dtype:
   |       ^^^^^^^^^^^^^^^^^^^ D101
12 |     def __init__(self, dtype):
13 |         self.saved_dtype = None
   |

geom3d\models\from_se3cnn\SO3.py:12:9: D107 Missing docstring in `__init__`
   |
11 | class torch_default_dtype:
12 |     def __init__(self, dtype):
   |         ^^^^^^^^ D107
13 |         self.saved_dtype = None
14 |         self.dtype = dtype
   |

geom3d\models\from_se3cnn\SO3.py:16:9: D105 Missing docstring in magic method
   |
14 |         self.dtype = dtype
15 | 
16 |     def __enter__(self):
   |         ^^^^^^^^^ D105
17 |         self.saved_dtype = torch.get_default_dtype()
18 |         torch.set_default_dtype(self.dtype)
   |

geom3d\models\from_se3cnn\SO3.py:20:9: D105 Missing docstring in magic method
   |
18 |         torch.set_default_dtype(self.dtype)
19 | 
20 |     def __exit__(self, exc_type, exc_value, traceback):
   |         ^^^^^^^^ D105
21 |         torch.set_default_dtype(self.saved_dtype)
   |

geom3d\models\from_se3cnn\SO3.py:68:1: ERA001 Found commented-out code
   |
67 | # These functions (x_to_alpha_beta and rot) satisfies that
68 | # rot(*x_to_alpha_beta([x, y, z]), 0) @ np.array([[0], [0], [1]])
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
69 | # is proportional to
70 | # [x, y, z]
   |
   = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:70:1: ERA001 Found commented-out code
   |
68 | # rot(*x_to_alpha_beta([x, y, z]), 0) @ np.array([[0], [0], [1]])
69 | # is proportional to
70 | # [x, y, z]
   | ^^^^^^^^^^^ ERA001
   |
   = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:74:5: D205 1 blank line required between summary line and description
   |
73 |   def irr_repr(order, alpha, beta, gamma, dtype=None):
74 |       """Irreducible representation of SO3
   |  _____^
75 | |     - compatible with compose and spherical_harmonics.
76 | |     """
   | |_______^ D205
77 |       # from from_lielearn_SO3.wigner_d import wigner_D_matrix
78 |       from lie_learn.representations.SO3.wigner_d import wigner_D_matrix
   |
   = help: Insert single blank line

geom3d\models\from_se3cnn\SO3.py:77:5: ERA001 Found commented-out code
   |
75 |     - compatible with compose and spherical_harmonics.
76 |     """
77 |     # from from_lielearn_SO3.wigner_d import wigner_D_matrix
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
78 |     from lie_learn.representations.SO3.wigner_d import wigner_D_matrix
   |
   = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:82:5: ERA001 Found commented-out code
   |
80 |     # if order == 1:
81 |     #     # change of basis to have vector_field[x, y, z] = [vx, vy, vz]
82 |     #     A = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
83 |     #     return A @ wigner_D_matrix(1, alpha, beta, gamma) @ A.T
84 |     # TODO (non-essential): try to do everything in torch
   |
   = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:83:5: ERA001 Found commented-out code
   |
81 |     #     # change of basis to have vector_field[x, y, z] = [vx, vy, vz]
82 |     #     A = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])
83 |     #     return A @ wigner_D_matrix(1, alpha, beta, gamma) @ A.T
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
84 |     # TODO (non-essential): try to do everything in torch
85 |     # return torch.tensor(wigner_D_matrix(torch.tensor(order), alpha, beta, gamma), dtype=torch.get_default_dtype() if dtype is None else dtype)
   |
   = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:84:7: TD003 Missing issue link on the line following this TODO
   |
82 |     #     A = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])
83 |     #     return A @ wigner_D_matrix(1, alpha, beta, gamma) @ A.T
84 |     # TODO (non-essential): try to do everything in torch
   |       ^^^^ TD003
85 |     # return torch.tensor(wigner_D_matrix(torch.tensor(order), alpha, beta, gamma), dtype=torch.get_default_dtype() if dtype is None else dtype)
86 |     return torch.tensor(
   |

geom3d\models\from_se3cnn\SO3.py:84:7: FIX002 Line contains TODO, consider resolving the issue
   |
82 |     #     A = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])
83 |     #     return A @ wigner_D_matrix(1, alpha, beta, gamma) @ A.T
84 |     # TODO (non-essential): try to do everything in torch
   |       ^^^^ FIX002
85 |     # return torch.tensor(wigner_D_matrix(torch.tensor(order), alpha, beta, gamma), dtype=torch.get_default_dtype() if dtype is None else dtype)
86 |     return torch.tensor(
   |

geom3d\models\from_se3cnn\SO3.py:85:5: ERA001 Found commented-out code
   |
83 |     #     return A @ wigner_D_matrix(1, alpha, beta, gamma) @ A.T
84 |     # TODO (non-essential): try to do everything in torch
85 |     # return torch.tensor(wigner_D_matrix(torch.tensor(order), alpha, beta, gamma), dtype=torch.get_default_dtype() if dtype is None else dtype)
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
86 |     return torch.tensor(
87 |         wigner_D_matrix(order, np.array(alpha), np.array(beta), np.array(gamma)),
   |
   = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:97:1: ERA001 Found commented-out code
   |
95 | #     - compatible with irr_repr and compose
96 | #     """
97 | #     # from from_lielearn_SO3.spherical_harmonics import sh
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
98 | #     from lie_learn.representations.SO3.spherical_harmonics import sh  # real valued by default
99 | #
   |
   = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:98:1: ERA001 Found commented-out code
    |
 96 | #     """
 97 | #     # from from_lielearn_SO3.spherical_harmonics import sh
 98 | #     from lie_learn.representations.SO3.spherical_harmonics import sh  # real valued by default
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
 99 | #
100 | #     ###################################################################################################################
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:109:1: ERA001 Found commented-out code
    |
107 | #     # this function therefore (probably) has the following convention for alpha and beta:
108 | #     # beta = pi - theta; ranging from 0(South Pole, (X, Y, Z) = (0, 0, -1)) to pi(North Pole, (X, Y, Z) = (0, 0, 1)).
109 | #     # alpha = phi
    | ^^^^^^^^^^^^^^^^^^^ ERA001
110 | #     #
111 | #     ###################################################################################################################
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:113:1: ERA001 Found commented-out code
    |
111 | #     ###################################################################################################################
112 | #
113 | #     Y = torch.tensor([sh(order, m, theta=math.pi - beta, phi=alpha) for m in range(-order, order + 1)], dtype=torch.get_default_dtype() if dtype is None else dtype)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
114 | #     # if order == 1:
115 | #     #     # change of basis to have vector_field[x, y, z] = [vx, vy, vz]
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:116:1: ERA001 Found commented-out code
    |
114 | #     # if order == 1:
115 | #     #     # change of basis to have vector_field[x, y, z] = [vx, vy, vz]
116 | #     #     A = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
117 | #     #     return A @ Y
118 | #     return Y
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:117:1: ERA001 Found commented-out code
    |
115 | #     #     # change of basis to have vector_field[x, y, z] = [vx, vy, vz]
116 | #     #     A = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])
117 | #     #     return A @ Y
    | ^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
118 | #     return Y
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:118:1: ERA001 Found commented-out code
    |
116 | #     #     A = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])
117 | #     #     return A @ Y
118 | #     return Y
    | ^^^^^^^^^^^^^^ ERA001
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:121:5: PLR0913 Too many arguments in function definition (6 > 5)
    |
121 | def compose(a1, b1, c1, a2, b2, c2):
    |     ^^^^^^^ PLR0913
122 |     """(a, b, c) = (a1, b1, c1) composed with (a2, b2, c2)."""
123 |     comp = rot(a1, b1, c1) @ rot(a2, b2, c2)
    |

geom3d\models\from_se3cnn\SO3.py:122:5: D401 First line of docstring should be in imperative mood: "(a, b, c) = (a1, b1, c1) composed with (a2, b2, c2)."
    |
121 | def compose(a1, b1, c1, a2, b2, c2):
122 |     """(a, b, c) = (a1, b1, c1) composed with (a2, b2, c2)."""
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
123 |     comp = rot(a1, b1, c1) @ rot(a2, b2, c2)
124 |     xyz = comp @ torch.tensor([0, 0, 1.0])
    |

geom3d\models\from_se3cnn\SO3.py:131:5: D103 Missing docstring in public function
    |
131 | def kron(x, y):
    |     ^^^^ D103
132 |     assert x.ndimension() == 2
133 |     assert y.ndimension() == 2
    |

geom3d\models\from_se3cnn\SO3.py:132:5: S101 Use of `assert` detected
    |
131 | def kron(x, y):
132 |     assert x.ndimension() == 2
    |     ^^^^^^ S101
133 |     assert y.ndimension() == 2
134 |     return torch.einsum("ij,kl->ikjl", (x, y)).view(
    |

geom3d\models\from_se3cnn\SO3.py:132:30: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
131 | def kron(x, y):
132 |     assert x.ndimension() == 2
    |                              ^ PLR2004
133 |     assert y.ndimension() == 2
134 |     return torch.einsum("ij,kl->ikjl", (x, y)).view(
    |

geom3d\models\from_se3cnn\SO3.py:133:5: S101 Use of `assert` detected
    |
131 | def kron(x, y):
132 |     assert x.ndimension() == 2
133 |     assert y.ndimension() == 2
    |     ^^^^^^ S101
134 |     return torch.einsum("ij,kl->ikjl", (x, y)).view(
135 |         x.size(0) * y.size(0), x.size(1) * y.size(1)
    |

geom3d\models\from_se3cnn\SO3.py:133:30: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
131 | def kron(x, y):
132 |     assert x.ndimension() == 2
133 |     assert y.ndimension() == 2
    |                              ^ PLR2004
134 |     return torch.einsum("ij,kl->ikjl", (x, y)).view(
135 |         x.size(0) * y.size(0), x.size(1) * y.size(1)
    |

geom3d\models\from_se3cnn\SO3.py:145:5: D205 1 blank line required between summary line and description
    |
144 |   def xyz_vector_basis_to_spherical_basis():
145 |       """To convert a vector [x, y, z] transforming with rot(a, b, c)
    |  _____^
146 | |     into a vector transforming with irr_repr(1, a, b, c)
147 | |     see assert for usage.
148 | |     """
    | |_______^ D205
149 |       with torch_default_dtype(torch.float64):
150 |           A = torch.tensor([[0, 1, 0], [0, 0, 1], [1, 0, 0]], dtype=torch.float64)
    |
    = help: Insert single blank line

geom3d\models\from_se3cnn\SO3.py:150:9: N806 Variable `A` in function should be lowercase
    |
148 |     """
149 |     with torch_default_dtype(torch.float64):
150 |         A = torch.tensor([[0, 1, 0], [0, 0, 1], [1, 0, 0]], dtype=torch.float64)
    |         ^ N806
151 |         assert all(
152 |             torch.allclose(irr_repr(1, a, b, c) @ A, A @ rot(a, b, c))
    |

geom3d\models\from_se3cnn\SO3.py:151:9: S101 Use of `assert` detected
    |
149 |     with torch_default_dtype(torch.float64):
150 |         A = torch.tensor([[0, 1, 0], [0, 0, 1], [1, 0, 0]], dtype=torch.float64)
151 |         assert all(
    |         ^^^^^^ S101
152 |             torch.allclose(irr_repr(1, a, b, c) @ A, A @ rot(a, b, c))
153 |             for a, b, c in torch.rand(10, 3)
    |

geom3d\models\from_se3cnn\SO3.py:159:5: D205 1 blank line required between summary line and description
    |
158 |   def tensor3x3_repr(a, b, c):
159 |       """Representation of 3x3 tensors
    |  _____^
160 | |     T --> R T R^t.
161 | |     """
    | |_______^ D205
162 |       r = rot(a, b, c)
163 |       return kron(r, r)
    |
    = help: Insert single blank line

geom3d\models\from_se3cnn\SO3.py:167:5: D205 1 blank line required between summary line and description
    |
166 |   def tensor3x3_repr_basis_to_spherical_basis():
167 |       """To convert a 3x3 tensor transforming with tensor3x3_repr(a, b, c)
    |  _____^
168 | |     into its 1 + 3 + 5 component transforming with irr_repr(0, a, b, c), irr_repr(1, a, b, c), irr_repr(3, a, b, c)
169 | |     see assert for usage.
170 | |     """
    | |_______^ D205
171 |       with torch_default_dtype(torch.float64):
172 |           to1 = torch.tensor(
    |
    = help: Insert single blank line

geom3d\models\from_se3cnn\SO3.py:178:9: S101 Use of `assert` detected
    |
176 |             dtype=torch.get_default_dtype(),
177 |         )
178 |         assert all(
    |         ^^^^^^ S101
179 |             torch.allclose(irr_repr(0, a, b, c) @ to1, to1 @ tensor3x3_repr(a, b, c))
180 |             for a, b, c in torch.rand(10, 3)
    |

geom3d\models\from_se3cnn\SO3.py:191:9: S101 Use of `assert` detected
    |
189 |             dtype=torch.get_default_dtype(),
190 |         )
191 |         assert all(
    |         ^^^^^^ S101
192 |             torch.allclose(irr_repr(1, a, b, c) @ to3, to3 @ tensor3x3_repr(a, b, c))
193 |             for a, b, c in torch.rand(10, 3)
    |

geom3d\models\from_se3cnn\SO3.py:206:9: S101 Use of `assert` detected
    |
204 |             dtype=torch.get_default_dtype(),
205 |         )
206 |         assert all(
    |         ^^^^^^ S101
207 |             torch.allclose(irr_repr(2, a, b, c) @ to5, to5 @ tensor3x3_repr(a, b, c))
208 |             for a, b, c in torch.rand(10, 3)
    |

geom3d\models\from_se3cnn\SO3.py:237:9: S101 Use of `assert` detected
    |
236 |         d, r = (r - r_).abs().max(), r.abs().max()
237 |         assert d < 1e-10 * r, d / r
    |         ^^^^^^ S101
    |

geom3d\models\from_se3cnn\SO3.py:241:5: D205 1 blank line required between summary line and description
    |
240 |   def _test_spherical_harmonics(order) -> None:
241 |       """This test tests that
    |  _____^
242 | |     - irr_repr
243 | |     - compose
244 | |     - spherical_harmonics
245 | |     are compatible.
246 | | 
247 | |     Y(Z(alpha) Y(beta) Z(gamma) x) = D(alpha, beta, gamma) Y(x)
248 | |     with x = Z(a) Y(b) eta
249 | |     """
    | |_______^ D205
250 |       with torch_default_dtype(torch.float64):
251 |           a, b = torch.rand(2)
    |
    = help: Insert single blank line

geom3d\models\from_se3cnn\SO3.py:241:5: D401 First line of docstring should be in imperative mood: "This test tests that"
    |
240 |   def _test_spherical_harmonics(order) -> None:
241 |       """This test tests that
    |  _____^
242 | |     - irr_repr
243 | |     - compose
244 | |     - spherical_harmonics
245 | |     are compatible.
246 | | 
247 | |     Y(Z(alpha) Y(beta) Z(gamma) x) = D(alpha, beta, gamma) Y(x)
248 | |     with x = Z(a) Y(b) eta
249 | |     """
    | |_______^ D401
250 |       with torch_default_dtype(torch.float64):
251 |           a, b = torch.rand(2)
    |

geom3d\models\from_se3cnn\SO3.py:241:5: D404 First word of the docstring should not be "This"
    |
240 |   def _test_spherical_harmonics(order) -> None:
241 |       """This test tests that
    |  _____^
242 | |     - irr_repr
243 | |     - compose
244 | |     - spherical_harmonics
245 | |     are compatible.
246 | | 
247 | |     Y(Z(alpha) Y(beta) Z(gamma) x) = D(alpha, beta, gamma) Y(x)
248 | |     with x = Z(a) Y(b) eta
249 | |     """
    | |_______^ D404
250 |       with torch_default_dtype(torch.float64):
251 |           a, b = torch.rand(2)
    |

geom3d\models\from_se3cnn\SO3.py:255:9: N806 Variable `Yrx` in function should be lowercase
    |
254 |         ra, rb, _ = compose(alpha, beta, gamma, a, b, 0)
255 |         Yrx = spherical_harmonics(order, ra, rb)
    |         ^^^ N806
256 | 
257 |         Y = spherical_harmonics(order, a, b)
    |

geom3d\models\from_se3cnn\SO3.py:255:15: F821 Undefined name `spherical_harmonics`
    |
254 |         ra, rb, _ = compose(alpha, beta, gamma, a, b, 0)
255 |         Yrx = spherical_harmonics(order, ra, rb)
    |               ^^^^^^^^^^^^^^^^^^^ F821
256 | 
257 |         Y = spherical_harmonics(order, a, b)
    |

geom3d\models\from_se3cnn\SO3.py:257:9: N806 Variable `Y` in function should be lowercase
    |
255 |         Yrx = spherical_harmonics(order, ra, rb)
256 | 
257 |         Y = spherical_harmonics(order, a, b)
    |         ^ N806
258 |         DrY = irr_repr(order, alpha, beta, gamma) @ Y
    |

geom3d\models\from_se3cnn\SO3.py:257:13: F821 Undefined name `spherical_harmonics`
    |
255 |         Yrx = spherical_harmonics(order, ra, rb)
256 | 
257 |         Y = spherical_harmonics(order, a, b)
    |             ^^^^^^^^^^^^^^^^^^^ F821
258 |         DrY = irr_repr(order, alpha, beta, gamma) @ Y
    |

geom3d\models\from_se3cnn\SO3.py:258:9: N806 Variable `DrY` in function should be lowercase
    |
257 |         Y = spherical_harmonics(order, a, b)
258 |         DrY = irr_repr(order, alpha, beta, gamma) @ Y
    |         ^^^ N806
259 | 
260 |         d, r = (Yrx - DrY).abs().max(), Y.abs().max()
    |

geom3d\models\from_se3cnn\SO3.py:261:9: S101 Use of `assert` detected
    |
260 |         d, r = (Yrx - DrY).abs().max(), Y.abs().max()
261 |         assert d < 1e-10 * r, d / r
    |         ^^^^^^ S101
    |

geom3d\models\from_se3cnn\SO3.py:265:5: ERA001 Found commented-out code
    |
264 | def _test_change_basis_wigner_to_rot() -> None:
265 |     # from from_lielearn_SO3.wigner_d import wigner_D_matrix
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
266 |     from lie_learn.representations.SO3.wigner_d import wigner_D_matrix
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\SO3.py:269:9: N806 Variable `A` in function should be lowercase
    |
268 |     with torch_default_dtype(torch.float64):
269 |         A = torch.tensor([[0, 1, 0], [0, 0, 1], [1, 0, 0]], dtype=torch.float64)
    |         ^ N806
270 | 
271 |         a, b, c = torch.rand(3)
    |

geom3d\models\from_se3cnn\SO3.py:277:9: S101 Use of `assert` detected
    |
276 |         d = (r1 - r2).abs().max()
277 |         assert d < 1e-10
    |         ^^^^^^ S101
    |

geom3d\models\from_se3cnn\SO3.py:277:20: PLR2004 Magic value used in comparison, consider replacing `1e-10` with a constant variable
    |
276 |         d = (r1 - r2).abs().max()
277 |         assert d < 1e-10
    |                    ^^^^^ PLR2004
    |

geom3d\models\from_se3cnn\SO3.py:291:9: E741 Ambiguous variable name: `l`
    |
289 |     _test_change_basis_wigner_to_rot()
290 | 
291 |     for l in range(7):
    |         ^ E741
292 |         _test_spherical_harmonics(l)
    |

geom3d\models\from_se3cnn\SO3.py:294:9: E741 Ambiguous variable name: `l`
    |
292 |         _test_spherical_harmonics(l)
293 | 
294 |     for l in range(7):
    |         ^ E741
295 |         test_is_representation(partial(irr_repr, l))
    |

geom3d\models\from_se3cnn\__init__.py:1:1: D104 Missing docstring in public package
geom3d\models\from_se3cnn\cache_file.py:10:5: N802 Function name `LOCK_EX` should be lowercase
   |
10 | def LOCK_EX():
   |     ^^^^^^^ N802
11 |     return 0
   |

geom3d\models\from_se3cnn\cache_file.py:10:5: D103 Missing docstring in public function
   |
10 | def LOCK_EX():
   |     ^^^^^^^ D103
11 |     return 0
   |

geom3d\models\from_se3cnn\cache_file.py:13:5: D103 Missing docstring in public function
   |
11 |     return 0
12 | 
13 | def lockf(fd, operation, length=0, start=0, whence=0):
   |     ^^^^^ D103
14 |     pass
   |

geom3d\models\from_se3cnn\cache_file.py:13:11: ARG001 Unused function argument: `fd`
   |
11 |     return 0
12 | 
13 | def lockf(fd, operation, length=0, start=0, whence=0):
   |           ^^ ARG001
14 |     pass
   |

geom3d\models\from_se3cnn\cache_file.py:13:15: ARG001 Unused function argument: `operation`
   |
11 |     return 0
12 | 
13 | def lockf(fd, operation, length=0, start=0, whence=0):
   |               ^^^^^^^^^ ARG001
14 |     pass
   |

geom3d\models\from_se3cnn\cache_file.py:13:26: ARG001 Unused function argument: `length`
   |
11 |     return 0
12 | 
13 | def lockf(fd, operation, length=0, start=0, whence=0):
   |                          ^^^^^^ ARG001
14 |     pass
   |

geom3d\models\from_se3cnn\cache_file.py:13:36: ARG001 Unused function argument: `start`
   |
11 |     return 0
12 | 
13 | def lockf(fd, operation, length=0, start=0, whence=0):
   |                                    ^^^^^ ARG001
14 |     pass
   |

geom3d\models\from_se3cnn\cache_file.py:13:45: ARG001 Unused function argument: `whence`
   |
11 |     return 0
12 | 
13 | def lockf(fd, operation, length=0, start=0, whence=0):
   |                                             ^^^^^^ ARG001
14 |     pass
   |

geom3d\models\from_se3cnn\cache_file.py:19:9: D107 Missing docstring in `__init__`
   |
17 |     """Mutual exclusion of different **processes** using the file system."""
18 | 
19 |     def __init__(self, filename):
   |         ^^^^^^^^ D107
20 |         self.handle = None
21 |         self.filename = filename
   |

geom3d\models\from_se3cnn\cache_file.py:24:9: D205 1 blank line required between summary line and description
   |
23 |       def acquire(self):
24 |           """Locks the mutex
   |  _________^
25 | |         if it is already locked, it waits (blocking function).
26 | |         """
   | |___________^ D205
27 |           self.handle = open(self.filename, "w")
28 |           lockf(self.handle, LOCK_EX)
   |
   = help: Insert single blank line

geom3d\models\from_se3cnn\cache_file.py:27:23: SIM115 Use context handler for opening files
   |
25 |         if it is already locked, it waits (blocking function).
26 |         """
27 |         self.handle = open(self.filename, "w")
   |                       ^^^^ SIM115
28 |         lockf(self.handle, LOCK_EX)
29 |         self.handle.write(f"{os.getpid()}\n")
   |

geom3d\models\from_se3cnn\cache_file.py:27:23: PTH123 `open()` should be replaced by `Path.open()`
   |
25 |         if it is already locked, it waits (blocking function).
26 |         """
27 |         self.handle = open(self.filename, "w")
   |                       ^^^^ PTH123
28 |         lockf(self.handle, LOCK_EX)
29 |         self.handle.write(f"{os.getpid()}\n")
   |

geom3d\models\from_se3cnn\cache_file.py:40:9: D105 Missing docstring in magic method
   |
38 |         self.handle = None
39 | 
40 |     def __enter__(self):
   |         ^^^^^^^^^ D105
41 |         self.acquire()
   |

geom3d\models\from_se3cnn\cache_file.py:43:9: D105 Missing docstring in magic method
   |
41 |         self.acquire()
42 | 
43 |     def __exit__(self, exc_type, exc_value, traceback):
   |         ^^^^^^^^ D105
44 |         self.release()
   |

geom3d\models\from_se3cnn\cache_file.py:54:9: ANN202 Missing return type annotation for private function `decorator`
   |
52 |     """
53 | 
54 |     def decorator(func):
   |         ^^^^^^^^^ ANN202
55 |         """The actual decorator."""
   |
   = help: Add return type annotation

geom3d\models\from_se3cnn\cache_file.py:55:9: D401 First line of docstring should be in imperative mood: "The actual decorator."
   |
54 |     def decorator(func):
55 |         """The actual decorator."""
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
56 | 
57 |         @lru_cache(maxsize=maxsize)
   |

geom3d\models\from_se3cnn\cache_file.py:59:13: ANN202 Missing return type annotation for private function `wrapper`
   |
57 |         @lru_cache(maxsize=maxsize)
58 |         @wraps(func)
59 |         def wrapper(*args, **kwargs):
   |             ^^^^^^^ ANN202
60 |             """The wrapper of the function."""
61 |             with contextlib.suppress(FileExistsError):
   |
   = help: Add return type annotation

geom3d\models\from_se3cnn\cache_file.py:59:21: ANN002 Missing type annotation for `*args`
   |
57 |         @lru_cache(maxsize=maxsize)
58 |         @wraps(func)
59 |         def wrapper(*args, **kwargs):
   |                     ^^^^^ ANN002
60 |             """The wrapper of the function."""
61 |             with contextlib.suppress(FileExistsError):
   |

geom3d\models\from_se3cnn\cache_file.py:59:28: ANN003 Missing type annotation for `**kwargs`
   |
57 |         @lru_cache(maxsize=maxsize)
58 |         @wraps(func)
59 |         def wrapper(*args, **kwargs):
   |                            ^^^^^^^^ ANN003
60 |             """The wrapper of the function."""
61 |             with contextlib.suppress(FileExistsError):
   |

geom3d\models\from_se3cnn\cache_file.py:60:13: D401 First line of docstring should be in imperative mood: "The wrapper of the function."
   |
58 |         @wraps(func)
59 |         def wrapper(*args, **kwargs):
60 |             """The wrapper of the function."""
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
61 |             with contextlib.suppress(FileExistsError):
62 |                 os.makedirs(dirname)
   |

geom3d\models\from_se3cnn\cache_file.py:62:17: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   |
60 |             """The wrapper of the function."""
61 |             with contextlib.suppress(FileExistsError):
62 |                 os.makedirs(dirname)
   |                 ^^^^^^^^^^^ PTH103
63 | 
64 |             indexfile = os.path.join(dirname, "index.pkl")
   |

geom3d\models\from_se3cnn\cache_file.py:64:25: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   |
62 |                 os.makedirs(dirname)
63 | 
64 |             indexfile = os.path.join(dirname, "index.pkl")
   |                         ^^^^^^^^^^^^ PTH118
65 |             mutexfile = os.path.join(dirname, "mutex")
   |

geom3d\models\from_se3cnn\cache_file.py:65:25: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   |
64 |             indexfile = os.path.join(dirname, "index.pkl")
65 |             mutexfile = os.path.join(dirname, "mutex")
   |                         ^^^^^^^^^^^^ PTH118
66 | 
67 |             with FileSystemMutex(mutexfile):
   |

geom3d\models\from_se3cnn\cache_file.py:69:26: PTH123 `open()` should be replaced by `Path.open()`
   |
67 |             with FileSystemMutex(mutexfile):
68 |                 try:
69 |                     with open(indexfile, "rb") as file:
   |                          ^^^^ PTH123
70 |                         index = pickle.load(file)
71 |                 except FileNotFoundError:
   |

geom3d\models\from_se3cnn\cache_file.py:70:33: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
   |
68 |                 try:
69 |                     with open(indexfile, "rb") as file:
70 |                         index = pickle.load(file)
   |                                 ^^^^^^^^^^^^^^^^^ S301
71 |                 except FileNotFoundError:
72 |                     index = {}
   |

geom3d\models\from_se3cnn\cache_file.py:80:26: PTH123 `open()` should be replaced by `Path.open()`
   |
78 |                 except KeyError:
79 |                     index[key] = filename = f"{len(index)}.pkl.gz"
80 |                     with open(indexfile, "wb") as file:
   |                          ^^^^ PTH123
81 |                         pickle.dump(index, file)
   |

geom3d\models\from_se3cnn\cache_file.py:83:24: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   |
81 |                         pickle.dump(index, file)
82 | 
83 |             filepath = os.path.join(dirname, filename)
   |                        ^^^^^^^^^^^^ PTH118
84 | 
85 |             try:
   |

geom3d\models\from_se3cnn\cache_file.py:86:17: SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
   |
85 |               try:
86 |                   with FileSystemMutex(mutexfile):
   |  _________________^
87 | |                     with gzip.open(filepath, "rb") as file:
   | |___________________________________________________________^ SIM117
88 |                           result = pickle.load(file)
89 |               except FileNotFoundError:
   |
   = help: Combine `with` statements

geom3d\models\from_se3cnn\cache_file.py:88:34: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
   |
86 |                 with FileSystemMutex(mutexfile):
87 |                     with gzip.open(filepath, "rb") as file:
88 |                         result = pickle.load(file)
   |                                  ^^^^^^^^^^^^^^^^^ S301
89 |             except FileNotFoundError:
90 |                 sys.stdout.flush()
   |

geom3d\models\from_se3cnn\cache_file.py:93:17: SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
   |
91 |                   result = func(*args, **kwargs)
92 |                   sys.stdout.flush()
93 |                   with FileSystemMutex(mutexfile):
   |  _________________^
94 | |                     with gzip.open(filepath, "wb") as file:
   | |___________________________________________________________^ SIM117
95 |                           pickle.dump(result, file)
96 |               return result
   |
   = help: Combine `with` statements

geom3d\models\from_se3cnn\representations.py:1:1: D100 Missing docstring in public module
geom3d\models\from_se3cnn\representations.py:25:5: D417 Missing argument description in the docstring for `pochhammer`: `k`
   |
25 | def pochhammer(x, k):
   |     ^^^^^^^^^^ D417
26 |     """Compute the pochhammer symbol (x)_k.
   |

geom3d\models\from_se3cnn\representations.py:43:5: D417 Missing argument descriptions in the docstring for `lpmv`: `l`, `x`
   |
43 | def lpmv(l, m, x):
   |     ^^^^ D417
44 |     """Associated Legendre function including Condon-Shortley phase.
   |

geom3d\models\from_se3cnn\representations.py:43:10: E741 Ambiguous variable name: `l`
   |
43 | def lpmv(l, m, x):
   |          ^ E741
44 |     """Associated Legendre function including Condon-Shortley phase.
   |

geom3d\models\from_se3cnn\representations.py:81:5: D417 Missing argument descriptions in the docstring for `tesseral_harmonics`: `m`, `phi`, `theta`
   |
81 | def tesseral_harmonics(l, m, theta=0.0, phi=0.0):
   |     ^^^^^^^^^^^^^^^^^^ D417
82 |     """Tesseral spherical harmonic with Condon-Shortley phase.
   |

geom3d\models\from_se3cnn\representations.py:81:24: E741 Ambiguous variable name: `l`
   |
81 | def tesseral_harmonics(l, m, theta=0.0, phi=0.0):
   |                        ^ E741
82 |     """Tesseral spherical harmonic with Condon-Shortley phase.
   |

geom3d\models\from_se3cnn\representations.py:97:5: S101 Use of `assert` detected
   |
96 |     """
97 |     assert abs(m) <= l, "absolute value of order m must be <= degree l"
   |     ^^^^^^ S101
98 | 
99 |     N = np.sqrt((2 * l + 1) / (4 * np.pi))
   |

geom3d\models\from_se3cnn\representations.py:99:5: N806 Variable `N` in function should be lowercase
    |
 97 |     assert abs(m) <= l, "absolute value of order m must be <= degree l"
 98 | 
 99 |     N = np.sqrt((2 * l + 1) / (4 * np.pi))
    |     ^ N806
100 |     leg = lpmv(l, abs(m), torch.cos(theta))
101 |     if m == 0:
    |

geom3d\models\from_se3cnn\representations.py:103:5: RET505 Unnecessary `elif` after `return` statement
    |
101 |     if m == 0:
102 |         return N * leg
103 |     elif m > 0:
    |     ^^^^ RET505
104 |         Y = torch.cos(m * phi) * leg
105 |     else:
    |
    = help: Remove unnecessary `elif`

geom3d\models\from_se3cnn\representations.py:104:9: N806 Variable `Y` in function should be lowercase
    |
102 |         return N * leg
103 |     elif m > 0:
104 |         Y = torch.cos(m * phi) * leg
    |         ^ N806
105 |     else:
106 |         Y = torch.sin(abs(m) * phi) * leg
    |

geom3d\models\from_se3cnn\representations.py:106:9: N806 Variable `Y` in function should be lowercase
    |
104 |         Y = torch.cos(m * phi) * leg
105 |     else:
106 |         Y = torch.sin(abs(m) * phi) * leg
    |         ^ N806
107 |     N *= np.sqrt(2.0 / pochhammer(l - abs(m) + 1, 2 * abs(m)))
108 |     Y *= N
    |

geom3d\models\from_se3cnn\representations.py:107:5: N806 Variable `N` in function should be lowercase
    |
105 |     else:
106 |         Y = torch.sin(abs(m) * phi) * leg
107 |     N *= np.sqrt(2.0 / pochhammer(l - abs(m) + 1, 2 * abs(m)))
    |     ^ N806
108 |     Y *= N
109 |     return Y
    |

geom3d\models\from_se3cnn\representations.py:108:5: N806 Variable `Y` in function should be lowercase
    |
106 |         Y = torch.sin(abs(m) * phi) * leg
107 |     N *= np.sqrt(2.0 / pochhammer(l - abs(m) + 1, 2 * abs(m)))
108 |     Y *= N
    |     ^ N806
109 |     return Y
    |

geom3d\models\from_se3cnn\representations.py:112:7: D101 Missing docstring in public class
    |
112 | class SphericalHarmonics:
    |       ^^^^^^^^^^^^^^^^^^ D101
113 |     def __init__(self):
114 |         self.leg = {}
    |

geom3d\models\from_se3cnn\representations.py:113:9: D107 Missing docstring in `__init__`
    |
112 | class SphericalHarmonics:
113 |     def __init__(self):
    |         ^^^^^^^^ D107
114 |         self.leg = {}
    |

geom3d\models\from_se3cnn\representations.py:116:9: D102 Missing docstring in public method
    |
114 |         self.leg = {}
115 | 
116 |     def clear(self):
    |         ^^^^^ D102
117 |         self.leg = {}
    |

geom3d\models\from_se3cnn\representations.py:119:29: E741 Ambiguous variable name: `l`
    |
117 |         self.leg = {}
118 | 
119 |     def negative_lpmv(self, l, m, y):
    |                             ^ E741
120 |         """Compute negative order coefficients."""
121 |         if m < 0:
    |

geom3d\models\from_se3cnn\representations.py:125:9: D417 Missing argument descriptions in the docstring for `lpmv`: `l`, `x`
    |
123 |         return y
124 | 
125 |     def lpmv(self, l, m, x):
    |         ^^^^ D417
126 |         """Associated Legendre function including Condon-Shortley phase.
    |

geom3d\models\from_se3cnn\representations.py:125:20: E741 Ambiguous variable name: `l`
    |
123 |         return y
124 | 
125 |     def lpmv(self, l, m, x):
    |                    ^ E741
126 |         """Associated Legendre function including Condon-Shortley phase.
    |

geom3d\models\from_se3cnn\representations.py:141:9: RET505 Unnecessary `elif` after `return` statement
    |
139 |         if (l, m) in self.leg:
140 |             return self.leg[(l, m)]
141 |         elif m_abs > l:
    |         ^^^^ RET505
142 |             return None
143 |         elif l == 0:
    |
    = help: Remove unnecessary `elif`

geom3d\models\from_se3cnn\representations.py:154:9: RET505 Unnecessary `else` after `return` statement
    |
152 |             self.leg[(l, m)] = self.negative_lpmv(l, m, y)
153 |             return self.leg[(l, m)]
154 |         else:
    |         ^^^^ RET505
155 |             # Recursively precompute lower degree harmonics
156 |             self.lpmv(l - 1, m, x)
    |
    = help: Remove unnecessary `else`

geom3d\models\from_se3cnn\representations.py:163:9: ERA001 Found commented-out code
    |
161 |         if l - m_abs > 1:
162 |             y -= ((l + m_abs - 1) / (l - m_abs)) * self.leg[(l - 2, m_abs)]
163 |         # self.leg[(l, m_abs)] = y
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
164 | 
165 |         if m < 0:
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\representations.py:171:9: D417 Missing argument descriptions in the docstring for `get_element`: `m`, `phi`, `theta`
    |
169 |         return self.leg[(l, m)]
170 | 
171 |     def get_element(self, l, m, theta, phi):
    |         ^^^^^^^^^^^ D417
172 |         """Tesseral spherical harmonic with Condon-Shortley phase.
    |

geom3d\models\from_se3cnn\representations.py:171:27: E741 Ambiguous variable name: `l`
    |
169 |         return self.leg[(l, m)]
170 | 
171 |     def get_element(self, l, m, theta, phi):
    |                           ^ E741
172 |         """Tesseral spherical harmonic with Condon-Shortley phase.
    |

geom3d\models\from_se3cnn\representations.py:187:9: S101 Use of `assert` detected
    |
186 |         """
187 |         assert abs(m) <= l, "absolute value of order m must be <= degree l"
    |         ^^^^^^ S101
188 | 
189 |         N = np.sqrt((2 * l + 1) / (4 * np.pi))
    |

geom3d\models\from_se3cnn\representations.py:189:9: N806 Variable `N` in function should be lowercase
    |
187 |         assert abs(m) <= l, "absolute value of order m must be <= degree l"
188 | 
189 |         N = np.sqrt((2 * l + 1) / (4 * np.pi))
    |         ^ N806
190 |         leg = self.lpmv(l, abs(m), torch.cos(theta))
191 |         if m == 0:
    |

geom3d\models\from_se3cnn\representations.py:193:9: RET505 Unnecessary `elif` after `return` statement
    |
191 |         if m == 0:
192 |             return N * leg
193 |         elif m > 0:
    |         ^^^^ RET505
194 |             Y = torch.cos(m * phi) * leg
195 |         else:
    |
    = help: Remove unnecessary `elif`

geom3d\models\from_se3cnn\representations.py:194:13: N806 Variable `Y` in function should be lowercase
    |
192 |             return N * leg
193 |         elif m > 0:
194 |             Y = torch.cos(m * phi) * leg
    |             ^ N806
195 |         else:
196 |             Y = torch.sin(abs(m) * phi) * leg
    |

geom3d\models\from_se3cnn\representations.py:196:13: N806 Variable `Y` in function should be lowercase
    |
194 |             Y = torch.cos(m * phi) * leg
195 |         else:
196 |             Y = torch.sin(abs(m) * phi) * leg
    |             ^ N806
197 |         N *= np.sqrt(2.0 / pochhammer(l - abs(m) + 1, 2 * abs(m)))
198 |         Y *= N
    |

geom3d\models\from_se3cnn\representations.py:197:9: N806 Variable `N` in function should be lowercase
    |
195 |         else:
196 |             Y = torch.sin(abs(m) * phi) * leg
197 |         N *= np.sqrt(2.0 / pochhammer(l - abs(m) + 1, 2 * abs(m)))
    |         ^ N806
198 |         Y *= N
199 |         return Y
    |

geom3d\models\from_se3cnn\representations.py:198:9: N806 Variable `Y` in function should be lowercase
    |
196 |             Y = torch.sin(abs(m) * phi) * leg
197 |         N *= np.sqrt(2.0 / pochhammer(l - abs(m) + 1, 2 * abs(m)))
198 |         Y *= N
    |         ^ N806
199 |         return Y
    |

geom3d\models\from_se3cnn\representations.py:201:9: D417 Missing argument descriptions in the docstring for `get`: `phi`, `refresh`, `theta`
    |
199 |         return Y
200 | 
201 |     def get(self, l, theta, phi, refresh=True):
    |         ^^^ D417
202 |         """Tesseral harmonic with Condon-Shortley phase.
    |

geom3d\models\from_se3cnn\representations.py:201:19: E741 Ambiguous variable name: `l`
    |
199 |         return Y
200 | 
201 |     def get(self, l, theta, phi, refresh=True):
    |                   ^ E741
202 |         """Tesseral harmonic with Condon-Shortley phase.
    |

geom3d\models\from_se3cnn\representations.py:201:34: FBT002 Boolean default positional argument in function definition
    |
199 |         return Y
200 | 
201 |     def get(self, l, theta, phi, refresh=True):
    |                                  ^^^^^^^ FBT002
202 |         """Tesseral harmonic with Condon-Shortley phase.
    |

geom3d\models\from_se3cnn\representations.py:220:13: PERF401 Use a list comprehension to create a transformed list
    |
218 |             self.clear()
219 |         for m in range(-l, l + 1):
220 |             results.append(self.get_element(l, m, theta, phi))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PERF401
221 |         return torch.stack(results, -1)
    |

geom3d\models\from_se3cnn\representations.py:238:9: E741 Ambiguous variable name: `l`
    |
237 |     sph_har = SphericalHarmonics()
238 |     for l in range(10):
    |         ^ E741
239 |         for m in range(l, -l - 1, -1):
240 |             start = time.time()
    |

geom3d\models\from_se3cnn\representations.py:241:13: ERA001 Found commented-out code
    |
239 |         for m in range(l, -l - 1, -1):
240 |             start = time.time()
241 |             # y = tesseral_harmonics(l, m, theta, phi)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
242 |             y = sph_har.get_element(l, m, cu_theta, cu_phi).type(torch.float32)
243 |             # y = sph_har.lpmv(l, m, phi)
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\representations.py:243:13: ERA001 Found commented-out code
    |
241 |             # y = tesseral_harmonics(l, m, theta, phi)
242 |             y = sph_har.get_element(l, m, cu_theta, cu_phi).type(torch.float32)
243 |             # y = sph_har.lpmv(l, m, phi)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
244 |             s0 += time.time() - start
245 |             start = time.time()
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\representations.py:247:13: ERA001 Found commented-out code
    |
245 |             start = time.time()
246 |             z = sh(l, m, theta, phi)
247 |             # z = lpmv_scipy(m, l, phi).numpy()
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
248 |             s1 += time.time() - start
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\representations.py:253:9: ERA001 Found commented-out code
    |
251 |             max_error = max(max_error, error)
252 | 
253 |         # start = time.time()
    |         ^^^^^^^^^^^^^^^^^^^^^ ERA001
254 |         # sph_har.get(l, theta, phi)
255 |         # s2 += time.time() - start
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\representations.py:254:9: ERA001 Found commented-out code
    |
253 |         # start = time.time()
254 |         # sph_har.get(l, theta, phi)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
255 |         # s2 += time.time() - start
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\representations.py:255:9: ERA001 Found commented-out code
    |
253 |         # start = time.time()
254 |         # sph_har.get(l, theta, phi)
255 |         # s2 += time.time() - start
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\representations.py:258:5: ERA001 Found commented-out code
    |
258 |     # print(f"Time diff: {s2/s1}")
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:1:1: D100 Missing docstring in public module
geom3d\models\from_se3cnn\utils_steerable.py:15:23: N803 Argument name `A` should be lowercase
   |
15 | def get_matrix_kernel(A, eps=1e-10):
   |                       ^ N803
16 |     """Compute an orthonormal basis of the kernel (x_1, x_2, ...)
17 |     A x_i = 0
   |

geom3d\models\from_se3cnn\utils_steerable.py:16:5: D205 1 blank line required between summary line and description
   |
15 |   def get_matrix_kernel(A, eps=1e-10):
16 |       """Compute an orthonormal basis of the kernel (x_1, x_2, ...)
   |  _____^
17 | |     A x_i = 0
18 | |     scalar_product(x_i, x_j) = delta_ij.
19 | | 
20 | |     :param A: matrix
21 | |     :return: matrix where each row is a basis vector of the kernel of A
22 | |     """
   | |_______^ D205
23 |       _u, s, v = torch.svd(A)
   |
   = help: Insert single blank line

geom3d\models\from_se3cnn\utils_steerable.py:25:5: ERA001 Found commented-out code
   |
23 |     _u, s, v = torch.svd(A)
24 | 
25 |     # A = u @ torch.diag(s) @ v.t()
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
26 |     return v.t()[s < eps]
   |
   = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:29:25: N803 Argument name `As` should be lowercase
   |
29 | def get_matrices_kernel(As, eps=1e-10):
   |                         ^^ N803
30 |     """Computes the commun kernel of all the As matrices."""
31 |     return get_matrix_kernel(torch.cat(As, dim=0), eps)
   |

geom3d\models\from_se3cnn\utils_steerable.py:30:5: D401 First line of docstring should be in imperative mood: "Computes the commun kernel of all the As matrices."
   |
29 | def get_matrices_kernel(As, eps=1e-10):
30 |     """Computes the commun kernel of all the As matrices."""
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
31 |     return get_matrix_kernel(torch.cat(As, dim=0), eps)
   |

geom3d\models\from_se3cnn\utils_steerable.py:35:5: N802 Function name `_basis_transformation_Q_J` should be lowercase
   |
34 | @cached_dirpklgz("cache/trans_Q")
35 | def _basis_transformation_Q_J(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ N802
36 |     J, order_in, order_out, version=3
37 | ):  # pylint: disable=W0613
   |

geom3d\models\from_se3cnn\utils_steerable.py:35:5: ANN202 Missing return type annotation for private function `_basis_transformation_Q_J`
   |
34 | @cached_dirpklgz("cache/trans_Q")
35 | def _basis_transformation_Q_J(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ ANN202
36 |     J, order_in, order_out, version=3
37 | ):  # pylint: disable=W0613
   |
   = help: Add return type annotation

geom3d\models\from_se3cnn\utils_steerable.py:36:5: N803 Argument name `J` should be lowercase
   |
34 | @cached_dirpklgz("cache/trans_Q")
35 | def _basis_transformation_Q_J(
36 |     J, order_in, order_out, version=3
   |     ^ N803
37 | ):  # pylint: disable=W0613
38 |     """:param J: order of the spherical harmonics
   |

geom3d\models\from_se3cnn\utils_steerable.py:36:29: ARG001 Unused function argument: `version`
   |
34 | @cached_dirpklgz("cache/trans_Q")
35 | def _basis_transformation_Q_J(
36 |     J, order_in, order_out, version=3
   |                             ^^^^^^^ ARG001
37 | ):  # pylint: disable=W0613
38 |     """:param J: order of the spherical harmonics
   |

geom3d\models\from_se3cnn\utils_steerable.py:38:5: D205 1 blank line required between summary line and description
   |
36 |       J, order_in, order_out, version=3
37 |   ):  # pylint: disable=W0613
38 |       """:param J: order of the spherical harmonics
   |  _____^
39 | |     :param order_in: order of the input representation
40 | |     :param order_out: order of the output representation
41 | |     :return: one part of the Q^-1 matrix of the article
42 | |     """
   | |_______^ D205
43 |       with torch_default_dtype(torch.float64):
   |
   = help: Insert single blank line

geom3d\models\from_se3cnn\utils_steerable.py:45:13: N802 Function name `_R_tensor` should be lowercase
   |
43 |     with torch_default_dtype(torch.float64):
44 | 
45 |         def _R_tensor(a, b, c):
   |             ^^^^^^^^^ N802
46 |             return kron(irr_repr(order_out, a, b, c), irr_repr(order_in, a, b, c))
   |

geom3d\models\from_se3cnn\utils_steerable.py:45:13: ANN202 Missing return type annotation for private function `_R_tensor`
   |
43 |     with torch_default_dtype(torch.float64):
44 | 
45 |         def _R_tensor(a, b, c):
   |             ^^^^^^^^^ ANN202
46 |             return kron(irr_repr(order_out, a, b, c), irr_repr(order_in, a, b, c))
   |
   = help: Add return type annotation

geom3d\models\from_se3cnn\utils_steerable.py:48:13: ANN202 Missing return type annotation for private function `_sylvester_submatrix`
   |
46 |             return kron(irr_repr(order_out, a, b, c), irr_repr(order_in, a, b, c))
47 | 
48 |         def _sylvester_submatrix(J, a, b, c):
   |             ^^^^^^^^^^^^^^^^^^^^ ANN202
49 |             """Generate Kronecker product matrix for solving the Sylvester equation in subspace J."""
50 |             R_tensor = _R_tensor(a, b, c)  # [m_out * m_in, m_out * m_in]
   |
   = help: Add return type annotation

geom3d\models\from_se3cnn\utils_steerable.py:48:34: N803 Argument name `J` should be lowercase
   |
46 |             return kron(irr_repr(order_out, a, b, c), irr_repr(order_in, a, b, c))
47 | 
48 |         def _sylvester_submatrix(J, a, b, c):
   |                                  ^ N803
49 |             """Generate Kronecker product matrix for solving the Sylvester equation in subspace J."""
50 |             R_tensor = _R_tensor(a, b, c)  # [m_out * m_in, m_out * m_in]
   |

geom3d\models\from_se3cnn\utils_steerable.py:50:13: N806 Variable `R_tensor` in function should be lowercase
   |
48 |         def _sylvester_submatrix(J, a, b, c):
49 |             """Generate Kronecker product matrix for solving the Sylvester equation in subspace J."""
50 |             R_tensor = _R_tensor(a, b, c)  # [m_out * m_in, m_out * m_in]
   |             ^^^^^^^^ N806
51 |             R_irrep_J = irr_repr(J, a, b, c)  # [m, m]
52 |             return kron(R_tensor, torch.eye(R_irrep_J.size(0))) - kron(
   |

geom3d\models\from_se3cnn\utils_steerable.py:51:13: N806 Variable `R_irrep_J` in function should be lowercase
   |
49 |             """Generate Kronecker product matrix for solving the Sylvester equation in subspace J."""
50 |             R_tensor = _R_tensor(a, b, c)  # [m_out * m_in, m_out * m_in]
51 |             R_irrep_J = irr_repr(J, a, b, c)  # [m, m]
   |             ^^^^^^^^^ N806
52 |             return kron(R_tensor, torch.eye(R_irrep_J.size(0))) - kron(
53 |                 torch.eye(R_tensor.size(0)), R_irrep_J.t()
   |

geom3d\models\from_se3cnn\utils_steerable.py:66:9: S101 Use of `assert` detected
   |
64 |             [_sylvester_submatrix(J, a, b, c) for a, b, c in random_angles]
65 |         )
66 |         assert null_space.size(0) == 1, null_space.size()  # unique subspace solution
   |         ^^^^^^ S101
67 |         Q_J = null_space[0]  # [(m_out * m_in) * m]
68 |         Q_J = Q_J.view(
   |

geom3d\models\from_se3cnn\utils_steerable.py:67:9: N806 Variable `Q_J` in function should be lowercase
   |
65 |         )
66 |         assert null_space.size(0) == 1, null_space.size()  # unique subspace solution
67 |         Q_J = null_space[0]  # [(m_out * m_in) * m]
   |         ^^^ N806
68 |         Q_J = Q_J.view(
69 |             (2 * order_out + 1) * (2 * order_in + 1), 2 * J + 1
   |

geom3d\models\from_se3cnn\utils_steerable.py:68:9: N806 Variable `Q_J` in function should be lowercase
   |
66 |         assert null_space.size(0) == 1, null_space.size()  # unique subspace solution
67 |         Q_J = null_space[0]  # [(m_out * m_in) * m]
68 |         Q_J = Q_J.view(
   |         ^^^ N806
69 |             (2 * order_out + 1) * (2 * order_in + 1), 2 * J + 1
70 |         )  # [m_out * m_in, m]
   |

geom3d\models\from_se3cnn\utils_steerable.py:71:9: S101 Use of `assert` detected
   |
69 |             (2 * order_out + 1) * (2 * order_in + 1), 2 * J + 1
70 |         )  # [m_out * m_in, m]
71 |         assert all(
   |         ^^^^^^ S101
72 |             torch.allclose(_R_tensor(a, b, c) @ Q_J, Q_J @ irr_repr(J, a, b, c))
73 |             for a, b, c in torch.rand(4, 3)
   |

geom3d\models\from_se3cnn\utils_steerable.py:76:5: S101 Use of `assert` detected
   |
74 |         )
75 | 
76 |     assert Q_J.dtype == torch.float64
   |     ^^^^^^ S101
77 |     return Q_J  # [m_out * m_in, m]
   |

geom3d\models\from_se3cnn\utils_steerable.py:81:5: D103 Missing docstring in public function
   |
80 | # @profile
81 | def get_spherical_from_cartesian_torch(cartesian, divide_radius_by=1.0):
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
82 | 
83 |     ###################################################################################################################
   |

geom3d\models\from_se3cnn\utils_steerable.py:92:5: ERA001 Found commented-out code
   |
90 |     # the 3D steerable CNN code therefore (probably) has the following convention for alpha and beta:
91 |     # beta = pi - theta; ranging from 0(South Pole, (X, Y, Z) = (0, 0, -1)) to pi(North Pole, (X, Y, Z) = (0, 0, 1)).
92 |     # alpha = phi
   |     ^^^^^^^^^^^^^ ERA001
93 |     #
94 |     ###################################################################################################################
   |
   = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:97:5: ERA001 Found commented-out code
   |
96 |     # initialise return array
97 |     # ptsnew = np.hstack((xyz, np.zeros(xyz.shape)))
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
98 |     spherical = torch.zeros_like(cartesian)
   |
   = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:110:5: ERA001 Found commented-out code
    |
109 |     # get projected radius in xy plane
110 |     # xy = xyz[:,0]**2 + xyz[:,1]**2
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
111 |     r_xy = cartesian[..., cartesian_x] ** 2 + cartesian[..., cartesian_y] ** 2
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:118:5: ERA001 Found commented-out code
    |
116 |         torch.sqrt(r_xy), cartesian[..., cartesian_z]
117 |     )
118 |     # ptsnew[:,4] = np.arctan2(np.sqrt(xy), xyz[:,2])
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
119 |     # version 'elevation angle defined from XY-plane up'
120 |     # ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy))
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:120:5: ERA001 Found commented-out code
    |
118 |     # ptsnew[:,4] = np.arctan2(np.sqrt(xy), xyz[:,2])
119 |     # version 'elevation angle defined from XY-plane up'
120 |     # ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy))
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
121 |     # spherical[:, ind_beta] = np.arctan2(cartesian[:, 2], np.sqrt(r_xy))
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:121:5: ERA001 Found commented-out code
    |
119 |     # version 'elevation angle defined from XY-plane up'
120 |     # ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy))
121 |     # spherical[:, ind_beta] = np.arctan2(cartesian[:, 2], np.sqrt(r_xy))
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
122 | 
123 |     # get angle in x-y plane
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:129:5: ERA001 Found commented-out code
    |
128 |     # get overall radius
129 |     # ptsnew[:,3] = np.sqrt(xy + xyz[:,2]**2)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
130 |     if divide_radius_by == 1.0:
131 |         spherical[..., ind_radius] = torch.sqrt(r_xy + cartesian[..., cartesian_z] ** 2)
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:141:5: D103 Missing docstring in public function
    |
140 | # @profile
141 | def get_spherical_from_cartesian(cartesian):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
142 | 
143 |     ###################################################################################################################
    |

geom3d\models\from_se3cnn\utils_steerable.py:152:5: ERA001 Found commented-out code
    |
150 |     # the 3D steerable CNN code therefore (probably) has the following convention for alpha and beta:
151 |     # beta = pi - theta; ranging from 0(South Pole, (X, Y, Z) = (0, 0, -1)) to pi(North Pole, (X, Y, Z) = (0, 0, 1)).
152 |     # alpha = phi
    |     ^^^^^^^^^^^^^ ERA001
153 |     #
154 |     ###################################################################################################################
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:160:5: ERA001 Found commented-out code
    |
159 |     # initialise return array
160 |     # ptsnew = np.hstack((xyz, np.zeros(xyz.shape)))
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
161 |     spherical = np.zeros(cartesian.shape)
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:173:5: ERA001 Found commented-out code
    |
172 |     # get projected radius in xy plane
173 |     # xy = xyz[:,0]**2 + xyz[:,1]**2
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
174 |     r_xy = cartesian[..., cartesian_x] ** 2 + cartesian[..., cartesian_y] ** 2
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:177:5: ERA001 Found commented-out code
    |
176 |     # get overall radius
177 |     # ptsnew[:,3] = np.sqrt(xy + xyz[:,2]**2)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
178 |     spherical[..., ind_radius] = np.sqrt(r_xy + cartesian[..., cartesian_z] ** 2)
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:183:5: ERA001 Found commented-out code
    |
181 |     # version 'elevation angle defined from Z-axis down'
182 |     spherical[..., ind_beta] = np.arctan2(np.sqrt(r_xy), cartesian[..., cartesian_z])
183 |     # ptsnew[:,4] = np.arctan2(np.sqrt(xy), xyz[:,2])
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
184 |     # version 'elevation angle defined from XY-plane up'
185 |     # ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy))
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:185:5: ERA001 Found commented-out code
    |
183 |     # ptsnew[:,4] = np.arctan2(np.sqrt(xy), xyz[:,2])
184 |     # version 'elevation angle defined from XY-plane up'
185 |     # ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy))
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
186 |     # spherical[:, ind_beta] = np.arctan2(cartesian[:, 2], np.sqrt(r_xy))
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:186:5: ERA001 Found commented-out code
    |
184 |     # version 'elevation angle defined from XY-plane up'
185 |     # ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy))
186 |     # spherical[:, ind_beta] = np.arctan2(cartesian[:, 2], np.sqrt(r_xy))
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
187 | 
188 |     # get angle in x-y plane
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:196:5: D103 Missing docstring in public function
    |
196 | def test_coordinate_conversion():
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
197 |     p = np.array([0, 0, -1])
198 |     expected = np.array([1, 0, 0])
    |

geom3d\models\from_se3cnn\utils_steerable.py:199:5: S101 Use of `assert` detected
    |
197 |     p = np.array([0, 0, -1])
198 |     expected = np.array([1, 0, 0])
199 |     assert get_spherical_from_cartesian(p) == expected
    |     ^^^^^^ S101
200 |     return True
    |

geom3d\models\from_se3cnn\utils_steerable.py:203:45: ARG001 Unused function argument: `dtype`
    |
203 | def spherical_harmonics(order, alpha, beta, dtype=None):
    |                                             ^^^^^ ARG001
204 |     """Spherical harmonics
205 |     - compatible with irr_repr and compose.
    |

geom3d\models\from_se3cnn\utils_steerable.py:204:5: D205 1 blank line required between summary line and description
    |
203 |   def spherical_harmonics(order, alpha, beta, dtype=None):
204 |       """Spherical harmonics
    |  _____^
205 | |     - compatible with irr_repr and compose.
206 | | 
207 | |     computation time: excecuting 1000 times with array length 1 took 0.29 seconds;
208 | |     executing it once with array of length 1000 took 0.0022 seconds
209 | |     """
    | |_______^ D205
210 |       # Y = [tesseral_harmonics(order, m, theta=math.pi - beta, phi=alpha) for m in range(-order, order + 1)]
211 |       # Y = torch.stack(Y, -1)
    |
    = help: Insert single blank line

geom3d\models\from_se3cnn\utils_steerable.py:210:5: ERA001 Found commented-out code
    |
208 |     executing it once with array of length 1000 took 0.0022 seconds
209 |     """
210 |     # Y = [tesseral_harmonics(order, m, theta=math.pi - beta, phi=alpha) for m in range(-order, order + 1)]
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
211 |     # Y = torch.stack(Y, -1)
212 |     # Y should have dimension 2*order + 1
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:211:5: ERA001 Found commented-out code
    |
209 |     """
210 |     # Y = [tesseral_harmonics(order, m, theta=math.pi - beta, phi=alpha) for m in range(-order, order + 1)]
211 |     # Y = torch.stack(Y, -1)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
212 |     # Y should have dimension 2*order + 1
213 |     return SphericalHarmonics.get(order, theta=math.pi - beta, phi=alpha)
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:218:5: D401 First line of docstring should be in imperative mood: "A part of the pylabyk library: numpytorch.py at https://github.com/yulkang/pylabyk."
    |
216 |   # @profile
217 |   def kron(a, b):
218 |       """A part of the pylabyk library: numpytorch.py at https://github.com/yulkang/pylabyk.
    |  _____^
219 | | 
220 | |     Kronecker product of matrices a and b with leading batch dimensions.
221 | |     Batch dimensions are broadcast. The number of them mush
222 | |     :type a: torch.Tensor
223 | |     :type b: torch.Tensor
224 | |     :rtype: torch.Tensor
225 | |     """
    | |_______^ D401
226 |       siz1 = torch.Size(torch.tensor(a.shape[-2:]) * torch.tensor(b.shape[-2:]))
227 |       res = a.unsqueeze(-1).unsqueeze(-3) * b.unsqueeze(-2).unsqueeze(-4)
    |

geom3d\models\from_se3cnn\utils_steerable.py:233:5: D205 1 blank line required between summary line and description
    |
232 |   def get_maximum_order_unary_only(per_layer_orders_and_multiplicities):
233 |       """Determine what spherical harmonics we need to pre-compute. if we have the
    |  _____^
234 | |     unary term only, we need to compare all adjacent layers.
235 | | 
236 | |     the spherical harmonics function depends on J (irrep order) purely, which is dedfined by
237 | |     order_irreps = list(range(abs(order_in - order_out), order_in + order_out + 1))
238 | |     simplification: we only care about the maximum (in some circumstances that means we calculate a few lower
239 | |     order spherical harmonics which we won't actually need)
240 | | 
241 | |     :param per_layer_orders_and_multiplicities: nested list of lists of 2-tuples
242 | |     :return: integer indicating maximum order J
243 | |     """
    | |_______^ D205
244 |       n_layers = len(per_layer_orders_and_multiplicities)
    |
    = help: Insert single blank line

geom3d\models\from_se3cnn\utils_steerable.py:264:5: D205 1 blank line required between summary line and description
    |
263 |   def get_maximum_order_with_pairwise(per_layer_orders_and_multiplicities):
264 |       """Determine what spherical harmonics we need to pre-compute. for pairwise
    |  _____^
265 | |     interactions, this will just be twice the maximum order.
266 | | 
267 | |     the spherical harmonics function depends on J (irrep order) purely, which is defined by
268 | |     order_irreps = list(range(abs(order_in - order_out), order_in + order_out + 1))
269 | |     simplification: we only care about the maximum (in some circumstances that means we calculate a few lower
270 | |     order spherical harmonics which we won't actually need)
271 | | 
272 | |     :param per_layer_orders_and_multiplicities: nested list of lists of 2-tuples
273 | |     :return: integer indicating maximum order J
274 | |     """
    | |_______^ D205
275 |       n_layers = len(per_layer_orders_and_multiplicities)
    |
    = help: Insert single blank line

geom3d\models\from_se3cnn\utils_steerable.py:287:25: N803 Argument name `max_J` should be lowercase
    |
287 | def precompute_sh(r_ij, max_J):
    |                         ^^^^^ N803
288 |     """pre-comput spherical harmonics up to order max_J.
    |

geom3d\models\from_se3cnn\utils_steerable.py:297:5: N806 Variable `Y_Js` in function should be lowercase
    |
295 |     i_beta = 2
296 | 
297 |     Y_Js = {}
    |     ^^^^ N806
298 |     sh = SphericalHarmonics()
    |

geom3d\models\from_se3cnn\utils_steerable.py:300:9: N806 Variable `J` in function should be lowercase
    |
298 |     sh = SphericalHarmonics()
299 | 
300 |     for J in range(max_J + 1):
    |         ^ N806
301 |         # dimension [B,N,K,2J+1]
302 |         # Y_Js[J] = spherical_harmonics(order=J, alpha=r_ij[...,i_alpha], beta=r_ij[...,i_beta])
    |

geom3d\models\from_se3cnn\utils_steerable.py:301:9: ERA001 Found commented-out code
    |
300 |     for J in range(max_J + 1):
301 |         # dimension [B,N,K,2J+1]
    |         ^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
302 |         # Y_Js[J] = spherical_harmonics(order=J, alpha=r_ij[...,i_alpha], beta=r_ij[...,i_beta])
303 |         Y_Js[J] = sh.get(
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:302:9: ERA001 Found commented-out code
    |
300 |     for J in range(max_J + 1):
301 |         # dimension [B,N,K,2J+1]
302 |         # Y_Js[J] = spherical_harmonics(order=J, alpha=r_ij[...,i_alpha], beta=r_ij[...,i_beta])
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
303 |         Y_Js[J] = sh.get(
304 |             J, theta=math.pi - r_ij[..., i_beta], phi=r_ij[..., i_alpha], refresh=False
    |
    = help: Remove commented-out code

geom3d\models\from_se3cnn\utils_steerable.py:311:7: D101 Missing docstring in public class
    |
311 | class ScalarActivation3rdDim(torch.nn.Module):
    |       ^^^^^^^^^^^^^^^^^^^^^^ D101
312 |     def __init__(self, n_dim, activation, bias=True):
313 |         """Can be used only with scalar fields [B, N, s] on last dimension.
    |

geom3d\models\from_se3cnn\utils_steerable.py:312:43: FBT002 Boolean default positional argument in function definition
    |
311 | class ScalarActivation3rdDim(torch.nn.Module):
312 |     def __init__(self, n_dim, activation, bias=True):
    |                                           ^^^^ FBT002
313 |         """Can be used only with scalar fields [B, N, s] on last dimension.
    |

geom3d\models\from_se3cnn\utils_steerable.py:327:23: A002 Argument `input` is shadowing a Python builtin
    |
325 |             self.bias = None
326 | 
327 |     def forward(self, input):
    |                       ^^^^^ A002
328 |         """:param input: [B, N, s]"""
329 |         assert len(np.array(input.shape)) == 3
    |

geom3d\models\from_se3cnn\utils_steerable.py:329:9: S101 Use of `assert` detected
    |
327 |     def forward(self, input):
328 |         """:param input: [B, N, s]"""
329 |         assert len(np.array(input.shape)) == 3
    |         ^^^^^^ S101
330 | 
331 |         if self.bias is not None:
    |

geom3d\models\from_se3cnn\utils_steerable.py:329:46: PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
    |
327 |     def forward(self, input):
328 |         """:param input: [B, N, s]"""
329 |         assert len(np.array(input.shape)) == 3
    |                                              ^ PLR2004
330 | 
331 |         if self.bias is not None:
    |

geom3d\models\molecule_gnn_model.py:1:1: D100 Missing docstring in public module
geom3d\models\molecule_gnn_model.py:2:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | import torch
2 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
3 | from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder
4 | from torch import nn
  |

geom3d\models\molecule_gnn_model.py:15:7: D101 Missing docstring in public class
   |
15 | class GINConv(MessagePassing):
   |       ^^^^^^^ D101
16 |     def __init__(self, emb_dim):
17 |         super().__init__(aggr="add")
   |

geom3d\models\molecule_gnn_model.py:16:9: D107 Missing docstring in `__init__`
   |
15 | class GINConv(MessagePassing):
16 |     def __init__(self, emb_dim):
   |         ^^^^^^^^ D107
17 |         super().__init__(aggr="add")
   |

geom3d\models\molecule_gnn_model.py:24:9: D102 Missing docstring in public method
   |
22 |         self.bond_encoder = BondEncoder(emb_dim = emb_dim)
23 | 
24 |     def forward(self, x, edge_index, edge_attr):
   |         ^^^^^^^ D102
25 |         edge_embedding = self.bond_encoder(edge_attr)
26 |         return self.mlp((1 + self.eps) *x + self.propagate(edge_index, x=x, edge_attr=edge_embedding))
   |

geom3d\models\molecule_gnn_model.py:29:9: D102 Missing docstring in public method
   |
29 |     def message(self, x_j, edge_attr):
   |         ^^^^^^^ D102
30 |         return F.relu(x_j + edge_attr)
   |

geom3d\models\molecule_gnn_model.py:32:9: D102 Missing docstring in public method
   |
30 |         return F.relu(x_j + edge_attr)
31 | 
32 |     def update(self, aggr_out):
   |         ^^^^^^ D102
33 |         return aggr_out
   |

geom3d\models\molecule_gnn_model.py:36:7: D101 Missing docstring in public class
   |
36 | class GCNConv(MessagePassing):
   |       ^^^^^^^ D101
37 |     def __init__(self, emb_dim):
38 |         super().__init__(aggr="add")
   |

geom3d\models\molecule_gnn_model.py:37:9: D107 Missing docstring in `__init__`
   |
36 | class GCNConv(MessagePassing):
37 |     def __init__(self, emb_dim):
   |         ^^^^^^^^ D107
38 |         super().__init__(aggr="add")
   |

geom3d\models\molecule_gnn_model.py:44:9: D102 Missing docstring in public method
   |
42 |         self.bond_encoder = BondEncoder(emb_dim = emb_dim)
43 | 
44 |     def forward(self, x, edge_index, edge_attr):
   |         ^^^^^^^ D102
45 |         x = self.linear(x)
46 |         edge_embedding = self.bond_encoder(edge_attr)
   |

geom3d\models\molecule_gnn_model.py:50:9: ERA001 Found commented-out code
   |
48 |         row, col = edge_index
49 | 
50 |         #edge_weight = torch.ones((edge_index.size(1), ), device=edge_index.device)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
51 |         deg = degree(row, x.size(0), dtype = x.dtype) + 1
52 |         deg_inv_sqrt = deg.pow(-0.5)
   |
   = help: Remove commented-out code

geom3d\models\molecule_gnn_model.py:59:9: D102 Missing docstring in public method
   |
57 |         return self.propagate(edge_index, x=x, edge_attr = edge_embedding, norm=norm) + F.relu(x + self.root_emb.weight) * 1./deg.view(-1,1)
58 | 
59 |     def message(self, x_j, edge_attr, norm):
   |         ^^^^^^^ D102
60 |         return norm.view(-1, 1) * F.relu(x_j + edge_attr)
   |

geom3d\models\molecule_gnn_model.py:62:9: D102 Missing docstring in public method
   |
60 |         return norm.view(-1, 1) * F.relu(x_j + edge_attr)
61 | 
62 |     def update(self, aggr_out):
   |         ^^^^^^ D102
63 |         return aggr_out
   |

geom3d\models\molecule_gnn_model.py:66:7: D101 Missing docstring in public class
   |
66 | class GATConv(MessagePassing):
   |       ^^^^^^^ D101
67 |     def __init__(self, emb_dim, heads=2, negative_slope=0.2, aggr="add"):
68 |         super().__init__(node_dim=0)
   |

geom3d\models\molecule_gnn_model.py:67:9: D107 Missing docstring in `__init__`
   |
66 | class GATConv(MessagePassing):
67 |     def __init__(self, emb_dim, heads=2, negative_slope=0.2, aggr="add"):
   |         ^^^^^^^^ D107
68 |         super().__init__(node_dim=0)
69 |         self.aggr = aggr
   |

geom3d\models\molecule_gnn_model.py:82:9: D102 Missing docstring in public method
   |
80 |         self.reset_parameters()
81 | 
82 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
83 |         glorot(self.att)
84 |         zeros(self.bias)
   |

geom3d\models\molecule_gnn_model.py:86:9: D102 Missing docstring in public method
   |
84 |         zeros(self.bias)
85 | 
86 |     def forward(self, x, edge_index, edge_attr):
   |         ^^^^^^^ D102
87 |         edge_embedding = self.bond_encoder(edge_attr)
   |

geom3d\models\molecule_gnn_model.py:92:9: D102 Missing docstring in public method
   |
90 |         return self.propagate(edge_index, x=x, edge_attr=edge_embedding)
91 | 
92 |     def message(self, edge_index, x_i, x_j, edge_attr):
   |         ^^^^^^^ D102
93 |         x_i = x_i.view(-1, self.heads, self.emb_dim)
94 |         x_j = x_j.view(-1, self.heads, self.emb_dim)
   |

geom3d\models\molecule_gnn_model.py:104:9: D102 Missing docstring in public method
    |
102 |         return x_j * alpha.view(-1, self.heads, 1)
103 | 
104 |     def update(self, aggr_out):
    |         ^^^^^^ D102
105 |         aggr_out = aggr_out.mean(dim=1)
106 |         aggr_out += self.bias
    |

geom3d\models\molecule_gnn_model.py:110:7: D101 Missing docstring in public class
    |
110 | class GraphSAGEConv(MessagePassing):
    |       ^^^^^^^^^^^^^ D101
111 |     def __init__(self, emb_dim, aggr="mean"):
112 |         super().__init__()
    |

geom3d\models\molecule_gnn_model.py:111:9: D107 Missing docstring in `__init__`
    |
110 | class GraphSAGEConv(MessagePassing):
111 |     def __init__(self, emb_dim, aggr="mean"):
    |         ^^^^^^^^ D107
112 |         super().__init__()
    |

geom3d\models\molecule_gnn_model.py:120:9: D102 Missing docstring in public method
    |
120 |     def forward(self, x, edge_index, edge_attr):
    |         ^^^^^^^ D102
121 |         x = self.linear(x)
122 |         edge_embedding = self.bond_encoder(edge_attr)
    |

geom3d\models\molecule_gnn_model.py:126:9: D102 Missing docstring in public method
    |
124 |         return self.propagate(edge_index, x=x, edge_attr=edge_embedding)
125 | 
126 |     def message(self, x_j, edge_attr):
    |         ^^^^^^^ D102
127 |         return x_j + edge_attr
    |

geom3d\models\molecule_gnn_model.py:129:9: D102 Missing docstring in public method
    |
127 |         return x_j + edge_attr
128 | 
129 |     def update(self, aggr_out):
    |         ^^^^^^ D102
130 |         return F.normalize(aggr_out, p=2, dim=-1)
    |

geom3d\models\molecule_gnn_model.py:133:7: D101 Missing docstring in public class
    |
133 | class GNN(nn.Module):
    |       ^^^ D101
134 |     def __init__(self, num_layer, emb_dim, JK="last", drop_ratio=0, gnn_type="gin"):
135 |         super().__init__()
    |

geom3d\models\molecule_gnn_model.py:134:9: D107 Missing docstring in `__init__`
    |
133 | class GNN(nn.Module):
134 |     def __init__(self, num_layer, emb_dim, JK="last", drop_ratio=0, gnn_type="gin"):
    |         ^^^^^^^^ D107
135 |         super().__init__()
136 |         self.num_layer = num_layer
    |

geom3d\models\molecule_gnn_model.py:134:44: N803 Argument name `JK` should be lowercase
    |
133 | class GNN(nn.Module):
134 |     def __init__(self, num_layer, emb_dim, JK="last", drop_ratio=0, gnn_type="gin"):
    |                                            ^^ N803
135 |         super().__init__()
136 |         self.num_layer = num_layer
    |

geom3d\models\molecule_gnn_model.py:140:29: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
138 |         self.JK = JK
139 | 
140 |         if self.num_layer < 2:
    |                             ^ PLR2004
141 |             msg = "Number of GNN layers must be greater than 1."
142 |             raise ValueError(msg)
    |

geom3d\models\molecule_gnn_model.py:164:9: D102 Missing docstring in public method
    |
163 |     # def forward(self, x, edge_index, edge_attr):
164 |     def forward(self, *argv):
    |         ^^^^^^^ D102
165 |         if len(argv) == 3:
166 |             x, edge_index, edge_attr = argv[0], argv[1], argv[2]
    |

geom3d\models\molecule_gnn_model.py:164:23: ANN002 Missing type annotation for `*argv`
    |
163 |     # def forward(self, x, edge_index, edge_attr):
164 |     def forward(self, *argv):
    |                       ^^^^^ ANN002
165 |         if len(argv) == 3:
166 |             x, edge_index, edge_attr = argv[0], argv[1], argv[2]
    |

geom3d\models\molecule_gnn_model.py:165:25: PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
    |
163 |     # def forward(self, x, edge_index, edge_attr):
164 |     def forward(self, *argv):
165 |         if len(argv) == 3:
    |                         ^ PLR2004
166 |             x, edge_index, edge_attr = argv[0], argv[1], argv[2]
167 |         elif len(argv) == 1:
    |

geom3d\models\molecule_gnn_model.py:180:13: ERA001 Found commented-out code
    |
178 |             h = self.gnns[layer](h_list[layer], edge_index, edge_attr)
179 |             h = self.batch_norms[layer](h)
180 |             # h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
181 |             if layer == self.num_layer - 1:
182 |                 # remove relu for the last layer
    |
    = help: Remove commented-out code

geom3d\models\molecule_gnn_model.py:203:7: N801 Class name `GNN_graphpred` should use CapWords convention
    |
203 | class GNN_graphpred(nn.Module):
    |       ^^^^^^^^^^^^^ N801
204 |     def __init__(self, args, num_tasks, molecule_model=None):
205 |         super().__init__()
    |

geom3d\models\molecule_gnn_model.py:203:7: D101 Missing docstring in public class
    |
203 | class GNN_graphpred(nn.Module):
    |       ^^^^^^^^^^^^^ D101
204 |     def __init__(self, args, num_tasks, molecule_model=None):
205 |         super().__init__()
    |

geom3d\models\molecule_gnn_model.py:204:9: D107 Missing docstring in `__init__`
    |
203 | class GNN_graphpred(nn.Module):
204 |     def __init__(self, args, num_tasks, molecule_model=None):
    |         ^^^^^^^^ D107
205 |         super().__init__()
206 |         self.num_layer = args.num_layer
    |

geom3d\models\molecule_gnn_model.py:212:29: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
210 |         self.num_tasks = num_tasks
211 | 
212 |         if self.num_layer < 2:
    |                             ^ PLR2004
213 |             msg = "Number of GNN layers must be greater than 1."
214 |             raise ValueError(msg)
    |

geom3d\models\molecule_gnn_model.py:241:9: D102 Missing docstring in public method
    |
239 |             )
240 | 
241 |     def from_pretrained(self, model_file):
    |         ^^^^^^^^^^^^^^^ D102
242 |         self.molecule_model.load_state_dict(torch.load(model_file))
    |

geom3d\models\molecule_gnn_model.py:244:9: D102 Missing docstring in public method
    |
242 |         self.molecule_model.load_state_dict(torch.load(model_file))
243 | 
244 |     def get_graph_representation(self, *argv):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^ D102
245 |         if len(argv) == 4:
246 |             x, edge_index, edge_attr, batch = argv[0], argv[1], argv[2], argv[3]
    |

geom3d\models\molecule_gnn_model.py:244:40: ANN002 Missing type annotation for `*argv`
    |
242 |         self.molecule_model.load_state_dict(torch.load(model_file))
243 | 
244 |     def get_graph_representation(self, *argv):
    |                                        ^^^^^ ANN002
245 |         if len(argv) == 4:
246 |             x, edge_index, edge_attr, batch = argv[0], argv[1], argv[2], argv[3]
    |

geom3d\models\molecule_gnn_model.py:245:25: PLR2004 Magic value used in comparison, consider replacing `4` with a constant variable
    |
244 |     def get_graph_representation(self, *argv):
245 |         if len(argv) == 4:
    |                         ^ PLR2004
246 |             x, edge_index, edge_attr, batch = argv[0], argv[1], argv[2], argv[3]
247 |         elif len(argv) == 1:
    |

geom3d\models\molecule_gnn_model.py:266:9: D102 Missing docstring in public method
    |
264 |         return graph_representation, pred
265 | 
266 |     def forward(self, *argv):
    |         ^^^^^^^ D102
267 |         if len(argv) == 4:
268 |             x, edge_index, edge_attr, batch = argv[0], argv[1], argv[2], argv[3]
    |

geom3d\models\molecule_gnn_model.py:266:23: ANN002 Missing type annotation for `*argv`
    |
264 |         return graph_representation, pred
265 | 
266 |     def forward(self, *argv):
    |                       ^^^^^ ANN002
267 |         if len(argv) == 4:
268 |             x, edge_index, edge_attr, batch = argv[0], argv[1], argv[2], argv[3]
    |

geom3d\models\molecule_gnn_model.py:267:25: PLR2004 Magic value used in comparison, consider replacing `4` with a constant variable
    |
266 |     def forward(self, *argv):
267 |         if len(argv) == 4:
    |                         ^ PLR2004
268 |             x, edge_index, edge_attr, batch = argv[0], argv[1], argv[2], argv[3]
269 |         elif len(argv) == 1:
    |

geom3d\models\molecule_gnn_model_simplified.py:1:1: D100 Missing docstring in public module
geom3d\models\molecule_gnn_model_simplified.py:2:8: N812 Lowercase `functional` imported as non-lowercase `F`
  |
1 | import torch
2 | import torch.nn.functional as F
  |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
3 | from ogb.graphproppred.mol_encoder import (
4 |     full_atom_feature_dims,
  |

geom3d\models\molecule_gnn_model_simplified.py:15:7: D101 Missing docstring in public class
   |
15 | class GINConv(MessagePassing):
   |       ^^^^^^^ D101
16 |     def __init__(self, emb_dim):
17 |         super().__init__(aggr="add")
   |

geom3d\models\molecule_gnn_model_simplified.py:16:9: D107 Missing docstring in `__init__`
   |
15 | class GINConv(MessagePassing):
16 |     def __init__(self, emb_dim):
   |         ^^^^^^^^ D107
17 |         super().__init__(aggr="add")
   |

geom3d\models\molecule_gnn_model_simplified.py:24:9: D102 Missing docstring in public method
   |
22 |         self.bond_encoder = nn.Embedding(full_bond_feature_dims[0], emb_dim)
23 | 
24 |     def forward(self, x, edge_index, edge_attr):
   |         ^^^^^^^ D102
25 |         edge_embedding = self.bond_encoder(edge_attr)
26 |         return self.mlp((1 + self.eps) *x + self.propagate(edge_index, x=x, edge_attr=edge_embedding))
   |

geom3d\models\molecule_gnn_model_simplified.py:29:9: D102 Missing docstring in public method
   |
29 |     def message(self, x_j, edge_attr):
   |         ^^^^^^^ D102
30 |         return F.relu(x_j + edge_attr)
   |

geom3d\models\molecule_gnn_model_simplified.py:32:9: D102 Missing docstring in public method
   |
30 |         return F.relu(x_j + edge_attr)
31 | 
32 |     def update(self, aggr_out):
   |         ^^^^^^ D102
33 |         return aggr_out
   |

geom3d\models\molecule_gnn_model_simplified.py:36:7: D101 Missing docstring in public class
   |
36 | class GCNConv(MessagePassing):
   |       ^^^^^^^ D101
37 |     def __init__(self, emb_dim):
38 |         super().__init__(aggr="add")
   |

geom3d\models\molecule_gnn_model_simplified.py:37:9: D107 Missing docstring in `__init__`
   |
36 | class GCNConv(MessagePassing):
37 |     def __init__(self, emb_dim):
   |         ^^^^^^^^ D107
38 |         super().__init__(aggr="add")
   |

geom3d\models\molecule_gnn_model_simplified.py:44:9: D102 Missing docstring in public method
   |
42 |         self.bond_encoder = nn.Embedding(full_bond_feature_dims[0], emb_dim)
43 | 
44 |     def forward(self, x, edge_index, edge_attr):
   |         ^^^^^^^ D102
45 |         x = self.linear(x)
46 |         edge_embedding = self.bond_encoder(edge_attr)
   |

geom3d\models\molecule_gnn_model_simplified.py:50:9: ERA001 Found commented-out code
   |
48 |         row, col = edge_index
49 | 
50 |         #edge_weight = torch.ones((edge_index.size(1), ), device=edge_index.device)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
51 |         deg = degree(row, x.size(0), dtype = x.dtype) + 1
52 |         deg_inv_sqrt = deg.pow(-0.5)
   |
   = help: Remove commented-out code

geom3d\models\molecule_gnn_model_simplified.py:59:9: D102 Missing docstring in public method
   |
57 |         return self.propagate(edge_index, x=x, edge_attr = edge_embedding, norm=norm) + F.relu(x + self.root_emb.weight) * 1./deg.view(-1,1)
58 | 
59 |     def message(self, x_j, edge_attr, norm):
   |         ^^^^^^^ D102
60 |         return norm.view(-1, 1) * F.relu(x_j + edge_attr)
   |

geom3d\models\molecule_gnn_model_simplified.py:62:9: D102 Missing docstring in public method
   |
60 |         return norm.view(-1, 1) * F.relu(x_j + edge_attr)
61 | 
62 |     def update(self, aggr_out):
   |         ^^^^^^ D102
63 |         return aggr_out
   |

geom3d\models\molecule_gnn_model_simplified.py:66:7: D101 Missing docstring in public class
   |
66 | class GATConv(MessagePassing):
   |       ^^^^^^^ D101
67 |     def __init__(self, emb_dim, heads=2, negative_slope=0.2, aggr="add"):
68 |         super().__init__(node_dim=0)
   |

geom3d\models\molecule_gnn_model_simplified.py:67:9: D107 Missing docstring in `__init__`
   |
66 | class GATConv(MessagePassing):
67 |     def __init__(self, emb_dim, heads=2, negative_slope=0.2, aggr="add"):
   |         ^^^^^^^^ D107
68 |         super().__init__(node_dim=0)
69 |         self.aggr = aggr
   |

geom3d\models\molecule_gnn_model_simplified.py:82:9: D102 Missing docstring in public method
   |
80 |         self.reset_parameters()
81 | 
82 |     def reset_parameters(self):
   |         ^^^^^^^^^^^^^^^^ D102
83 |         glorot(self.att)
84 |         zeros(self.bias)
   |

geom3d\models\molecule_gnn_model_simplified.py:86:9: D102 Missing docstring in public method
   |
84 |         zeros(self.bias)
85 | 
86 |     def forward(self, x, edge_index, edge_attr):
   |         ^^^^^^^ D102
87 |         edge_embedding = self.bond_encoder(edge_attr)
   |

geom3d\models\molecule_gnn_model_simplified.py:92:9: D102 Missing docstring in public method
   |
90 |         return self.propagate(edge_index, x=x, edge_attr=edge_embedding)
91 | 
92 |     def message(self, edge_index, x_i, x_j, edge_attr):
   |         ^^^^^^^ D102
93 |         x_i = x_i.view(-1, self.heads, self.emb_dim)
94 |         x_j = x_j.view(-1, self.heads, self.emb_dim)
   |

geom3d\models\molecule_gnn_model_simplified.py:104:9: D102 Missing docstring in public method
    |
102 |         return x_j * alpha.view(-1, self.heads, 1)
103 | 
104 |     def update(self, aggr_out):
    |         ^^^^^^ D102
105 |         aggr_out = aggr_out.mean(dim=1)
106 |         aggr_out += self.bias
    |

geom3d\models\molecule_gnn_model_simplified.py:110:7: D101 Missing docstring in public class
    |
110 | class GraphSAGEConv(MessagePassing):
    |       ^^^^^^^^^^^^^ D101
111 |     def __init__(self, emb_dim, aggr="mean"):
112 |         super().__init__()
    |

geom3d\models\molecule_gnn_model_simplified.py:111:9: D107 Missing docstring in `__init__`
    |
110 | class GraphSAGEConv(MessagePassing):
111 |     def __init__(self, emb_dim, aggr="mean"):
    |         ^^^^^^^^ D107
112 |         super().__init__()
    |

geom3d\models\molecule_gnn_model_simplified.py:120:9: D102 Missing docstring in public method
    |
120 |     def forward(self, x, edge_index, edge_attr):
    |         ^^^^^^^ D102
121 |         x = self.linear(x)
122 |         edge_embedding = self.bond_encoder(edge_attr)
    |

geom3d\models\molecule_gnn_model_simplified.py:126:9: D102 Missing docstring in public method
    |
124 |         return self.propagate(edge_index, x=x, edge_attr=edge_embedding)
125 | 
126 |     def message(self, x_j, edge_attr):
    |         ^^^^^^^ D102
127 |         return x_j + edge_attr
    |

geom3d\models\molecule_gnn_model_simplified.py:129:9: D102 Missing docstring in public method
    |
127 |         return x_j + edge_attr
128 | 
129 |     def update(self, aggr_out):
    |         ^^^^^^ D102
130 |         return F.normalize(aggr_out, p=2, dim=-1)
    |

geom3d\models\molecule_gnn_model_simplified.py:133:7: D101 Missing docstring in public class
    |
133 | class GNNSimplified(nn.Module):
    |       ^^^^^^^^^^^^^ D101
134 |     def __init__(self, num_layer, emb_dim, JK="last", drop_ratio=0, gnn_type="gin"):
135 |         super().__init__()
    |

geom3d\models\molecule_gnn_model_simplified.py:134:9: D107 Missing docstring in `__init__`
    |
133 | class GNNSimplified(nn.Module):
134 |     def __init__(self, num_layer, emb_dim, JK="last", drop_ratio=0, gnn_type="gin"):
    |         ^^^^^^^^ D107
135 |         super().__init__()
136 |         self.num_layer = num_layer
    |

geom3d\models\molecule_gnn_model_simplified.py:134:44: N803 Argument name `JK` should be lowercase
    |
133 | class GNNSimplified(nn.Module):
134 |     def __init__(self, num_layer, emb_dim, JK="last", drop_ratio=0, gnn_type="gin"):
    |                                            ^^ N803
135 |         super().__init__()
136 |         self.num_layer = num_layer
    |

geom3d\models\molecule_gnn_model_simplified.py:140:29: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
138 |         self.JK = JK
139 | 
140 |         if self.num_layer < 2:
    |                             ^ PLR2004
141 |             msg = "Number of GNN layers must be greater than 1."
142 |             raise ValueError(msg)
    |

geom3d\models\molecule_gnn_model_simplified.py:153:30: F821 Undefined name `GAT`
    |
151 |             elif gnn_type == "GCN":
152 |                 self.gnns.append(GCNConv(emb_dim))
153 |             elif gnn_type == GAT:
    |                              ^^^ F821
154 |                 self.gnns.append(GATConv(emb_dim))
155 |             elif gnn_type == "GraphSAGE":
    |

geom3d\models\molecule_gnn_model_simplified.py:164:9: D102 Missing docstring in public method
    |
163 |     # def forward(self, x, edge_index, edge_attr):
164 |     def forward(self, *argv):
    |         ^^^^^^^ D102
165 |         if len(argv) == 3:
166 |             x, edge_index, edge_attr = argv[0], argv[1], argv[2]
    |

geom3d\models\molecule_gnn_model_simplified.py:164:23: ANN002 Missing type annotation for `*argv`
    |
163 |     # def forward(self, x, edge_index, edge_attr):
164 |     def forward(self, *argv):
    |                       ^^^^^ ANN002
165 |         if len(argv) == 3:
166 |             x, edge_index, edge_attr = argv[0], argv[1], argv[2]
    |

geom3d\models\molecule_gnn_model_simplified.py:165:25: PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
    |
163 |     # def forward(self, x, edge_index, edge_attr):
164 |     def forward(self, *argv):
165 |         if len(argv) == 3:
    |                         ^ PLR2004
166 |             x, edge_index, edge_attr = argv[0], argv[1], argv[2]
167 |         elif len(argv) == 1:
    |

geom3d\models\molecule_gnn_model_simplified.py:180:13: ERA001 Found commented-out code
    |
178 |             h = self.gnns[layer](h_list[layer], edge_index, edge_attr)
179 |             h = self.batch_norms[layer](h)
180 |             # h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
181 |             if layer == self.num_layer - 1:
182 |                 # remove relu for the last layer
    |
    = help: Remove commented-out code

geom3d\models\utils.py:8:5: D417 Missing argument descriptions in the docstring for `get_basis`: `cloned_d`, `max_degree`
  |
8 | def get_basis(cloned_d, max_degree):
  |     ^^^^^^^^^ D417
9 |     """Precompute the SE(3)-equivariant weight basis, W_J^lk(x).
  |

geom3d\models\utils.py:26:9: N806 Variable `Y` in function should be lowercase
   |
24 |         r_ij = utils_steerable.get_spherical_from_cartesian_torch(cloned_d)
25 |         # Spherical harmonic basis
26 |         Y = utils_steerable.precompute_sh(r_ij, 2 * max_degree)
   |         ^ N806
27 |         device = Y[0].device
   |

geom3d\models\utils.py:32:17: N806 Variable `K_Js` in function should be lowercase
   |
30 |         for d_in in range(max_degree + 1):
31 |             for d_out in range(max_degree + 1):
32 |                 K_Js = []
   |                 ^^^^ N806
33 |                 for J in range(abs(d_in - d_out), d_in + d_out + 1):
34 |                     # Get spherical harmonic projection matrices
   |

geom3d\models\utils.py:33:21: N806 Variable `J` in function should be lowercase
   |
31 |             for d_out in range(max_degree + 1):
32 |                 K_Js = []
33 |                 for J in range(abs(d_in - d_out), d_in + d_out + 1):
   |                     ^ N806
34 |                     # Get spherical harmonic projection matrices
35 |                     Q_J = utils_steerable._basis_transformation_Q_J(J, d_in, d_out)
   |

geom3d\models\utils.py:35:21: N806 Variable `Q_J` in function should be lowercase
   |
33 |                 for J in range(abs(d_in - d_out), d_in + d_out + 1):
34 |                     # Get spherical harmonic projection matrices
35 |                     Q_J = utils_steerable._basis_transformation_Q_J(J, d_in, d_out)
   |                     ^^^ N806
36 |                     Q_J = Q_J.float().T.to(device)
   |

geom3d\models\utils.py:35:27: SLF001 Private member accessed: `_basis_transformation_Q_J`
   |
33 |                 for J in range(abs(d_in - d_out), d_in + d_out + 1):
34 |                     # Get spherical harmonic projection matrices
35 |                     Q_J = utils_steerable._basis_transformation_Q_J(J, d_in, d_out)
   |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
36 |                     Q_J = Q_J.float().T.to(device)
   |

geom3d\models\utils.py:36:21: N806 Variable `Q_J` in function should be lowercase
   |
34 |                     # Get spherical harmonic projection matrices
35 |                     Q_J = utils_steerable._basis_transformation_Q_J(J, d_in, d_out)
36 |                     Q_J = Q_J.float().T.to(device)
   |                     ^^^ N806
37 | 
38 |                     # Create kernel from spherical harmonics
   |

geom3d\models\utils.py:39:21: N806 Variable `K_J` in function should be lowercase
   |
38 |                     # Create kernel from spherical harmonics
39 |                     K_J = torch.matmul(Y[J], Q_J)
   |                     ^^^ N806
40 |                     K_Js.append(K_J)
   |

geom3d\oligomer_encoding_with_transformer.py:1:1: INP001 File `geom3d\oligomer_encoding_with_transformer.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\oligomer_encoding_with_transformer.py:1:1: D404 First word of the docstring should not be "This"
  |
1 | """this script is to encode the representation of the oligomer from the representation of the fragments."""
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D404
2 | 
3 | import glob
  |

geom3d\oligomer_encoding_with_transformer.py:8:8: N812 Lowercase `functional` imported as non-lowercase `Functional`
   |
 6 | import lightning.pytorch as pl
 7 | import torch
 8 | import torch.nn.functional as Functional
   |        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N812
 9 | from lightning.pytorch.callbacks import (
10 |     EarlyStopping,
   |

geom3d\oligomer_encoding_with_transformer.py:34:5: ERA001 Found commented-out code
   |
32 |     """
33 |     max_iters = config["max_epochs"] * len(train_loader)
34 |     # model_config = config["model"]
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
35 |     EncodingModel = initialise_model(config, max_iters)
36 |     wandb_logger = WandbLogger(
   |
   = help: Remove commented-out code

geom3d\oligomer_encoding_with_transformer.py:35:5: N806 Variable `EncodingModel` in function should be lowercase
   |
33 |     max_iters = config["max_epochs"] * len(train_loader)
34 |     # model_config = config["model"]
35 |     EncodingModel = initialise_model(config, max_iters)
   |     ^^^^^^^^^^^^^ N806
36 |     wandb_logger = WandbLogger(
37 |         log_model=True,
   |

geom3d\oligomer_encoding_with_transformer.py:75:5: D205 1 blank line required between summary line and description
   |
74 |   def save_encoding_dataset(dataset, config, dataset_name="",save_folder=""):
75 |       """Save the encoding of the dataset
   |  _____^
76 | |     Args:
77 | |         dataset (DataLoader): The data loader for the training data.
78 | |         config (dict): The configuration of the model.
79 | |         dataset_name (str): The name of the dataset.
80 | | 
81 | |     """
   | |_______^ D205
82 |       Checkpoint_dir = config["running_dir"] + "/transformer"
   |
   = help: Insert single blank line

geom3d\oligomer_encoding_with_transformer.py:82:5: N806 Variable `Checkpoint_dir` in function should be lowercase
   |
81 |     """
82 |     Checkpoint_dir = config["running_dir"] + "/transformer"
   |     ^^^^^^^^^^^^^^ N806
83 | 
84 |     files = glob.glob(Checkpoint_dir + "/*.ckpt")
   |

geom3d\oligomer_encoding_with_transformer.py:84:13: PTH207 Replace `glob` with `Path.glob` or `Path.rglob`
   |
82 |     Checkpoint_dir = config["running_dir"] + "/transformer"
83 | 
84 |     files = glob.glob(Checkpoint_dir + "/*.ckpt")
   |             ^^^^^^^^^ PTH207
85 |     min_val_loss = 1000
86 |     for file in files:
   |

geom3d\oligomer_encoding_with_transformer.py:94:5: N806 Variable `EncodingModel` in function should be lowercase
   |
92 |     save_config(config, config["running_dir"])
93 | 
94 |     EncodingModel = initialise_model(config)
   |     ^^^^^^^^^^^^^ N806
95 |     EncodingModel.eval()
96 |     EncodingModel = EncodingModel.to(config["device"])
   |

geom3d\oligomer_encoding_with_transformer.py:96:5: N806 Variable `EncodingModel` in function should be lowercase
   |
94 |     EncodingModel = initialise_model(config)
95 |     EncodingModel.eval()
96 |     EncodingModel = EncodingModel.to(config["device"])
   |     ^^^^^^^^^^^^^ N806
97 |     data_list = []
98 |     counter = 0
   |

geom3d\oligomer_encoding_with_transformer.py:111:9: SIM113 Use `enumerate()` for index variable `counter` in `for` loop
    |
109 |             )
110 |             data_list.append(molecule_frag.detach().cpu())
111 |         counter += 1
    |         ^^^^^^^^^^^^ SIM113
112 |         if counter % 1000 == 0:
113 |             if save_folder == "":
    |

geom3d\oligomer_encoding_with_transformer.py:142:5: D205 1 blank line required between summary line and description
    |
141 |   def initialise_model(config, max_iters=10):
142 |       """Initialise the model
    |  _____^
143 | |     Args:
144 | |         config (dict): The configuration of the model.
145 | |         max_iters (int): The maximum number of iterations.
146 | | 
147 | |     Returns
148 | |     -------
149 | |         Fragment_encoder: The initialised model.
150 | | 
151 | |     """
    | |_______^ D205
152 |       # config["device"] = "cuda" if torch.cuda.is_available() else "cpu"
153 |       model, graph_pred_linear = model_setup(config)
    |
    = help: Insert single blank line

geom3d\oligomer_encoding_with_transformer.py:152:5: ERA001 Found commented-out code
    |
151 |     """
152 |     # config["device"] = "cuda" if torch.cuda.is_available() else "cpu"
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
153 |     model, graph_pred_linear = model_setup(config)
154 |     pymodel = Pymodel(model, graph_pred_linear, config)
    |
    = help: Remove commented-out code

geom3d\oligomer_encoding_with_transformer.py:156:8: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
    |
154 |     pymodel = Pymodel(model, graph_pred_linear, config)
155 | 
156 |     if os.path.exists(config["model_embedding_chkpt"]):
    |        ^^^^^^^^^^^^^^ PTH110
157 |         chkpt_path = config["model_embedding_chkpt"]
158 |         checkpoint = torch.load(chkpt_path, map_location=config["device"])
    |

geom3d\oligomer_encoding_with_transformer.py:169:5: N806 Variable `EncodingModel` in function should be lowercase
    |
167 |     else:
168 |         num_classes = config["model"]["emb_dim"]
169 |     EncodingModel = Fragment_encoder(
    |     ^^^^^^^^^^^^^ N806
170 |         input_dim=num_classes * max_oligomer_size,
171 |         model_dim=num_classes,
    |

geom3d\oligomer_encoding_with_transformer.py:186:9: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
    |
184 |     EncodingModel.model_name = config["model_name"]
185 |     if (
186 |         os.path.exists(f"{config['model_transformer_chkpt']}")
    |         ^^^^^^^^^^^^^^ PTH110
187 |         and config["model_transformer_chkpt"] != ""
188 |     ):
    |

geom3d\oligomer_encoding_with_transformer.py:195:9: S110 `try`-`except`-`pass` detected, consider logging the exception
    |
193 |               )
194 |               EncodingModel.load_state_dict(state_dict["state_dict"])
195 |           except Exception:
    |  _________^
196 | |             pass
    | |________________^ S110
197 |               # delete the checkpoint
198 |               # os.remove(config["model_transformer_chkpt"])
    |

geom3d\oligomer_encoding_with_transformer.py:195:16: BLE001 Do not catch blind exception: `Exception`
    |
193 |             )
194 |             EncodingModel.load_state_dict(state_dict["state_dict"])
195 |         except Exception:
    |                ^^^^^^^^^ BLE001
196 |             pass
197 |             # delete the checkpoint
    |

geom3d\oligomer_encoding_with_transformer.py:198:13: ERA001 Found commented-out code
    |
196 |             pass
197 |             # delete the checkpoint
198 |             # os.remove(config["model_transformer_chkpt"])
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
199 |     else:
200 |         pass
    |
    = help: Remove commented-out code

geom3d\oligomer_encoding_with_transformer.py:201:5: ERA001 Found commented-out code
    |
199 |     else:
200 |         pass
201 |     # print(EncodingModel.hparams.model_dim)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
202 |     return EncodingModel
    |
    = help: Remove commented-out code

geom3d\oligomer_encoding_with_transformer.py:205:7: N801 Class name `Fragment_encoder` should use CapWords convention
    |
205 | class Fragment_encoder(TransformerPredictor):
    |       ^^^^^^^^^^^^^^^^ N801
206 |     def add_encoder(self, model_encoder, batch_size):
207 |         self.model_encoder = model_encoder
    |

geom3d\oligomer_encoding_with_transformer.py:205:7: D101 Missing docstring in public class
    |
205 | class Fragment_encoder(TransformerPredictor):
    |       ^^^^^^^^^^^^^^^^ D101
206 |     def add_encoder(self, model_encoder, batch_size):
207 |         self.model_encoder = model_encoder
    |

geom3d\oligomer_encoding_with_transformer.py:206:9: D102 Missing docstring in public method
    |
205 | class Fragment_encoder(TransformerPredictor):
206 |     def add_encoder(self, model_encoder, batch_size):
    |         ^^^^^^^^^^^ D102
207 |         self.model_encoder = model_encoder
208 |         self.hparams.batch_size = batch_size
    |

geom3d\oligomer_encoding_with_transformer.py:210:9: D102 Missing docstring in public method
    |
208 |         self.hparams.batch_size = batch_size
209 | 
210 |     def add_graph_pred_linear(self, graph_pred_linear):
    |         ^^^^^^^^^^^^^^^^^^^^^ D102
211 |         self.graph_pred_linear = graph_pred_linear
212 |         # set the graph_pred_linear to eval mode
    |

geom3d\oligomer_encoding_with_transformer.py:213:9: ERA001 Found commented-out code
    |
211 |         self.graph_pred_linear = graph_pred_linear
212 |         # set the graph_pred_linear to eval mode
213 |         # self.graph_pred_linear.eval()
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
214 |         # freeze all the parameters
215 |         for param in self.graph_pred_linear.parameters():
    |
    = help: Remove commented-out code

geom3d\oligomer_encoding_with_transformer.py:218:41: FBT002 Boolean default positional argument in function definition
    |
216 |             param.requires_grad = False
217 | 
218 |     def forward(self, batch, mask=None, add_positional_encoding=True):
    |                                         ^^^^^^^^^^^^^^^^^^^^^^^ FBT002
219 |         """Args:
220 |         ----
    |

geom3d\oligomer_encoding_with_transformer.py:219:9: D205 1 blank line required between summary line and description
    |
218 |       def forward(self, batch, mask=None, add_positional_encoding=True):
219 |           """Args:
    |  _________^
220 | |         ----
221 | |             x: Input features of shape [Batch, SeqLen, input_dim]
222 | |             mask: Mask to apply on the attention outputs (optional)
223 | |             add_positional_encoding: If True, we add the positional encoding to the input.
224 | |                                       Might not be desired for some tasks.
225 | | 
226 | |         """
    | |___________^ D205
227 |           if self.model_encoder is not None:
228 |               x = torch.zeros(
    |
    = help: Insert single blank line

geom3d\oligomer_encoding_with_transformer.py:219:9: D400 First line should end with a period
    |
218 |       def forward(self, batch, mask=None, add_positional_encoding=True):
219 |           """Args:
    |  _________^
220 | |         ----
221 | |             x: Input features of shape [Batch, SeqLen, input_dim]
222 | |             mask: Mask to apply on the attention outputs (optional)
223 | |             add_positional_encoding: If True, we add the positional encoding to the input.
224 | |                                       Might not be desired for some tasks.
225 | | 
226 | |         """
    | |___________^ D400
227 |           if self.model_encoder is not None:
228 |               x = torch.zeros(
    |
    = help: Add period

geom3d\oligomer_encoding_with_transformer.py:219:9: D415 First line should end with a period, question mark, or exclamation point
    |
218 |       def forward(self, batch, mask=None, add_positional_encoding=True):
219 |           """Args:
    |  _________^
220 | |         ----
221 | |             x: Input features of shape [Batch, SeqLen, input_dim]
222 | |             mask: Mask to apply on the attention outputs (optional)
223 | |             add_positional_encoding: If True, we add the positional encoding to the input.
224 | |                                       Might not be desired for some tasks.
225 | | 
226 | |         """
    | |___________^ D415
227 |           if self.model_encoder is not None:
228 |               x = torch.zeros(
    |
    = help: Add closing punctuation

geom3d\oligomer_encoding_with_transformer.py:261:9: ANN202 Missing return type annotation for private function `_calculate_loss`
    |
259 |         return self.output_net(x)
260 | 
261 |     def _calculate_loss(self, batch, mode="train"):
    |         ^^^^^^^^^^^^^^^ ANN202
262 |         """Calculate the loss for the given batch.
    |
    = help: Add return type annotation

geom3d\oligomer_encoding_with_transformer.py:277:9: ERA001 Found commented-out code
    |
275 |         inp_data, labels = batch, batch[0].y.squeeze()
276 | 
277 |         # inp_data = F.one_hot(inp_data, num_classes=self.hparams.num_classes).float()
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
278 | 
279 |         # Perform prediction and calculate loss and accuracy
    |
    = help: Remove commented-out code

geom3d\oligomer_encoding_with_transformer.py:289:9: ERA001 Found commented-out code
    |
287 |         )
288 |         loss = loss1 + 10*loss2
289 |         # print (labels.shape, preds.argmax(dim=-1).shape)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
290 |         # acc = (preds.argmax(dim=-1) == labels).float().mean()
    |
    = help: Remove commented-out code

geom3d\oligomer_encoding_with_transformer.py:290:9: ERA001 Found commented-out code
    |
288 |         loss = loss1 + 10*loss2
289 |         # print (labels.shape, preds.argmax(dim=-1).shape)
290 |         # acc = (preds.argmax(dim=-1) == labels).float().mean()
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
291 | 
292 |         # Logging
    |
    = help: Remove commented-out code

geom3d\oligomer_encoding_with_transformer.py:299:9: D102 Missing docstring in public method
    |
297 |         return loss
298 | 
299 |     def training_step(self, batch, batch_idx):
    |         ^^^^^^^^^^^^^ D102
300 |         return self._calculate_loss(batch, mode="train")
    |

geom3d\oligomer_encoding_with_transformer.py:299:36: ARG002 Unused method argument: `batch_idx`
    |
297 |         return loss
298 | 
299 |     def training_step(self, batch, batch_idx):
    |                                    ^^^^^^^^^ ARG002
300 |         return self._calculate_loss(batch, mode="train")
    |

geom3d\oligomer_encoding_with_transformer.py:302:9: D102 Missing docstring in public method
    |
300 |         return self._calculate_loss(batch, mode="train")
301 | 
302 |     def validation_step(self, batch, batch_idx):
    |         ^^^^^^^^^^^^^^^ D102
303 |         self._calculate_loss(batch, mode="val")
    |

geom3d\oligomer_encoding_with_transformer.py:302:38: ARG002 Unused method argument: `batch_idx`
    |
300 |         return self._calculate_loss(batch, mode="train")
301 | 
302 |     def validation_step(self, batch, batch_idx):
    |                                      ^^^^^^^^^ ARG002
303 |         self._calculate_loss(batch, mode="val")
    |

geom3d\oligomer_encoding_with_transformer.py:305:9: D102 Missing docstring in public method
    |
303 |         self._calculate_loss(batch, mode="val")
304 | 
305 |     def test_step(self, batch, batch_idx):
    |         ^^^^^^^^^ D102
306 |         self._calculate_loss(batch, mode="test")
    |

geom3d\oligomer_encoding_with_transformer.py:305:32: ARG002 Unused method argument: `batch_idx`
    |
303 |         self._calculate_loss(batch, mode="val")
304 | 
305 |     def test_step(self, batch, batch_idx):
    |                                ^^^^^^^^^ ARG002
306 |         self._calculate_loss(batch, mode="test")
    |

geom3d\pl_model.py:1:1: INP001 File `geom3d\pl_model.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\pl_model.py:5:8: N812 Lowercase `functional` imported as non-lowercase `Functional`
  |
3 | import lightning.pytorch as pl
4 | import torch
5 | import torch.nn.functional as Functional
  |        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N812
6 | from stk_search.geom3d.models import (
7 |     DimeNet,
  |

geom3d\pl_model.py:18:7: D101 Missing docstring in public class
   |
18 | class PrintLearningRate(pl.Callback):
   |       ^^^^^^^^^^^^^^^^^ D101
19 |     def on_train_epoch_start(self, trainer, pl_module):
20 |         trainer.optimizers[0].param_groups[0]["lr"]
   |

geom3d\pl_model.py:19:9: D102 Missing docstring in public method
   |
18 | class PrintLearningRate(pl.Callback):
19 |     def on_train_epoch_start(self, trainer, pl_module):
   |         ^^^^^^^^^^^^^^^^^^^^ D102
20 |         trainer.optimizers[0].param_groups[0]["lr"]
   |

geom3d\pl_model.py:19:45: ARG002 Unused method argument: `pl_module`
   |
18 | class PrintLearningRate(pl.Callback):
19 |     def on_train_epoch_start(self, trainer, pl_module):
   |                                             ^^^^^^^^^ ARG002
20 |         trainer.optimizers[0].param_groups[0]["lr"]
   |

geom3d\pl_model.py:24:5: D205 1 blank line required between summary line and description
   |
23 |   class Pymodel(pl.LightningModule):
24 |       """PyTorch Lightning model for 3D molecular representation learning.
   |  _____^
25 | |     The loss function is the mean squared error (MSE) loss.
26 | |     The learning rate scheduler can be chosen from CosineAnnealingLR, CosineAnnealingWarmRestarts, and StepLR.
27 | |     The initial learning rate and the learning rate scheduler parameters can be set in the configuration file.
28 | | 
29 | |     Args:
30 | |     ----
31 | |     - model (nn.Module): 3D molecular representation learning model
32 | |     - graph_pred_linear (nn.Module): linear layer for graph prediction
33 | |     - config (dict): dictionary containing the configuration
34 | | 
35 | |     """
   | |_______^ D205
36 |   
37 |       def __init__(self, model, graph_pred_linear, config):
   |
   = help: Insert single blank line

geom3d\pl_model.py:37:9: D107 Missing docstring in `__init__`
   |
35 |     """
36 | 
37 |     def __init__(self, model, graph_pred_linear, config):
   |         ^^^^^^^^ D107
38 |         super().__init__()
39 |         self.save_hyperparameters(ignore=["graph_pred_linear", "model"])
   |

geom3d\pl_model.py:44:9: D102 Missing docstring in public method
   |
42 |         self.config = config
43 | 
44 |     def training_step(self, batch, batch_idx):
   |         ^^^^^^^^^^^^^ D102
45 |         # training_step defines the train loop.
46 |         with torch.cuda.amp.autocast(
   |

geom3d\pl_model.py:44:36: ARG002 Unused method argument: `batch_idx`
   |
42 |         self.config = config
43 | 
44 |     def training_step(self, batch, batch_idx):
   |                                    ^^^^^^^^^ ARG002
45 |         # training_step defines the train loop.
46 |         with torch.cuda.amp.autocast(
   |

geom3d\pl_model.py:47:47: PLR2004 Magic value used in comparison, consider replacing `16` with a constant variable
   |
45 |         # training_step defines the train loop.
46 |         with torch.cuda.amp.autocast(
47 |             enabled=self.trainer.precision == 16
   |                                               ^^ PLR2004
48 |         ):  # 16-bit precision for mixed precision training, activated only when self.trainer.precision == 16
49 |             loss = self._get_preds_loss_accuracy(batch)
   |

geom3d\pl_model.py:66:38: ARG002 Unused method argument: `batch_idx`
   |
64 |         return loss
65 | 
66 |     def validation_step(self, batch, batch_idx):
   |                                      ^^^^^^^^^ ARG002
67 |         """Used for logging metrics."""
68 |         with torch.cuda.amp.autocast(
   |

geom3d\pl_model.py:67:9: D401 First line of docstring should be in imperative mood: "Used for logging metrics."
   |
66 |     def validation_step(self, batch, batch_idx):
67 |         """Used for logging metrics."""
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
68 |         with torch.cuda.amp.autocast(
69 |             enabled=self.trainer.precision == 16
   |

geom3d\pl_model.py:69:47: PLR2004 Magic value used in comparison, consider replacing `16` with a constant variable
   |
67 |         """Used for logging metrics."""
68 |         with torch.cuda.amp.autocast(
69 |             enabled=self.trainer.precision == 16
   |                                               ^^ PLR2004
70 |         ):  # 16-bit precision for mixed precision training, activated only when self.trainer.precision == 16
71 |             loss = self._get_preds_loss_accuracy(batch)
   |

geom3d\pl_model.py:77:9: ANN202 Missing return type annotation for private function `_get_preds_loss_accuracy`
   |
75 |         return loss
76 | 
77 |     def _get_preds_loss_accuracy(self, batch):
   |         ^^^^^^^^^^^^^^^^^^^^^^^^ ANN202
78 |         """Convenience function since train/valid/test steps are similar."""
79 |         batch = batch.to(self.device)
   |
   = help: Add return type annotation

geom3d\pl_model.py:78:9: D401 First line of docstring should be in imperative mood: "Convenience function since train/valid/test steps are similar."
   |
77 |     def _get_preds_loss_accuracy(self, batch):
78 |         """Convenience function since train/valid/test steps are similar."""
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
79 |         batch = batch.to(self.device)
80 |         z = self.forward(batch)
   |

geom3d\pl_model.py:88:9: D102 Missing docstring in public method
   |
86 |         return loss
87 | 
88 |     def configure_optimizers(self):
   |         ^^^^^^^^^^^^^^^^^^^^ D102
89 |         # set up optimizer
90 |         # make sure the optimiser step does not reset the val_loss metrics
   |

geom3d\pl_model.py:116:9: ERA001 Found commented-out code
    |
114 |         return [optimizer], [lr_scheduler]
115 | 
116 |         # optimizer = torch.optim.Adam(self.parameters(), lr=5e-4)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
117 |         # return optimizer
    |
    = help: Remove commented-out code

geom3d\pl_model.py:117:9: ERA001 Found commented-out code
    |
116 |         # optimizer = torch.optim.Adam(self.parameters(), lr=5e-4)
117 |         # return optimizer
    |         ^^^^^^^^^^^^^^^^^^ ERA001
118 | 
119 |     def forward(self, batch):
    |
    = help: Remove commented-out code

geom3d\pl_model.py:119:9: D102 Missing docstring in public method
    |
117 |         # return optimizer
118 | 
119 |     def forward(self, batch):
    |         ^^^^^^^ D102
120 |         batch = batch.to(self.device)
121 |         model_name = type(self.molecule_3D_repr).__name__
    |

geom3d\pl_model.py:154:7: N801 Class name `Pymodel_new` should use CapWords convention
    |
154 | class Pymodel_new(pl.LightningModule):
    |       ^^^^^^^^^^^ N801
155 |     """lightning model taking into account two different oligomer representations."""
    |

geom3d\pl_model.py:157:9: D107 Missing docstring in `__init__`
    |
155 |     """lightning model taking into account two different oligomer representations."""
156 | 
157 |     def __init__(self, model, graph_pred_linear, config):
    |         ^^^^^^^^ D107
158 |         super().__init__()
    |

geom3d\pl_model.py:167:9: D102 Missing docstring in public method
    |
167 |     def training_step(self, batch, batch_idx):
    |         ^^^^^^^^^^^^^ D102
168 |         # training_step defines the train loop.
169 |         with torch.cuda.amp.autocast(
    |

geom3d\pl_model.py:167:36: ARG002 Unused method argument: `batch_idx`
    |
167 |     def training_step(self, batch, batch_idx):
    |                                    ^^^^^^^^^ ARG002
168 |         # training_step defines the train loop.
169 |         with torch.cuda.amp.autocast(
    |

geom3d\pl_model.py:170:47: PLR2004 Magic value used in comparison, consider replacing `16` with a constant variable
    |
168 |         # training_step defines the train loop.
169 |         with torch.cuda.amp.autocast(
170 |             enabled=self.trainer.precision == 16
    |                                               ^^ PLR2004
171 |         ):  # 16-bit precision for mixed precision training, activated only when self.trainer.precision == 16
172 |             loss, loss1, loss2 = self._get_preds_loss_accuracy(batch)
    |

geom3d\pl_model.py:190:38: ARG002 Unused method argument: `batch_idx`
    |
188 |         return loss
189 | 
190 |     def validation_step(self, batch, batch_idx):
    |                                      ^^^^^^^^^ ARG002
191 |         """Used for logging metrics."""
192 |         with torch.cuda.amp.autocast(
    |

geom3d\pl_model.py:191:9: D401 First line of docstring should be in imperative mood: "Used for logging metrics."
    |
190 |     def validation_step(self, batch, batch_idx):
191 |         """Used for logging metrics."""
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
192 |         with torch.cuda.amp.autocast(
193 |             enabled=self.trainer.precision == 16
    |

geom3d\pl_model.py:193:47: PLR2004 Magic value used in comparison, consider replacing `16` with a constant variable
    |
191 |         """Used for logging metrics."""
192 |         with torch.cuda.amp.autocast(
193 |             enabled=self.trainer.precision == 16
    |                                               ^^ PLR2004
194 |         ):  # 16-bit precision for mixed precision training, activated only when self.trainer.precision == 16
195 |             loss, loss1, loss2 = self._get_preds_loss_accuracy(batch)
    |

geom3d\pl_model.py:203:9: ANN202 Missing return type annotation for private function `_get_preds_loss_accuracy`
    |
201 |         return loss
202 | 
203 |     def _get_preds_loss_accuracy(self, batch):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^ ANN202
204 |         """Convenience function since train/valid/test steps are similar."""
205 |         batch = batch.to(self.device)
    |
    = help: Add return type annotation

geom3d\pl_model.py:204:9: D401 First line of docstring should be in imperative mood: "Convenience function since train/valid/test steps are similar."
    |
203 |     def _get_preds_loss_accuracy(self, batch):
204 |         """Convenience function since train/valid/test steps are similar."""
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
205 |         batch = batch.to(self.device)
206 |         z, z_opt, z_repr, z_repr_opt = self.forward_train(batch)
    |

geom3d\pl_model.py:211:13: ERA001 Found commented-out code
    |
209 |             loss1 = Functional.mse_loss(z_opt, batch.y.unsqueeze(1))
210 |             loss2 = Functional.mse_loss(z_repr, z_repr_opt)
211 |             # loss = loss + Functional.mse_loss(z, batch.y.unsqueeze(1))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
212 |             a = torch.tensor(0.5, requires_grad=True)
213 |             loss = a * loss1 + (1 - a) * loss2
    |
    = help: Remove commented-out code

geom3d\pl_model.py:218:9: D102 Missing docstring in public method
    |
216 |         return loss, loss1, loss2
217 | 
218 |     def forward_train(self, batch):
    |         ^^^^^^^^^^^^^ D102
219 | 
220 |         batch = batch.to(self.device)
    |

geom3d\pl_model.py:223:13: N802 Function name `get_Z` should be lowercase
    |
221 |         model_name = type(self.molecule_3D_repr).__name__
222 | 
223 |         def get_Z(x, positions, model_name, batch):
    |             ^^^^^ N802
224 |             if model_name == "EquiformerEnergy":
225 |                 model_name = "Equiformer"
    |

geom3d\pl_model.py:223:13: ANN202 Missing return type annotation for private function `get_Z`
    |
221 |         model_name = type(self.molecule_3D_repr).__name__
222 | 
223 |         def get_Z(x, positions, model_name, batch):
    |             ^^^^^ ANN202
224 |             if model_name == "EquiformerEnergy":
225 |                 model_name = "Equiformer"
    |
    = help: Add return type annotation

geom3d\pl_model.py:250:9: D102 Missing docstring in public method
    |
249 |         return z, z_opt, z_repr, z_repr_opt
250 |     def configure_optimizers(self):
    |         ^^^^^^^^^^^^^^^^^^^^ D102
251 |         # set up optimizer
252 |         # make sure the optimiser step does not reset the val_loss metrics
    |

geom3d\pl_model.py:278:9: ERA001 Found commented-out code
    |
276 |         return [optimizer], [lr_scheduler]
277 | 
278 |         # optimizer = torch.optim.Adam(self.parameters(), lr=5e-4)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
279 |         # return optimizer
    |
    = help: Remove commented-out code

geom3d\pl_model.py:279:9: ERA001 Found commented-out code
    |
278 |         # optimizer = torch.optim.Adam(self.parameters(), lr=5e-4)
279 |         # return optimizer
    |         ^^^^^^^^^^^^^^^^^^ ERA001
280 | 
281 |     def forward(self, batch):
    |
    = help: Remove commented-out code

geom3d\pl_model.py:281:9: D102 Missing docstring in public method
    |
279 |         # return optimizer
280 | 
281 |     def forward(self, batch):
    |         ^^^^^^^ D102
282 |         batch = batch.to(self.device)
283 |         model_name = type(self.molecule_3D_repr).__name__
    |

geom3d\pl_model.py:316:5: C901 `model_setup` is too complex (11 > 10)
    |
316 | def model_setup(config, trial=None):
    |     ^^^^^^^^^^^ C901
317 |     """Setup the model based on the configuration file.
    |

geom3d\pl_model.py:316:5: D417 Missing argument descriptions in the docstring for `model_setup`: `config`, `trial`
    |
316 | def model_setup(config, trial=None):
    |     ^^^^^^^^^^^ D417
317 |     """Setup the model based on the configuration file.
    |

geom3d\pl_model.py:317:5: D401 First line of docstring should be in imperative mood: "Setup the model based on the configuration file."
    |
316 |   def model_setup(config, trial=None):
317 |       """Setup the model based on the configuration file.
    |  _____^
318 | | 
319 | |     Args:
320 | |     ----
321 | |     - config (dict): configuration file
322 | |     - trial (optuna.trial): optuna trial object
323 | | 
324 | |     Returns:
325 | |     -------
326 | |     - model (nn.Module): model
327 | |     - graph_pred_linear (nn.Module): output layer for the model
328 | | 
329 | |     """
    | |_______^ D401
330 |       model_config = config["model"]
    |

geom3d\pl_model.py:333:18: F821 Undefined name `hyperparameter_setup`
    |
332 |     if trial:
333 |         config = hyperparameter_setup(config, trial)
    |                  ^^^^^^^^^^^^^^^^^^^^ F821
334 | 
335 |     if config["model_name"] == "SchNet":
    |

geom3d\polymer_GNN_architecture_utils.py:1:1: INP001 File `geom3d\polymer_GNN_architecture_utils.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\polymer_GNN_architecture_utils.py:1:1: D100 Missing docstring in public module
geom3d\polymer_GNN_architecture_utils.py:14:5: D103 Missing docstring in public function
   |
14 | def join_keys(polymer):
   |     ^^^^^^^^^ D103
15 |     keys = [stk.InchiKey().get_key(bb) for bb in polymer.get_building_blocks()]
16 |     return "_".join(keys)
   |

geom3d\polymer_GNN_architecture_utils.py:19:5: D103 Missing docstring in public function
   |
19 | def get_bbs_dict(client, database):
   |     ^^^^^^^^^^^^ D103
20 |     client = pymongo.MongoClient(client)
21 |     db_mol = stk.MoleculeMongoDb(
   |

geom3d\polymer_GNN_architecture_utils.py:36:5: N802 Function name `Build_polymers` should be lowercase
   |
36 | def Build_polymers(element: pd.DataFrame, bbs_dict):
   |     ^^^^^^^^^^^^^^ N802
37 | 
38 |     # print(genes)
   |

geom3d\polymer_GNN_architecture_utils.py:36:5: D103 Missing docstring in public function
   |
36 | def Build_polymers(element: pd.DataFrame, bbs_dict):
   |     ^^^^^^^^^^^^^^ D103
37 | 
38 |     # print(genes)
   |

geom3d\polymer_GNN_architecture_utils.py:38:5: ERA001 Found commented-out code
   |
36 | def Build_polymers(element: pd.DataFrame, bbs_dict):
37 | 
38 |     # print(genes)
   |     ^^^^^^^^^^^^^^ ERA001
39 | 
40 |     InchiKey_cols = [col for col in element.columns if "InChIKey_" in col]
   |
   = help: Remove commented-out code

geom3d\polymer_GNN_architecture_utils.py:40:5: N806 Variable `InchiKey_cols` in function should be lowercase
   |
38 |     # print(genes)
39 | 
40 |     InchiKey_cols = [col for col in element.columns if "InChIKey_" in col]
   |     ^^^^^^^^^^^^^ N806
41 |     oligomer_size = len(InchiKey_cols)
42 |     genes = "ABCDEFGH"
   |

geom3d\polymer_GNN_architecture_utils.py:48:5: ERA001 Found commented-out code
   |
46 |     repeating_unit = repeating_unit.join(genes)
47 | 
48 |     # print(element[InchiKey_cols].values.flatten())
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
49 |     def gen_mol(elem):
50 |         precursors = []
   |
   = help: Remove commented-out code

geom3d\polymer_GNN_architecture_utils.py:49:9: ANN202 Missing return type annotation for private function `gen_mol`
   |
48 |     # print(element[InchiKey_cols].values.flatten())
49 |     def gen_mol(elem):
   |         ^^^^^^^ ANN202
50 |         precursors = []
51 |         for fragment in elem[InchiKey_cols].values.flatten():
   |
   = help: Add return type annotation

geom3d\polymer_GNN_architecture_utils.py:51:25: PD011 Use `.to_numpy()` instead of `.values`
   |
49 |     def gen_mol(elem):
50 |         precursors = []
51 |         for fragment in elem[InchiKey_cols].values.flatten():
   |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
52 |             bb = bbs_dict[fragment]
53 |             precursors.append(bb)
   |

geom3d\polymer_GNN_architecture_utils.py:84:5: D417 Missing argument descriptions in the docstring for `load_molecule`: `InChIKey`, `db`, `target`
   |
84 | def load_molecule(InChIKey, target, db):
   |     ^^^^^^^^^^^^^ D417
85 |     """Load a molecule from the database.
   |

geom3d\polymer_GNN_architecture_utils.py:84:19: N803 Argument name `InChIKey` should be lowercase
   |
84 | def load_molecule(InChIKey, target, db):
   |                   ^^^^^^^^ N803
85 |     """Load a molecule from the database.
   |

geom3d\polymer_GNN_architecture_utils.py:99:5: SIM105 Use `contextlib.suppress(KeyError)` instead of `try`-`except`-`pass`
    |
 97 |       """
 98 |       polymer = None
 99 |       try:
    |  _____^
100 | |         polymer = db.get({"InChIKey": InChIKey})
101 | |         # Print the complete dictionary returned from the database
102 | |         # print("Database entry for InChIKey:", polymer)
103 | |     except KeyError:
104 | |         pass
    | |____________^ SIM105
105 |           # Handle the missing key case (e.g., return a default value or raise an exception)
    |
    = help: Replace with `contextlib.suppress(KeyError)`

geom3d\polymer_GNN_architecture_utils.py:102:9: ERA001 Found commented-out code
    |
100 |         polymer = db.get({"InChIKey": InChIKey})
101 |         # Print the complete dictionary returned from the database
102 |         # print("Database entry for InChIKey:", polymer)
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
103 |     except KeyError:
104 |         pass
    |
    = help: Remove commented-out code

geom3d\polymer_GNN_architecture_utils.py:125:5: RET505 Unnecessary `else` after `return` statement
    |
123 |             bb_key=join_keys(polymer),
124 |         )
125 |     else:
    |     ^^^^ RET505
126 |         return None
    |
    = help: Remove unnecessary `else`

geom3d\polymer_GNN_architecture_utils.py:129:5: D103 Missing docstring in public function
    |
129 | def get_dataset_polymer_opt(config, element):
    |     ^^^^^^^^^^^^^^^^^^^^^^^ D103
130 |     client = pymongo.MongoClient(config["pymongo_client"])
131 |     db = stk.ConstructedMoleculeMongoDb(
    |

geom3d\polymer_GNN_architecture_utils.py:141:5: D103 Missing docstring in public function
    |
141 | def add_position_opt(dataset, dataset_opt):
    |     ^^^^^^^^^^^^^^^^ D103
142 |     for i in range(len(dataset)):
143 |         dataset[i].positions_opt = dataset_opt[i].positions
    |

geom3d\polymer_GNN_architecture_utils.py:148:5: D103 Missing docstring in public function
    |
148 | def get_dataset_polymer(element: pd.DataFrame, bbs_dict, config):
    |     ^^^^^^^^^^^^^^^^^^^ D103
149 |     # element_copy = element[[f'InChIKey_{i}' for i in range(oligomer_size)]].copy()
150 |     dataset_poly = Build_polymers(element, bbs_dict)
    |

geom3d\polymer_GNN_architecture_utils.py:149:5: ERA001 Found commented-out code
    |
148 | def get_dataset_polymer(element: pd.DataFrame, bbs_dict, config):
149 |     # element_copy = element[[f'InChIKey_{i}' for i in range(oligomer_size)]].copy()
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
150 |     dataset_poly = Build_polymers(element, bbs_dict)
151 |     dataset_poly_opt = get_dataset_polymer_opt(config, element)
    |
    = help: Remove commented-out code

geom3d\polymer_GNN_architecture_utils.py:156:5: D205 1 blank line required between summary line and description
    |
155 |   def get_data_loader(dataset, config):
156 |       """Get the dataloader
    |  _____^
157 | |     Args:
158 | |         dataset: list
159 | |             list of the dataset
160 | |         config: dict
161 | |             configuration file.
162 | | 
163 | |     Returns
164 | |     -------
165 | |         loader: torch_geometric.loader.DataLoader
166 | |             dataloader for the dataset
167 | | 
168 | |     """
    | |_______^ D205
169 |       # Set dataloaders
170 |       return DataLoader(
    |
    = help: Insert single blank line

geom3d\polymer_GNN_architecture_utils.py:181:5: D205 1 blank line required between summary line and description
    |
180 |   def generate_dataset_and_dataloader(config, bbs_dict):
181 |       """Generate the dataset and the dataloader
    |  _____^
182 | |     Args:
183 | |         config: dict
184 | |             configuration file
185 | |     Returns:
186 | |         train_loader: torch_geometric.loader.DataLoader
187 | |             dataloader for the training set
188 | |         val_loader: torch_geometric.loader.DataLoader
189 | |             dataloader for the validation set
190 | |         test_loader: torch_geometric.loader.DataLoader
191 | |             dataloader for the test set
192 | |         dataset_train: list
193 | |             list of the training dataset
194 | |         dataset_val: list
195 | |             list of the validation dataset
196 | |         dataset_test: list
197 | |             list of the test dataset.
198 | |     """
    | |_______^ D205
199 |   
200 |       def get_dataset_dataloader(config, df_name="train"):
    |
    = help: Insert single blank line

geom3d\polymer_GNN_architecture_utils.py:200:9: ANN202 Missing return type annotation for private function `get_dataset_dataloader`
    |
198 |     """
199 | 
200 |     def get_dataset_dataloader(config, df_name="train"):
    |         ^^^^^^^^^^^^^^^^^^^^^^ ANN202
201 |         pd.read_pickle(config["df_precursor"])
202 |         if f"dataset_path_{df_name}" in config:
    |
    = help: Add return type annotation

geom3d\polymer_GNN_architecture_utils.py:201:9: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
    |
200 |     def get_dataset_dataloader(config, df_name="train"):
201 |         pd.read_pickle(config["df_precursor"])
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ S301
202 |         if f"dataset_path_{df_name}" in config:
203 |             if os.path.exists(config["dataset_path" + f"_{df_name}"]):
    |

geom3d\polymer_GNN_architecture_utils.py:203:16: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
    |
201 |         pd.read_pickle(config["df_precursor"])
202 |         if f"dataset_path_{df_name}" in config:
203 |             if os.path.exists(config["dataset_path" + f"_{df_name}"]):
    |                ^^^^^^^^^^^^^^ PTH110
204 |                 if "device" in config:
205 |                     dataset = torch.load(
    |

geom3d\polymer_GNN_architecture_utils.py:215:13: RET505 Unnecessary `else` after `return` statement
    |
213 |                 data_loader = get_data_loader(dataset, config)
214 |                 return dataset, data_loader
215 |             else:
    |             ^^^^ RET505
216 |                 pass
217 |         df = pd.read_csv(config["running_dir"] + f"/df_{df_name}.csv")
    |
    = help: Remove unnecessary `else`

geom3d\polymer_GNN_architecture_utils.py:217:9: PD901 Avoid using the generic variable name `df` for DataFrames
    |
215 |             else:
216 |                 pass
217 |         df = pd.read_csv(config["running_dir"] + f"/df_{df_name}.csv")
    |         ^^ PD901
218 |         dataset = get_dataset_polymer(
219 |             element=df, bbs_dict=bbs_dict, config=config
    |

geom3d\polymer_GNN_architecture_utils.py:240:5: D103 Missing docstring in public function
    |
240 | def save_datasets(config, dataset_train, dataset_val, dataset_test):
    |     ^^^^^^^^^^^^^ D103
241 |     name = config["name"]
242 |     ephemeral_dir = config["ephemeral_path"] + f"/{name.replace('_','/')}/"
    |

geom3d\polymer_GNN_architecture_utils.py:255:1: ERA001 Found commented-out code
    |
255 | # df_elements = df_total.sample(500)
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
256 | # dataset = get_dataset_polymer(
257 | #    oligomer_size=6,
    |
    = help: Remove commented-out code

geom3d\polymer_GNN_architecture_utils.py:256:1: ERA001 Found commented-out code
    |
255 | # df_elements = df_total.sample(500)
256 | # dataset = get_dataset_polymer(
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
257 | #    oligomer_size=6,
258 | #    element=df_elements,
    |
    = help: Remove commented-out code

geom3d\polymer_GNN_architecture_utils.py:257:1: ERA001 Found commented-out code
    |
255 | # df_elements = df_total.sample(500)
256 | # dataset = get_dataset_polymer(
257 | #    oligomer_size=6,
    | ^^^^^^^^^^^^^^^^^^^^^ ERA001
258 | #    element=df_elements,
259 | #    bbs_dict=bbs_dict,
    |
    = help: Remove commented-out code

geom3d\polymer_GNN_architecture_utils.py:258:1: ERA001 Found commented-out code
    |
256 | # dataset = get_dataset_polymer(
257 | #    oligomer_size=6,
258 | #    element=df_elements,
    | ^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
259 | #    bbs_dict=bbs_dict,
260 | #    config=config
    |
    = help: Remove commented-out code

geom3d\polymer_GNN_architecture_utils.py:259:1: ERA001 Found commented-out code
    |
257 | #    oligomer_size=6,
258 | #    element=df_elements,
259 | #    bbs_dict=bbs_dict,
    | ^^^^^^^^^^^^^^^^^^^^^^^ ERA001
260 | #    config=config
261 | # )
    |
    = help: Remove commented-out code

geom3d\polymer_GNN_architecture_utils.py:260:1: ERA001 Found commented-out code
    |
258 | #    element=df_elements,
259 | #    bbs_dict=bbs_dict,
260 | #    config=config
    | ^^^^^^^^^^^^^^^^^^ ERA001
261 | # )
    |
    = help: Remove commented-out code

geom3d\polymer_GNN_architecture_utils.py:261:1: ERA001 Found commented-out code
    |
259 | #    bbs_dict=bbs_dict,
260 | #    config=config
261 | # )
    | ^^^ ERA001
    |
    = help: Remove commented-out code

geom3d\script_plot_inference_BA.py:1:1: INP001 File `geom3d\script_plot_inference_BA.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\script_plot_inference_BA.py:1:1: D100 Missing docstring in public module
geom3d\script_plot_inference_BA.py:18:5: D103 Missing docstring in public function
   |
18 | def load_data(
   |     ^^^^^^^^^ D103
19 |     df_path="data/output/Full_datatset/df_total_new2023_08_20.csv",
20 |     df_precursors_path="data/output/Prescursor_data/calculation_data_precursor_190923_clean.pkl",
   |

geom3d\script_plot_inference_BA.py:25:5: N806 Variable `SP` in function should be lowercase
   |
23 |         df_path, df_precursors_path
24 |     )
25 |     SP = Searched_pace.Searched_Space(
   |     ^^ N806
26 |         number_of_fragments=6,
27 |         df=df_precursors,
   |

geom3d\script_plot_inference_BA.py:25:10: F821 Undefined name `Searched_pace`
   |
23 |         df_path, df_precursors_path
24 |     )
25 |     SP = Searched_pace.Searched_Space(
   |          ^^^^^^^^^^^^^ F821
26 |         number_of_fragments=6,
27 |         df=df_precursors,
   |

geom3d\script_plot_inference_BA.py:32:24: PD011 Use `.to_numpy()` instead of `.values`
   |
30 |     )
31 |     searched_space_df = SP.check_df_for_element_from_SP(df_to_check=df_total)
32 |     fitness_acquired = searched_space_df["target"].values
   |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
33 |     searched_space_df_InChIKey = searched_space_df[["InChIKey"]]
34 |     searched_space_df = searched_space_df[[f"InChIKey_{x}" for x in range(6)]]
   |

geom3d\script_plot_inference_BA.py:33:5: N806 Variable `searched_space_df_InChIKey` in function should be lowercase
   |
31 |     searched_space_df = SP.check_df_for_element_from_SP(df_to_check=df_total)
32 |     fitness_acquired = searched_space_df["target"].values
33 |     searched_space_df_InChIKey = searched_space_df[["InChIKey"]]
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ N806
34 |     searched_space_df = searched_space_df[[f"InChIKey_{x}" for x in range(6)]]
35 |     return (
   |

geom3d\script_plot_inference_BA.py:44:5: D103 Missing docstring in public function
   |
44 | def load_models(config, chkpt_path=None):
   |     ^^^^^^^^^^^ D103
45 |     EncodingModel = initialise_model(config)
46 |     if chkpt_path is not None:
   |

geom3d\script_plot_inference_BA.py:45:5: N806 Variable `EncodingModel` in function should be lowercase
   |
44 | def load_models(config, chkpt_path=None):
45 |     EncodingModel = initialise_model(config)
   |     ^^^^^^^^^^^^^ N806
46 |     if chkpt_path is not None:
47 |         # load pymodel
   |

geom3d\script_plot_inference_BA.py:51:9: ERA001 Found commented-out code
   |
49 |         checkpoint = torch.load(chkpt_path,map_location=config["device"])
50 |         model, graph_pred_linear = model_setup(config)
51 |         #config["device"] = "cuda:0" if torch.cuda.is_available() else "cpu"
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
52 |         # Pass the model and graph_pred_linear to the Pymodel constructor
   |
   = help: Remove commented-out code

geom3d\script_plot_inference_BA.py:62:5: RET505 Unnecessary `else` after `return` statement
   |
60 |         model_inferrence = pymodel.graph_pred_linear
61 |         return EncodingModel, model_embedding, model_inferrence
62 |     else:
   |     ^^^^ RET505
63 |         return EncodingModel
   |
   = help: Remove unnecessary `else`

geom3d\script_plot_inference_BA.py:66:5: N802 Function name `PredictTargetFromEmbedding` should be lowercase
   |
66 | def PredictTargetFromEmbedding(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ N802
67 |     data, model_inferecence, device=torch.device("cpu")
68 | ):
   |

geom3d\script_plot_inference_BA.py:66:5: D103 Missing docstring in public function
   |
66 | def PredictTargetFromEmbedding(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
67 |     data, model_inferecence, device=torch.device("cpu")
68 | ):
   |

geom3d\script_plot_inference_BA.py:67:37: B008 Do not perform function call `torch.device` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   |
66 | def PredictTargetFromEmbedding(
67 |     data, model_inferecence, device=torch.device("cpu")
   |                                     ^^^^^^^^^^^^^^^^^^^ B008
68 | ):
69 |     data = data.to(device)
   |

geom3d\script_plot_inference_BA.py:77:5: PLR0913 Too many arguments in function definition (8 > 5)
   |
77 | def generate_train_val_data(
   |     ^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
78 |     dataset,
79 |     EncodingModel,
   |

geom3d\script_plot_inference_BA.py:77:5: D103 Missing docstring in public function
   |
77 | def generate_train_val_data(
   |     ^^^^^^^^^^^^^^^^^^^^^^^ D103
78 |     dataset,
79 |     EncodingModel,
   |

geom3d\script_plot_inference_BA.py:79:5: N803 Argument name `EncodingModel` should be lowercase
   |
77 | def generate_train_val_data(
78 |     dataset,
79 |     EncodingModel,
   |     ^^^^^^^^^^^^^ N803
80 |     model_inferrence,
81 |     config,
   |

geom3d\script_plot_inference_BA.py:95:5: N806 Variable `X_explored_frag` in function should be lowercase
   |
93 |         drop_last=True,
94 |     )
95 |     X_explored_frag=torch.tensor([], device=config["device"])
   |     ^^^^^^^^^^^^^^^ N806
96 |     X_explored_org=torch.tensor([], device=config["device"])
97 |     y_explored=torch.tensor([], device=config["device"])
   |

geom3d\script_plot_inference_BA.py:96:5: N806 Variable `X_explored_org` in function should be lowercase
   |
94 |     )
95 |     X_explored_frag=torch.tensor([], device=config["device"])
96 |     X_explored_org=torch.tensor([], device=config["device"])
   |     ^^^^^^^^^^^^^^ N806
97 |     y_explored=torch.tensor([], device=config["device"])
98 |     y_predicted = torch.tensor([], device=config["device"])
   |

geom3d\script_plot_inference_BA.py:106:13: N806 Variable `Y_pred` in function should be lowercase
    |
104 |             representation = representation.squeeze()
105 |             model_inferrence.to(config["device"])
106 |             Y_pred = model_inferrence(representation.to(config["device"]))
    |             ^^^^^^ N806
107 |             # add y_pred from org representation
108 |             y_pred_org = model_inferrence(x[0].y.to(config["device"]))
    |

geom3d\script_plot_inference_BA.py:109:13: N806 Variable `X_explored_frag` in function should be lowercase
    |
107 |             # add y_pred from org representation
108 |             y_pred_org = model_inferrence(x[0].y.to(config["device"]))
109 |             X_explored_frag =torch.cat((X_explored_frag, representation), dim=0)
    |             ^^^^^^^^^^^^^^^ N806
110 |             if model_embedding is None:
111 |                 X_explored_org =torch.cat((X_explored_org, x[0].y), dim=0)
    |

geom3d\script_plot_inference_BA.py:111:17: N806 Variable `X_explored_org` in function should be lowercase
    |
109 |             X_explored_frag =torch.cat((X_explored_frag, representation), dim=0)
110 |             if model_embedding is None:
111 |                 X_explored_org =torch.cat((X_explored_org, x[0].y), dim=0)
    |                 ^^^^^^^^^^^^^^ N806
112 |             else:
113 |                 X_explored_org =torch.cat((X_explored_org, model_embedding(x)), dim=0)
    |

geom3d\script_plot_inference_BA.py:113:17: N806 Variable `X_explored_org` in function should be lowercase
    |
111 |                 X_explored_org =torch.cat((X_explored_org, x[0].y), dim=0)
112 |             else:
113 |                 X_explored_org =torch.cat((X_explored_org, model_embedding(x)), dim=0)
    |                 ^^^^^^^^^^^^^^ N806
114 |             y_predicted = torch.cat((y_predicted, Y_pred), dim=0)
115 |             y_predicted_org = torch.cat((y_predicted_org, y_pred_org), dim=0)
    |

geom3d\script_plot_inference_BA.py:127:5: PLR0913 Too many arguments in function definition (9 > 5)
    |
127 | def generate_test_val_data(
    |     ^^^^^^^^^^^^^^^^^^^^^^ PLR0913
128 |     dataset,
129 |     df_total,
    |

geom3d\script_plot_inference_BA.py:127:5: D103 Missing docstring in public function
    |
127 | def generate_test_val_data(
    |     ^^^^^^^^^^^^^^^^^^^^^^ D103
128 |     dataset,
129 |     df_total,
    |

geom3d\script_plot_inference_BA.py:132:5: N803 Argument name `EncodingModel` should be lowercase
    |
130 |     df_precursors,
131 |     config,
132 |     EncodingModel,
    |     ^^^^^^^^^^^^^ N803
133 |     model_embedding,
134 |     target_name="target",
    |

geom3d\script_plot_inference_BA.py:147:5: N806 Variable `SP` in function should be lowercase
    |
145 |         database=config["database_name"],
146 |     )
147 |     SP = Searched_pace.Searched_Space(
    |     ^^ N806
148 |         number_of_fragments=6,
149 |         df=df_precursors,
    |

geom3d\script_plot_inference_BA.py:147:10: F821 Undefined name `Searched_pace`
    |
145 |         database=config["database_name"],
146 |     )
147 |     SP = Searched_pace.Searched_Space(
    |          ^^^^^^^^^^^^^ F821
148 |         number_of_fragments=6,
149 |         df=df_precursors,
    |

geom3d\script_plot_inference_BA.py:160:14: PD011 Use `.to_numpy()` instead of `.values`
    |
158 |     searched_space_df = SP.check_df_for_element_from_SP(df_to_check=df_dataset)
159 | 
160 |     y_true = searched_space_df[target_name].values
    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
161 |     searched_space_df = searched_space_df[[f"InChIKey_{x}" for x in range(6)]]
162 |     Representation = Represenation_3D.Representation3DFrag_transformer(
    |

geom3d\script_plot_inference_BA.py:162:5: N806 Variable `Representation` in function should be lowercase
    |
160 |     y_true = searched_space_df[target_name].values
161 |     searched_space_df = searched_space_df[[f"InChIKey_{x}" for x in range(6)]]
162 |     Representation = Represenation_3D.Representation3DFrag_transformer(
    |     ^^^^^^^^^^^^^^ N806
163 |         EncodingModel,
164 |         df_total,
    |

geom3d\script_plot_inference_BA.py:169:5: N806 Variable `X_explored_frag` in function should be lowercase
    |
167 |         device=config["device"],
168 |     )
169 |     X_explored_frag = Representation.generate_repr(searched_space_df)
    |     ^^^^^^^^^^^^^^^ N806
170 |     # generate orginal representation
171 |     Representation_org = Represenation_3D.Representation3D(
    |

geom3d\script_plot_inference_BA.py:171:5: N806 Variable `Representation_org` in function should be lowercase
    |
169 |     X_explored_frag = Representation.generate_repr(searched_space_df)
170 |     # generate orginal representation
171 |     Representation_org = Represenation_3D.Representation3D(
    |     ^^^^^^^^^^^^^^^^^^ N806
172 |         model_embedding,
173 |         df_total,
    |

geom3d\script_plot_inference_BA.py:178:5: N806 Variable `X_explored_org` in function should be lowercase
    |
176 |         device=config["device"],
177 |     )
178 |     X_explored_org = Representation_org.generate_repr(searched_space_df)
    |     ^^^^^^^^^^^^^^ N806
179 |     y_explored = torch.tensor(
180 |         y_true, dtype=torch.float32, device=config["device"]
    |

geom3d\script_plot_inference_BA.py:188:1: E402 Module level import not at top of file
    |
187 |   # plot train
188 | / from sklearn.metrics import (
189 | |     mean_absolute_error,
190 | |     mean_squared_error,
191 | |     r2_score,
192 | | )
    | |_^ E402
    |

geom3d\script_plot_inference_BA.py:195:5: D103 Missing docstring in public function
    |
195 | def plot_inference_test(y_explored, X_explored_frag, X_explored_org,
    |     ^^^^^^^^^^^^^^^^^^^ D103
196 |                         model_inferrence, ax):
197 |     y_true = y_explored.cpu().numpy()
    |

geom3d\script_plot_inference_BA.py:195:37: N803 Argument name `X_explored_frag` should be lowercase
    |
195 | def plot_inference_test(y_explored, X_explored_frag, X_explored_org,
    |                                     ^^^^^^^^^^^^^^^ N803
196 |                         model_inferrence, ax):
197 |     y_true = y_explored.cpu().numpy()
    |

geom3d\script_plot_inference_BA.py:195:54: N803 Argument name `X_explored_org` should be lowercase
    |
195 | def plot_inference_test(y_explored, X_explored_frag, X_explored_org,
    |                                                      ^^^^^^^^^^^^^^ N803
196 |                         model_inferrence, ax):
197 |     y_true = y_explored.cpu().numpy()
    |

geom3d\script_plot_inference_BA.py:198:5: N806 Variable `Y_pred` in function should be lowercase
    |
196 |                         model_inferrence, ax):
197 |     y_true = y_explored.cpu().numpy()
198 |     Y_pred = (
    |     ^^^^^^ N806
199 |         PredictTargetFromEmbedding(
200 |             X_explored_frag, model_inferecence=model_inferrence
    |

geom3d\script_plot_inference_BA.py:205:5: N806 Variable `Y_pred_org` in function should be lowercase
    |
203 |         .numpy()
204 |     )
205 |     Y_pred_org = (
    |     ^^^^^^^^^^ N806
206 |         PredictTargetFromEmbedding(
207 |             X_explored_org, model_inferecence=model_inferrence
    |

geom3d\script_plot_inference_BA.py:249:9: TRY300 Consider moving this statement to an `else` block
    |
247 |         ax.text(0.4, 0.1, f"learned MAE: {score:.2f}", transform=ax.transAxes)
248 |         score_list.append(score)
249 |         return score_list
    |         ^^^^^^^^^^^^^^^^^ TRY300
250 |     except ValueError:
251 |         return []
    |

geom3d\script_plot_inference_BA.py:254:1: E402 Module level import not at top of file
    |
254 | from botorch.models.gp_regression import SingleTaskGP
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
255 | from gpytorch import kernels
    |

geom3d\script_plot_inference_BA.py:255:1: E402 Module level import not at top of file
    |
254 | from botorch.models.gp_regression import SingleTaskGP
255 | from gpytorch import kernels
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
256 | 
257 | # from stk_search.tanimoto_kernel import TanimotoKernel
    |

geom3d\script_plot_inference_BA.py:257:1: ERA001 Found commented-out code
    |
255 | from gpytorch import kernels
256 | 
257 | # from stk_search.tanimoto_kernel import TanimotoKernel
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
258 | from gpytorch.distributions import MultivariateNormal
259 | from gpytorch.kernels import ScaleKernel
    |
    = help: Remove commented-out code

geom3d\script_plot_inference_BA.py:258:1: E402 Module level import not at top of file
    |
257 | # from stk_search.tanimoto_kernel import TanimotoKernel
258 | from gpytorch.distributions import MultivariateNormal
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
259 | from gpytorch.kernels import ScaleKernel
260 | from gpytorch.means import ConstantMean
    |

geom3d\script_plot_inference_BA.py:259:1: E402 Module level import not at top of file
    |
257 | # from stk_search.tanimoto_kernel import TanimotoKernel
258 | from gpytorch.distributions import MultivariateNormal
259 | from gpytorch.kernels import ScaleKernel
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
260 | from gpytorch.means import ConstantMean
261 | from stk_search.Search_algorithm.tanimoto_kernel import TanimotoKernel
    |

geom3d\script_plot_inference_BA.py:260:1: E402 Module level import not at top of file
    |
258 | from gpytorch.distributions import MultivariateNormal
259 | from gpytorch.kernels import ScaleKernel
260 | from gpytorch.means import ConstantMean
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
261 | from stk_search.Search_algorithm.tanimoto_kernel import TanimotoKernel
    |

geom3d\script_plot_inference_BA.py:261:1: E402 Module level import not at top of file
    |
259 | from gpytorch.kernels import ScaleKernel
260 | from gpytorch.means import ConstantMean
261 | from stk_search.Search_algorithm.tanimoto_kernel import TanimotoKernel
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
    |

geom3d\script_plot_inference_BA.py:265:7: D101 Missing docstring in public class
    |
264 | # We define our custom GP surrogate model using the Tanimoto kernel
265 | class TanimotoGP(SingleTaskGP):
    |       ^^^^^^^^^^ D101
266 |     def __init__(self, train_X, train_Y):
267 |         super().__init__(train_X, train_Y)
    |

geom3d\script_plot_inference_BA.py:266:9: D107 Missing docstring in `__init__`
    |
264 | # We define our custom GP surrogate model using the Tanimoto kernel
265 | class TanimotoGP(SingleTaskGP):
266 |     def __init__(self, train_X, train_Y):
    |         ^^^^^^^^ D107
267 |         super().__init__(train_X, train_Y)
268 |         self.mean_module = ConstantMean()
    |

geom3d\script_plot_inference_BA.py:266:24: N803 Argument name `train_X` should be lowercase
    |
264 | # We define our custom GP surrogate model using the Tanimoto kernel
265 | class TanimotoGP(SingleTaskGP):
266 |     def __init__(self, train_X, train_Y):
    |                        ^^^^^^^ N803
267 |         super().__init__(train_X, train_Y)
268 |         self.mean_module = ConstantMean()
    |

geom3d\script_plot_inference_BA.py:266:33: N803 Argument name `train_Y` should be lowercase
    |
264 | # We define our custom GP surrogate model using the Tanimoto kernel
265 | class TanimotoGP(SingleTaskGP):
266 |     def __init__(self, train_X, train_Y):
    |                                 ^^^^^^^ N803
267 |         super().__init__(train_X, train_Y)
268 |         self.mean_module = ConstantMean()
    |

geom3d\script_plot_inference_BA.py:272:9: D102 Missing docstring in public method
    |
270 |         self.to(train_X)  # make sure we're on the right device/dtype
271 | 
272 |     def forward(self, x):
    |         ^^^^^^^ D102
273 |         mean_x = self.mean_module(x)
274 |         covar_x = self.covar_module(x)
    |

geom3d\script_plot_inference_BA.py:278:7: D101 Missing docstring in public class
    |
278 | class MaternKernel(SingleTaskGP):
    |       ^^^^^^^^^^^^ D101
279 |     def __init__(self, train_X, train_Y):
280 |         super().__init__(train_X, train_Y)
    |

geom3d\script_plot_inference_BA.py:279:9: D107 Missing docstring in `__init__`
    |
278 | class MaternKernel(SingleTaskGP):
279 |     def __init__(self, train_X, train_Y):
    |         ^^^^^^^^ D107
280 |         super().__init__(train_X, train_Y)
281 |         self.mean_module = ConstantMean()
    |

geom3d\script_plot_inference_BA.py:279:24: N803 Argument name `train_X` should be lowercase
    |
278 | class MaternKernel(SingleTaskGP):
279 |     def __init__(self, train_X, train_Y):
    |                        ^^^^^^^ N803
280 |         super().__init__(train_X, train_Y)
281 |         self.mean_module = ConstantMean()
    |

geom3d\script_plot_inference_BA.py:279:33: N803 Argument name `train_Y` should be lowercase
    |
278 | class MaternKernel(SingleTaskGP):
279 |     def __init__(self, train_X, train_Y):
    |                                 ^^^^^^^ N803
280 |         super().__init__(train_X, train_Y)
281 |         self.mean_module = ConstantMean()
    |

geom3d\script_plot_inference_BA.py:287:9: D102 Missing docstring in public method
    |
285 |         self.to(train_X)  # make sure we're on the right device/dtype
286 | 
287 |     def change_kernel(self, kernel):
    |         ^^^^^^^^^^^^^ D102
288 |         self.covar_module = ScaleKernel(base_kernel=kernel)
    |

geom3d\script_plot_inference_BA.py:290:9: D102 Missing docstring in public method
    |
288 |         self.covar_module = ScaleKernel(base_kernel=kernel)
289 | 
290 |     def forward(self, x):
    |         ^^^^^^^ D102
291 |         mean_x = self.mean_module(x)
292 |         covar_x = self.covar_module(x)
    |

geom3d\script_plot_inference_BA.py:296:5: PLR0913 Too many arguments in function definition (9 > 5)
    |
296 | def plot_prediction(
    |     ^^^^^^^^^^^^^^^ PLR0913
297 |     y_pred,
298 |     y_test,
    |

geom3d\script_plot_inference_BA.py:296:5: D103 Missing docstring in public function
    |
296 | def plot_prediction(
    |     ^^^^^^^^^^^^^^^ D103
297 |     y_pred,
298 |     y_test,
    |

geom3d\script_plot_inference_BA.py:304:5: FBT002 Boolean default positional argument in function definition
    |
302 |     fig=None,
303 |     axs=None,
304 |     save_plot=False,
    |     ^^^^^^^^^ FBT002
305 |     plot_name="prediction.png",
306 | ):
    |

geom3d\script_plot_inference_BA.py:307:9: ANN202 Missing return type annotation for private function `plot_prediction`
    |
305 |     plot_name="prediction.png",
306 | ):
307 |     def plot_prediction(y_pred, y_test, axis, label):
    |         ^^^^^^^^^^^^^^^ ANN202
308 |         axis.scatter(
309 |             y_test.detach().numpy(),
    |
    = help: Add return type annotation

geom3d\script_plot_inference_BA.py:314:9: ERA001 Found commented-out code
    |
312 |             color="red",
313 |         )
314 |         # axis.plot(y_test, y_test, linestyle="--", color="black")
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
315 |         axis.set_xlabel("True values")
316 |         axis.set_ylabel("Predicted values")
    |
    = help: Remove commented-out code

geom3d\script_plot_inference_BA.py:384:16: F821 Undefined name `os`
    |
382 |     if save_plot:
383 |         dir_name = "data/figures/test_BO/"
384 |         if not os.path.exists(dir_name):
    |                ^^ F821
385 |             os.makedirs(dir_name)
386 |         fig.savefig(dir_name + plot_name)
    |

geom3d\script_plot_inference_BA.py:385:13: F821 Undefined name `os`
    |
383 |         dir_name = "data/figures/test_BO/"
384 |         if not os.path.exists(dir_name):
385 |             os.makedirs(dir_name)
    |             ^^ F821
386 |         fig.savefig(dir_name + plot_name)
387 |     return fig, axs
    |

geom3d\script_plot_inference_BA.py:390:5: N802 Function name `run_training_BO_torch` should be lowercase
    |
390 | def run_training_BO_torch(
    |     ^^^^^^^^^^^^^^^^^^^^^ N802
391 |     BO,
392 |     X_explored_train,
    |

geom3d\script_plot_inference_BA.py:390:5: PLR0913 Too many arguments in function definition (6 > 5)
    |
390 | def run_training_BO_torch(
    |     ^^^^^^^^^^^^^^^^^^^^^ PLR0913
391 |     BO,
392 |     X_explored_train,
    |

geom3d\script_plot_inference_BA.py:390:5: D103 Missing docstring in public function
    |
390 | def run_training_BO_torch(
    |     ^^^^^^^^^^^^^^^^^^^^^ D103
391 |     BO,
392 |     X_explored_train,
    |

geom3d\script_plot_inference_BA.py:391:5: N803 Argument name `BO` should be lowercase
    |
390 | def run_training_BO_torch(
391 |     BO,
    |     ^^ N803
392 |     X_explored_train,
393 |     y_explored_train,
    |

geom3d\script_plot_inference_BA.py:392:5: N803 Argument name `X_explored_train` should be lowercase
    |
390 | def run_training_BO_torch(
391 |     BO,
392 |     X_explored_train,
    |     ^^^^^^^^^^^^^^^^ N803
393 |     y_explored_train,
394 |     X_explored_test,
    |

geom3d\script_plot_inference_BA.py:394:5: N803 Argument name `X_explored_test` should be lowercase
    |
392 |     X_explored_train,
393 |     y_explored_train,
394 |     X_explored_test,
    |     ^^^^^^^^^^^^^^^ N803
395 |     y_explored_test,
396 |     kernel=MaternKernel,
    |

geom3d\script_plot_inference_BA.py:398:9: ANN202 Missing return type annotation for private function `normalise_output`
    |
396 |     kernel=MaternKernel,
397 | ):
398 |     def normalise_output(y):
    |         ^^^^^^^^^^^^^^^^ ANN202
399 |         y_mean = y.mean()
400 |         y_std = y.std()
    |
    = help: Add return type annotation

geom3d\script_plot_inference_BA.py:404:9: ANN202 Missing return type annotation for private function `unnorm_output`
    |
402 |         return y, y_mean, y_std
403 | 
404 |     def unnorm_output(y, y_mean, y_std):
    |         ^^^^^^^^^^^^^ ANN202
405 |         return y * y_std + y_mean
    |
    = help: Add return type annotation

geom3d\script_plot_inference_BA.py:408:5: N806 Variable `X_train` in function should be lowercase
    |
407 |     BO.kernel = kernel
408 |     X_train = X_explored_train.cpu().type(torch.float64)
    |     ^^^^^^^ N806
409 |     y_train = y_explored_train.cpu().type(torch.float64).reshape(-1, 1)
410 |     X_test = X_explored_test.cpu().type(torch.float64)
    |

geom3d\script_plot_inference_BA.py:410:5: N806 Variable `X_test` in function should be lowercase
    |
408 |     X_train = X_explored_train.cpu().type(torch.float64)
409 |     y_train = y_explored_train.cpu().type(torch.float64).reshape(-1, 1)
410 |     X_test = X_explored_test.cpu().type(torch.float64)
    |     ^^^^^^ N806
411 |     y_test = y_explored_test.cpu().type(torch.float64).reshape(-1, 1)
412 |     y_train, y_mean, y_std = normalise_output(y_train)
    |

geom3d\script_plot_inference_BA.py:441:5: ERA001 Found commented-out code
    |
439 |     y_pred_train = unnorm_output(y_pred_train, y_mean, y_std)
440 |     y_var = y_var*y_std
441 |     # y_test = unnorm_output(y_test, y_mean, y_std)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
442 |     y_train = unnorm_output(y_train, y_mean, y_std)
443 |     fig, axs = plot_prediction(
    |
    = help: Remove commented-out code

geom3d\test_train.py:1:1: INP001 File `geom3d\test_train.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\test_train.py:1:1: D205 1 blank line required between summary line and description
  |
1 | / """script to train the SchNet model on the STK dataset
2 | | created by Mohammed Azzouzi
3 | | date: 2023-11-14.
4 | | """
  | |___^ D205
5 |   import os
6 |   from pathlib import Path
  |
  = help: Insert single blank line

geom3d\test_train.py:13:8: N812 Lowercase `functional` imported as non-lowercase `Functional`
   |
11 | import stk
12 | import torch
13 | import torch.nn.functional as Functional
   |        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ N812
14 | from lightning.pytorch.callbacks import ModelCheckpoint
15 | from lightning.pytorch.loggers import WandbLogger
   |

geom3d\test_train.py:25:5: D103 Missing docstring in public function
   |
25 | def main(config_dir):
   |     ^^^^ D103
26 |     config = read_config(config_dir)
27 |     np.random.seed(config["seed"])
   |

geom3d\test_train.py:27:5: NPY002 Replace legacy `np.random.seed` call with `np.random.Generator`
   |
25 | def main(config_dir):
26 |     config = read_config(config_dir)
27 |     np.random.seed(config["seed"])
   |     ^^^^^^^^^^^^^^ NPY002
28 |     torch.cuda.manual_seed_all(config["seed"])
29 |     config["device"] = (
   |

geom3d\test_train.py:53:8: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   |
51 |     # model
52 |     #check if chkpt exists
53 |     if os.path.exists(config["model_embedding_chkpt"]):
   |        ^^^^^^^^^^^^^^ PTH110
54 |         pymodel_SCHNET = Pymodel.load_from_checkpoint(config["model_embedding_chkpt"])
55 |     else:
   |

geom3d\test_train.py:54:9: N806 Variable `pymodel_SCHNET` in function should be lowercase
   |
52 |     #check if chkpt exists
53 |     if os.path.exists(config["model_embedding_chkpt"]):
54 |         pymodel_SCHNET = Pymodel.load_from_checkpoint(config["model_embedding_chkpt"])
   |         ^^^^^^^^^^^^^^ N806
55 |     else:
56 |         pymodel_SCHNET = Pymodel(model, graph_pred_linear)
   |

geom3d\test_train.py:56:9: N806 Variable `pymodel_SCHNET` in function should be lowercase
   |
54 |         pymodel_SCHNET = Pymodel.load_from_checkpoint(config["model_embedding_chkpt"])
55 |     else:
56 |         pymodel_SCHNET = Pymodel(model, graph_pred_linear)
   |         ^^^^^^^^^^^^^^ N806
57 |     wandb_logger = WandbLogger(log_model="all", project="Geom3D", name=config["name"])
58 |     wandb_logger.log_hyperparams(config)
   |

geom3d\test_train.py:85:5: D103 Missing docstring in public function
   |
85 | def load_data(config):
   |     ^^^^^^^^^ D103
86 | 
87 |     if config["load_dataset"]:
   |

geom3d\test_train.py:88:12: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   |
87 |     if config["load_dataset"]:
88 |         if os.path.exists(config["dataset_path"]):
   |            ^^^^^^^^^^^^^^ PTH110
89 |             return torch.load(config["dataset_path"])
90 |         else:
   |

geom3d\test_train.py:90:9: RET505 Unnecessary `else` after `return` statement
   |
88 |         if os.path.exists(config["dataset_path"]):
89 |             return torch.load(config["dataset_path"])
90 |         else:
   |         ^^^^ RET505
91 |             pass
92 |     df_path = Path(
   |
   = help: Remove unnecessary `else`

geom3d\test_train.py:117:13: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
    |
115 |     if config["save_dataset"]:
116 |             name = config["name"] + "_frag_" + str(config["number_of_fragement"])
117 |             os.makedirs(name, exist_ok=True)
    |             ^^^^^^^^^^^ PTH103
118 |             torch.save(dataset, name+"/dataset.pt")
119 |     return dataset
    |

geom3d\test_train.py:122:7: D101 Missing docstring in public class
    |
122 | class Pymodel(pl.LightningModule):
    |       ^^^^^^^ D101
123 |     def __init__(self, model, graph_pred_linear):
124 |         super().__init__()
    |

geom3d\test_train.py:123:9: D107 Missing docstring in `__init__`
    |
122 | class Pymodel(pl.LightningModule):
123 |     def __init__(self, model, graph_pred_linear):
    |         ^^^^^^^^ D107
124 |         super().__init__()
125 |         self.save_hyperparameters(ignore=["graph_pred_linear", "model"])
    |

geom3d\test_train.py:129:9: D102 Missing docstring in public method
    |
127 |         self.graph_pred_linear = graph_pred_linear
128 | 
129 |     def training_step(self, batch, batch_idx):
    |         ^^^^^^^^^^^^^ D102
130 |         # training_step defines the train loop.
131 |         loss = self._get_preds_loss_accuracy(batch)
    |

geom3d\test_train.py:129:36: ARG002 Unused method argument: `batch_idx`
    |
127 |         self.graph_pred_linear = graph_pred_linear
128 | 
129 |     def training_step(self, batch, batch_idx):
    |                                    ^^^^^^^^^ ARG002
130 |         # training_step defines the train loop.
131 |         loss = self._get_preds_loss_accuracy(batch)
    |

geom3d\test_train.py:136:38: ARG002 Unused method argument: `batch_idx`
    |
134 |         return loss
135 | 
136 |     def validation_step(self, batch, batch_idx):
    |                                      ^^^^^^^^^ ARG002
137 |         """Used for logging metrics."""
138 |         loss = self._get_preds_loss_accuracy(batch)
    |

geom3d\test_train.py:137:9: D401 First line of docstring should be in imperative mood: "Used for logging metrics."
    |
136 |     def validation_step(self, batch, batch_idx):
137 |         """Used for logging metrics."""
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
138 |         loss = self._get_preds_loss_accuracy(batch)
    |

geom3d\test_train.py:144:9: ANN202 Missing return type annotation for private function `_get_preds_loss_accuracy`
    |
142 |         return loss
143 | 
144 |     def _get_preds_loss_accuracy(self, batch):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^ ANN202
145 |         """Convenience function since train/valid/test steps are similar."""
146 |         z = self.molecule_3D_repr(batch.x, batch.positions, batch.batch)
    |
    = help: Add return type annotation

geom3d\test_train.py:145:9: D401 First line of docstring should be in imperative mood: "Convenience function since train/valid/test steps are similar."
    |
144 |     def _get_preds_loss_accuracy(self, batch):
145 |         """Convenience function since train/valid/test steps are similar."""
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
146 |         z = self.molecule_3D_repr(batch.x, batch.positions, batch.batch)
147 |         z = self.graph_pred_linear(z)
    |

geom3d\test_train.py:150:9: D102 Missing docstring in public method
    |
148 |         return Functional.mse_loss(z, batch.y.unsqueeze(1))
149 | 
150 |     def configure_optimizers(self):
    |         ^^^^^^^^^^^^^^^^^^^^ D102
151 |         return torch.optim.Adam(self.parameters(), lr=5e-4)
    |

geom3d\test_train.py:153:9: D102 Missing docstring in public method
    |
151 |         return torch.optim.Adam(self.parameters(), lr=5e-4)
152 | 
153 |     def forward(self, batch):
    |         ^^^^^^^ D102
154 |         z = self.molecule_3D_repr(batch.x, batch.positions, batch.batch)
155 |         return self.graph_pred_linear(z)
    |

geom3d\test_train.py:158:5: D103 Missing docstring in public function
    |
158 | def load_3d_rpr(model, output_model_path):
    |     ^^^^^^^^^^^ D103
159 |     saved_model_dict = torch.load(output_model_path)
160 |     model.load_state_dict(saved_model_dict["model"])
    |

geom3d\test_train.py:164:5: D103 Missing docstring in public function
    |
162 |     return model
163 | 
164 | def load_molecule(InChIKey, target, db):
    |     ^^^^^^^^^^^^^ D103
165 |     polymer = db.get({"InChIKey": InChIKey})
166 |     dat_list = list(polymer.get_atomic_positions())
    |

geom3d\test_train.py:164:19: N803 Argument name `InChIKey` should be lowercase
    |
162 |     return model
163 | 
164 | def load_molecule(InChIKey, target, db):
    |                   ^^^^^^^^ N803
165 |     polymer = db.get({"InChIKey": InChIKey})
166 |     dat_list = list(polymer.get_atomic_positions())
    |

geom3d\test_train.py:180:5: D103 Missing docstring in public function
    |
180 | def generate_dataset(df_total, df_precursors, db, number_of_molecules=1000):
    |     ^^^^^^^^^^^^^^^^ D103
181 |     molecule_index = np.random.choice(
182 |         len(df_total), number_of_molecules, replace=False
    |

geom3d\test_train.py:180:32: ARG001 Unused function argument: `df_precursors`
    |
180 | def generate_dataset(df_total, df_precursors, db, number_of_molecules=1000):
    |                                ^^^^^^^^^^^^^ ARG001
181 |     molecule_index = np.random.choice(
182 |         len(df_total), number_of_molecules, replace=False
    |

geom3d\test_train.py:181:22: NPY002 Replace legacy `np.random.choice` call with `np.random.Generator`
    |
180 | def generate_dataset(df_total, df_precursors, db, number_of_molecules=1000):
181 |     molecule_index = np.random.choice(
    |                      ^^^^^^^^^^^^^^^^ NPY002
182 |         len(df_total), number_of_molecules, replace=False
183 |     )
    |

geom3d\test_train.py:194:5: D103 Missing docstring in public function
    |
194 | def train_val_test_split(dataset, config, smiles_list=None):
    |     ^^^^^^^^^^^^^^^^^^^^ D103
195 |     seed = config["seed"]
196 |     num_mols = len(dataset)
    |

geom3d\test_train.py:197:5: NPY002 Replace legacy `np.random.seed` call with `np.random.Generator`
    |
195 |     seed = config["seed"]
196 |     num_mols = len(dataset)
197 |     np.random.seed(seed)
    |     ^^^^^^^^^^^^^^ NPY002
198 |     all_idx = np.random.permutation(num_mols)
    |

geom3d\test_train.py:198:15: NPY002 Replace legacy `np.random.permutation` call with `np.random.Generator`
    |
196 |     num_mols = len(dataset)
197 |     np.random.seed(seed)
198 |     all_idx = np.random.permutation(num_mols)
    |               ^^^^^^^^^^^^^^^^^^^^^ NPY002
199 | 
200 |     Nmols = num_mols
    |

geom3d\test_train.py:200:5: N806 Variable `Nmols` in function should be lowercase
    |
198 |     all_idx = np.random.permutation(num_mols)
199 | 
200 |     Nmols = num_mols
    |     ^^^^^ N806
201 |     Ntrain = int(num_mols * config["train_ratio"])
202 |     Nvalid = int(num_mols * config["valid_ratio"])
    |

geom3d\test_train.py:201:5: N806 Variable `Ntrain` in function should be lowercase
    |
200 |     Nmols = num_mols
201 |     Ntrain = int(num_mols * config["train_ratio"])
    |     ^^^^^^ N806
202 |     Nvalid = int(num_mols * config["valid_ratio"])
203 |     Nmols - (Ntrain + Nvalid)
    |

geom3d\test_train.py:202:5: N806 Variable `Nvalid` in function should be lowercase
    |
200 |     Nmols = num_mols
201 |     Ntrain = int(num_mols * config["train_ratio"])
202 |     Nvalid = int(num_mols * config["valid_ratio"])
    |     ^^^^^^ N806
203 |     Nmols - (Ntrain + Nvalid)
    |

geom3d\test_train.py:209:5: ERA001 Found commented-out code
    |
207 |     test_idx = all_idx[Ntrain + Nvalid :]
208 | 
209 |     # np.savez("customized_01", train_idx=train_idx, valid_idx=valid_idx, test_idx=test_idx)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
210 | 
211 |     assert len(set(train_idx).intersection(set(valid_idx))) == 0
    |
    = help: Remove commented-out code

geom3d\test_train.py:211:5: S101 Use of `assert` detected
    |
209 |     # np.savez("customized_01", train_idx=train_idx, valid_idx=valid_idx, test_idx=test_idx)
210 | 
211 |     assert len(set(train_idx).intersection(set(valid_idx))) == 0
    |     ^^^^^^ S101
212 |     assert len(set(valid_idx).intersection(set(test_idx))) == 0
213 |     assert len(train_idx) + len(valid_idx) + len(test_idx) == num_mols
    |

geom3d\test_train.py:212:5: S101 Use of `assert` detected
    |
211 |     assert len(set(train_idx).intersection(set(valid_idx))) == 0
212 |     assert len(set(valid_idx).intersection(set(test_idx))) == 0
    |     ^^^^^^ S101
213 |     assert len(train_idx) + len(valid_idx) + len(test_idx) == num_mols
214 |     train_dataset = [dataset[x] for x in train_idx]
    |

geom3d\test_train.py:213:5: S101 Use of `assert` detected
    |
211 |     assert len(set(train_idx).intersection(set(valid_idx))) == 0
212 |     assert len(set(valid_idx).intersection(set(test_idx))) == 0
213 |     assert len(train_idx) + len(valid_idx) + len(test_idx) == num_mols
    |     ^^^^^^ S101
214 |     train_dataset = [dataset[x] for x in train_idx]
215 |     valid_dataset = [dataset[x] for x in valid_idx]
    |

geom3d\test_train.py:238:5: RET505 Unnecessary `else` after `return` statement
    |
236 |     if not smiles_list:
237 |         return train_loader, val_loader, test_loader
238 |     else:
    |     ^^^^ RET505
239 |         train_smiles = [smiles_list[i] for i in train_idx]
240 |         valid_smiles = [smiles_list[i] for i in valid_idx]
    |
    = help: Remove unnecessary `else`

geom3d\test_train.py:252:12: PTH109 `os.getcwd()` should be replaced by `Path.cwd()`
    |
250 | if __name__ == "__main__":
251 |     from argparse import ArgumentParser
252 |     root = os.getcwd()
    |            ^^^^^^^^^ PTH109
253 |     argparser = ArgumentParser()
254 |     argparser.add_argument(
    |

geom3d\train_models.py:1:1: INP001 File `geom3d\train_models.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\train_models.py:1:1: D205 1 blank line required between summary line and description
  |
1 | / """script to train the SchNet model on the STK dataset
2 | | created by Mohammed Azzouzi
3 | | date: 2023-11-14.
4 | | """
  | |___^ D205
5 |   
6 |   import contextlib
  |
  = help: Insert single blank line

geom3d\train_models.py:22:5: D417 Missing argument description in the docstring for `load_and_run_model_training`: `lightning_model`
   |
22 | def load_and_run_model_training(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^ D417
23 |     config, train_loader, val_loader, lightning_model=Pymodel
24 | ):
   |

geom3d\train_models.py:36:16: PTH109 `os.getcwd()` should be replaced by `Path.cwd()`
   |
34 |     start_time = time.time()  # Record the start time
35 |     model, graph_pred_linear = pl_model.model_setup(config)
36 |     init_dir = os.getcwd()
   |                ^^^^^^^^^ PTH109
37 |     # if config["model_path"]:
38 |     #   model = load_3d_rpr(model, config["model_path"])
   |

geom3d\train_models.py:38:5: ERA001 Found commented-out code
   |
36 |     init_dir = os.getcwd()
37 |     # if config["model_path"]:
38 |     #   model = load_3d_rpr(model, config["model_path"])
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
39 |     os.chdir(config["running_dir"])
40 |     # wandb.login()
   |
   = help: Remove commented-out code

geom3d\train_models.py:40:5: ERA001 Found commented-out code
   |
38 |     #   model = load_3d_rpr(model, config["model_path"])
39 |     os.chdir(config["running_dir"])
40 |     # wandb.login()
   |     ^^^^^^^^^^^^^^^ ERA001
41 |     # wandb.init(settings=wandb.Settings(start_method="fork"))
42 |     # model
   |
   = help: Remove commented-out code

geom3d\train_models.py:41:5: ERA001 Found commented-out code
   |
39 |     os.chdir(config["running_dir"])
40 |     # wandb.login()
41 |     # wandb.init(settings=wandb.Settings(start_method="fork"))
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
42 |     # model
43 |     # check if chkpt exists
   |
   = help: Remove commented-out code

geom3d\train_models.py:45:8: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   |
43 |     # check if chkpt exists
44 |     pymodel = lightning_model(model, graph_pred_linear, config)
45 |     if os.path.exists(config["model_embedding_chkpt"]):
   |        ^^^^^^^^^^^^^^ PTH110
46 |         chkpt_path = config["model_embedding_chkpt"]
47 |         checkpoint = torch.load(chkpt_path, map_location=config["device"])
   |

geom3d\train_models.py:62:17: PTH109 `os.getcwd()` should be replaced by `Path.cwd()`
   |
60 |     # train model
61 |     checkpoint_callback = ModelCheckpoint(
62 |         dirpath=os.getcwd(),
   |                 ^^^^^^^^^ PTH109
63 |         filename="{epoch}-{val_loss:.2f}-{other_metric:.2f}",
64 |         monitor="val_loss",
   |

geom3d\train_models.py:108:13: PTH207 Replace `glob` with `Path.glob` or `Path.rglob`
    |
106 |     """
107 |     config = read_config(config_dir, model_name="SchNet")
108 |     files = glob.glob(config_dir + "/*.ckpt")
    |             ^^^^^^^^^ PTH207
109 |     min_val_loss = 1000
110 |     for file in files:
    |

geom3d\transformer_utils.py:1:1: INP001 File `geom3d\transformer_utils.py` is part of an implicit namespace package. Add an `__init__.py`.
geom3d\transformer_utils.py:8:8: N812 Lowercase `lightning` imported as non-lowercase `L`
   |
 7 | # PyTorch Lightning
 8 | import lightning as L
   |        ^^^^^^^^^^^^^^ N812
 9 | import numpy as np
10 | import torch
   |

geom3d\transformer_utils.py:11:8: N812 Lowercase `functional` imported as non-lowercase `F`
   |
 9 | import numpy as np
10 | import torch
11 | import torch.nn.functional as F
   |        ^^^^^^^^^^^^^^^^^^^^^^^^ N812
12 | from torch import nn, optim
   |

geom3d\transformer_utils.py:15:7: D101 Missing docstring in public class
   |
15 | class EncoderBlock(nn.Module):
   |       ^^^^^^^^^^^^ D101
16 |     def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0):
17 |         """EncoderBlock.
   |

geom3d\transformer_utils.py:45:9: D102 Missing docstring in public method
   |
43 |         self.dropout = nn.Dropout(dropout)
44 | 
45 |     def forward(self, x, mask=None):
   |         ^^^^^^^ D102
46 |         # Attention part
47 |         attn_out = self.self_attn(x, mask=mask)
   |

geom3d\transformer_utils.py:58:7: D101 Missing docstring in public class
   |
58 | class CosineWarmupScheduler(optim.lr_scheduler._LRScheduler):
   |       ^^^^^^^^^^^^^^^^^^^^^ D101
59 |     def __init__(self, optimizer, warmup, max_iters):
60 |         self.warmup = warmup
   |

geom3d\transformer_utils.py:58:29: SLF001 Private member accessed: `_LRScheduler`
   |
58 | class CosineWarmupScheduler(optim.lr_scheduler._LRScheduler):
   |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ SLF001
59 |     def __init__(self, optimizer, warmup, max_iters):
60 |         self.warmup = warmup
   |

geom3d\transformer_utils.py:59:9: D107 Missing docstring in `__init__`
   |
58 | class CosineWarmupScheduler(optim.lr_scheduler._LRScheduler):
59 |     def __init__(self, optimizer, warmup, max_iters):
   |         ^^^^^^^^ D107
60 |         self.warmup = warmup
61 |         self.max_num_iters = max_iters
   |

geom3d\transformer_utils.py:64:9: D102 Missing docstring in public method
   |
62 |         super().__init__(optimizer)
63 | 
64 |     def get_lr(self):
   |         ^^^^^^ D102
65 |         lr_factor = self.get_lr_factor(epoch=self.last_epoch)
66 |         return [base_lr * lr_factor for base_lr in self.base_lrs]
   |

geom3d\transformer_utils.py:68:9: D102 Missing docstring in public method
   |
66 |         return [base_lr * lr_factor for base_lr in self.base_lrs]
67 | 
68 |     def get_lr_factor(self, epoch):
   |         ^^^^^^^^^^^^^ D102
69 |         lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_num_iters))
70 |         if epoch <= self.warmup:
   |

geom3d\transformer_utils.py:75:7: D101 Missing docstring in public class
   |
75 | class TransformerEncoder(nn.Module):
   |       ^^^^^^^^^^^^^^^^^^ D101
76 |     def __init__(self, num_layers, **block_args):
77 |         super().__init__()
   |

geom3d\transformer_utils.py:76:9: D107 Missing docstring in `__init__`
   |
75 | class TransformerEncoder(nn.Module):
76 |     def __init__(self, num_layers, **block_args):
   |         ^^^^^^^^ D107
77 |         super().__init__()
78 |         self.layers = nn.ModuleList(
   |

geom3d\transformer_utils.py:76:36: ANN003 Missing type annotation for `**block_args`
   |
75 | class TransformerEncoder(nn.Module):
76 |     def __init__(self, num_layers, **block_args):
   |                                    ^^^^^^^^^^^^ ANN003
77 |         super().__init__()
78 |         self.layers = nn.ModuleList(
   |

geom3d\transformer_utils.py:82:9: D102 Missing docstring in public method
   |
80 |         )
81 | 
82 |     def forward(self, x, mask=None):
   |         ^^^^^^^ D102
83 |         for layer in self.layers:
84 |             x = layer(x, mask=mask)
   |

geom3d\transformer_utils.py:87:9: D102 Missing docstring in public method
   |
85 |         return x
86 | 
87 |     def get_attention_maps(self, x, mask=None):
   |         ^^^^^^^^^^^^^^^^^^ D102
88 |         attention_maps = []
89 |         for layer in self.layers:
   |

geom3d\transformer_utils.py:96:7: D101 Missing docstring in public class
   |
96 | class PositionalEncoding(nn.Module):
   |       ^^^^^^^^^^^^^^^^^^ D101
97 |     def __init__(self, d_model, max_len=5000):
98 |         """Positional Encoding.
   |

geom3d\transformer_utils.py:124:9: D102 Missing docstring in public method
    |
122 |         self.register_buffer("pe", pe, persistent=False)
123 | 
124 |     def forward(self, x):
    |         ^^^^^^^ D102
125 |         return x + self.pe[:, : x.size(1)]
    |

geom3d\transformer_utils.py:128:7: D101 Missing docstring in public class
    |
128 | class MultiheadAttention(nn.Module):
    |       ^^^^^^^^^^^^^^^^^^ D101
129 |     def __init__(self, input_dim, embed_dim, num_heads):
130 |         super().__init__()
    |

geom3d\transformer_utils.py:129:9: D107 Missing docstring in `__init__`
    |
128 | class MultiheadAttention(nn.Module):
129 |     def __init__(self, input_dim, embed_dim, num_heads):
    |         ^^^^^^^^ D107
130 |         super().__init__()
131 |         assert (
    |

geom3d\transformer_utils.py:131:9: S101 Use of `assert` detected
    |
129 |     def __init__(self, input_dim, embed_dim, num_heads):
130 |         super().__init__()
131 |         assert (
    |         ^^^^^^ S101
132 |             embed_dim % num_heads == 0
133 |         ), "Embedding dimension must be 0 modulo number of heads."
    |

geom3d\transformer_utils.py:153:9: D102 Missing docstring in public method
    |
151 |         self.o_proj.bias.data.fill_(0)
152 | 
153 |     def forward(self, x, mask=None, return_attention=False):
    |         ^^^^^^^ D102
154 |         batch_size, seq_length, embed_dim = x.size()
155 |         qkv = self.qkv_proj(x)
    |

geom3d\transformer_utils.py:153:37: FBT002 Boolean default positional argument in function definition
    |
151 |         self.o_proj.bias.data.fill_(0)
152 | 
153 |     def forward(self, x, mask=None, return_attention=False):
    |                                     ^^^^^^^^^^^^^^^^ FBT002
154 |         batch_size, seq_length, embed_dim = x.size()
155 |         qkv = self.qkv_proj(x)
    |

geom3d\transformer_utils.py:172:9: RET505 Unnecessary `else` after `return` statement
    |
170 |         if return_attention:
171 |             return o, attention
172 |         else:
    |         ^^^^ RET505
173 |             return o
    |
    = help: Remove unnecessary `else`

geom3d\transformer_utils.py:176:7: D101 Missing docstring in public class
    |
176 | class TransformerPredictor(L.LightningModule):
    |       ^^^^^^^^^^^^^^^^^^^^ D101
177 |     def __init__(
178 |         self,
    |

geom3d\transformer_utils.py:177:9: PLR0913 Too many arguments in function definition (10 > 5)
    |
176 | class TransformerPredictor(L.LightningModule):
177 |     def __init__(
    |         ^^^^^^^^ PLR0913
178 |         self,
179 |         input_dim,
    |

geom3d\transformer_utils.py:179:9: ARG002 Unused method argument: `input_dim`
    |
177 |     def __init__(
178 |         self,
179 |         input_dim,
    |         ^^^^^^^^^ ARG002
180 |         model_dim,
181 |         num_classes,
    |

geom3d\transformer_utils.py:180:9: ARG002 Unused method argument: `model_dim`
    |
178 |         self,
179 |         input_dim,
180 |         model_dim,
    |         ^^^^^^^^^ ARG002
181 |         num_classes,
182 |         num_heads,
    |

geom3d\transformer_utils.py:181:9: ARG002 Unused method argument: `num_classes`
    |
179 |         input_dim,
180 |         model_dim,
181 |         num_classes,
    |         ^^^^^^^^^^^ ARG002
182 |         num_heads,
183 |         num_layers,
    |

geom3d\transformer_utils.py:182:9: ARG002 Unused method argument: `num_heads`
    |
180 |         model_dim,
181 |         num_classes,
182 |         num_heads,
    |         ^^^^^^^^^ ARG002
183 |         num_layers,
184 |         lr,
    |

geom3d\transformer_utils.py:183:9: ARG002 Unused method argument: `num_layers`
    |
181 |         num_classes,
182 |         num_heads,
183 |         num_layers,
    |         ^^^^^^^^^^ ARG002
184 |         lr,
185 |         warmup,
    |

geom3d\transformer_utils.py:184:9: ARG002 Unused method argument: `lr`
    |
182 |         num_heads,
183 |         num_layers,
184 |         lr,
    |         ^^ ARG002
185 |         warmup,
186 |         max_iters,
    |

geom3d\transformer_utils.py:185:9: ARG002 Unused method argument: `warmup`
    |
183 |         num_layers,
184 |         lr,
185 |         warmup,
    |         ^^^^^^ ARG002
186 |         max_iters,
187 |         dropout=0.0,
    |

geom3d\transformer_utils.py:186:9: ARG002 Unused method argument: `max_iters`
    |
184 |         lr,
185 |         warmup,
186 |         max_iters,
    |         ^^^^^^^^^ ARG002
187 |         dropout=0.0,
188 |         input_dropout=0.0,
    |

geom3d\transformer_utils.py:187:9: ARG002 Unused method argument: `dropout`
    |
185 |         warmup,
186 |         max_iters,
187 |         dropout=0.0,
    |         ^^^^^^^ ARG002
188 |         input_dropout=0.0,
189 |     ):
    |

geom3d\transformer_utils.py:188:9: ARG002 Unused method argument: `input_dropout`
    |
186 |         max_iters,
187 |         dropout=0.0,
188 |         input_dropout=0.0,
    |         ^^^^^^^^^^^^^ ARG002
189 |     ):
190 |         """TransformerPredictor.
    |

geom3d\transformer_utils.py:238:37: FBT002 Boolean default positional argument in function definition
    |
236 |         self.model_encoder = None
237 | 
238 |     def forward(self, x, mask=None, add_positional_encoding=True):
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^ FBT002
239 |         """Args:
240 |         ----
    |

geom3d\transformer_utils.py:239:9: D205 1 blank line required between summary line and description
    |
238 |       def forward(self, x, mask=None, add_positional_encoding=True):
239 |           """Args:
    |  _________^
240 | |         ----
241 | |             x: Input features of shape [Batch, SeqLen, input_dim]
242 | |             mask: Mask to apply on the attention outputs (optional)
243 | |             add_positional_encoding: If True, we add the positional encoding to the input.
244 | |                                       Might not be desired for some tasks.
245 | | 
246 | |         """
    | |___________^ D205
247 |           x = self.input_net(x)
248 |           if add_positional_encoding:
    |
    = help: Insert single blank line

geom3d\transformer_utils.py:239:9: D400 First line should end with a period
    |
238 |       def forward(self, x, mask=None, add_positional_encoding=True):
239 |           """Args:
    |  _________^
240 | |         ----
241 | |             x: Input features of shape [Batch, SeqLen, input_dim]
242 | |             mask: Mask to apply on the attention outputs (optional)
243 | |             add_positional_encoding: If True, we add the positional encoding to the input.
244 | |                                       Might not be desired for some tasks.
245 | | 
246 | |         """
    | |___________^ D400
247 |           x = self.input_net(x)
248 |           if add_positional_encoding:
    |
    = help: Add period

geom3d\transformer_utils.py:239:9: D415 First line should end with a period, question mark, or exclamation point
    |
238 |       def forward(self, x, mask=None, add_positional_encoding=True):
239 |           """Args:
    |  _________^
240 | |         ----
241 | |             x: Input features of shape [Batch, SeqLen, input_dim]
242 | |             mask: Mask to apply on the attention outputs (optional)
243 | |             add_positional_encoding: If True, we add the positional encoding to the input.
244 | |                                       Might not be desired for some tasks.
245 | | 
246 | |         """
    | |___________^ D415
247 |           x = self.input_net(x)
248 |           if add_positional_encoding:
    |
    = help: Add closing punctuation

geom3d\transformer_utils.py:254:48: FBT002 Boolean default positional argument in function definition
    |
253 |     @torch.no_grad()
254 |     def get_attention_maps(self, x, mask=None, add_positional_encoding=True):
    |                                                ^^^^^^^^^^^^^^^^^^^^^^^ FBT002
255 |         """Function for extracting the attention matrices of the whole Transformer for a single batch.
    |

geom3d\transformer_utils.py:255:9: D401 First line of docstring should be in imperative mood: "Function for extracting the attention matrices of the whole Transformer for a single batch."
    |
253 |       @torch.no_grad()
254 |       def get_attention_maps(self, x, mask=None, add_positional_encoding=True):
255 |           """Function for extracting the attention matrices of the whole Transformer for a single batch.
    |  _________^
256 | | 
257 | |         Input arguments same as the forward pass.
258 | |         """
    | |___________^ D401
259 |           x = self.input_net(x)
260 |           if add_positional_encoding:
    |

geom3d\transformer_utils.py:264:9: D102 Missing docstring in public method
    |
262 |         return self.transformer.get_attention_maps(x, mask=mask)
263 | 
264 |     def configure_optimizers(self):
    |         ^^^^^^^^^^^^^^^^^^^^ D102
265 |         optimizer = optim.Adam(self.parameters(), lr=self.hparams.lr)
    |

geom3d\transformer_utils.py:275:9: D102 Missing docstring in public method
    |
273 |         return optimizer
274 | 
275 |     def optimizer_step(self, *args, **kwargs):
    |         ^^^^^^^^^^^^^^ D102
276 |         super().optimizer_step(*args, **kwargs)
277 |         self.lr_scheduler.step()  # Step per iteration
    |

geom3d\transformer_utils.py:275:30: ANN002 Missing type annotation for `*args`
    |
273 |         return optimizer
274 | 
275 |     def optimizer_step(self, *args, **kwargs):
    |                              ^^^^^ ANN002
276 |         super().optimizer_step(*args, **kwargs)
277 |         self.lr_scheduler.step()  # Step per iteration
    |

geom3d\transformer_utils.py:275:37: ANN003 Missing type annotation for `**kwargs`
    |
273 |         return optimizer
274 | 
275 |     def optimizer_step(self, *args, **kwargs):
    |                                     ^^^^^^^^ ANN003
276 |         super().optimizer_step(*args, **kwargs)
277 |         self.lr_scheduler.step()  # Step per iteration
    |

geom3d\transformer_utils.py:279:9: D102 Missing docstring in public method
    |
277 |         self.lr_scheduler.step()  # Step per iteration
278 | 
279 |     def training_step(self, batch, batch_idx):
    |         ^^^^^^^^^^^^^ D102
280 |         raise NotImplementedError
    |

geom3d\transformer_utils.py:282:9: D102 Missing docstring in public method
    |
280 |         raise NotImplementedError
281 | 
282 |     def validation_step(self, batch, batch_idx):
    |         ^^^^^^^^^^^^^^^ D102
283 |         raise NotImplementedError
    |

geom3d\transformer_utils.py:285:9: D102 Missing docstring in public method
    |
283 |         raise NotImplementedError
284 | 
285 |     def test_step(self, batch, batch_idx):
    |         ^^^^^^^^^ D102
286 |         raise NotImplementedError
    |

geom3d\transformer_utils.py:289:5: D103 Missing docstring in public function
    |
289 | def scaled_dot_product(q, k, v, mask=None):
    |     ^^^^^^^^^^^^^^^^^^ D103
290 |     d_k = q.size()[-1]
291 |     attn_logits = torch.matmul(q, k.transpose(-2, -1))
    |

utils\Chemiscope_functions.py:1:1: INP001 File `utils\Chemiscope_functions.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\Chemiscope_functions.py:1:1: D100 Missing docstring in public module
utils\Chemiscope_functions.py:14:5: N802 Function name `generate_Slatm` should be lowercase
   |
14 | def generate_Slatm(df_1, dirname, name, database_name="stk_mohammed_new"):
   |     ^^^^^^^^^^^^^^ N802
15 |     """Generate slatm representation following the script in :
16 |     https://github.com/lcmd-epfl/FORMED_ML/blob/a5d1e588dbb4883de19d4a69fae6694b9bde1101/data/generate_slatm.py.
   |

utils\Chemiscope_functions.py:15:5: D205 1 blank line required between summary line and description
   |
14 |   def generate_Slatm(df_1, dirname, name, database_name="stk_mohammed_new"):
15 |       """Generate slatm representation following the script in :
   |  _____^
16 | |     https://github.com/lcmd-epfl/FORMED_ML/blob/a5d1e588dbb4883de19d4a69fae6694b9bde1101/data/generate_slatm.py.
17 | |     """
   | |_______^ D205
18 |       client = pymongo.MongoClient("mongodb://129.31.66.201/")
19 |       os.makedirs(dirname, exist_ok=True)
   |
   = help: Insert single blank line

utils\Chemiscope_functions.py:19:5: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   |
17 |     """
18 |     client = pymongo.MongoClient("mongodb://129.31.66.201/")
19 |     os.makedirs(dirname, exist_ok=True)
   |     ^^^^^^^^^^^ PTH103
20 |     db = stk.MoleculeMongoDb(
21 |         client,
   |

utils\Chemiscope_functions.py:27:20: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   |
25 |     for inchkey in set(df_1["InChIKey"]):
26 |         try:
27 |             if not os.path.exists("cache/{inchkey}.xyz"):
   |                    ^^^^^^^^^^^^^^ PTH110
28 |                 polymer = db.get({"InChIKey": inchkey})
29 |                 polymer.write(f"cache/{inchkey}.xyz")
   |

utils\Chemiscope_functions.py:30:13: ERA001 Found commented-out code
   |
28 |                 polymer = db.get({"InChIKey": inchkey})
29 |                 polymer.write(f"cache/{inchkey}.xyz")
30 |             # mols_1.append(ase.io.read(f'cache/{inchkey}.xyz'))
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
31 |             namelist.append(qml.Compound(xyz=f"cache/{inchkey}.xyz"))
   |
   = help: Remove commented-out code

utils\Chemiscope_functions.py:33:9: S110 `try`-`except`-`pass` detected, consider logging the exception
   |
31 |               namelist.append(qml.Compound(xyz=f"cache/{inchkey}.xyz"))
32 |   
33 |           except Exception:
   |  _________^
34 | |             pass
   | |________________^ S110
35 |       compounds = np.asarray(namelist, dtype=object)  # WARNING: REMOVE SLICING
36 |       if os.path.exists(dirname + "/mbtypes.npy"):
   |

utils\Chemiscope_functions.py:33:9: PERF203 `try`-`except` within a loop incurs performance overhead
   |
31 |               namelist.append(qml.Compound(xyz=f"cache/{inchkey}.xyz"))
32 |   
33 |           except Exception:
   |  _________^
34 | |             pass
   | |________________^ PERF203
35 |       compounds = np.asarray(namelist, dtype=object)  # WARNING: REMOVE SLICING
36 |       if os.path.exists(dirname + "/mbtypes.npy"):
   |

utils\Chemiscope_functions.py:33:16: BLE001 Do not catch blind exception: `Exception`
   |
31 |             namelist.append(qml.Compound(xyz=f"cache/{inchkey}.xyz"))
32 | 
33 |         except Exception:
   |                ^^^^^^^^^ BLE001
34 |             pass
35 |     compounds = np.asarray(namelist, dtype=object)  # WARNING: REMOVE SLICING
   |

utils\Chemiscope_functions.py:36:8: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   |
34 |             pass
35 |     compounds = np.asarray(namelist, dtype=object)  # WARNING: REMOVE SLICING
36 |     if os.path.exists(dirname + "/mbtypes.npy"):
   |        ^^^^^^^^^^^^^^ PTH110
37 |         mbtypes = np.load(dirname + "/mbtypes.npy", allow_pickle=True)
38 |     else:
   |

utils\Chemiscope_functions.py:42:9: B007 Loop control variable `i` not used within loop body
   |
40 |         mbtypes = np.array(mbtypes)
41 |         np.save(dirname + "/mbtypes.npy", mbtypes)
42 |     for i, mol in enumerate(compounds):
   |         ^ B007
43 |         mol.generate_slatm(mbtypes, local=False, dgrids=[0.1, 0.1])
44 |         break
   |
   = help: Rename unused `i` to `_i`

utils\Chemiscope_functions.py:45:5: N806 Variable `SIZEOFSLATM` in function should be lowercase
   |
43 |         mol.generate_slatm(mbtypes, local=False, dgrids=[0.1, 0.1])
44 |         break
45 |     SIZEOFSLATM = len(mol.representation)
   |     ^^^^^^^^^^^ N806
46 |     Slatm_array = np.zeros((len(compounds), SIZEOFSLATM), dtype=np.float16)
47 |     N = []
   |

utils\Chemiscope_functions.py:46:5: N806 Variable `Slatm_array` in function should be lowercase
   |
44 |         break
45 |     SIZEOFSLATM = len(mol.representation)
46 |     Slatm_array = np.zeros((len(compounds), SIZEOFSLATM), dtype=np.float16)
   |     ^^^^^^^^^^^ N806
47 |     N = []
48 |     for i, mol in enumerate(compounds):
   |

utils\Chemiscope_functions.py:47:5: N806 Variable `N` in function should be lowercase
   |
45 |     SIZEOFSLATM = len(mol.representation)
46 |     Slatm_array = np.zeros((len(compounds), SIZEOFSLATM), dtype=np.float16)
47 |     N = []
   |     ^ N806
48 |     for i, mol in enumerate(compounds):
49 |         mol.generate_slatm(mbtypes, local=False, dgrids=[0.1, 0.1])
   |

utils\Chemiscope_functions.py:50:9: ERA001 Found commented-out code
   |
48 |     for i, mol in enumerate(compounds):
49 |         mol.generate_slatm(mbtypes, local=False, dgrids=[0.1, 0.1])
50 |         # print(mol.representation.shape)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
51 |         Slatm_array[i, :] = np.float16(mol.representation)
52 |         N.append(mol.name)
   |
   = help: Remove commented-out code

utils\Chemiscope_functions.py:55:5: N806 Variable `N` in function should be lowercase
   |
53 |         del mol
54 | 
55 |     N = np.array(N)
   |     ^ N806
56 |     np.save(f"{dirname}/repr_{name}.npy", Slatm_array)
57 |     np.save(f"{dirname}/names_{name}.npy", N)
   |

utils\Chemiscope_functions.py:61:5: N802 Function name `generate_Slatm_CM` should be lowercase
   |
61 | def generate_Slatm_CM(df_1, dirname, name, database_name="stk_mohammed_BO"):
   |     ^^^^^^^^^^^^^^^^^ N802
62 |     """Generate slatm representation following the script in :
63 |     https://github.com/lcmd-epfl/FORMED_ML/blob/a5d1e588dbb4883de19d4a69fae6694b9bde1101/data/generate_slatm.py.
   |

utils\Chemiscope_functions.py:62:5: D205 1 blank line required between summary line and description
   |
61 |   def generate_Slatm_CM(df_1, dirname, name, database_name="stk_mohammed_BO"):
62 |       """Generate slatm representation following the script in :
   |  _____^
63 | |     https://github.com/lcmd-epfl/FORMED_ML/blob/a5d1e588dbb4883de19d4a69fae6694b9bde1101/data/generate_slatm.py.
64 | |     """
   | |_______^ D205
65 |       client = pymongo.MongoClient("mongodb://129.31.66.201/")
66 |       os.makedirs(dirname, exist_ok=True)
   |
   = help: Insert single blank line

utils\Chemiscope_functions.py:66:5: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   |
64 |     """
65 |     client = pymongo.MongoClient("mongodb://129.31.66.201/")
66 |     os.makedirs(dirname, exist_ok=True)
   |     ^^^^^^^^^^^ PTH103
67 |     db = stk.ConstructedMoleculeMongoDb(
68 |         client,
   |

utils\Chemiscope_functions.py:74:20: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   |
72 |     for inchkey in df_1["InChIKey"]:
73 |         try:
74 |             if not os.path.exists("cache/{inchkey}.xyz"):
   |                    ^^^^^^^^^^^^^^ PTH110
75 |                 polymer = db.get({"InChIKey": inchkey})
76 |                 polymer.write(f"cache/{inchkey}.xyz")
   |

utils\Chemiscope_functions.py:77:13: ERA001 Found commented-out code
   |
75 |                 polymer = db.get({"InChIKey": inchkey})
76 |                 polymer.write(f"cache/{inchkey}.xyz")
77 |             # mols_1.append(ase.io.read(f'cache/{inchkey}.xyz'))
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
78 |             namelist.append(qml.Compound(xyz=f"cache/{inchkey}.xyz"))
   |
   = help: Remove commented-out code

utils\Chemiscope_functions.py:80:9: S110 `try`-`except`-`pass` detected, consider logging the exception
   |
78 |               namelist.append(qml.Compound(xyz=f"cache/{inchkey}.xyz"))
79 |   
80 |           except Exception:
   |  _________^
81 | |             pass
   | |________________^ S110
82 |       compounds = np.asarray(namelist, dtype=object)  # WARNING: REMOVE SLICING
83 |       if os.path.exists(dirname + "/mbtypes.npy"):
   |

utils\Chemiscope_functions.py:80:9: PERF203 `try`-`except` within a loop incurs performance overhead
   |
78 |               namelist.append(qml.Compound(xyz=f"cache/{inchkey}.xyz"))
79 |   
80 |           except Exception:
   |  _________^
81 | |             pass
   | |________________^ PERF203
82 |       compounds = np.asarray(namelist, dtype=object)  # WARNING: REMOVE SLICING
83 |       if os.path.exists(dirname + "/mbtypes.npy"):
   |

utils\Chemiscope_functions.py:80:16: BLE001 Do not catch blind exception: `Exception`
   |
78 |             namelist.append(qml.Compound(xyz=f"cache/{inchkey}.xyz"))
79 | 
80 |         except Exception:
   |                ^^^^^^^^^ BLE001
81 |             pass
82 |     compounds = np.asarray(namelist, dtype=object)  # WARNING: REMOVE SLICING
   |

utils\Chemiscope_functions.py:83:8: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   |
81 |             pass
82 |     compounds = np.asarray(namelist, dtype=object)  # WARNING: REMOVE SLICING
83 |     if os.path.exists(dirname + "/mbtypes.npy"):
   |        ^^^^^^^^^^^^^^ PTH110
84 |         mbtypes = np.load(dirname + "/mbtypes.npy", allow_pickle=True)
85 |     else:
   |

utils\Chemiscope_functions.py:89:9: B007 Loop control variable `i` not used within loop body
   |
87 |         mbtypes = np.array(mbtypes)
88 |         np.save(dirname + "/mbtypes.npy", mbtypes)
89 |     for i, mol in enumerate(compounds):
   |         ^ B007
90 |         mol.generate_slatm(mbtypes, local=False, dgrids=[0.1, 0.1])
91 |         break
   |
   = help: Rename unused `i` to `_i`

utils\Chemiscope_functions.py:92:5: N806 Variable `SIZEOFSLATM` in function should be lowercase
   |
90 |         mol.generate_slatm(mbtypes, local=False, dgrids=[0.1, 0.1])
91 |         break
92 |     SIZEOFSLATM = len(mol.representation)
   |     ^^^^^^^^^^^ N806
93 |     Slatm_array = np.zeros((len(compounds), SIZEOFSLATM), dtype=np.float16)
94 |     N = []
   |

utils\Chemiscope_functions.py:93:5: N806 Variable `Slatm_array` in function should be lowercase
   |
91 |         break
92 |     SIZEOFSLATM = len(mol.representation)
93 |     Slatm_array = np.zeros((len(compounds), SIZEOFSLATM), dtype=np.float16)
   |     ^^^^^^^^^^^ N806
94 |     N = []
95 |     for i, mol in enumerate(compounds):
   |

utils\Chemiscope_functions.py:94:5: N806 Variable `N` in function should be lowercase
   |
92 |     SIZEOFSLATM = len(mol.representation)
93 |     Slatm_array = np.zeros((len(compounds), SIZEOFSLATM), dtype=np.float16)
94 |     N = []
   |     ^ N806
95 |     for i, mol in enumerate(compounds):
96 |         mol.generate_slatm(mbtypes, local=False, dgrids=[0.1, 0.1])
   |

utils\Chemiscope_functions.py:97:9: ERA001 Found commented-out code
   |
95 |     for i, mol in enumerate(compounds):
96 |         mol.generate_slatm(mbtypes, local=False, dgrids=[0.1, 0.1])
97 |         # print(mol.representation.shape)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
98 |         Slatm_array[i, :] = np.float16(mol.representation)
99 |         N.append(mol.name)
   |
   = help: Remove commented-out code

utils\Chemiscope_functions.py:102:5: N806 Variable `N` in function should be lowercase
    |
100 |         del mol
101 | 
102 |     N = np.array(N)
    |     ^ N806
103 |     np.save(f"{dirname}/repr_{name}.npy", Slatm_array)
104 |     np.save(f"{dirname}/names_{name}.npy", N)
    |

utils\EXP_plot_utils.py:1:1: INP001 File `utils\EXP_plot_utils.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\EXP_plot_utils.py:1:1: D100 Missing docstring in public module
utils\EXP_plot_utils.py:18:5: D103 Missing docstring in public function
   |
17 | # plot the results of the experiment
18 | def plot_exp_batch_results(
   |     ^^^^^^^^^^^^^^^^^^^^^^ D103
19 |     exp_name="Inputs/exp1_2023_09_05_14_47_02/",
20 |     df_total: pd.DataFrame | None = None,
   |

utils\EXP_plot_utils.py:27:9: N806 Variable `SP` in function should be lowercase
   |
25 |     for i in [3, 4, 5, 6]:
26 |         search_space_loc = exp_name + f"search_space_{i}.pkl"
27 |         SP = pickle.load(open(search_space_loc, "rb"))
   |         ^^ N806
28 |         df_eval = SP.check_df_for_element_from_SP(df_to_check=df_total)
29 |         df_list.append(df_eval)
   |

utils\EXP_plot_utils.py:27:14: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
   |
25 |     for i in [3, 4, 5, 6]:
26 |         search_space_loc = exp_name + f"search_space_{i}.pkl"
27 |         SP = pickle.load(open(search_space_loc, "rb"))
   |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ S301
28 |         df_eval = SP.check_df_for_element_from_SP(df_to_check=df_total)
29 |         df_list.append(df_eval)
   |

utils\EXP_plot_utils.py:27:26: SIM115 Use context handler for opening files
   |
25 |     for i in [3, 4, 5, 6]:
26 |         search_space_loc = exp_name + f"search_space_{i}.pkl"
27 |         SP = pickle.load(open(search_space_loc, "rb"))
   |                          ^^^^ SIM115
28 |         df_eval = SP.check_df_for_element_from_SP(df_to_check=df_total)
29 |         df_list.append(df_eval)
   |

utils\EXP_plot_utils.py:27:26: PTH123 `open()` should be replaced by `Path.open()`
   |
25 |     for i in [3, 4, 5, 6]:
26 |         search_space_loc = exp_name + f"search_space_{i}.pkl"
27 |         SP = pickle.load(open(search_space_loc, "rb"))
   |                          ^^^^ PTH123
28 |         df_eval = SP.check_df_for_element_from_SP(df_to_check=df_total)
29 |         df_list.append(df_eval)
   |

utils\EXP_plot_utils.py:81:5: F821 Undefined name `display`
   |
79 |         layout=vbox_layout,
80 |     )
81 |     display(vb)
   |     ^^^^^^^ F821
   |

utils\Precursor_calculation.py:1:1: INP001 File `utils\Precursor_calculation.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\Precursor_calculation.py:1:1: D100 Missing docstring in public module
utils\Precursor_calculation.py:11:5: D103 Missing docstring in public function
   |
11 | def get_inchi_key(molecule):
   |     ^^^^^^^^^^^^^ D103
12 |     return stk.InchiKey().get_key(molecule)
   |

utils\Precursor_calculation.py:14:7: N801 Class name `Calculate_Precursor` should use CapWords convention
   |
12 |     return stk.InchiKey().get_key(molecule)
13 | 
14 | class Calculate_Precursor:
   |       ^^^^^^^^^^^^^^^^^^^ N801
15 |     def __init__(self):
16 |         self.client = "mongodb://ch-atarzia.ch.ic.ac.uk/"
   |

utils\Precursor_calculation.py:14:7: D101 Missing docstring in public class
   |
12 |     return stk.InchiKey().get_key(molecule)
13 | 
14 | class Calculate_Precursor:
   |       ^^^^^^^^^^^^^^^^^^^ D101
15 |     def __init__(self):
16 |         self.client = "mongodb://ch-atarzia.ch.ic.ac.uk/"
   |

utils\Precursor_calculation.py:15:9: D107 Missing docstring in `__init__`
   |
14 | class Calculate_Precursor:
15 |     def __init__(self):
   |         ^^^^^^^^ D107
16 |         self.client = "mongodb://ch-atarzia.ch.ic.ac.uk/"
17 |         self.db_mol = "stk_mohammed_new"
   |

utils\Precursor_calculation.py:22:13: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   |
20 |         self.Db_folder = None
21 |         if self.Db_folder is not None:
22 |             os.makedirs(self.Db_folder, exist_ok=True)
   |             ^^^^^^^^^^^ PTH103
23 |         # print(self.collection_name)
24 |         self.host_IP = "cx1"
   |

utils\Precursor_calculation.py:23:9: ERA001 Found commented-out code
   |
21 |         if self.Db_folder is not None:
22 |             os.makedirs(self.Db_folder, exist_ok=True)
23 |         # print(self.collection_name)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
24 |         self.host_IP = "cx1"
25 |         self.collection_name = "Precursors"
   |
   = help: Remove commented-out code

utils\Precursor_calculation.py:28:9: D401 First line of docstring should be in imperative mood: "Function to generate stk building block from smiles."
   |
27 |     def load_precursors(self, smile):
28 |         """Function to generate stk building block from smiles."""
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D401
29 |         return stk.BuildingBlock(
30 |                 smile, functional_groups=[
   |

utils\Precursor_calculation.py:35:9: D205 1 blank line required between summary line and description
   |
34 |       def evaluate_element(self, smile):
35 |           """Function to evaluate the element
   |  _________^
36 | |         depending on the paths provided (xtb or stda )
37 | |         the function will add those calculations to the model.
38 | |         """
   | |___________^ D205
39 |           # initialise the database
40 |           client = pymongo.MongoClient(self.client)
   |
   = help: Insert single blank line

utils\Precursor_calculation.py:35:9: D401 First line of docstring should be in imperative mood: "Function to evaluate the element"
   |
34 |       def evaluate_element(self, smile):
35 |           """Function to evaluate the element
   |  _________^
36 | |         depending on the paths provided (xtb or stda )
37 | |         the function will add those calculations to the model.
38 | |         """
   | |___________^ D401
39 |           # initialise the database
40 |           client = pymongo.MongoClient(self.client)
   |

utils\Precursor_calculation.py:49:9: N806 Variable `Db_folder` in function should be lowercase
   |
48 |         # define the output directories
49 |         Db_folder = self.Db_folder
   |         ^^^^^^^^^ N806
50 |         output_dir_ipea = os.path.join(
51 |             Db_folder, "Database", "xtb_calculations"
   |

utils\Precursor_calculation.py:50:27: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   |
48 |         # define the output directories
49 |         Db_folder = self.Db_folder
50 |         output_dir_ipea = os.path.join(
   |                           ^^^^^^^^^^^^ PTH118
51 |             Db_folder, "Database", "xtb_calculations"
52 |         )
   |

utils\Precursor_calculation.py:53:30: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   |
51 |             Db_folder, "Database", "xtb_calculations"
52 |         )
53 |         xtb_opt_output_dir = os.path.join(
   |                              ^^^^^^^^^^^^ PTH118
54 |             Db_folder, "Database", "xtb_opt_output_dir"
55 |         )
   |

utils\Precursor_calculation.py:56:27: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   |
54 |             Db_folder, "Database", "xtb_opt_output_dir"
55 |         )
56 |         output_dir_stda = os.path.join(
   |                           ^^^^^^^^^^^^ PTH118
57 |             Db_folder, "Database", "stda_output_dir"
58 |         )
   |

utils\Precursor_calculation.py:59:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   |
57 |             Db_folder, "Database", "stda_output_dir"
58 |         )
59 |         os.makedirs(output_dir_ipea, exist_ok=True)
   |         ^^^^^^^^^^^ PTH103
60 |         os.makedirs(xtb_opt_output_dir, exist_ok=True)
61 |         os.makedirs(output_dir_stda, exist_ok=True)
   |

utils\Precursor_calculation.py:60:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   |
58 |         )
59 |         os.makedirs(output_dir_ipea, exist_ok=True)
60 |         os.makedirs(xtb_opt_output_dir, exist_ok=True)
   |         ^^^^^^^^^^^ PTH103
61 |         os.makedirs(output_dir_stda, exist_ok=True)
62 |         # define the database and collection name
   |

utils\Precursor_calculation.py:61:9: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   |
59 |         os.makedirs(output_dir_ipea, exist_ok=True)
60 |         os.makedirs(xtb_opt_output_dir, exist_ok=True)
61 |         os.makedirs(output_dir_stda, exist_ok=True)
   |         ^^^^^^^^^^^ PTH103
62 |         # define the database and collection name
63 |         collection_name = self.collection_name
   |

utils\Precursor_calculation.py:64:9: ERA001 Found commented-out code
   |
62 |         # define the database and collection name
63 |         collection_name = self.collection_name
64 |         # print(collection_name)
   |         ^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
65 |         precursor = self.load_precursors(smile)
66 |         if self.xtb_path is not None:
   |
   = help: Remove commented-out code

utils\Precursor_calculation.py:75:13: N806 Variable `Inchikey` in function should be lowercase
   |
73 |                 client=client,
74 |             )
75 |             Inchikey = stk.InchiKey().get_key(precursor)
   |             ^^^^^^^^ N806
76 | 
77 |             IP = self.run_xtb_ipea(
   |

utils\Precursor_calculation.py:77:13: N806 Variable `IP` in function should be lowercase
   |
75 |             Inchikey = stk.InchiKey().get_key(precursor)
76 | 
77 |             IP = self.run_xtb_ipea(
   |             ^^ N806
78 |                 precursor,
79 |                 xtb_path,
   |

utils\Precursor_calculation.py:87:17: N806 Variable `STDA_bin_path` in function should be lowercase
   |
85 |             )
86 |             if self.STDA_bin_path is not None:
87 |                 STDA_bin_path = self.STDA_bin_path
   |                 ^^^^^^^^^^^^^ N806
88 |                 Es1 = self.run_stda(
89 |                     precursor,
   |

utils\Precursor_calculation.py:88:17: N806 Variable `Es1` in function should be lowercase
   |
86 |             if self.STDA_bin_path is not None:
87 |                 STDA_bin_path = self.STDA_bin_path
88 |                 Es1 = self.run_stda(
   |                 ^^^ N806
89 |                     precursor,
90 |                     STDA_bin_path,
   |

utils\Precursor_calculation.py:100:9: RET505 Unnecessary `else` after `return` statement
    |
 98 |                 return Es1, Inchikey
 99 |             return IP, Inchikey
100 |         else:
    |         ^^^^ RET505
101 |             precursor = self.run_ETKDG_opt(
102 |                 precursor,
    |
    = help: Remove unnecessary `else`

utils\Precursor_calculation.py:107:13: N806 Variable `Inchikey` in function should be lowercase
    |
105 |                 client=client,
106 |             )
107 |             Inchikey = stk.InchiKey().get_key(precursor)
    |             ^^^^^^^^ N806
108 |             return None, Inchikey
    |

utils\Precursor_calculation.py:111:9: N802 Function name `run_ETKDG_opt` should be lowercase
    |
111 |     def run_ETKDG_opt(
    |         ^^^^^^^^^^^^^ N802
112 |         self,
113 |         polymer,
    |

utils\Precursor_calculation.py:111:9: D102 Missing docstring in public method
    |
111 |     def run_ETKDG_opt(
    |         ^^^^^^^^^^^^^ D102
112 |         self,
113 |         polymer,
    |

utils\Precursor_calculation.py:118:9: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
116 |         client=None,
117 |     ):
118 |         os.path.join(xtb_opt_output_dir, get_inchi_key(polymer))
    |         ^^^^^^^^^^^^ PTH118
119 |         get_inchi_key(polymer)
120 |         ETKDG = stko.OptimizerSequence(
    |

utils\Precursor_calculation.py:120:9: N806 Variable `ETKDG` in function should be lowercase
    |
118 |         os.path.join(xtb_opt_output_dir, get_inchi_key(polymer))
119 |         get_inchi_key(polymer)
120 |         ETKDG = stko.OptimizerSequence(
    |         ^^^^^ N806
121 |             stko.ETKDG(),
122 |         )
    |

utils\Precursor_calculation.py:131:9: PLR0913 Too many arguments in function definition (6 > 5)
    |
129 |         return polymer
130 | 
131 |     def run_xtb_opt(
    |         ^^^^^^^^^^^ PLR0913
132 |         self,
133 |         polymer,
    |

utils\Precursor_calculation.py:131:9: D102 Missing docstring in public method
    |
129 |         return polymer
130 | 
131 |     def run_xtb_opt(
    |         ^^^^^^^^^^^ D102
132 |         self,
133 |         polymer,
    |

utils\Precursor_calculation.py:141:59: N803 Argument name `InchiKey_initial` should be lowercase
    |
139 |     ):
140 |         def save_xtb_opt_calculation(
141 |             polymer, xtb_opt_output_dir, collection=None, InchiKey_initial=None
    |                                                           ^^^^^^^^^^^^^^^^ N803
142 |         ) -> None:
143 |             def get_property_value(data, property_name):
    |

utils\Precursor_calculation.py:143:17: ANN202 Missing return type annotation for private function `get_property_value`
    |
141 |             polymer, xtb_opt_output_dir, collection=None, InchiKey_initial=None
142 |         ) -> None:
143 |             def get_property_value(data, property_name):
    |                 ^^^^^^^^^^^^^^^^^^ ANN202
144 |                 for line in data:
145 |                     if property_name in line:
    |
    = help: Add return type annotation

utils\Precursor_calculation.py:162:31: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
160 |             polymer_xtb_opt_calc = {
161 |                 "InChIKey": stk.InchiKey().get_key(polymer),
162 |                 "cal_folder": os.path.join(
    |                               ^^^^^^^^^^^^ PTH118
163 |                     xtb_opt_output_dir, stk.InchiKey().get_key(polymer)
164 |                 ),
    |

utils\Precursor_calculation.py:168:23: SIM115 Use context handler for opening files
    |
166 |                 "InChIKey_initial": InchiKey_initial,
167 |             }
168 |             outfile = open(
    |                       ^^^^ SIM115
169 |                 os.path.join(
170 |                     polymer_xtb_opt_calc["cal_folder"], "optimization_1.output"
    |

utils\Precursor_calculation.py:168:23: PTH123 `open()` should be replaced by `Path.open()`
    |
166 |                 "InChIKey_initial": InchiKey_initial,
167 |             }
168 |             outfile = open(
    |                       ^^^^ PTH123
169 |                 os.path.join(
170 |                     polymer_xtb_opt_calc["cal_folder"], "optimization_1.output"
    |

utils\Precursor_calculation.py:169:17: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
167 |             }
168 |             outfile = open(
169 |                 os.path.join(
    |                 ^^^^^^^^^^^^ PTH118
170 |                     polymer_xtb_opt_calc["cal_folder"], "optimization_1.output"
171 |                 ),
    |

utils\Precursor_calculation.py:196:13: ERA001 Found commented-out code
    |
194 |             is not None
195 |         ):
196 |             # print("already calculated", end="\r")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
197 | 
198 |             db_polymer = stk.MoleculeMongoDb(
    |
    = help: Remove commented-out code

utils\Precursor_calculation.py:203:13: ERA001 Found commented-out code
    |
201 |             )
202 |             return db_polymer.get({"InChIKey": get_inchi_key(polymer)})
203 |             # print(get_inchi_key(polymer), ' opt geom already calculated')
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
204 |         if (
205 |             collection.find_one({"InChIKey_initial": get_inchi_key(polymer)})
    |
    = help: Remove commented-out code

utils\Precursor_calculation.py:208:13: ERA001 Found commented-out code
    |
206 |             is not None
207 |         ):
208 |             # print("already calculated", end="\r")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
209 |             db_polymer = stk.MoleculeMongoDb(
210 |                 client,
    |
    = help: Remove commented-out code

utils\Precursor_calculation.py:216:13: ERA001 Found commented-out code
    |
214 |                 {"InChIKey_initial": get_inchi_key(polymer)}
215 |             )
216 |             # print(get_inchi_key(polymer), ' opt geom already calculated with old geom')
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
217 | 
218 |             return db_polymer.get({"InChIKey": data["InChIKey"]})
    |
    = help: Remove commented-out code

utils\Precursor_calculation.py:219:22: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
218 |             return db_polymer.get({"InChIKey": data["InChIKey"]})
219 |         output_dir = os.path.join(xtb_opt_output_dir, get_inchi_key(polymer))
    |                      ^^^^^^^^^^^^ PTH118
220 |         InchiKey_initial = get_inchi_key(polymer)
221 |         xtb = stko.OptimizerSequence(
    |

utils\Precursor_calculation.py:220:9: N806 Variable `InchiKey_initial` in function should be lowercase
    |
218 |             return db_polymer.get({"InChIKey": data["InChIKey"]})
219 |         output_dir = os.path.join(xtb_opt_output_dir, get_inchi_key(polymer))
220 |         InchiKey_initial = get_inchi_key(polymer)
    |         ^^^^^^^^^^^^^^^^ N806
221 |         xtb = stko.OptimizerSequence(
222 |             stko.ETKDG(),
    |

utils\Precursor_calculation.py:231:26: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
229 |         )
230 |         polymer = xtb.optimize(polymer)
231 |         new_output_dir = os.path.join(
    |                          ^^^^^^^^^^^^ PTH118
232 |             xtb_opt_output_dir, get_inchi_key(polymer)
233 |         )
    |

utils\Precursor_calculation.py:234:13: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
    |
232 |             xtb_opt_output_dir, get_inchi_key(polymer)
233 |         )
234 |         if ~os.path.exists(new_output_dir):
    |             ^^^^^^^^^^^^^^ PTH110
235 |             os.rename(output_dir, new_output_dir)
236 |         save_xtb_opt_calculation(
    |

utils\Precursor_calculation.py:235:13: PTH104 `os.rename()` should be replaced by `Path.rename()`
    |
233 |         )
234 |         if ~os.path.exists(new_output_dir):
235 |             os.rename(output_dir, new_output_dir)
    |             ^^^^^^^^^ PTH104
236 |         save_xtb_opt_calculation(
237 |             polymer,
    |

utils\Precursor_calculation.py:249:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
247 |         return polymer
248 | 
249 |     def run_xtb_ipea(
    |         ^^^^^^^^^^^^ PLR0913
250 |         self,
251 |         polymer,
    |

utils\Precursor_calculation.py:249:9: D102 Missing docstring in public method
    |
247 |         return polymer
248 | 
249 |     def run_xtb_ipea(
    |         ^^^^^^^^^^^^ D102
250 |         self,
251 |         polymer,
    |

utils\Precursor_calculation.py:260:9: N806 Variable `XTB_results` in function should be lowercase
    |
258 |     ):
259 |         collection = client[database][collection]
260 |         XTB_results = collection.find_one({"InChIKey": get_inchi_key(polymer)})
    |         ^^^^^^^^^^^ N806
261 |         if XTB_results is not None:
262 |             # print("already calculated", end="\r")
    |

utils\Precursor_calculation.py:262:13: ERA001 Found commented-out code
    |
260 |         XTB_results = collection.find_one({"InChIKey": get_inchi_key(polymer)})
261 |         if XTB_results is not None:
262 |             # print("already calculated", end="\r")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
263 |             # print(get_inchi_key(polymer), ' ipea geom already calculated')
264 |             return XTB_results[target]
    |
    = help: Remove commented-out code

utils\Precursor_calculation.py:263:13: ERA001 Found commented-out code
    |
261 |         if XTB_results is not None:
262 |             # print("already calculated", end="\r")
263 |             # print(get_inchi_key(polymer), ' ipea geom already calculated')
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
264 |             return XTB_results[target]
265 |         xtb = XTBEnergy2(
    |
    = help: Remove commented-out code

utils\Precursor_calculation.py:267:24: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
265 |         xtb = XTBEnergy2(
266 |             xtb_path=xtb_path,
267 |             output_dir=os.path.join(
    |                        ^^^^^^^^^^^^ PTH118
268 |                 xtb_opt_output_dir, get_inchi_key(polymer)
269 |             ),
    |

utils\Precursor_calculation.py:275:9: N806 Variable `XTB_results` in function should be lowercase
    |
273 |         )
274 |         xtb_results = xtb.get_results(polymer)
275 |         XTB_results = {
    |         ^^^^^^^^^^^ N806
276 |             "total energy (au)": xtb_results.get_total_energy()[0],
277 |             "homo lumo_gap (eV)": xtb_results.get_homo_lumo_gap()[0],
    |

utils\Precursor_calculation.py:283:27: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
281 |             ],
282 |             "InChIKey": get_inchi_key(polymer),
283 |             "cal_folder": os.path.join(
    |                           ^^^^^^^^^^^^ PTH118
284 |                 xtb_opt_output_dir, get_inchi_key(polymer)
285 |             ),
    |

utils\Precursor_calculation.py:295:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
293 |         return XTB_results[target]
294 | 
295 |     def run_stda(
    |         ^^^^^^^^ PLR0913
296 |         self,
297 |         polymer,
    |

utils\Precursor_calculation.py:295:9: D102 Missing docstring in public method
    |
293 |         return XTB_results[target]
294 | 
295 |     def run_stda(
    |         ^^^^^^^^ D102
296 |         self,
297 |         polymer,
    |

utils\Precursor_calculation.py:298:9: N803 Argument name `STDA_bin_path` should be lowercase
    |
296 |         self,
297 |         polymer,
298 |         STDA_bin_path,
    |         ^^^^^^^^^^^^^ N803
299 |         output_dir,
300 |         property="Excited state energy (eV)",
    |

utils\Precursor_calculation.py:300:9: A002 Argument `property` is shadowing a Python builtin
    |
298 |         STDA_bin_path,
299 |         output_dir,
300 |         property="Excited state energy (eV)",
    |         ^^^^^^^^ A002
301 |         state=1,
302 |         database="stk_mohammed",
    |

utils\Precursor_calculation.py:307:9: N806 Variable `STDA_results` in function should be lowercase
    |
305 |     ):
306 |         collection = client[database][collection]
307 |         STDA_results = collection.find_one(
    |         ^^^^^^^^^^^^ N806
308 |             {"InChIKey": get_inchi_key(polymer)}
309 |         )
    |

utils\Precursor_calculation.py:311:13: ERA001 Found commented-out code
    |
309 |         )
310 |         if STDA_results is not None:
311 |             # print(get_inchi_key(polymer), ' stda geom already calculated')
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
312 |             # print(STDA_results[property][state])
313 |             return STDA_results[property][state]
    |
    = help: Remove commented-out code

utils\Precursor_calculation.py:312:13: ERA001 Found commented-out code
    |
310 |         if STDA_results is not None:
311 |             # print(get_inchi_key(polymer), ' stda geom already calculated')
312 |             # print(STDA_results[property][state])
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
313 |             return STDA_results[property][state]
314 |         stda = sTDA_XTB(
    |
    = help: Remove commented-out code

utils\Precursor_calculation.py:317:24: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
315 |             STDA_bin_path=STDA_bin_path,
316 |             Num_threads=25,
317 |             output_dir=os.path.join(output_dir, get_inchi_key(polymer)),
    |                        ^^^^^^^^^^^^ PTH118
318 |         )
319 |         Excited_state_energy, Excited_state_osc = stda.get_results(polymer)
    |

utils\Precursor_calculation.py:319:9: N806 Variable `Excited_state_energy` in function should be lowercase
    |
317 |             output_dir=os.path.join(output_dir, get_inchi_key(polymer)),
318 |         )
319 |         Excited_state_energy, Excited_state_osc = stda.get_results(polymer)
    |         ^^^^^^^^^^^^^^^^^^^^ N806
320 |         STDA_results = {
321 |             "Excited state energy (eV)": Excited_state_energy,
    |

utils\Precursor_calculation.py:319:31: N806 Variable `Excited_state_osc` in function should be lowercase
    |
317 |             output_dir=os.path.join(output_dir, get_inchi_key(polymer)),
318 |         )
319 |         Excited_state_energy, Excited_state_osc = stda.get_results(polymer)
    |                               ^^^^^^^^^^^^^^^^^ N806
320 |         STDA_results = {
321 |             "Excited state energy (eV)": Excited_state_energy,
    |

utils\Precursor_calculation.py:320:9: N806 Variable `STDA_results` in function should be lowercase
    |
318 |         )
319 |         Excited_state_energy, Excited_state_osc = stda.get_results(polymer)
320 |         STDA_results = {
    |         ^^^^^^^^^^^^ N806
321 |             "Excited state energy (eV)": Excited_state_energy,
322 |             "Excited state oscillator strength": Excited_state_osc,
    |

utils\Precursor_calculation.py:324:27: PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
    |
322 |             "Excited state oscillator strength": Excited_state_osc,
323 |             "InChIKey": get_inchi_key(polymer),
324 |             "cal_folder": os.path.join(output_dir, get_inchi_key(polymer)),
    |                           ^^^^^^^^^^^^ PTH118
325 |             "Host IP": self.host_IP,
326 |         }
    |

utils\Search_results_plot.py:1:1: INP001 File `utils\Search_results_plot.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\Search_results_plot.py:1:1: D100 Missing docstring in public module
utils\Search_results_plot.py:11:1: ERA001 Found commented-out code
   |
10 | #plt.matplotlib.style.use(
11 | #    "https://gist.githubusercontent.com/JonnyCBB/c464d302fefce4722fe6cf5f461114ea/raw/64a78942d3f7b4b5054902f2cee84213eaff872f/matplotlibrc"
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
12 | #)
13 | cool_colors = [
   |
   = help: Remove commented-out code

utils\Search_results_plot.py:12:1: ERA001 Found commented-out code
   |
10 | #plt.matplotlib.style.use(
11 | #    "https://gist.githubusercontent.com/JonnyCBB/c464d302fefce4722fe6cf5f461114ea/raw/64a78942d3f7b4b5054902f2cee84213eaff872f/matplotlibrc"
12 | #)
   | ^^ ERA001
13 | cool_colors = [
14 |     "#00BEFF",
   |
   = help: Remove commented-out code

utils\Search_results_plot.py:38:5: D103 Missing docstring in public function
   |
38 | def moving_average(x, w):
   |     ^^^^^^^^^^^^^^ D103
39 |     return np.convolve(x, np.ones(w), "same") / w
   |

utils\Search_results_plot.py:42:5: PLR0913 Too many arguments in function definition (8 > 5)
   |
42 | def plot_simple_regret(
   |     ^^^^^^^^^^^^^^^^^^ PLR0913
43 |     res,
44 |     nb_iterations=100,
   |

utils\Search_results_plot.py:42:5: D417 Missing argument descriptions in the docstring for `plot_simple_regret`: `df_total`, `label`, `nb_initialisation`, `target_name`
   |
42 | def plot_simple_regret(
   |     ^^^^^^^^^^^^^^^^^^ D417
43 |     res,
44 |     nb_iterations=100,
   |

utils\Search_results_plot.py:82:9: S101 Use of `assert` detected
   |
80 |         ]
81 |         y_maxes = np.array(y_maxes)
82 |         assert np.size(y_maxes) == nb_runs
   |         ^^^^^^ S101
83 |         y_max_mu[i - 1] = np.mean(y_maxes)
84 |         y_max_sig_bot[i - 1] = np.std(y_maxes[y_maxes < y_max_mu[i - 1]])
   |

utils\Search_results_plot.py:100:5: N802 Function name `plot_target_MFBO` should be lowercase
    |
 98 |     return max(y_max_mu)
 99 | 
100 | def plot_target_MFBO(
    |     ^^^^^^^^^^^^^^^^ N802
101 |     res,
102 |     axs=None,
    |

utils\Search_results_plot.py:100:5: PLR0913 Too many arguments in function definition (6 > 5)
    |
 98 |     return max(y_max_mu)
 99 | 
100 | def plot_target_MFBO(
    |     ^^^^^^^^^^^^^^^^ PLR0913
101 |     res,
102 |     axs=None,
    |

utils\Search_results_plot.py:100:5: D103 Missing docstring in public function
    |
 98 |     return max(y_max_mu)
 99 | 
100 | def plot_target_MFBO(
    |     ^^^^^^^^^^^^^^^^ D103
101 |     res,
102 |     axs=None,
    |

utils\Search_results_plot.py:104:5: ARG001 Unused function argument: `target_name`
    |
102 |     axs=None,
103 |     title="",
104 |     target_name="target",
    |     ^^^^^^^^^^^ ARG001
105 |     df_total=None,
106 |     colours=None
    |

utils\Search_results_plot.py:121:21: PD008 Use `.loc` instead of `.at`. If speed is important, use NumPy.
    |
119 |             fidelity_iteration=[]
120 |             for i in range(nb_iterations):
121 |                 if (df_sample.at[i, "fidelity"] == fidelity):
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD008
122 |                     fidelity_target.append(fitness_list[i])
123 |                     fidelity_iteration.append(i)
    |

utils\Search_results_plot.py:139:5: PLR0913 Too many arguments in function definition (8 > 5)
    |
137 |     return max(fitness_list)
138 | 
139 | def plot_inst_regret(
    |     ^^^^^^^^^^^^^^^^ PLR0913
140 |     res,
141 |     nb_iterations=100,
    |

utils\Search_results_plot.py:139:5: D417 Missing argument descriptions in the docstring for `plot_inst_regret`: `df_total`, `label`, `nb_initialisation`, `target_name`
    |
137 |     return max(fitness_list)
138 | 
139 | def plot_inst_regret(
    |     ^^^^^^^^^^^^^^^^ D417
140 |     res,
141 |     nb_iterations=100,
    |

utils\Search_results_plot.py:147:5: ARG001 Unused function argument: `nb_initialisation`
    |
145 |     target_name="target",
146 |     df_total=None,
147 |     nb_initialisation=0,
    |     ^^^^^^^^^^^^^^^^^ ARG001
148 | ):
149 |     """Plot the maximum value acquired up to this point.
    |

utils\Search_results_plot.py:174:9: ERA001 Found commented-out code
    |
172 |         ]
173 |         y_maxes = np.array(y_maxes)
174 |         #assert np.size(y_maxes) == nb_runs
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
175 |         y_max_mu[i - 1] = np.mean(y_maxes)
176 |         y_max_sig_bot[i - 1] = np.std(y_maxes)
    |
    = help: Remove commented-out code

utils\Search_results_plot.py:193:5: PLR0913 Too many arguments in function definition (8 > 5)
    |
193 | def plot_cumulative_regret(
    |     ^^^^^^^^^^^^^^^^^^^^^^ PLR0913
194 |     res,
195 |     nb_iterations=100,
    |

utils\Search_results_plot.py:193:5: D417 Missing argument descriptions in the docstring for `plot_cumulative_regret`: `df_total`, `label`, `nb_initialisation`, `target_name`
    |
193 | def plot_cumulative_regret(
    |     ^^^^^^^^^^^^^^^^^^^^^^ D417
194 |     res,
195 |     nb_iterations=100,
    |

utils\Search_results_plot.py:234:9: S101 Use of `assert` detected
    |
233 |         y_maxes = -np.array(y_maxes)
234 |         assert np.size(y_maxes) == nb_runs
    |         ^^^^^^ S101
235 |         y_max_mu[i - 1] = np.mean(y_maxes)
236 |         y_max_sig_bot[i - 1] = np.std(y_maxes[y_maxes < y_max_mu[i - 1]])
    |

utils\Search_results_plot.py:252:5: PLR0913 Too many arguments in function definition (8 > 5)
    |
252 | def plot_y_max(
    |     ^^^^^^^^^^ PLR0913
253 |     res,
254 |     nb_iterations=100,
    |

utils\Search_results_plot.py:252:5: D417 Missing argument descriptions in the docstring for `plot_y_max`: `df_total`, `label`, `nb_initialisation`, `target_name`
    |
252 | def plot_y_max(
    |     ^^^^^^^^^^ D417
253 |     res,
254 |     nb_iterations=100,
    |

utils\Search_results_plot.py:292:9: S101 Use of `assert` detected
    |
290 |             ]
291 |         )  # among runs
292 |         assert np.size(y_maxes) == nb_runs
    |         ^^^^^^ S101
293 |         y_max_mu[i - 1] = np.mean(y_maxes)
294 |         y_max_sig_bot[i - 1] = np.std(y_maxes[y_maxes < y_max_mu[i - 1]])
    |

utils\Search_results_plot.py:318:5: PLR0913 Too many arguments in function definition (8 > 5)
    |
318 | def plot_all_y_max(
    |     ^^^^^^^^^^^^^^ PLR0913
319 |     res,
320 |     nb_iterations=100,
    |

utils\Search_results_plot.py:318:5: D103 Missing docstring in public function
    |
318 | def plot_all_y_max(
    |     ^^^^^^^^^^^^^^ D103
319 |     res,
320 |     nb_iterations=100,
    |

utils\Search_results_plot.py:382:5: PLR0913 Too many arguments in function definition (8 > 5)
    |
382 | def plot_all_y_max_diff(
    |     ^^^^^^^^^^^^^^^^^^^ PLR0913
383 |     res,
384 |     nb_iterations=100,
    |

utils\Search_results_plot.py:382:5: D103 Missing docstring in public function
    |
382 | def plot_all_y_max_diff(
    |     ^^^^^^^^^^^^^^^^^^^ D103
383 |     res,
384 |     nb_iterations=100,
    |

utils\Search_results_plot.py:389:5: ARG001 Unused function argument: `target_name`
    |
387 |     label="BO",
388 |     nb_initialisation=0,
389 |     target_name="target",
    |     ^^^^^^^^^^^ ARG001
390 |     df_total=None,
391 | ):
    |

utils\Search_results_plot.py:439:5: PLR0913 Too many arguments in function definition (8 > 5)
    |
439 | def plot_y_mean(
    |     ^^^^^^^^^^^ PLR0913
440 |     res,
441 |     nb_iterations=100,
    |

utils\Search_results_plot.py:439:5: D103 Missing docstring in public function
    |
439 | def plot_y_mean(
    |     ^^^^^^^^^^^ D103
440 |     res,
441 |     nb_iterations=100,
    |

utils\Search_results_plot.py:453:5: N806 Variable `y_mean_mu_BO` in function should be lowercase
    |
451 |         df_total = []
452 |     nb_iterations_range = np.arange(nb_iterations) + 1
453 |     y_mean_mu_BO = -10 * np.ones(nb_iterations)
    |     ^^^^^^^^^^^^ N806
454 |     nb_runs = len(res)
455 |     for i in range(1, nb_iterations + 1):
    |

utils\Search_results_plot.py:483:5: PLR0913 Too many arguments in function definition (9 > 5)
    |
483 | def plot_number_of_molecule_discovered(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
484 |     res,
485 |     nb_iterations=100,
    |

utils\Search_results_plot.py:483:5: D103 Missing docstring in public function
    |
483 | def plot_number_of_molecule_discovered(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
484 |     res,
485 |     nb_iterations=100,
    |

utils\Search_results_plot.py:486:5: N803 Argument name `topKmol` should be lowercase
    |
484 |     res,
485 |     nb_iterations=100,
486 |     topKmol=1000,
    |     ^^^^^^^ N803
487 |     axs=None,
488 |     color=search_to_color["BO"],
    |

utils\Search_results_plot.py:496:5: N806 Variable `topKmol` in function should be lowercase
    |
494 |     if df_total is None:
495 |         df_total = []
496 |     topKmol = int(df_total.shape[0]*0.01)
    |     ^^^^^^^ N806
497 |     min_target = -np.sort(-df_total[target_name].values)[topKmol]
498 |     nb_iterations_range = np.arange(nb_iterations) + 1
    |

utils\Search_results_plot.py:497:28: PD011 Use `.to_numpy()` instead of `.values`
    |
495 |         df_total = []
496 |     topKmol = int(df_total.shape[0]*0.01)
497 |     min_target = -np.sort(-df_total[target_name].values)[topKmol]
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
498 |     nb_iterations_range = np.arange(nb_iterations) + 1
499 |     y_elm = -10 * np.ones(nb_iterations)
    |

utils\Search_results_plot.py:539:5: PLR0913 Too many arguments in function definition (11 > 5)
    |
539 | def plot_number_of_molecule_discovered_sum(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
540 |     res,
541 |     nb_iterations=100,
    |

utils\Search_results_plot.py:539:5: D103 Missing docstring in public function
    |
539 | def plot_number_of_molecule_discovered_sum(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
540 |     res,
541 |     nb_iterations=100,
    |

utils\Search_results_plot.py:542:5: N803 Argument name `topKmol` should be lowercase
    |
540 |     res,
541 |     nb_iterations=100,
542 |     topKmol=1000,
    |     ^^^^^^^ N803
543 |     axs=None,
544 |     color=search_to_color["BO"],
    |

utils\Search_results_plot.py:555:32: PD011 Use `.to_numpy()` instead of `.values`
    |
553 |         df_total = []
554 |     if topKmol is not None:
555 |         min_target = -np.sort(-df_total[target_name].values)[topKmol]
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
556 |     df_results = pd.concat(
557 |         list(
    |

utils\Search_results_plot.py:586:5: PLR0913 Too many arguments in function definition (11 > 5)
    |
584 |     return max(max_mol_found)
585 | 
586 | def plot_simple_regret_batch(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
587 |     res,
588 |     nb_iterations=100,
    |

utils\Search_results_plot.py:586:5: D103 Missing docstring in public function
    |
584 |     return max(max_mol_found)
585 | 
586 | def plot_simple_regret_batch(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^ D103
587 |     res,
588 |     nb_iterations=100,
    |

utils\Search_results_plot.py:589:5: N803 Argument name `topKmol` should be lowercase
    |
587 |     res,
588 |     nb_iterations=100,
589 |     topKmol=1000,
    |     ^^^^^^^ N803
590 |     axs=None,
591 |     color=search_to_color["BO"],
    |

utils\Search_results_plot.py:602:32: PD011 Use `.to_numpy()` instead of `.values`
    |
600 |         df_total = []
601 |     if topKmol is not None:
602 |         min_target = -np.sort(-df_total[target_name].values)[topKmol]
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
603 |     df_results = pd.concat(
604 |         list(
    |

utils\Search_results_plot.py:630:5: PLR0913 Too many arguments in function definition (11 > 5)
    |
630 | def plot_total_rate_of_discovery(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
631 |     res,
632 |     nb_iterations=100,
    |

utils\Search_results_plot.py:630:5: D103 Missing docstring in public function
    |
630 | def plot_total_rate_of_discovery(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
631 |     res,
632 |     nb_iterations=100,
    |

utils\Search_results_plot.py:633:5: N803 Argument name `topKmol` should be lowercase
    |
631 |     res,
632 |     nb_iterations=100,
633 |     topKmol=1000,
    |     ^^^^^^^ N803
634 |     axs=None,
635 |     color=search_to_color["BO"],
    |

utils\Search_results_plot.py:646:32: PD011 Use `.to_numpy()` instead of `.values`
    |
644 |         df_total = []
645 |     if topKmol is not None:
646 |         min_target = -np.sort(-df_total[target_name].values)[topKmol]
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
647 |     df_results = pd.concat(
648 |         list(
    |

utils\Search_results_plot.py:681:5: PLR0913 Too many arguments in function definition (11 > 5)
    |
681 | def plot_rate_of_discovery(
    |     ^^^^^^^^^^^^^^^^^^^^^^ PLR0913
682 |     res,
683 |     nb_iterations=350,
    |

utils\Search_results_plot.py:681:5: D103 Missing docstring in public function
    |
681 | def plot_rate_of_discovery(
    |     ^^^^^^^^^^^^^^^^^^^^^^ D103
682 |     res,
683 |     nb_iterations=350,
    |

utils\Search_results_plot.py:684:5: N803 Argument name `topKmol` should be lowercase
    |
682 |     res,
683 |     nb_iterations=350,
684 |     topKmol=1000,
    |     ^^^^^^^ N803
685 |     axs=None,
686 |     color="C0",
    |

utils\Search_results_plot.py:696:5: N806 Variable `topKmol` in function should be lowercase
    |
694 |     if df_total is None:
695 |         df_total = []
696 |     topKmol = int(df_total.shape[0]*0.01)
    |     ^^^^^^^ N806
697 |     if topKmol is not None:
698 |         min_target = -np.sort(-df_total[target_name].values)[topKmol]
    |

utils\Search_results_plot.py:698:32: PD011 Use `.to_numpy()` instead of `.values`
    |
696 |     topKmol = int(df_total.shape[0]*0.01)
697 |     if topKmol is not None:
698 |         min_target = -np.sort(-df_total[target_name].values)[topKmol]
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
699 |     y_results = np.zeros((nb_iterations + nb_initialisation, len(res)))
700 |     top_mol_inchikey_list = df_total[df_total[target_name] > min_target][
    |

utils\Search_results_plot.py:700:29: PD011 Use `.to_numpy()` instead of `.values`
    |
698 |           min_target = -np.sort(-df_total[target_name].values)[topKmol]
699 |       y_results = np.zeros((nb_iterations + nb_initialisation, len(res)))
700 |       top_mol_inchikey_list = df_total[df_total[target_name] > min_target][
    |  _____________________________^
701 | |         "InChIKey"
702 | |     ].values
    | |____________^ PD011
703 |       nb_iterations_range = np.arange(0, nb_iterations)
704 |       for ii, results in enumerate(res):
    |

utils\Search_results_plot.py:718:5: ERA001 Found commented-out code
    |
716 |     y_elm = np.mean(y_results, axis=1)
717 |     # get bottom  variance of data
718 |     #y_elm_sig_bot = np.std(y_results[y_results < y_elm], axis=1)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
719 |     #y_elm_sig_top = np.std(y_results[y_results > y_elm], axis=1)
720 |     y_elm_sig_bot = np.array([np.std(row[row < y_elm[i]]) for i, row in enumerate(y_results)])
    |
    = help: Remove commented-out code

utils\Search_results_plot.py:719:5: ERA001 Found commented-out code
    |
717 |     # get bottom  variance of data
718 |     #y_elm_sig_bot = np.std(y_results[y_results < y_elm], axis=1)
719 |     #y_elm_sig_top = np.std(y_results[y_results > y_elm], axis=1)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
720 |     y_elm_sig_bot = np.array([np.std(row[row < y_elm[i]]) for i, row in enumerate(y_results)])
721 |     y_elm_sig_top = np.array([np.std(row[row > y_elm[i]]) for i, row in enumerate(y_results)])
    |
    = help: Remove commented-out code

utils\Search_results_plot.py:738:5: PLR0913 Too many arguments in function definition (6 > 5)
    |
738 | def plot_hist_mol_found(
    |     ^^^^^^^^^^^^^^^^^^^ PLR0913
739 |     search_results,
740 |     target_name,
    |

utils\Search_results_plot.py:738:5: D103 Missing docstring in public function
    |
738 | def plot_hist_mol_found(
    |     ^^^^^^^^^^^^^^^^^^^ D103
739 |     search_results,
740 |     target_name,
    |

utils\Search_results_plot.py:746:5: N806 Variable `INchikeys_found` in function should be lowercase
    |
744 |     color=search_to_color["BO"],
745 | ):
746 |     INchikeys_found = []
    |     ^^^^^^^^^^^^^^^ N806
747 |     for search_result in search_results:
748 |         INchikeys_found.append(
    |

utils\Search_results_plot.py:748:9: PERF401 Use a list comprehension to create a transformed list
    |
746 |       INchikeys_found = []
747 |       for search_result in search_results:
748 |           INchikeys_found.append(
    |  _________^
749 | |             search_result["InchiKey_acquired"][num_elem_initialisation:]
750 | |         )
    | |_________^ PERF401
751 |       INchikeys_found = np.concatenate(INchikeys_found)
752 |       df_total_found = df_total[df_total["InChIKey"].isin(INchikeys_found)]
    |

utils\Search_results_plot.py:751:5: N806 Variable `INchikeys_found` in function should be lowercase
    |
749 |             search_result["InchiKey_acquired"][num_elem_initialisation:]
750 |         )
751 |     INchikeys_found = np.concatenate(INchikeys_found)
    |     ^^^^^^^^^^^^^^^ N806
752 |     df_total_found = df_total[df_total["InChIKey"].isin(INchikeys_found)]
753 |     df_total_found[target_name].hist(
    |

utils\Search_results_plot.py:762:5: ERA001 Found commented-out code
    |
760 |     )
761 |     axs.set_ylim([df_total[target_name].min(), df_total[target_name].max()])
762 |     # axs.set_xscale('log')
    |     ^^^^^^^^^^^^^^^^^^^^^^^ ERA001
763 |     # axs.set_xlim([0.9,1e4])
    |
    = help: Remove commented-out code

utils\Search_results_plot.py:763:5: ERA001 Found commented-out code
    |
761 |     axs.set_ylim([df_total[target_name].min(), df_total[target_name].max()])
762 |     # axs.set_xscale('log')
763 |     # axs.set_xlim([0.9,1e4])
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
    |
    = help: Remove commented-out code

utils\Search_results_plot.py:766:5: PLR0913 Too many arguments in function definition (11 > 5)
    |
766 | def plot_exploration_evolution(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
767 |     BOresults,
768 |     df_total_org,
    |

utils\Search_results_plot.py:766:5: D103 Missing docstring in public function
    |
766 | def plot_exploration_evolution(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
767 |     BOresults,
768 |     df_total_org,
    |

utils\Search_results_plot.py:767:5: N803 Argument name `BOresults` should be lowercase
    |
766 | def plot_exploration_evolution(
767 |     BOresults,
    |     ^^^^^^^^^ N803
768 |     df_total_org,
769 |     nb_initialisation,
    |

utils\Search_results_plot.py:769:5: ARG001 Unused function argument: `nb_initialisation`
    |
767 |     BOresults,
768 |     df_total_org,
769 |     nb_initialisation,
    |     ^^^^^^^^^^^^^^^^^ ARG001
770 |     nb_iteration=100,
771 |     axs=None,
    |

utils\Search_results_plot.py:777:5: N803 Argument name `topKmol` should be lowercase
    |
775 |     target_name="target",
776 |     aim=5.5,
777 |     topKmol=1000,
    |     ^^^^^^^ N803
778 | ):
    |

utils\Search_results_plot.py:784:44: PD011 Use `.to_numpy()` instead of `.values`
    |
782 |         lambda x: -np.sqrt((x - aim) ** 2)
783 |     )
784 |     min_target_out_of_database = -np.sort(-df_total[target_name].values)[
    |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
785 |         topKmol
786 |     ]
    |

utils\Search_results_plot.py:787:43: F821 Undefined name `plot_element_above_min`
    |
785 |         topKmol
786 |     ]
787 |     y_elm, y_elm_sig_bot, y_elm_sig_top = plot_element_above_min(
    |                                           ^^^^^^^^^^^^^^^^^^^^^^ F821
788 |         BOresults,
789 |         min_target_out_of_database,
    |

utils\Search_results_plot.py:808:5: N806 Variable `y_max_mu_BO` in function should be lowercase
    |
806 |         nb_initialisation=0,
807 |     )
808 |     y_max_mu_BO, y_max_sig_bot_BO, y_max_sig_top_BO = plot_y_max(
    |     ^^^^^^^^^^^ N806
809 |         BOresults,
810 |         nb_iterations=nb_iteration,
    |

utils\Search_results_plot.py:808:18: N806 Variable `y_max_sig_bot_BO` in function should be lowercase
    |
806 |         nb_initialisation=0,
807 |     )
808 |     y_max_mu_BO, y_max_sig_bot_BO, y_max_sig_top_BO = plot_y_max(
    |                  ^^^^^^^^^^^^^^^^ N806
809 |         BOresults,
810 |         nb_iterations=nb_iteration,
    |

utils\Search_results_plot.py:808:36: N806 Variable `y_max_sig_top_BO` in function should be lowercase
    |
806 |         nb_initialisation=0,
807 |     )
808 |     y_max_mu_BO, y_max_sig_bot_BO, y_max_sig_top_BO = plot_y_max(
    |                                    ^^^^^^^^^^^^^^^^ N806
809 |         BOresults,
810 |         nb_iterations=nb_iteration,
    |

utils\Search_results_plot.py:819:5: ERA001 Found commented-out code
    |
817 |         nb_initialisation=0,
818 |     )
819 |     # df_total[target_name].hist(ax=axs[3], bins=20, orientation="horizontal", color=search_to_color['BO'])
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
820 |     # axs[3].set_ylim([df_total[target_name].min(),df_total[target_name].max()])
821 |     min_target_out_of_database = -np.sort(-df_total[target_name].values)[100]
    |
    = help: Remove commented-out code

utils\Search_results_plot.py:820:5: ERA001 Found commented-out code
    |
818 |     )
819 |     # df_total[target_name].hist(ax=axs[3], bins=20, orientation="horizontal", color=search_to_color['BO'])
820 |     # axs[3].set_ylim([df_total[target_name].min(),df_total[target_name].max()])
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
821 |     min_target_out_of_database = -np.sort(-df_total[target_name].values)[100]
822 |     y_elm, y_elm_sig_bot, y_elm_sig_top = plot_element_above_min(
    |
    = help: Remove commented-out code

utils\Search_results_plot.py:821:44: PD011 Use `.to_numpy()` instead of `.values`
    |
819 |     # df_total[target_name].hist(ax=axs[3], bins=20, orientation="horizontal", color=search_to_color['BO'])
820 |     # axs[3].set_ylim([df_total[target_name].min(),df_total[target_name].max()])
821 |     min_target_out_of_database = -np.sort(-df_total[target_name].values)[100]
    |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
822 |     y_elm, y_elm_sig_bot, y_elm_sig_top = plot_element_above_min(
823 |         BOresults,
    |

utils\Search_results_plot.py:822:43: F821 Undefined name `plot_element_above_min`
    |
820 |     # axs[3].set_ylim([df_total[target_name].min(),df_total[target_name].max()])
821 |     min_target_out_of_database = -np.sort(-df_total[target_name].values)[100]
822 |     y_elm, y_elm_sig_bot, y_elm_sig_top = plot_element_above_min(
    |                                           ^^^^^^^^^^^^^^^^^^^^^^ F821
823 |         BOresults,
824 |         min_target_out_of_database,
    |

utils\Search_results_plot.py:837:5: D103 Missing docstring in public function
    |
837 | def load_search_data(search_type, date, test_name, min_eval=100):
    |     ^^^^^^^^^^^^^^^^ D103
838 |     files = glob.glob(
839 |         f"data/output/search_experiment/{test_name}/"
    |

utils\Search_results_plot.py:838:13: PTH207 Replace `glob` with `Path.glob` or `Path.rglob`
    |
837 | def load_search_data(search_type, date, test_name, min_eval=100):
838 |     files = glob.glob(
    |             ^^^^^^^^^ PTH207
839 |         f"data/output/search_experiment/{test_name}/"
840 |         + search_type
    |

utils\Search_results_plot.py:845:5: N806 Variable `BOresults` in function should be lowercase
    |
843 |         + "/*.pkl"
844 |     )
845 |     BOresults = []
    |     ^^^^^^^^^ N806
846 |     max_num_eval = 0
847 |     for file in files:
    |

utils\Search_results_plot.py:849:14: PTH123 `open()` should be replaced by `Path.open()`
    |
847 |     for file in files:
848 | 
849 |         with open(file, "rb") as f:
    |              ^^^^ PTH123
850 |             results = pickle.load(f)
851 |             if len(results["fitness_acquired"]) > min_eval:
    |

utils\Search_results_plot.py:850:23: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
    |
849 |         with open(file, "rb") as f:
850 |             results = pickle.load(f)
    |                       ^^^^^^^^^^^^^^ S301
851 |             if len(results["fitness_acquired"]) > min_eval:
852 |                 BOresults.append(results)
    |

utils\Search_results_plot.py:872:9: A001 Variable `dict` is shadowing a Python builtin
    |
870 |     """
871 |     for dict_org in search_results:
872 |         dict = dict_org.copy()
    |         ^^^^ A001
873 | 
874 |         dict.pop("searched_space_df")
    |

utils\Search_results_plot.py:875:9: PD901 Avoid using the generic variable name `df` for DataFrames
    |
874 |         dict.pop("searched_space_df")
875 |         df = pd.DataFrame.from_records(dict)
    |         ^^ PD901
876 |         df = df[df["ids_acquired"] < max_iteration]
877 |         df = df[df["ids_acquired"] > num_initialisation]
    |

utils\Search_results_plot.py:876:9: PD901 Avoid using the generic variable name `df` for DataFrames
    |
874 |         dict.pop("searched_space_df")
875 |         df = pd.DataFrame.from_records(dict)
876 |         df = df[df["ids_acquired"] < max_iteration]
    |         ^^ PD901
877 |         df = df[df["ids_acquired"] > num_initialisation]
878 |         yield df
    |

utils\Search_results_plot.py:877:9: PD901 Avoid using the generic variable name `df` for DataFrames
    |
875 |         df = pd.DataFrame.from_records(dict)
876 |         df = df[df["ids_acquired"] < max_iteration]
877 |         df = df[df["ids_acquired"] > num_initialisation]
    |         ^^ PD901
878 |         yield df
    |

utils\Search_results_plot.py:881:5: PLR0913 Too many arguments in function definition (6 > 5)
    |
881 | def get_df_max_found(
    |     ^^^^^^^^^^^^^^^^ PLR0913
882 |     search_results,
883 |     df_total,
    |

utils\Search_results_plot.py:881:5: D417 Missing argument description in the docstring for `get_df_max_found`: `target_name`
    |
881 | def get_df_max_found(
    |     ^^^^^^^^^^^^^^^^ D417
882 |     search_results,
883 |     df_total,
    |

utils\Search_results_plot.py:885:5: N803 Argument name `topKmol` should be lowercase
    |
883 |     df_total,
884 |     max_iteration=200,
885 |     topKmol=1000,
    |     ^^^^^^^ N803
886 |     num_initialisation=0,
887 |     target_name="target",
    |

utils\Search_results_plot.py:918:5: PLR0913 Too many arguments in function definition (6 > 5)
    |
918 | def get_df_max_target_found(
    |     ^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
919 |     search_results,
920 |     df_total,
    |

utils\Search_results_plot.py:918:5: D417 Missing argument descriptions in the docstring for `get_df_max_target_found`: `min_target`, `target_name`
    |
918 | def get_df_max_target_found(
    |     ^^^^^^^^^^^^^^^^^^^^^^^ D417
919 |     search_results,
920 |     df_total,
    |

utils\Search_results_plot.py:955:5: D103 Missing docstring in public function
    |
955 | def get_clusters(df):
    |     ^^^^^^^^^^^^ D103
956 |     hdb_model = HDBSCAN(min_cluster_size=1000, min_samples=100)
957 |     # Fit the model to the average PCA scores
    |

utils\Search_results_plot.py:963:5: D103 Missing docstring in public function
    |
963 | def plot_space_with_target(df, target_name="target", ax=None, size_of_bin=1):
    |     ^^^^^^^^^^^^^^^^^^^^^^ D103
964 | 
965 |     list_target_splits = [
    |

utils\Search_results_plot.py:966:9: PD011 Use `.to_numpy()` instead of `.values`
    |
965 |     list_target_splits = [
966 |         df[df[target_name] > i][target_name].values
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
967 |         for i in range(
968 |             int(df[target_name].min()), int(df[target_name].max()), size_of_bin
    |

utils\Search_results_plot.py:984:5: D103 Missing docstring in public function
    |
984 | def oligomer_cluster_plot(
    |     ^^^^^^^^^^^^^^^^^^^^^ D103
985 |     df,
986 |     target_name="target",
    |

utils\Search_results_plot.py:991:9: PD901 Avoid using the generic variable name `df` for DataFrames
    |
989 |     fig, ax = plt.subplots(1, 3, figsize=(30, 10))
990 |     if "Cluster" not in df.columns:
991 |         df = get_clusters(df)
    |         ^^ PD901
992 |     for cluster in df["Cluster"].unique():
993 |         df_total_cluster = df[df["Cluster"] == cluster]
    |

utils\Search_results_plot.py:1027:5: D103 Missing docstring in public function
     |
1027 | def load_search_data(search_type, date, test_name, min_eval=100):
     |     ^^^^^^^^^^^^^^^^ D103
1028 |     files = glob.glob(
1029 |         f"data/output/search_experiment/{test_name}/"
     |

utils\Search_results_plot.py:1027:5: F811 Redefinition of unused `load_search_data` from line 837
     |
1027 | def load_search_data(search_type, date, test_name, min_eval=100):
     |     ^^^^^^^^^^^^^^^^ F811
1028 |     files = glob.glob(
1029 |         f"data/output/search_experiment/{test_name}/"
     |
     = help: Remove definition: `load_search_data`

utils\Search_results_plot.py:1028:13: PTH207 Replace `glob` with `Path.glob` or `Path.rglob`
     |
1027 | def load_search_data(search_type, date, test_name, min_eval=100):
1028 |     files = glob.glob(
     |             ^^^^^^^^^ PTH207
1029 |         f"data/output/search_experiment/{test_name}/"
1030 |         + search_type
     |

utils\Search_results_plot.py:1035:5: N806 Variable `BOresults` in function should be lowercase
     |
1033 |         + "/*.pkl"
1034 |     )
1035 |     BOresults = []
     |     ^^^^^^^^^ N806
1036 |     max_num_eval = 0
1037 |     for file in files:
     |

utils\Search_results_plot.py:1039:14: PTH123 `open()` should be replaced by `Path.open()`
     |
1037 |     for file in files:
1038 | 
1039 |         with open(file, "rb") as f:
     |              ^^^^ PTH123
1040 |             results = pickle.load(f)
1041 |             if len(results["fitness_acquired"]) > min_eval:
     |

utils\Search_results_plot.py:1040:23: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
     |
1039 |         with open(file, "rb") as f:
1040 |             results = pickle.load(f)
     |                       ^^^^^^^^^^^^^^ S301
1041 |             if len(results["fitness_acquired"]) > min_eval:
1042 |                 BOresults.append(results)
     |

utils\Search_results_plot.py:1049:5: N802 Function name `plot_BO_results_in_space` should be lowercase
     |
1049 | def plot_BO_results_in_space(BOresults, ax, title_label, df_rep):
     |     ^^^^^^^^^^^^^^^^^^^^^^^^ N802
1050 |     bo = BOresults.copy()
1051 |     bo.pop("searched_space_df")
     |

utils\Search_results_plot.py:1049:5: D103 Missing docstring in public function
     |
1049 | def plot_BO_results_in_space(BOresults, ax, title_label, df_rep):
     |     ^^^^^^^^^^^^^^^^^^^^^^^^ D103
1050 |     bo = BOresults.copy()
1051 |     bo.pop("searched_space_df")
     |

utils\Search_results_plot.py:1049:30: N803 Argument name `BOresults` should be lowercase
     |
1049 | def plot_BO_results_in_space(BOresults, ax, title_label, df_rep):
     |                              ^^^^^^^^^ N803
1050 |     bo = BOresults.copy()
1051 |     bo.pop("searched_space_df")
     |

utils\Search_results_plot.py:1056:9: ANN202 Missing return type annotation for private function `plot_pca_space_results`
     |
1054 |     df_plot_results = pd_results.merge(df_rep, on="InChIKey", how="left")
1055 | 
1056 |     def plot_pca_space_results(
     |         ^^^^^^^^^^^^^^^^^^^^^^ ANN202
1057 |         df_tot_plot, df_plot_results, property_name, added_text=""
1058 |     ):
     |
     = help: Add return type annotation

utils\Search_results_plot.py:1057:39: ARG001 Unused function argument: `property_name`
     |
1056 |     def plot_pca_space_results(
1057 |         df_tot_plot, df_plot_results, property_name, added_text=""
     |                                       ^^^^^^^^^^^^^ ARG001
1058 |     ):
     |

utils\Search_results_plot.py:1092:5: D103 Missing docstring in public function
     |
1092 | def plot_df_results_in_space(pd_results, ax, title_label, df_rep):
     |     ^^^^^^^^^^^^^^^^^^^^^^^^ D103
1093 | 
1094 |     df_plot_results = pd_results.merge(
     |

utils\Search_results_plot.py:1098:9: ANN202 Missing return type annotation for private function `plot_pca_space_results`
     |
1096 |     )
1097 | 
1098 |     def plot_pca_space_results(
     |         ^^^^^^^^^^^^^^^^^^^^^^ ANN202
1099 |         df_tot_plot, df_plot_results, property_name, added_text=""
1100 |     ):
     |
     = help: Add return type annotation

utils\Search_results_plot.py:1099:39: ARG001 Unused function argument: `property_name`
     |
1098 |     def plot_pca_space_results(
1099 |         df_tot_plot, df_plot_results, property_name, added_text=""
     |                                       ^^^^^^^^^^^^^ ARG001
1100 |     ):
     |

utils\Search_results_plot.py:1134:5: D103 Missing docstring in public function
     |
1134 | def plot_df_max_in_space(pd_results, ax, title_label, df_rep):
     |     ^^^^^^^^^^^^^^^^^^^^ D103
1135 | 
1136 |     df_plot_results = pd_results.merge(
     |

utils\Search_results_plot.py:1141:39: ARG001 Unused function argument: `property_name`
     |
1140 |     def plot_pca_space_results(
1141 |         df_tot_plot, df_plot_results, property_name, added_text=""
     |                                       ^^^^^^^^^^^^^ ARG001
1142 |     ) -> None:
     |

utils\Search_results_plot.py:1144:9: ERA001 Found commented-out code
     |
1142 |     ) -> None:
1143 | 
1144 |         # ax.scatter(df_all_plot_morgan['PCA1'], df_all_plot_morgan['PCA2'], c='black', s=20, alpha=0.9, label='random generation')
     |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
1145 | 
1146 |         ax.scatter(
     |
     = help: Remove commented-out code

utils\Search_results_plot.py:1171:5: D103 Missing docstring in public function
     |
1171 | def plot_pca_space(df_tot_plot, property_name, added_text="", ax=None):
     |     ^^^^^^^^^^^^^^ D103
1172 | 
1173 |     # ax.scatter(df_all_plot_morgan['PCA1'], df_all_plot_morgan['PCA2'], c='black', s=20, alpha=0.9, label='random generation')
     |

utils\Search_results_plot.py:1173:5: ERA001 Found commented-out code
     |
1171 | def plot_pca_space(df_tot_plot, property_name, added_text="", ax=None):
1172 | 
1173 |     # ax.scatter(df_all_plot_morgan['PCA1'], df_all_plot_morgan['PCA2'], c='black', s=20, alpha=0.9, label='random generation')
     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
1174 | 
1175 |     cax = ax.scatter(
     |
     = help: Remove commented-out code

utils\Search_results_plot.py:1192:5: D103 Missing docstring in public function
     |
1192 | def get_rep_pca(InChIKey, dataset_dict, pca_kernel):
     |     ^^^^^^^^^^^ D103
1193 |     learned_rpr = (
1194 |         dataset_dict[InChIKey].learned_rpr.detach().numpy().reshape(1, -1)
     |

utils\Search_results_plot.py:1192:17: N803 Argument name `InChIKey` should be lowercase
     |
1192 | def get_rep_pca(InChIKey, dataset_dict, pca_kernel):
     |                 ^^^^^^^^ N803
1193 |     learned_rpr = (
1194 |         dataset_dict[InChIKey].learned_rpr.detach().numpy().reshape(1, -1)
     |

utils\config_utils.py:1:1: INP001 File `utils\config_utils.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\config_utils.py:1:1: D100 Missing docstring in public module
utils\config_utils.py:8:5: PLR0915 Too many statements (141 > 50)
   |
 8 | def read_config(dir, model_name=""):
   |     ^^^^^^^^^^^ PLR0915
 9 |     if os.path.exists(dir + "/config.json"):
10 |         config = load_config(dir)
   |

utils\config_utils.py:8:5: D103 Missing docstring in public function
   |
 8 | def read_config(dir, model_name=""):
   |     ^^^^^^^^^^^ D103
 9 |     if os.path.exists(dir + "/config.json"):
10 |         config = load_config(dir)
   |

utils\config_utils.py:8:17: A002 Argument `dir` is shadowing a Python builtin
   |
 8 | def read_config(dir, model_name=""):
   |                 ^^^ A002
 9 |     if os.path.exists(dir + "/config.json"):
10 |         config = load_config(dir)
   |

utils\config_utils.py:9:8: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   |
 8 | def read_config(dir, model_name=""):
 9 |     if os.path.exists(dir + "/config.json"):
   |        ^^^^^^^^^^^^^^ PTH110
10 |         config = load_config(dir)
11 |     else:
   |

utils\config_utils.py:166:5: D103 Missing docstring in public function
    |
166 | def save_config(config, dir):
    |     ^^^^^^^^^^^ D103
167 |     os.makedirs(dir, exist_ok=True)
168 |     # save config to json
    |

utils\config_utils.py:166:25: A002 Argument `dir` is shadowing a Python builtin
    |
166 | def save_config(config, dir):
    |                         ^^^ A002
167 |     os.makedirs(dir, exist_ok=True)
168 |     # save config to json
    |

utils\config_utils.py:167:5: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
    |
166 | def save_config(config, dir):
167 |     os.makedirs(dir, exist_ok=True)
    |     ^^^^^^^^^^^ PTH103
168 |     # save config to json
169 |     with open(dir + "/config.json", "w") as f:
    |

utils\config_utils.py:169:10: PTH123 `open()` should be replaced by `Path.open()`
    |
167 |     os.makedirs(dir, exist_ok=True)
168 |     # save config to json
169 |     with open(dir + "/config.json", "w") as f:
    |          ^^^^ PTH123
170 |         json.dump(config, f, indent=4, separators=(",", ": "), sort_keys=True)
    |

utils\config_utils.py:173:5: D103 Missing docstring in public function
    |
173 | def load_config(dir):
    |     ^^^^^^^^^^^ D103
174 |     # load config from json
175 |     with open(dir + "/config.json") as f:
    |

utils\config_utils.py:173:17: A002 Argument `dir` is shadowing a Python builtin
    |
173 | def load_config(dir):
    |                 ^^^ A002
174 |     # load config from json
175 |     with open(dir + "/config.json") as f:
    |

utils\config_utils.py:175:10: PTH123 `open()` should be replaced by `Path.open()`
    |
173 | def load_config(dir):
174 |     # load config from json
175 |     with open(dir + "/config.json") as f:
    |          ^^^^ PTH123
176 |         config = json.load(f)
177 |     config["device"] = "cuda" if torch.cuda.is_available() else "cpu"
    |

utils\config_utils.py:181:5: D103 Missing docstring in public function
    |
181 | def read_search_config(config_search_dir):
    |     ^^^^^^^^^^^^^^^^^^ D103
182 |     if os.path.exists(config_search_dir + "/config_search.json"):
183 |         config = load_search_config(config_search_dir)
    |

utils\config_utils.py:182:8: PTH110 `os.path.exists()` should be replaced by `Path.exists()`
    |
181 | def read_search_config(config_search_dir):
182 |     if os.path.exists(config_search_dir + "/config_search.json"):
    |        ^^^^^^^^^^^^^^ PTH110
183 |         config = load_search_config(config_search_dir)
184 |     else:
    |

utils\config_utils.py:208:5: D103 Missing docstring in public function
    |
208 | def save_search_config(config, dir):
    |     ^^^^^^^^^^^^^^^^^^ D103
209 |     os.makedirs(dir, exist_ok=True)
210 |     # save config to json
    |

utils\config_utils.py:208:32: A002 Argument `dir` is shadowing a Python builtin
    |
208 | def save_search_config(config, dir):
    |                                ^^^ A002
209 |     os.makedirs(dir, exist_ok=True)
210 |     # save config to json
    |

utils\config_utils.py:209:5: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
    |
208 | def save_search_config(config, dir):
209 |     os.makedirs(dir, exist_ok=True)
    |     ^^^^^^^^^^^ PTH103
210 |     # save config to json
211 |     with open(dir + "/config_search.json", "w") as f:
    |

utils\config_utils.py:211:10: PTH123 `open()` should be replaced by `Path.open()`
    |
209 |     os.makedirs(dir, exist_ok=True)
210 |     # save config to json
211 |     with open(dir + "/config_search.json", "w") as f:
    |          ^^^^ PTH123
212 |         json.dump(config, f, indent=4, separators=(",", ": "), sort_keys=True)
    |

utils\config_utils.py:215:5: D103 Missing docstring in public function
    |
215 | def load_search_config(dir):
    |     ^^^^^^^^^^^^^^^^^^ D103
216 |     # load config from json
217 |     with open(dir + "/config_search.json") as f:
    |

utils\config_utils.py:215:24: A002 Argument `dir` is shadowing a Python builtin
    |
215 | def load_search_config(dir):
    |                        ^^^ A002
216 |     # load config from json
217 |     with open(dir + "/config_search.json") as f:
    |

utils\config_utils.py:217:10: PTH123 `open()` should be replaced by `Path.open()`
    |
215 | def load_search_config(dir):
216 |     # load config from json
217 |     with open(dir + "/config_search.json") as f:
    |          ^^^^ PTH123
218 |         return json.load(f)
    |

utils\config_utils.py:221:5: PLR0913 Too many arguments in function definition (9 > 5)
    |
221 | def generate_config(
    |     ^^^^^^^^^^^^^^^ PLR0913
222 |     target_name="target",
223 |     aim=0.0,
    |

utils\config_utils.py:221:5: D103 Missing docstring in public function
    |
221 | def generate_config(
    |     ^^^^^^^^^^^^^^^ D103
222 |     target_name="target",
223 |     aim=0.0,
    |

utils\config_utils.py:223:5: ARG001 Unused function argument: `aim`
    |
221 | def generate_config(
222 |     target_name="target",
223 |     aim=0.0,
    |     ^^^ ARG001
224 |     num_molecules=20000,
225 |     max_epochs=100,
    |

utils\config_utils.py:233:16: DTZ005 `datetime.datetime.now()` called without a `tz` argument
    |
231 | ):
232 |     # get config and set it up
233 |     date_now = datetime.datetime.now().strftime("%y%m%d")
    |                ^^^^^^^^^^^^^^^^^^^^^^^ DTZ005
234 |     name = f"{num_fragment}-frag_{target_name}_{date_now}__{model_name}_split{split_type}-nummol{num_molecules}"
235 |     config_dir = running_dir + f"/{name.replace('_','/')}/"
    |
    = help: Pass a `datetime.timezone` object to the `tz` parameter

utils\config_utils.py:268:9: ISC003 Explicitly concatenated string should be implicitly concatenated
    |
266 |       config["split_type"] = split_type
267 |       config["dataset_all_path"] = (
268 |           "/rds/general/ephemeral/user/ma11115/ephemeral/STK_search/data/representation_learning/6-frag/target"
    |  _________^
269 | |         + "/dataset_all_schnet.pth"
    | |___________________________________^ ISC003
270 |       )
271 |       config["dataset_all_frag_path"] = (
    |

utils\config_utils.py:272:9: ISC003 Explicitly concatenated string should be implicitly concatenated
    |
270 |       )
271 |       config["dataset_all_frag_path"] = (
272 |           "/rds/general/ephemeral/user/ma11115/ephemeral/STK_search/data/representation_learning/6-frag/target"
    |  _________^
273 | |         + "/dataset_all_frag_schnet.pth"
    | |________________________________________^ ISC003
274 |       )
275 |       save_config(config, config_dir)
    |

utils\database_utils.py:1:1: INP001 File `utils\database_utils.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\database_utils.py:9:5: D103 Missing docstring in public function
   |
 8 | # read data in database
 9 | def load_data_database(
   |     ^^^^^^^^^^^^^^^^^^ D103
10 |     df_precursor_loc="Data/calculation_data_precursor_310823_clean.pkl",
11 |     num_fragm=6,
   |

utils\database_utils.py:13:49: PLR2004 Magic value used in comparison, consider replacing `6` with a constant variable
   |
11 |     num_fragm=6,
12 | ):
13 |     collection_name = "BO_exp1" if num_fragm == 6 else f"BO_{num_fragm}"
   |                                                 ^ PLR2004
14 | 
15 |     def load_data():
   |

utils\database_utils.py:15:9: ANN202 Missing return type annotation for private function `load_data`
   |
13 |     collection_name = "BO_exp1" if num_fragm == 6 else f"BO_{num_fragm}"
14 | 
15 |     def load_data():
   |         ^^^^^^^^^ ANN202
16 |         client = pymongo.MongoClient("mongodb://ch-atarzia.ch.ic.ac.uk/")
17 |         database = client["stk_mohammed_BO"]
   |
   = help: Add return type annotation

utils\database_utils.py:19:9: N806 Variable `df_IPEA` in function should be lowercase
   |
17 |         database = client["stk_mohammed_BO"]
18 |         collection = database[f"{collection_name}_IPEA"]
19 |         df_IPEA = pd.DataFrame(list(collection.find()))
   |         ^^^^^^^ N806
20 |         collection = database[f"{collection_name}_Stda"]
21 |         df_STDA = pd.DataFrame(list(collection.find()))
   |

utils\database_utils.py:21:9: N806 Variable `df_STDA` in function should be lowercase
   |
19 |         df_IPEA = pd.DataFrame(list(collection.find()))
20 |         collection = database[f"{collection_name}_Stda"]
21 |         df_STDA = pd.DataFrame(list(collection.find()))
   |         ^^^^^^^ N806
22 |         collection = database["constructed_molecules"]
23 |         df_CM = pd.DataFrame(list(collection.find()))
   |

utils\database_utils.py:23:9: N806 Variable `df_CM` in function should be lowercase
   |
21 |         df_STDA = pd.DataFrame(list(collection.find()))
22 |         collection = database["constructed_molecules"]
23 |         df_CM = pd.DataFrame(list(collection.find()))
   |         ^^^^^ N806
24 |         df_total = df_CM.merge(df_STDA, on="InChIKey", how="outer")
25 |         df_total = df_total.merge(df_IPEA, on="InChIKey", how="outer")
   |

utils\database_utils.py:39:57: PLR2004 Magic value used in comparison, consider replacing `11` with a constant variable
   |
37 |     df_total_new = df_total_new.dropna(subset=["fosc1", "BB"])
38 |     df_total_new = df_total_new[df_total_new["fosc1"] > 0]
39 |     df_total_new = df_total_new[df_total_new["fosc1"] < 11]
   |                                                         ^^ PLR2004
40 |     df_total_new["target"] = (
41 |         -np.abs(df_total_new["ES1"] - 3)
   |

utils\database_utils.py:46:9: ANN202 Missing return type annotation for private function `prepare_df_for_plot`
   |
44 |     )
45 | 
46 |     def prepare_df_for_plot(df_total_new=df_total_new):
   |         ^^^^^^^^^^^^^^^^^^^ ANN202
47 |         df_test = df_total_new
48 |         for id, x in df_test.iterrows():
   |
   = help: Add return type annotation

utils\database_utils.py:48:13: A001 Variable `id` is shadowing a Python builtin
   |
46 |     def prepare_df_for_plot(df_total_new=df_total_new):
47 |         df_test = df_total_new
48 |         for id, x in df_test.iterrows():
   |             ^^ A001
49 |             # print(x)
50 |             if len(x["BB"]) != num_fragm:
   |

utils\database_utils.py:49:13: ERA001 Found commented-out code
   |
47 |         df_test = df_total_new
48 |         for id, x in df_test.iterrows():
49 |             # print(x)
   |             ^^^^^^^^^^ ERA001
50 |             if len(x["BB"]) != num_fragm:
51 |                 df_test = df_test.drop(id)
   |
   = help: Remove commented-out code

utils\database_utils.py:52:25: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
   |
50 |             if len(x["BB"]) != num_fragm:
51 |                 df_test = df_test.drop(id)
52 |         df_precursors = pd.read_pickle(df_precursor_loc)
   |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ S301
53 |         for i in range(num_fragm):
54 |             df_test[f"InChIKey_{i}"] = df_test["BB"].apply(
   |

utils\database_utils.py:55:33: B023 Function definition does not bind loop variable `i`
   |
53 |         for i in range(num_fragm):
54 |             df_test[f"InChIKey_{i}"] = df_test["BB"].apply(
55 |                 lambda x: str(x[i]["InChIKey"])
   |                                 ^ B023
56 |             )
57 |             df_test= df_test[df_test[f"InChIKey_{i}"].isin(df_precursors["InChIKey"])]
   |

utils\database_utils.py:65:5: D103 Missing docstring in public function
   |
64 | # or load data from files
65 | def load_data_from_file(
   |     ^^^^^^^^^^^^^^^^^^^ D103
66 |     df_path="",
67 |     df_precursors_path="Data/calculation_data_precursor_310823_clean.pkl",
   |

utils\database_utils.py:69:5: FBT002 Boolean default positional argument in function definition
   |
67 |     df_precursors_path="Data/calculation_data_precursor_310823_clean.pkl",
68 |     features_frag=None,
69 |     add_feature_frag=True,
   |     ^^^^^^^^^^^^^^^^ FBT002
70 |     num_fragm=6,
71 | ):
   |

utils\database_utils.py:72:9: ANN202 Missing return type annotation for private function `prepare_df_for_plot`
   |
70 |     num_fragm=6,
71 | ):
72 |     def prepare_df_for_plot(
   |         ^^^^^^^^^^^^^^^^^^^ ANN202
73 |         df_total_new: pd.DataFrame = None, features_frag=features_frag
74 |     ):
   |
   = help: Add return type annotation

utils\database_utils.py:78:25: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
   |
76 |             df_total_new = []
77 |         df_test = df_total_new
78 |         df_precursors = pd.read_pickle(df_precursors_path)
   |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ S301
79 |         if features_frag is None:
80 |             # consider only columns that are np.number
   |

utils\database_utils.py:98:25: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
    |
 97 |     if df_path == "":
 98 |         df_precursors = pd.read_pickle(df_precursors_path)
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ S301
 99 |         return None, df_precursors
100 |     else:
    |

utils\database_utils.py:100:5: RET505 Unnecessary `else` after `return` statement
    |
 98 |         df_precursors = pd.read_pickle(df_precursors_path)
 99 |         return None, df_precursors
100 |     else:
    |     ^^^^ RET505
101 |         df_total = pd.read_csv(df_path)
102 |         if add_feature_frag:
    |
    = help: Remove unnecessary `else`

utils\database_utils.py:107:29: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
    |
105 |             )
106 |         else:
107 |             df_precursors = pd.read_pickle(df_precursors_path)
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ S301
108 |         return df_total, df_precursors
    |

utils\database_utils.py:111:5: D103 Missing docstring in public function
    |
111 | def load_precursors_df(
    |     ^^^^^^^^^^^^^^^^^^ D103
112 |     df_precursors_path="Data/calculation_data_precursor_310823_clean.pkl",
113 | ):
    |

utils\database_utils.py:115:12: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
    |
113 | ):
114 | 
115 |     return pd.read_pickle(df_precursors_path)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ S301
    |

utils\database_utils.py:119:5: D103 Missing docstring in public function
    |
119 | def save_data(
    |     ^^^^^^^^^ D103
120 |     df_total, stk_path="/rds/general/user/ma11115/home/STK_Search/STK_search"
121 | ):
    |

utils\database_utils.py:124:11: DTZ005 `datetime.datetime.now()` called without a `tz` argument
    |
122 |     import datetime
123 | 
124 |     now = datetime.datetime.now()
    |           ^^^^^^^^^^^^^^^^^^^^^^^ DTZ005
125 |     now = now.strftime("%Y-%m-%d")
126 |     df_total.to_csv(stk_path + f"/data/output/Full_dataset/df_total_{now}.csv")
    |
    = help: Pass a `datetime.timezone` object to the `tz` parameter

utils\get_modred_descriptors.py:1:1: INP001 File `utils\get_modred_descriptors.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\get_modred_descriptors.py:1:1: D100 Missing docstring in public module
utils\get_modred_descriptors.py:9:5: D103 Missing docstring in public function
   |
 9 | def main(df_total_path,save_path,number=0):
   |     ^^^^ D103
10 |     os.makedirs(save_path, exist_ok=True)
11 |     df_total = pd.read_csv(df_total_path)
   |

utils\get_modred_descriptors.py:10:5: PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   |
 9 | def main(df_total_path,save_path,number=0):
10 |     os.makedirs(save_path, exist_ok=True)
   |     ^^^^^^^^^^^ PTH103
11 |     df_total = pd.read_csv(df_total_path)
12 |     df_total["mol"] = df_total["InChIKey"].apply(tanimoto_similarity_utils.get_mol_from_df_single)
   |

utils\get_modred_descriptors.py:21:5: ERA001 Found commented-out code
   |
19 |     descriptors_df = descriptors_df.reset_index(drop=True)
20 |     descriptors_df.to_csv(save_path+f"descriptors_{number}.csv", index=False)
21 |     #pca = PCA(n_components=2)
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
22 |     #frag_properties = descriptors_df.select_dtypes(include=[np.number]).columns
23 |     #pca_transformed = pca.fit_transform(descriptors_df[frag_properties])
   |
   = help: Remove commented-out code

utils\get_modred_descriptors.py:22:5: ERA001 Found commented-out code
   |
20 |     descriptors_df.to_csv(save_path+f"descriptors_{number}.csv", index=False)
21 |     #pca = PCA(n_components=2)
22 |     #frag_properties = descriptors_df.select_dtypes(include=[np.number]).columns
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
23 |     #pca_transformed = pca.fit_transform(descriptors_df[frag_properties])
24 |     #pca_df = pd.DataFrame(pca_transformed, columns=["PC1", "PC2"])
   |
   = help: Remove commented-out code

utils\get_modred_descriptors.py:23:5: ERA001 Found commented-out code
   |
21 |     #pca = PCA(n_components=2)
22 |     #frag_properties = descriptors_df.select_dtypes(include=[np.number]).columns
23 |     #pca_transformed = pca.fit_transform(descriptors_df[frag_properties])
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
24 |     #pca_df = pd.DataFrame(pca_transformed, columns=["PC1", "PC2"])
25 |     #pca_df["InChIKey"] = descriptors_df["InChIKey"]
   |
   = help: Remove commented-out code

utils\get_modred_descriptors.py:24:5: ERA001 Found commented-out code
   |
22 |     #frag_properties = descriptors_df.select_dtypes(include=[np.number]).columns
23 |     #pca_transformed = pca.fit_transform(descriptors_df[frag_properties])
24 |     #pca_df = pd.DataFrame(pca_transformed, columns=["PC1", "PC2"])
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
25 |     #pca_df["InChIKey"] = descriptors_df["InChIKey"]
26 |     #pca_df.to_csv(save_path+f"pca{number}.csv", index=False)
   |
   = help: Remove commented-out code

utils\get_modred_descriptors.py:25:5: ERA001 Found commented-out code
   |
23 |     #pca_transformed = pca.fit_transform(descriptors_df[frag_properties])
24 |     #pca_df = pd.DataFrame(pca_transformed, columns=["PC1", "PC2"])
25 |     #pca_df["InChIKey"] = descriptors_df["InChIKey"]
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
26 |     #pca_df.to_csv(save_path+f"pca{number}.csv", index=False)
   |
   = help: Remove commented-out code

utils\get_modred_descriptors.py:26:5: ERA001 Found commented-out code
   |
24 |     #pca_df = pd.DataFrame(pca_transformed, columns=["PC1", "PC2"])
25 |     #pca_df["InChIKey"] = descriptors_df["InChIKey"]
26 |     #pca_df.to_csv(save_path+f"pca{number}.csv", index=False)
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
27 | 
28 | if __name__ == "__main__":
   |
   = help: Remove commented-out code

utils\oligomer_scaffold_split.py:1:1: INP001 File `utils\oligomer_scaffold_split.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\oligomer_scaffold_split.py:19:5: D417 Missing argument descriptions in the docstring for `oligomer_scaffold_splitter`: `config`, `dataset`
   |
19 | def oligomer_scaffold_splitter(dataset, config):
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ D417
20 |     """Split a dataset into a training and test set based on the scaffold of the oligomers.
21 |     The test set contains the oligomers with the specified scaffold.
   |

utils\oligomer_scaffold_split.py:20:5: D205 1 blank line required between summary line and description
   |
19 |   def oligomer_scaffold_splitter(dataset, config):
20 |       """Split a dataset into a training and test set based on the scaffold of the oligomers.
   |  _____^
21 | |     The test set contains the oligomers with the specified scaffold.
22 | | 
23 | |     Args:
24 | |     ----
25 | |     - dataset: list of dictionaries
26 | |     - config: dictionary with the following
27 | | 
28 | |     Returns:
29 | |     -------
30 | |     - test_set_inchikeys: list of InChIKeys of the oligomers in the test set
31 | | 
32 | |     """
   | |_______^ D205
33 |       df_total, df_precursors = load_dataframes(dataset, config)
   |
   = help: Insert single blank line

utils\oligomer_scaffold_split.py:69:5: D417 Missing argument descriptions in the docstring for `cluster_analysis`: `config`, `dataset`, `min_cluster_size`, `min_samples`
   |
69 | def cluster_analysis(dataset, config, min_cluster_size=750, min_samples=50):
   |     ^^^^^^^^^^^^^^^^ D417
70 |     """Perform clustering on the dataset and print the number of clusters and the number of oligomers in each cluster.
   |

utils\oligomer_scaffold_split.py:96:5: D417 Missing argument descriptions in the docstring for `pca_plot`: `config`, `df_total`
   |
96 | def pca_plot(df_total, config):
   |     ^^^^^^^^ D417
97 |     """Plot the 2D PCA space of the dataset, highlighting the chosen cluster.
   |

utils\oligomer_scaffold_split.py:105:47: F821 Undefined name `dataset`
    |
104 |     """
105 |     df_total, df_precursors = load_dataframes(dataset, config)
    |                                               ^^^^^^^ F821
106 |     check_data_exists(df_total, dataset, config)
    |

utils\oligomer_scaffold_split.py:106:33: F821 Undefined name `dataset`
    |
104 |     """
105 |     df_total, df_precursors = load_dataframes(dataset, config)
106 |     check_data_exists(df_total, dataset, config)
    |                                 ^^^^^^^ F821
107 | 
108 |     min_cluster_size = config[
    |

utils\oligomer_scaffold_split.py:156:5: D417 Missing argument descriptions in the docstring for `substructure_analysis_oligomers`: `config`, `dataset`, `min_cluster_size`, `min_samples`, `selected_cluster`
    |
155 | # still to do for oligomer
156 | def substructure_analysis_oligomers(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D417
157 |     dataset, config, selected_cluster=1, min_cluster_size=750, min_samples=50
158 | ):
    |

utils\oligomer_scaffold_split.py:172:5: N806 Variable `X_frag_mol` in function should be lowercase
    |
170 |     df_total, df_precursors = load_dataframes(dataset, config)
171 | 
172 |     X_frag_mol = df_precursors["mol_opt"].values
    |     ^^^^^^^^^^ N806
173 |     X_frag_inch = df_precursors["InChIKey"].values
174 |     keys_6mer = df_total["InChIKey"].values
    |

utils\oligomer_scaffold_split.py:172:18: PD011 Use `.to_numpy()` instead of `.values`
    |
170 |     df_total, df_precursors = load_dataframes(dataset, config)
171 | 
172 |     X_frag_mol = df_precursors["mol_opt"].values
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
173 |     X_frag_inch = df_precursors["InChIKey"].values
174 |     keys_6mer = df_total["InChIKey"].values
    |

utils\oligomer_scaffold_split.py:173:5: N806 Variable `X_frag_inch` in function should be lowercase
    |
172 |     X_frag_mol = df_precursors["mol_opt"].values
173 |     X_frag_inch = df_precursors["InChIKey"].values
    |     ^^^^^^^^^^^ N806
174 |     keys_6mer = df_total["InChIKey"].values
    |

utils\oligomer_scaffold_split.py:173:19: PD011 Use `.to_numpy()` instead of `.values`
    |
172 |     X_frag_mol = df_precursors["mol_opt"].values
173 |     X_frag_inch = df_precursors["InChIKey"].values
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
174 |     keys_6mer = df_total["InChIKey"].values
    |

utils\oligomer_scaffold_split.py:174:17: PD011 Use `.to_numpy()` instead of `.values`
    |
172 |     X_frag_mol = df_precursors["mol_opt"].values
173 |     X_frag_inch = df_precursors["InChIKey"].values
174 |     keys_6mer = df_total["InChIKey"].values
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
175 | 
176 |     check_data_exists(df_total, dataset, config)
    |

utils\oligomer_scaffold_split.py:191:5: PLW0127 Self-assignment of variable `selected_cluster`
    |
189 |     cluster_assignments = dict(zip(keys_6mer, cluster_labels))
190 | 
191 |     selected_cluster = selected_cluster
    |     ^^^^^^^^^^^^^^^^ PLW0127
192 |     # Filter out the data points in the specified cluster
193 |     selected_cluster_keys = [
    |

utils\oligomer_scaffold_split.py:212:13: PD011 Use `.to_numpy()` instead of `.values`
    |
210 |           # Extract InChIKeys from columns InChIKeys_0 to InChIKeys_5
211 |           inchikeys = [
212 |               df_total.loc[
    |  _____________^
213 | |                 df_total["InChIKey"] == oligomer_key, f"InChIKey_{i}"
214 | |             ].values[0]
    | |____________________^ PD011
215 |               for i in range(6)
216 |           ]
    |

utils\oligomer_scaffold_split.py:236:41: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
235 |         # Check if there's only one molecule in the cluster
236 |         if len(selected_cluster_keys) < 2:
    |                                         ^ PLR2004
237 |             pass
238 |         else:
    |

utils\oligomer_scaffold_split.py:249:30: PLR2004 Magic value used in comparison, consider replacing `6` with a constant variable
    |
248 |         # visualise only one combined molecule in the cluster in 2D, so its easier to see
249 |         if len(fragments) == 6 and counter == 0:
    |                              ^ PLR2004
250 |             mol = Chem.MolFromSmiles(oligomer_smiles)
251 |             img = Draw.MolToImage(mol)
    |

utils\oligomer_scaffold_split.py:269:9: B007 Loop control variable `i` not used within loop body
    |
267 |         3, len(ranked_substructures)
268 |     )  # Choose the smaller of 3 and the actual number of substructures
269 |     for i, (substructure, _count) in enumerate(ranked_substructures[:top_n]):
    |         ^ B007
270 |         img = Draw.MolToImage(Chem.MolFromSmarts(substructure))
271 |         display(img)
    |
    = help: Rename unused `i` to `_i`

utils\oligomer_scaffold_split.py:274:5: D103 Missing docstring in public function
    |
274 | def load_dataframes(dataset, config):
    |     ^^^^^^^^^^^^^^^ D103
275 |     seed = config["seed"]
276 |     len(dataset)
    |

utils\oligomer_scaffold_split.py:277:5: NPY002 Replace legacy `np.random.seed` call with `np.random.Generator`
    |
275 |     seed = config["seed"]
276 |     len(dataset)
277 |     np.random.seed(seed)
    |     ^^^^^^^^^^^^^^ NPY002
278 | 
279 |     df_path = Path(
    |

utils\oligomer_scaffold_split.py:295:5: D103 Missing docstring in public function
    |
295 | def check_data_exists(df_total, dataset, config):
    |     ^^^^^^^^^^^^^^^^^ D103
296 |     # check if df_total['2d_tani_pca_1'] and df_total['2d_tani_pca_2'] exist, if not, calculate them
297 |     if (
    |

utils\oligomer_scaffold_split.py:308:5: D103 Missing docstring in public function
    |
308 | def calculate_morgan_fingerprints(mols,radius=2,nBits=1024):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
309 |     return [
310 |         AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)
    |

utils\oligomer_scaffold_split.py:308:49: N803 Argument name `nBits` should be lowercase
    |
308 | def calculate_morgan_fingerprints(mols,radius=2,nBits=1024):
    |                                                 ^^^^^ N803
309 |     return [
310 |         AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)
    |

utils\oligomer_scaffold_split.py:315:5: D103 Missing docstring in public function
    |
315 | def calculate_tanimoto_similarity(fp1, fp2):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
316 |     return DataStructs.TanimotoSimilarity(fp1, fp2)
    |

utils\oligomer_scaffold_split.py:319:5: D103 Missing docstring in public function
    |
319 | def generate_repr(df_total, df_precursors, frag_properties, idx=0):
    |     ^^^^^^^^^^^^^ D103
320 |     init_rpr = []
321 |     frag_properties = frag_properties.union(["InChIKey"])
    |

utils\oligomer_scaffold_split.py:324:14: S307 Use of possibly insecure function; consider using `ast.literal_eval`
    |
322 |     if "InChIKey_0" not in df_total.columns:
323 |         elements_curr = [
324 |             [eval(df_total["BB"][x])[i]["InChIKey"] for i in range(6)] for x in idx
    |              ^^^^^^^^^^^^^^^^^^^^^^^ S307
325 |         ]
326 |         elements_curr = pd.DataFrame(
    |

utils\oligomer_scaffold_split.py:335:19: PD015 Use `.merge` method instead of `pd.merge` function. They have equivalent functionality.
    |
333 |     for i in range(num_frag):
334 |         elements_curr["InChIKey"] = elements_curr[f"InChIKey_{i}"].astype(str)
335 |         df_eval = pd.merge(
    |                   ^^^^^^^^ PD015
336 |             elements_curr,
337 |             df_precursors[frag_properties],
    |

utils\oligomer_scaffold_split.py:343:24: PD011 Use `.to_numpy()` instead of `.values`
    |
341 |         )
342 |         if len(init_rpr) == 0:
343 |             init_rpr = df_eval[df_eval.columns[num_frag + 1 :]].values
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
344 |         else:
345 |             init_rpr = np.concatenate(
    |

utils\oligomer_scaffold_split.py:346:28: PD011 Use `.to_numpy()` instead of `.values`
    |
344 |         else:
345 |             init_rpr = np.concatenate(
346 |                 [init_rpr, df_eval[df_eval.columns[num_frag + 1 :]].values],
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
347 |                 axis=1,
348 |             )
    |

utils\oligomer_scaffold_split.py:355:5: N802 Function name `generate_2d_PCA` should be lowercase
    |
355 | def generate_2d_PCA(df, df_precursors):
    |     ^^^^^^^^^^^^^^^ N802
356 |     """Generate 2D PCA scores for the dataset and append them to df_total."""
357 |     #df_total, df_precursors = load_dataframes(dataset, config)
    |

utils\oligomer_scaffold_split.py:357:5: ERA001 Found commented-out code
    |
355 | def generate_2d_PCA(df, df_precursors):
356 |     """Generate 2D PCA scores for the dataset and append them to df_total."""
357 |     #df_total, df_precursors = load_dataframes(dataset, config)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
358 |     df_total = df.copy()
359 |     X_frag_mol = df_precursors["mol_opt"].values
    |
    = help: Remove commented-out code

utils\oligomer_scaffold_split.py:359:5: N806 Variable `X_frag_mol` in function should be lowercase
    |
357 |     #df_total, df_precursors = load_dataframes(dataset, config)
358 |     df_total = df.copy()
359 |     X_frag_mol = df_precursors["mol_opt"].values
    |     ^^^^^^^^^^ N806
360 | 
361 |     morgan_fps = calculate_morgan_fingerprints(X_frag_mol)
    |

utils\oligomer_scaffold_split.py:359:18: PD011 Use `.to_numpy()` instead of `.values`
    |
357 |     #df_total, df_precursors = load_dataframes(dataset, config)
358 |     df_total = df.copy()
359 |     X_frag_mol = df_precursors["mol_opt"].values
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
360 | 
361 |     morgan_fps = calculate_morgan_fingerprints(X_frag_mol)
    |

utils\oligomer_scaffold_split.py:395:29: PD011 Use `.to_numpy()` instead of `.values`
    |
393 |     pca2 = PCA(n_components=2)
394 |     # Perform PCA on the first 42 columns of the dataframe
395 |     oligomer_pca_scores_2 = df_pca_scores[df_pca_scores.columns[:42]].values
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
396 |     oligomer_pca_scores_2_final = pca2.fit_transform(oligomer_pca_scores_2)
    |

utils\oligomer_scaffold_split.py:410:5: ERA001 Found commented-out code
    |
408 |     )
409 | 
410 |     # df_total.to_csv(df_path, index=False)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
411 |     # df_precursors.to_csv(df_precursors_path, index=False)
    |
    = help: Remove commented-out code

utils\oligomer_scaffold_split.py:411:5: ERA001 Found commented-out code
    |
410 |     # df_total.to_csv(df_path, index=False)
411 |     # df_precursors.to_csv(df_precursors_path, index=False)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
412 | 
413 |     return df_total, df_precursors
    |
    = help: Remove commented-out code

utils\plot_results_all.py:1:1: INP001 File `utils\plot_results_all.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\plot_results_all.py:1:1: D100 Missing docstring in public module
utils\plot_results_all.py:10:5: PLR0913 Too many arguments in function definition (10 > 5)
   |
10 | def plot_metric(
   |     ^^^^^^^^^^^ PLR0913
11 |     df_plot,
12 |     plot_function_list,
   |

utils\plot_results_all.py:10:5: D103 Missing docstring in public function
   |
10 | def plot_metric(
   |     ^^^^^^^^^^^ D103
11 |     df_plot,
12 |     plot_function_list,
   |

utils\plot_results_all.py:14:5: ARG001 Unused function argument: `df_list_dict`
   |
12 |     plot_function_list,
13 |     results_dict,
14 |     df_list_dict,
   |     ^^^^^^^^^^^^ ARG001
15 |     nb_iterations=300,
16 |     target_name="target",
   |

utils\plot_results_all.py:33:16: PD011 Use `.to_numpy()` instead of `.values`
   |
31 |     keys = df_plot["key"]
32 |     metric_dict_res = {}
33 |     for key in keys.values:
   |                ^^^^^^^^^^^ PD011
34 |         res = results_dict[key][:num_results_min]
35 |         color = df_plot[df_plot["key"] == key]["color"].iloc[0]
   |

utils\plot_results_all.py:58:5: ERA001 Found commented-out code
   |
56 |             ax.axvspan(0, nb_initialisation, alpha=0.1, color="grey")
57 |         metric_dict_res[key] = metric_dict
58 |     # ax.set_ylabel("Max Fitness")
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
59 |     # ax.set_ylim(-6, 0)
   |
   = help: Remove commented-out code

utils\plot_results_all.py:59:5: ERA001 Found commented-out code
   |
57 |         metric_dict_res[key] = metric_dict
58 |     # ax.set_ylabel("Max Fitness")
59 |     # ax.set_ylim(-6, 0)
   |     ^^^^^^^^^^^^^^^^^^^^ ERA001
60 | 
61 |     axes[0].legend(
   |
   = help: Remove commented-out code

utils\plot_results_all.py:67:5: D103 Missing docstring in public function
   |
67 | def plot_metric_mae(metric_dict_res, metric, df_list_dict):
   |     ^^^^^^^^^^^^^^^ D103
68 |     mae_list, metric_list = [], []
69 |     r2_list = []
   |

utils\plot_results_all.py:80:31: S307 Use of possibly insecure function; consider using `ast.literal_eval`
   |
78 |             df_results["predicted_target_learned_embedding"] = df_results[
79 |                 "predicted_target_learned_embedding"
80 |             ].apply(lambda x: eval(x)[0])
   |                               ^^^^^^^ S307
81 |             mae = mean_absolute_error(
82 |                 df_results["target"].values,
   |

utils\plot_results_all.py:93:9: E722 Do not use bare `except`
   |
91 |                 )
92 |             )
93 |         except:
   |         ^^^^^^ E722
94 |             pass
95 |     fig, ax = plt.subplots()
   |

utils\plot_results_all.py:93:9: S110 `try`-`except`-`pass` detected, consider logging the exception
   |
91 |                   )
92 |               )
93 |           except:
   |  _________^
94 | |             pass
   | |________________^ S110
95 |       fig, ax = plt.subplots()
96 |       key = "evolution_algorithm_total"
   |

utils\plot_results_all.py:93:9: PERF203 `try`-`except` within a loop incurs performance overhead
   |
91 |                   )
92 |               )
93 |           except:
   |  _________^
94 | |             pass
   | |________________^ PERF203
95 |       fig, ax = plt.subplots()
96 |       key = "evolution_algorithm_total"
   |

utils\plot_results_all.py:104:5: PLR0913 Too many arguments in function definition (6 > 5)
    |
104 | def add_similarity_plots(axes, df_plot, df_mol_dict, results_dict,
    |     ^^^^^^^^^^^^^^^^^^^^ PLR0913
105 |                          nb_iterations=250,  nb_initialisation=50):
106 |     keys = df_plot["key"].values
    |

utils\plot_results_all.py:104:5: D103 Missing docstring in public function
    |
104 | def add_similarity_plots(axes, df_plot, df_mol_dict, results_dict,
    |     ^^^^^^^^^^^^^^^^^^^^ D103
105 |                          nb_iterations=250,  nb_initialisation=50):
106 |     keys = df_plot["key"].values
    |

utils\plot_results_all.py:106:12: PD011 Use `.to_numpy()` instead of `.values`
    |
104 | def add_similarity_plots(axes, df_plot, df_mol_dict, results_dict,
105 |                          nb_iterations=250,  nb_initialisation=50):
106 |     keys = df_plot["key"].values
    |            ^^^^^^^^^^^^^^^^^^^^^ PD011
107 |     ax = axes.flatten()
108 |     for key in keys:
    |

utils\plot_results_all.py:134:5: ERA001 Found commented-out code
    |
132 |         )
133 |     return df_mol_dict
134 |     # ax[0].legend(loc='upper left', bbox_to_anchor=(-0.1, 1.3), ncol=3)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
    |
    = help: Remove commented-out code

utils\plot_results_all.py:137:5: D103 Missing docstring in public function
    |
137 | def save_mol_dict(df_mol_dict):
    |     ^^^^^^^^^^^^^ D103
138 |     df = pd.DataFrame(df_mol_dict, index=[0]).T
139 |     df.columns = ["mol"]
    |

utils\plot_results_all.py:138:5: PD901 Avoid using the generic variable name `df` for DataFrames
    |
137 | def save_mol_dict(df_mol_dict):
138 |     df = pd.DataFrame(df_mol_dict, index=[0]).T
    |     ^^ PD901
139 |     df.columns = ["mol"]
140 |     df["InChIKey"] = df.index
    |

utils\plot_results_all.py:147:5: D103 Missing docstring in public function
    |
147 | def load_mol_dict():
    |     ^^^^^^^^^^^^^ D103
148 |     df = pd.read_pickle(
149 |         "data/output/search_experiment/mol_dict.pkl"
    |

utils\plot_results_all.py:148:5: PD901 Avoid using the generic variable name `df` for DataFrames
    |
147 | def load_mol_dict():
148 |     df = pd.read_pickle(
    |     ^^ PD901
149 |         "data/output/search_experiment/mol_dict.pkl"
150 |     )
    |

utils\plot_results_all.py:148:10: S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
    |
147 |   def load_mol_dict():
148 |       df = pd.read_pickle(
    |  __________^
149 | |         "data/output/search_experiment/mol_dict.pkl"
150 | |     )
    | |_____^ S301
151 |       return df.T.loc["mol"].to_dict()
    |

utils\plotter.py:1:1: INP001 File `utils\plotter.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\plotter.py:1:1: D100 Missing docstring in public module
utils\plotter.py:31:5: D103 Missing docstring in public function
   |
31 | def calltracker(func):
   |     ^^^^^^^^^^^ D103
32 |     @functools.wraps(func)
33 |     def wrapper(*args):
   |

utils\plotter.py:33:9: ANN202 Missing return type annotation for private function `wrapper`
   |
31 | def calltracker(func):
32 |     @functools.wraps(func)
33 |     def wrapper(*args):
   |         ^^^^^^^ ANN202
34 |         wrapper.has_been_called = True
35 |         return func(*args)
   |
   = help: Add return type annotation

utils\plotter.py:33:17: ANN002 Missing type annotation for `*args`
   |
31 | def calltracker(func):
32 |     @functools.wraps(func)
33 |     def wrapper(*args):
   |                 ^^^^^ ANN002
34 |         wrapper.has_been_called = True
35 |         return func(*args)
   |

utils\plotter.py:40:5: D205 1 blank line required between summary line and description
   |
39 |   class Plotter:
40 |       """A class used to plot the ECFP fingerprints of the molecules used to
   |  _____^
41 | |     instantiate it.
42 | |     
43 | |     :param __sim_type: similarity type structural or tailored
44 | |     :param __target_type: target type R (regression) or C (classificatino)
45 | |     :param __target: list containing the target values. Is empty if a target does not exist
46 | |     :param __mols: list of valid molecules that can be plotted
47 | |     :param __df_descriptors: datatframe containing the descriptors representation of each molecule
48 | |     :param __df_2_components: dataframe containing the two-dimenstional representation of each molecule
49 | |     :param __plot_title: title of the plot reflecting the dimensionality reduction algorithm used
50 | |     :param __data: list of the scaled descriptors to which the dimensionality reduction algorithm is applied
51 | |     :param pca_fit: PCA object created when the corresponding algorithm is applied to the data
52 | |     :param tsne_fit: t-SNE object created when the corresponding algorithm is applied to the data
53 | |     :param umap_fit: UMAP object created when the corresponding algorithm is applied to the data
54 | |     :param df_plot_xy: dataframe containing the coordinates that have been plotted
55 | |     :type __sim_type: string
56 | |     :type __target_type: string
57 | |     :type __target: list
58 | |     :type __mols: rdkit.Chem.rdchem.Mol
59 | |     :type __df_descriptors: Dataframe
60 | |     :type __df_2_components: Dataframe
61 | |     :type __plot_title: string
62 | |     :type __data: list
63 | |     :type pca_fit: sklearn.decomposition.TSNE
64 | |     :type tsne_fit: sklearn.manifold.TSNE
65 | |     :type umap_fit: umap.umap_.UMAP
66 | |     :type df_plot_xy: Dataframe
67 | |     """
   | |_______^ D205
68 |   
69 |       _static_plots = {"scatter", "hex", "kde"}
   |
   = help: Insert single blank line

utils\plotter.py:69:21: RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   |
67 |     """
68 | 
69 |     _static_plots = {"scatter", "hex", "kde"}
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^ RUF012
70 | 
71 |     _interactive_plots = {"scatter", "hex"}
   |

utils\plotter.py:71:26: RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   |
69 |     _static_plots = {"scatter", "hex", "kde"}
70 | 
71 |     _interactive_plots = {"scatter", "hex"}
   |                          ^^^^^^^^^^^^^^^^^^ RUF012
72 | 
73 |     _sim_types = {"tailored", "structural"}
   |

utils\plotter.py:73:18: RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   |
71 |     _interactive_plots = {"scatter", "hex"}
72 | 
73 |     _sim_types = {"tailored", "structural"}
   |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^ RUF012
74 | 
75 |     _target_types = {"R", "C"}
   |

utils\plotter.py:75:21: RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   |
73 |     _sim_types = {"tailored", "structural"}
74 | 
75 |     _target_types = {"R", "C"}
   |                     ^^^^^^^^^^ RUF012
76 | 
77 |     def __init__(self, encoding_list, target, target_type, sim_type, get_desc, get_fingerprints):
   |

utils\plotter.py:77:9: C901 `__init__` is too complex (16 > 10)
   |
75 |     _target_types = {"R", "C"}
76 | 
77 |     def __init__(self, encoding_list, target, target_type, sim_type, get_desc, get_fingerprints):
   |         ^^^^^^^^ C901
78 | 
79 |         # Error handeling sym_type
   |

utils\plotter.py:77:9: PLR0913 Too many arguments in function definition (6 > 5)
   |
75 |     _target_types = {"R", "C"}
76 | 
77 |     def __init__(self, encoding_list, target, target_type, sim_type, get_desc, get_fingerprints):
   |         ^^^^^^^^ PLR0913
78 | 
79 |         # Error handeling sym_type
   |

utils\plotter.py:77:9: PLR0912 Too many branches (20 > 12)
   |
75 |     _target_types = {"R", "C"}
76 | 
77 |     def __init__(self, encoding_list, target, target_type, sim_type, get_desc, get_fingerprints):
   |         ^^^^^^^^ PLR0912
78 | 
79 |         # Error handeling sym_type
   |

utils\plotter.py:77:9: D107 Missing docstring in `__init__`
   |
75 |     _target_types = {"R", "C"}
76 | 
77 |     def __init__(self, encoding_list, target, target_type, sim_type, get_desc, get_fingerprints):
   |         ^^^^^^^^ D107
78 | 
79 |         # Error handeling sym_type
   |

utils\plotter.py:90:19: TRY002 Create your own exception
   |
88 |         if self.__sim_type != "structural" and len(target) == 0:
89 |             msg = "Target values missing"
90 |             raise Exception(msg)
   |                   ^^^^^^^^^^^^^^ TRY002
91 | 
92 |         # Error handeling target_type
   |

utils\plotter.py:93:9: SIM102 Use a single `if` statement instead of nested `if` statements
   |
92 |           # Error handeling target_type
93 |           if len(target) > 0:
   |  _________^
94 | |             if len(target) != len(encoding_list):
   | |_________________________________________________^ SIM102
95 |                   msg = "If target is provided its length must match the instances of molecules"
96 |                   raise Exception(msg)
   |
   = help: Combine `if` statements using `and`

utils\plotter.py:96:23: TRY002 Create your own exception
   |
94 |             if len(target) != len(encoding_list):
95 |                 msg = "If target is provided its length must match the instances of molecules"
96 |                 raise Exception(msg)
   |                       ^^^^^^^^^^^^^^ TRY002
97 | 
98 |         if len(target) > 0:
   |

utils\plotter.py:100:101: PLR2004 Magic value used in comparison, consider replacing `0.05` with a constant variable
    |
 98 |         if len(target) > 0:
 99 |             df_target = pd.DataFrame(data=target)
100 |             unique_targets_ratio = 1.*df_target.iloc[:, 0].nunique()/df_target.iloc[:, 0].count() < 0.05
    |                                                                                                     ^^^^ PLR2004
101 |             numeric_target = is_numeric_dtype(df_target.dtypes[0])
102 |             if target_type == "R" and (unique_targets_ratio or not numeric_target):
    |

utils\plotter.py:116:16: PD101 Using `series.nunique()` for checking that a series is constant is inefficient
    |
114 |         if len(target) > 0 and self.__target_type == "C":
115 |             df_target = pd.DataFrame(data=target)
116 |             if df_target.iloc[:, 0].nunique() == 1:
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD101
117 |                 target = []
118 |                 self.__sim_type = "structural"
    |

utils\plotter.py:125:23: TRY002 Create your own exception
    |
123 |             if df_descriptors.empty:
124 |                 msg = "Descriptors could not be computed for given molecules"
125 |                 raise Exception(msg)
    |                       ^^^^^^^^^^^^^^ TRY002
126 |             self.__df_descriptors, self.__target = desc.select_descriptors_lasso(df_descriptors,target,kind=self.__target_type)
127 |         elif self.__sim_type == "structural":
    |

utils\plotter.py:130:31: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
128 |             self.__mols, self.__df_descriptors, self.__target = get_fingerprints(encoding_list,target,2,2048)
129 | 
130 |         if len(self.__mols) < 2 or len(self.__df_descriptors.columns) < 2:
    |                               ^ PLR2004
131 |             msg = "Plotter object cannot be instantiated for given molecules"
132 |             raise Exception(msg)
    |

utils\plotter.py:130:73: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
128 |             self.__mols, self.__df_descriptors, self.__target = get_fingerprints(encoding_list,target,2,2048)
129 | 
130 |         if len(self.__mols) < 2 or len(self.__df_descriptors.columns) < 2:
    |                                                                         ^ PLR2004
131 |             msg = "Plotter object cannot be instantiated for given molecules"
132 |             raise Exception(msg)
    |

utils\plotter.py:132:19: TRY002 Create your own exception
    |
130 |         if len(self.__mols) < 2 or len(self.__df_descriptors.columns) < 2:
131 |             msg = "Plotter object cannot be instantiated for given molecules"
132 |             raise Exception(msg)
    |                   ^^^^^^^^^^^^^^ TRY002
133 | 
134 |         self.__df_2_components = None
    |

utils\plotter.py:139:9: ANN206 Missing return type annotation for classmethod `from_smiles`
    |
138 |     @classmethod
139 |     def from_smiles(cls, smiles_list, target=None, target_type=None, sim_type=None):
    |         ^^^^^^^^^^^ ANN206
140 |         """Class method to construct a Plotter object from a list of SMILES.
    |
    = help: Add return type annotation

utils\plotter.py:159:9: ANN206 Missing return type annotation for classmethod `from_inchi`
    |
158 |     @classmethod
159 |     def from_inchi(cls, inchi_list, target=None, target_type=None, sim_type=None):
    |         ^^^^^^^^^^ ANN206
160 |         """Class method to construct a Plotter object from a list of InChi.
    |
    = help: Add return type annotation

utils\plotter.py:178:19: ANN003 Missing type annotation for `**kwargs`
    |
178 |     def pca(self, **kwargs):
    |                   ^^^^^^^^ ANN003
179 |         """Calculates the first 2 PCA components of the molecular descriptors.
    |

utils\plotter.py:179:9: D401 First line of docstring should be in imperative mood: "Calculates the first 2 PCA components of the molecular descriptors."
    |
178 |       def pca(self, **kwargs):
179 |           """Calculates the first 2 PCA components of the molecular descriptors.
    |  _________^
180 | |         
181 | |         :param kwargs: Other keyword arguments are passed down to sklearn.decomposition.PCA
182 | |         :type kwargs: key, value mappings
183 | |         :returns: The dataframe containing the PCA components.
184 | |         :rtype: Dataframe
185 | |         """
    | |___________^ D401
186 |           self.__data = self.__data_scaler()
    |

utils\plotter.py:208:37: FBT002 Boolean default positional argument in function definition
    |
208 |     def tsne(self, perplexity=None, pca=False, random_state=None, **kwargs):
    |                                     ^^^ FBT002
209 |         """Calculates the first 2 t-SNE components of the molecular descriptors.
    |

utils\plotter.py:208:67: ANN003 Missing type annotation for `**kwargs`
    |
208 |     def tsne(self, perplexity=None, pca=False, random_state=None, **kwargs):
    |                                                                   ^^^^^^^^ ANN003
209 |         """Calculates the first 2 t-SNE components of the molecular descriptors.
    |

utils\plotter.py:209:9: D401 First line of docstring should be in imperative mood: "Calculates the first 2 t-SNE components of the molecular descriptors."
    |
208 |       def tsne(self, perplexity=None, pca=False, random_state=None, **kwargs):
209 |           """Calculates the first 2 t-SNE components of the molecular descriptors.
    |  _________^
210 | |         
211 | |         :param perplexity: perplexity value for the t-SNE model  
212 | |         :param pca: indicates if the features must be preprocessed by PCA
213 | |         :param random_state: random seed that can be passed as a parameter for reproducing the same results     
214 | |         :param kwargs: Other keyword arguments are passed down to sklearn.manifold.TSNE
215 | |         :type perplexity: int
216 | |         :type pca: boolean
217 | |         :type random_state: int
218 | |         :type kwargs: key, value mappings
219 | |         :returns: The dataframe containing the t-SNE components.
220 | |         :rtype: Dataframe
221 | |         """
    | |___________^ D401
222 |           self.__data = self.__data_scaler()
223 |           self.__plot_title = "t-SNE plot"
    |

utils\plotter.py:242:25: PLR2004 Magic value used in comparison, consider replacing `5` with a constant variable
    |
240 |             else:
241 |                 perplexity = parameters.perplexity_tailored(len(self.__data))
242 |         elif perplexity<5 or perplexity>50:
    |                         ^ PLR2004
243 |             pass
    |

utils\plotter.py:242:41: PLR2004 Magic value used in comparison, consider replacing `50` with a constant variable
    |
240 |             else:
241 |                 perplexity = parameters.perplexity_tailored(len(self.__data))
242 |         elif perplexity<5 or perplexity>50:
    |                                         ^^ PLR2004
243 |             pass
    |

utils\plotter.py:258:9: PLR0912 Too many branches (14 > 12)
    |
258 |     def umap(self, n_neighbors=None, min_dist=None, pca=False, random_state=None, **kwargs):
    |         ^^^^ PLR0912
259 |         """Calculates the first 2 UMAP components of the molecular descriptors.
    |

utils\plotter.py:258:53: FBT002 Boolean default positional argument in function definition
    |
258 |     def umap(self, n_neighbors=None, min_dist=None, pca=False, random_state=None, **kwargs):
    |                                                     ^^^ FBT002
259 |         """Calculates the first 2 UMAP components of the molecular descriptors.
    |

utils\plotter.py:258:83: ANN003 Missing type annotation for `**kwargs`
    |
258 |     def umap(self, n_neighbors=None, min_dist=None, pca=False, random_state=None, **kwargs):
    |                                                                                   ^^^^^^^^ ANN003
259 |         """Calculates the first 2 UMAP components of the molecular descriptors.
    |

utils\plotter.py:259:9: D401 First line of docstring should be in imperative mood: "Calculates the first 2 UMAP components of the molecular descriptors."
    |
258 |       def umap(self, n_neighbors=None, min_dist=None, pca=False, random_state=None, **kwargs):
259 |           """Calculates the first 2 UMAP components of the molecular descriptors.
    |  _________^
260 | |         
261 | |         :param num_neighbors: Number of neighbours used in the UMAP madel.
262 | |         :param min_dist: Value between 0.0 and 0.99, indicates how close to each other the points can be displayed.
263 | |         :param random_state: random seed that can be passed as a parameter for reproducing the same results
264 | |         :param kwargs: Other keyword arguments are passed down to umap.UMAP
265 | |         :type num_neighbors: int
266 | |         :type min_dist: float
267 | |         :type random_state: int
268 | |         :type kwargs: key, value mappings
269 | |         :returns: The dataframe containing the UMAP components.
270 | |         :rtype: Dataframe
271 | |         """
    | |___________^ D401
272 |           self.__data = self.__data_scaler()
    |

utils\plotter.py:291:61: PLR2004 Magic value used in comparison, consider replacing `0.99` with a constant variable
    |
289 |                 n_neighbors = parameters.n_neighbors_tailored(len(self.__data))
290 | 
291 |         if min_dist is None or min_dist < 0.0 or min_dist > 0.99:
    |                                                             ^^^^ PLR2004
292 |             if min_dist is not None and (min_dist < 0.0 or min_dist > 0.99):
293 |                 pass
    |

utils\plotter.py:292:71: PLR2004 Magic value used in comparison, consider replacing `0.99` with a constant variable
    |
291 |         if min_dist is None or min_dist < 0.0 or min_dist > 0.99:
292 |             if min_dist is not None and (min_dist < 0.0 or min_dist > 0.99):
    |                                                                       ^^^^ PLR2004
293 |                 pass
294 |             if self.__sim_type == "structural":
    |

utils\plotter.py:315:37: ANN003 Missing type annotation for `**kwargs`
    |
315 |     def cluster(self, n_clusters=5, **kwargs):
    |                                     ^^^^^^^^ ANN003
316 |         """Computes the clusters presents in the embedded chemical space.
    |

utils\plotter.py:316:9: D401 First line of docstring should be in imperative mood: "Computes the clusters presents in the embedded chemical space."
    |
315 |       def cluster(self, n_clusters=5, **kwargs):
316 |           """Computes the clusters presents in the embedded chemical space.
    |  _________^
317 | |         
318 | |         :param n_clusters: Number of clusters that will be computed  
319 | |         :param kwargs: Other keyword arguments are passed down to sklearn.cluster.KMeans
320 | |         :type n_clusters: int
321 | |         :type kwargs: key, value mappings
322 | |         :returns: The dataframe containing the 2D embedding.
323 | |         :rtype: Dataframe
324 | |         """
    | |___________^ D401
325 |           if self.__df_2_components is None:
326 |               return None
    |

utils\plotter.py:339:9: C901 `visualize_plot` is too complex (17 > 10)
    |
339 |     def visualize_plot(self, size=20, kind="scatter", remove_outliers=False, is_colored=True, colorbar=False, clusters=False, filename=None, title=None):
    |         ^^^^^^^^^^^^^^ C901
340 |         """Generates a plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:339:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
339 |     def visualize_plot(self, size=20, kind="scatter", remove_outliers=False, is_colored=True, colorbar=False, clusters=False, filename=None, title=None):
    |         ^^^^^^^^^^^^^^ PLR0913
340 |         """Generates a plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:339:9: PLR0912 Too many branches (17 > 12)
    |
339 |     def visualize_plot(self, size=20, kind="scatter", remove_outliers=False, is_colored=True, colorbar=False, clusters=False, filename=None, title=None):
    |         ^^^^^^^^^^^^^^ PLR0912
340 |         """Generates a plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:339:9: PLR0915 Too many statements (70 > 50)
    |
339 |     def visualize_plot(self, size=20, kind="scatter", remove_outliers=False, is_colored=True, colorbar=False, clusters=False, filename=None, title=None):
    |         ^^^^^^^^^^^^^^ PLR0915
340 |         """Generates a plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:339:55: FBT002 Boolean default positional argument in function definition
    |
339 |     def visualize_plot(self, size=20, kind="scatter", remove_outliers=False, is_colored=True, colorbar=False, clusters=False, filename=None, title=None):
    |                                                       ^^^^^^^^^^^^^^^ FBT002
340 |         """Generates a plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:339:78: FBT002 Boolean default positional argument in function definition
    |
339 |     def visualize_plot(self, size=20, kind="scatter", remove_outliers=False, is_colored=True, colorbar=False, clusters=False, filename=None, title=None):
    |                                                                              ^^^^^^^^^^ FBT002
340 |         """Generates a plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:339:95: FBT002 Boolean default positional argument in function definition
    |
339 |     def visualize_plot(self, size=20, kind="scatter", remove_outliers=False, is_colored=True, colorbar=False, clusters=False, filename=None, title=None):
    |                                                                                               ^^^^^^^^ FBT002
340 |         """Generates a plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:339:111: FBT002 Boolean default positional argument in function definition
    |
339 |     def visualize_plot(self, size=20, kind="scatter", remove_outliers=False, is_colored=True, colorbar=False, clusters=False, filename=None, title=None):
    |                                                                                                               ^^^^^^^^ FBT002
340 |         """Generates a plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:340:9: D401 First line of docstring should be in imperative mood: "Generates a plot for the given molecules embedded in two dimensions."
    |
339 |       def visualize_plot(self, size=20, kind="scatter", remove_outliers=False, is_colored=True, colorbar=False, clusters=False, filename=None, title=None):
340 |           """Generates a plot for the given molecules embedded in two dimensions.
    |  _________^
341 | |         
342 | |         :param size: Size of the plot  
343 | |         :param kind: Type of plot 
344 | |         :param remove_outliers: Boolean value indicating if the outliers must be identified and removed 
345 | |         :param is_colored: Indicates if the points must be colored according to target 
346 | |         :param colorbar: Indicates if the plot legend must be represented as a colorbar. Only considered when the target_type is "R".
347 | |         :param clusters: If True the clusters are shown instead of possible targets. Pass a list or a int to only show selected clusters (indexed by int).
348 | |         :param filename: Indicates the file where to save the plot
349 | |         :param title: Title of the plot.
350 | |         :type size: int
351 | |         :type kind: string
352 | |         :type remove_outliers: boolean
353 | |         :type is_colored: boolean
354 | |         :type colorbar: boolean
355 | |         :type clusters: boolean or list or int
356 | |         :type filename: string
357 | |         :type title: string
358 | |         :returns: The matplotlib axes containing the plot.
359 | |         :rtype: Axes
360 | |         """
    | |___________^ D401
361 |           if self.__df_2_components is None:
362 |               return None
    |

utils\plotter.py:383:45: E701 Multiple statements on one line (colon)
    |
381 |             palette = "deep"
382 |             if not isinstance(clusters, bool):
383 |                 if isinstance(clusters, int): clusters = [clusters]
    |                                             ^ E701
384 |                 df_data["clusters"] = df_data["clusters"].isin(clusters)
385 |                 # Labels cluster
    |

utils\plotter.py:457:9: C901 `interactive_plot` is too complex (12 > 10)
    |
455 |         return axis
456 | 
457 |     def interactive_plot(self, size=700, kind="scatter", remove_outliers=False, is_colored=True, clusters=False, filename=None, show_plot=False, title=None):
    |         ^^^^^^^^^^^^^^^^ C901
458 |         """Generates an interactive Bokeh plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:457:9: PLR0913 Too many arguments in function definition (8 > 5)
    |
455 |         return axis
456 | 
457 |     def interactive_plot(self, size=700, kind="scatter", remove_outliers=False, is_colored=True, clusters=False, filename=None, show_plot=False, title=None):
    |         ^^^^^^^^^^^^^^^^ PLR0913
458 |         """Generates an interactive Bokeh plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:457:9: PLR0912 Too many branches (13 > 12)
    |
455 |         return axis
456 | 
457 |     def interactive_plot(self, size=700, kind="scatter", remove_outliers=False, is_colored=True, clusters=False, filename=None, show_plot=False, title=None):
    |         ^^^^^^^^^^^^^^^^ PLR0912
458 |         """Generates an interactive Bokeh plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:457:58: FBT002 Boolean default positional argument in function definition
    |
455 |         return axis
456 | 
457 |     def interactive_plot(self, size=700, kind="scatter", remove_outliers=False, is_colored=True, clusters=False, filename=None, show_plot=False, title=None):
    |                                                          ^^^^^^^^^^^^^^^ FBT002
458 |         """Generates an interactive Bokeh plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:457:81: FBT002 Boolean default positional argument in function definition
    |
455 |         return axis
456 | 
457 |     def interactive_plot(self, size=700, kind="scatter", remove_outliers=False, is_colored=True, clusters=False, filename=None, show_plot=False, title=None):
    |                                                                                 ^^^^^^^^^^ FBT002
458 |         """Generates an interactive Bokeh plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:457:98: FBT002 Boolean default positional argument in function definition
    |
455 |         return axis
456 | 
457 |     def interactive_plot(self, size=700, kind="scatter", remove_outliers=False, is_colored=True, clusters=False, filename=None, show_plot=False, title=None):
    |                                                                                                  ^^^^^^^^ FBT002
458 |         """Generates an interactive Bokeh plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:457:129: FBT002 Boolean default positional argument in function definition
    |
455 |         return axis
456 | 
457 |     def interactive_plot(self, size=700, kind="scatter", remove_outliers=False, is_colored=True, clusters=False, filename=None, show_plot=False, title=None):
    |                                                                                                                                 ^^^^^^^^^ FBT002
458 |         """Generates an interactive Bokeh plot for the given molecules embedded in two dimensions.
    |

utils\plotter.py:458:9: D401 First line of docstring should be in imperative mood: "Generates an interactive Bokeh plot for the given molecules embedded in two dimensions."
    |
457 |       def interactive_plot(self, size=700, kind="scatter", remove_outliers=False, is_colored=True, clusters=False, filename=None, show_plot=False, title=None):
458 |           """Generates an interactive Bokeh plot for the given molecules embedded in two dimensions.
    |  _________^
459 | |         
460 | |         :param size: Size of the plot  
461 | |         :param kind: Type of plot 
462 | |         :param remove_outliers: Boolean value indicating if the outliers must be identified and removed 
463 | |         :param is_colored: Indicates if the points must be colored according to target 
464 | |         :param clusters: Indicates if to add a tab with the clusters if these have been computed
465 | |         :param filename: Indicates the file where to save the Bokeh plot
466 | |         :param show_plot: Immediately display the current plot. 
467 | |         :param title: Title of the plot.
468 | |         :type size: int
469 | |         :type kind: string
470 | |         :type remove_outliers: boolean
471 | |         :type is_colored: boolean
472 | |         :type cluster: boolean
473 | |         :type filename: string
474 | |         :type show_plot: boolean
475 | |         :type title: string
476 | |         :returns: The bokeh figure containing the plot.
477 | |         :rtype: Figure
478 | |         """
    | |___________^ D401
479 |           if self.__df_2_components is None:
480 |               return None
    |

utils\plotter.py:537:9: ANN202 Missing return type annotation for private function `__data_scaler`
    |
535 |         return p
536 | 
537 |     def __data_scaler(self):
    |         ^^^^^^^^^^^^^ ANN202
538 |         # Scale the data
539 |         if self.__sim_type != "structural":
    |
    = help: Add return type annotation

utils\plotter.py:540:58: PD011 Use `.to_numpy()` instead of `.values`
    |
538 |         # Scale the data
539 |         if self.__sim_type != "structural":
540 |             scaled_data = StandardScaler().fit_transform(self.__df_descriptors.values.tolist())
    |                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
541 |         else:
542 |             scaled_data = self.__df_descriptors.values.tolist()
    |

utils\plotter.py:542:27: PD011 Use `.to_numpy()` instead of `.values`
    |
540 |             scaled_data = StandardScaler().fit_transform(self.__df_descriptors.values.tolist())
541 |         else:
542 |             scaled_data = self.__df_descriptors.values.tolist()
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
543 | 
544 |         return scaled_data
    |

utils\plotter.py:546:9: ANN202 Missing return type annotation for private function `__parse_dataframe`
    |
544 |         return scaled_data
545 | 
546 |     def __parse_dataframe(self):
    |         ^^^^^^^^^^^^^^^^^ ANN202
547 |         x = self.__df_2_components.columns[0]
548 |         y = self.__df_2_components.columns[1]
    |
    = help: Add return type annotation

utils\plotter.py:552:9: ANN202 Missing return type annotation for private function `__remove_outliers`
    |
550 |         return x, y, self.__df_2_components.copy()
551 | 
552 |     def __remove_outliers(self, x, y, df):
    |         ^^^^^^^^^^^^^^^^^ ANN202
553 |         # Remove outliers (using Z-score)
554 |         z_scores = stats.zscore(df[[x,y]])
    |
    = help: Add return type annotation

utils\plotter.py:556:44: PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
    |
554 |         z_scores = stats.zscore(df[[x,y]])
555 |         abs_z_scores = np.abs(z_scores)
556 |         filtered_entries = (abs_z_scores < 3).all(axis=1)
    |                                            ^ PLR2004
557 | 
558 |         return df[filtered_entries]
    |

utils\plotter.py:560:9: ANN202 Missing return type annotation for private function `__percentage_clusters`
    |
558 |         return df[filtered_entries]
559 | 
560 |     def __percentage_clusters(self, df_data):
    |         ^^^^^^^^^^^^^^^^^^^^^ ANN202
561 |         total = df_data["clusters"].value_counts()
562 |         sum_tot = total.sum()
    |
    = help: Add return type annotation

utils\plotter.py:578:9: PLR0913 Too many arguments in function definition (7 > 5)
    |
576 |         return list(labels.values())
577 | 
578 |     def __interactive_scatter(self, x, y, df_data, size, is_colored, clusters, title):
    |         ^^^^^^^^^^^^^^^^^^^^^ PLR0913
579 |         # Add images column
580 |         df_data["imgs"] = self.__mol_to_2Dimage(list(df_data["mols"]))
    |

utils\plotter.py:578:9: ANN202 Missing return type annotation for private function `__interactive_scatter`
    |
576 |         return list(labels.values())
577 | 
578 |     def __interactive_scatter(self, x, y, df_data, size, is_colored, clusters, title):
    |         ^^^^^^^^^^^^^^^^^^^^^ ANN202
579 |         # Add images column
580 |         df_data["imgs"] = self.__mol_to_2Dimage(list(df_data["mols"]))
    |
    = help: Add return type annotation

utils\plotter.py:586:13: N806 Variable `TOOLTIPS` in function should be lowercase
    |
585 |         if len(self.__target) == 0:
586 |             TOOLTIPS = parameters.TOOLTIPS_NO_TARGET
    |             ^^^^^^^^ N806
587 |         else:
588 |             TOOLTIPS = parameters.TOOLTIPS_TARGET
    |

utils\plotter.py:588:13: N806 Variable `TOOLTIPS` in function should be lowercase
    |
586 |             TOOLTIPS = parameters.TOOLTIPS_NO_TARGET
587 |         else:
588 |             TOOLTIPS = parameters.TOOLTIPS_TARGET
    |             ^^^^^^^^ N806
589 | 
590 |         # Create plot
    |

utils\plotter.py:640:9: ANN202 Missing return type annotation for private function `__interactive_hex`
    |
638 |         return p, tabs
639 | 
640 |     def __interactive_hex(self, x, y, df_data, size, title):
    |         ^^^^^^^^^^^^^^^^^ ANN202
641 |         # Hex Plot
642 |         df_data = df_data.drop(columns=["mols"])
    |
    = help: Add return type annotation

utils\plotter.py:667:9: N802 Function name `__mol_to_2Dimage` should be lowercase
    |
665 |         return p
666 | 
667 |     def __mol_to_2Dimage(self, list_mols):
    |         ^^^^^^^^^^^^^^^^ N802
668 |         # Create molecule images
669 |         images_mol=[]
    |

utils\plotter.py:667:9: ANN202 Missing return type annotation for private function `__mol_to_2Dimage`
    |
665 |         return p
666 | 
667 |     def __mol_to_2Dimage(self, list_mols):
    |         ^^^^^^^^^^^^^^^^ ANN202
668 |         # Create molecule images
669 |         images_mol=[]
    |
    = help: Add return type annotation

utils\plotter.py:678:13: E722 Do not use bare `except`
    |
676 |                 png = out.getvalue()
677 |                 url = "data:image/jpeg;base64," + base64.b64encode(png).decode("utf-8")
678 |             except:
    |             ^^^^^^ E722
679 |                 url = None
    |

utils\plotter.py:689:9: D102 Missing docstring in public method
    |
687 |         show(p)
688 | 
689 |     def get_target(self):
    |         ^^^^^^^^^^ D102
690 |         return self.__target
    |

utils\run_hpc_utils.py:1:1: INP001 File `utils\run_hpc_utils.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\run_hpc_utils.py:1:1: D100 Missing docstring in public module
utils\run_hpc_utils.py:6:5: PLR0913 Too many arguments in function definition (16 > 5)
  |
6 | def generate_string_run(
  |     ^^^^^^^^^^^^^^^^^^^ PLR0913
7 | 
8 |     case = "BO_precursor",
  |

utils\run_hpc_utils.py:6:5: D417 Missing argument descriptions in the docstring for `generate_string_run`: `aim`, `benchmark`, `budget`, `config_dir`, `dataset_representation_path`, `df_path`, `df_representation_path`, `frag_properties`, `lim_counter`, `num_elem_initialisation`, `num_iteration`, `search_space_loc`, `target`, `test_name`, `which_acquisition`
  |
6 | def generate_string_run(
  |     ^^^^^^^^^^^^^^^^^^^ D417
7 | 
8 |     case = "BO_precursor",
  |

utils\run_hpc_utils.py:11:5: FBT002 Boolean default positional argument in function definition
   |
 9 |     test_name = "test",
10 |     target = "target", aim = 0,
11 |     benchmark = True,
   |     ^^^^^^^^^ FBT002
12 |     num_iteration = 2,
13 |     num_elem_initialisation = 10,
   |

utils\run_hpc_utils.py:62:5: A001 Variable `input` is shadowing a Python builtin
   |
61 |     """
62 |     input = locals()
   |     ^^^^^ A001
63 | 
64 |     string_to_run_notbook = "src/dev_scripts/run_search_new.py "
   |

utils\run_hpc_utils.py:81:19: ISC003 Explicitly concatenated string should be implicitly concatenated
   |
79 |           num_cpus, mem = 30 , 50
80 |           num_iterations = 20
81 |       script_qsub = "#!/bin/bash \n"+\
   |  ___________________^
82 | |                     "#PBS -l walltime=07:59:01 \n"+\
   | |__________________________________________________^ ISC003
83 |                       f"#PBS -l select=1:ncpus={num_cpus}:mem={mem}gb:avx=true \n"+\
84 |                       f"#PBS -J 1-{num_iterations} \n"+\
   |

utils\run_hpc_utils.py:92:5: D103 Missing docstring in public function
   |
90 |     return string_to_run_notbook, script_qsub
91 | 
92 | def submit_job(script_qsub, case_name):
   |     ^^^^^^^^^^ D103
93 | 
94 |     now = datetime.datetime.now()
   |

utils\run_hpc_utils.py:94:11: DTZ005 `datetime.datetime.now()` called without a `tz` argument
   |
92 | def submit_job(script_qsub, case_name):
93 | 
94 |     now = datetime.datetime.now()
   |           ^^^^^^^^^^^^^^^^^^^^^^^ DTZ005
95 |     # print (now.strftime("%Y-%m-%d %H:%M:%S"))
96 |     sh_file_name = (
   |
   = help: Pass a `datetime.timezone` object to the `tz` parameter

utils\run_hpc_utils.py:95:5: ERA001 Found commented-out code
   |
94 |     now = datetime.datetime.now()
95 |     # print (now.strftime("%Y-%m-%d %H:%M:%S"))
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
96 |     sh_file_name = (
97 |         f"HPC_bash_script/Runsearch_{case_name}_{now.strftime('%M_%S_%f')}.sh"
   |
   = help: Remove commented-out code

utils\run_hpc_utils.py:99:10: PTH123 `open()` should be replaced by `Path.open()`
    |
 97 |         f"HPC_bash_script/Runsearch_{case_name}_{now.strftime('%M_%S_%f')}.sh"
 98 |     )
 99 |     with open(sh_file_name, "w") as text_file:
    |          ^^^^ PTH123
100 |         text_file.write(script_qsub)
    |

utils\run_hpc_utils.py:102:5: S605 Starting a process with a shell, possible injection detected
    |
100 |         text_file.write(script_qsub)
101 | 
102 |     os.system(f"qsub -e ./cache -o ./cache {sh_file_name}")
    |     ^^^^^^^^^ S605
    |

utils\sklearn_models.py:1:1: INP001 File `utils\sklearn_models.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\sklearn_models.py:1:1: D100 Missing docstring in public module
utils\sklearn_models.py:8:5: PLR0913 Too many arguments in function definition (6 > 5)
   |
 8 | def plot_results(y_test,y_pred_test,y_train,y_pred_train,y_val,y_pred_val):
   |     ^^^^^^^^^^^^ PLR0913
 9 |     """Plot results of the model
10 |     Inputs: y_test, y_pred_test, y_train, y_pred_train, y_val, y_pred_val.
   |

utils\sklearn_models.py:9:5: D205 1 blank line required between summary line and description
   |
 8 |   def plot_results(y_test,y_pred_test,y_train,y_pred_train,y_val,y_pred_val):
 9 |       """Plot results of the model
   |  _____^
10 | |     Inputs: y_test, y_pred_test, y_train, y_pred_train, y_val, y_pred_val.
11 | |     """
   | |_______^ D205
12 |       fig, ax = plt.subplots()
13 |       ax.scatter(y_test, y_pred_test,label="test")
   |
   = help: Insert single blank line

utils\sklearn_models.py:23:5: PLR0913 Too many arguments in function definition (7 > 5)
   |
23 | def train_test_model(model, X_train, y_train, X_test, y_test,X_val,y_val):
   |     ^^^^^^^^^^^^^^^^ PLR0913
24 |         """Function that trains a model, and tests it.
25 |         Inputs: sklearn model, train_data, test_data.
   |

utils\sklearn_models.py:23:29: N803 Argument name `X_train` should be lowercase
   |
23 | def train_test_model(model, X_train, y_train, X_test, y_test,X_val,y_val):
   |                             ^^^^^^^ N803
24 |         """Function that trains a model, and tests it.
25 |         Inputs: sklearn model, train_data, test_data.
   |

utils\sklearn_models.py:23:47: N803 Argument name `X_test` should be lowercase
   |
23 | def train_test_model(model, X_train, y_train, X_test, y_test,X_val,y_val):
   |                                               ^^^^^^ N803
24 |         """Function that trains a model, and tests it.
25 |         Inputs: sklearn model, train_data, test_data.
   |

utils\sklearn_models.py:23:62: N803 Argument name `X_val` should be lowercase
   |
23 | def train_test_model(model, X_train, y_train, X_test, y_test,X_val,y_val):
   |                                                              ^^^^^ N803
24 |         """Function that trains a model, and tests it.
25 |         Inputs: sklearn model, train_data, test_data.
   |

utils\sklearn_models.py:23:68: ARG001 Unused function argument: `y_val`
   |
23 | def train_test_model(model, X_train, y_train, X_test, y_test,X_val,y_val):
   |                                                                    ^^^^^ ARG001
24 |         """Function that trains a model, and tests it.
25 |         Inputs: sklearn model, train_data, test_data.
   |

utils\sklearn_models.py:24:9: D205 1 blank line required between summary line and description
   |
23 |   def train_test_model(model, X_train, y_train, X_test, y_test,X_val,y_val):
24 |           """Function that trains a model, and tests it.
   |  _________^
25 | |         Inputs: sklearn model, train_data, test_data.
26 | |         """
   | |___________^ D205
27 |           # Train model
28 |           model.fit(X_train, y_train)
   |
   = help: Insert single blank line

utils\sklearn_models.py:24:9: D401 First line of docstring should be in imperative mood: "Function that trains a model, and tests it."
   |
23 |   def train_test_model(model, X_train, y_train, X_test, y_test,X_val,y_val):
24 |           """Function that trains a model, and tests it.
   |  _________^
25 | |         Inputs: sklearn model, train_data, test_data.
26 | |         """
   | |___________^ D401
27 |           # Train model
28 |           model.fit(X_train, y_train)
   |

utils\sklearn_models.py:40:17: N803 Argument name `X_rpr` should be lowercase
   |
38 |         return y_pred_train, y_pred_test, y_pred_val,model
39 | 
40 | def train_model(X_rpr,y,min_test_set=-3):
   |                 ^^^^^ N803
41 |     """Train a model using XGBoost
42 |     Inputs: X_rpr, y, min_test_set
   |

utils\sklearn_models.py:41:5: D205 1 blank line required between summary line and description
   |
40 |   def train_model(X_rpr,y,min_test_set=-3):
41 |       """Train a model using XGBoost
   |  _____^
42 | |     Inputs: X_rpr, y, min_test_set
43 | |     Returns: y_train, y_test, y_val, y_pred_train, y_pred_test, y_pred_val, model.
44 | |     """
   | |_______^ D205
45 |       X_test = X_rpr[y>min_test_set]#.detach().numpy()
46 |       y_test = y[y>min_test_set]#.detach().numpy()
   |
   = help: Insert single blank line

utils\sklearn_models.py:45:5: N806 Variable `X_test` in function should be lowercase
   |
43 |     Returns: y_train, y_test, y_val, y_pred_train, y_pred_test, y_pred_val, model.
44 |     """
45 |     X_test = X_rpr[y>min_test_set]#.detach().numpy()
   |     ^^^^^^ N806
46 |     y_test = y[y>min_test_set]#.detach().numpy()
   |

utils\sklearn_models.py:48:5: N806 Variable `X_train` in function should be lowercase
   |
46 |     y_test = y[y>min_test_set]#.detach().numpy()
47 | 
48 |     X_train, X_val, y_train, y_val = train_test_split(X_rpr[y<min_test_set],y[y<min_test_set] , test_size=0.2, random_state=42)
   |     ^^^^^^^ N806
49 |     scaler = MinMaxScaler()
50 |     scaler.fit(X_train)
   |

utils\sklearn_models.py:48:14: N806 Variable `X_val` in function should be lowercase
   |
46 |     y_test = y[y>min_test_set]#.detach().numpy()
47 | 
48 |     X_train, X_val, y_train, y_val = train_test_split(X_rpr[y<min_test_set],y[y<min_test_set] , test_size=0.2, random_state=42)
   |              ^^^^^ N806
49 |     scaler = MinMaxScaler()
50 |     scaler.fit(X_train)
   |

utils\sklearn_models.py:52:5: N806 Variable `X_train` in function should be lowercase
   |
50 |     scaler.fit(X_train)
51 |     # transform data
52 |     X_train = scaler.transform(X_train)
   |     ^^^^^^^ N806
53 |     X_test = scaler.transform(X_test)
54 |     X_val = scaler.transform(X_val)
   |

utils\sklearn_models.py:53:5: N806 Variable `X_test` in function should be lowercase
   |
51 |     # transform data
52 |     X_train = scaler.transform(X_train)
53 |     X_test = scaler.transform(X_test)
   |     ^^^^^^ N806
54 |     X_val = scaler.transform(X_val)
55 |     xgb_reg = HistGradientBoostingRegressor(random_state=0)  # using 10 trees and seed=0
   |

utils\sklearn_models.py:54:5: N806 Variable `X_val` in function should be lowercase
   |
52 |     X_train = scaler.transform(X_train)
53 |     X_test = scaler.transform(X_test)
54 |     X_val = scaler.transform(X_val)
   |     ^^^^^ N806
55 |     xgb_reg = HistGradientBoostingRegressor(random_state=0)  # using 10 trees and seed=0
56 |     #xgb_reg = GradientBoostingRegressor(n_estimators=50, random_state=0)  # using 10 trees and seed=0
   |

utils\sklearn_models.py:56:5: ERA001 Found commented-out code
   |
54 |     X_val = scaler.transform(X_val)
55 |     xgb_reg = HistGradientBoostingRegressor(random_state=0)  # using 10 trees and seed=0
56 |     #xgb_reg = GradientBoostingRegressor(n_estimators=50, random_state=0)  # using 10 trees and seed=0
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
57 |     # Train and test XGBoost model
58 |     y_pred_train, y_pred_test,y_pred_val,model = train_test_model(xgb_reg, X_train, y_train, X_test, y_test,X_val,y_val)
   |
   = help: Remove commented-out code

utils\tanimoto_similarity_utils.py:1:1: INP001 File `utils\tanimoto_similarity_utils.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\tanimoto_similarity_utils.py:1:1: D100 Missing docstring in public module
utils\tanimoto_similarity_utils.py:13:5: D103 Missing docstring in public function
   |
12 | # Function to generate Morgan fingerprints
13 | def generate_morgan_fingerprints(molecules, radius=2, n_bits=2048):
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
14 |     return [
15 |         AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)
   |

utils\tanimoto_similarity_utils.py:21:5: D103 Missing docstring in public function
   |
20 | # Function to generate ECFP fingerprints
21 | def generate_ecfp_fingerprints(molecules, radius=2, n_bits=2048):
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
22 |     return [
23 |         AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)
   |

utils\tanimoto_similarity_utils.py:29:5: D103 Missing docstring in public function
   |
28 | # Function to calculate Tanimoto similarity between fingerprints
29 | def calculate_tanimoto_similarity(fingerprint1, fingerprint2):
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
30 |     return DataStructs.TanimotoSimilarity(fingerprint1, fingerprint2)
   |

utils\tanimoto_similarity_utils.py:33:5: D103 Missing docstring in public function
   |
33 | def get_inchi_key(molecule):
   |     ^^^^^^^^^^^^^ D103
34 |     return stk.InchiKey().get_key(molecule)
   |

utils\tanimoto_similarity_utils.py:37:5: D103 Missing docstring in public function
   |
37 | def get_mol_from_df_single(InChIKey):
   |     ^^^^^^^^^^^^^^^^^^^^^^ D103
38 |     client = "mongodb://ch-atarzia.ch.ic.ac.uk/"
   |

utils\tanimoto_similarity_utils.py:37:28: N803 Argument name `InChIKey` should be lowercase
   |
37 | def get_mol_from_df_single(InChIKey):
   |                            ^^^^^^^^ N803
38 |     client = "mongodb://ch-atarzia.ch.ic.ac.uk/"
   |

utils\tanimoto_similarity_utils.py:51:5: D103 Missing docstring in public function
   |
51 | def get_mol_from_df(df, num_mol):
   |     ^^^^^^^^^^^^^^^ D103
52 |     client = "mongodb://ch-atarzia.ch.ic.ac.uk/"
   |

utils\tanimoto_similarity_utils.py:61:9: N806 Variable `InChIKey` in function should be lowercase
   |
59 |     )
60 |     mol_list = []
61 |     for InChIKey in df["InChIKey"].sample(num_mol).values:
   |         ^^^^^^^^ N806
62 |         mol = db_polymer.get({"InChIKey": InChIKey}).to_rdkit_mol()
63 |         Chem.SanitizeMol(mol)
   |

utils\tanimoto_similarity_utils.py:61:21: PD011 Use `.to_numpy()` instead of `.values`
   |
59 |     )
60 |     mol_list = []
61 |     for InChIKey in df["InChIKey"].sample(num_mol).values:
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PD011
62 |         mol = db_polymer.get({"InChIKey": InChIKey}).to_rdkit_mol()
63 |         Chem.SanitizeMol(mol)
   |

utils\tanimoto_similarity_utils.py:68:5: D103 Missing docstring in public function
   |
68 | def get_mol_from_res(results, num_initialisation,db_polymer=None,df_mol_dict=None):
   |     ^^^^^^^^^^^^^^^^ D103
69 |     if db_polymer is None:
70 |         client = "mongodb://ch-atarzia.ch.ic.ac.uk/"
   |

utils\tanimoto_similarity_utils.py:80:9: N806 Variable `InChIKey` in function should be lowercase
   |
78 |         df_mol_dict={}
79 |     mol_list_suggested, mol_list_init = [], []
80 |     for InChIKey in results["InchiKey_acquired"][num_initialisation:]:
   |         ^^^^^^^^ N806
81 |         if InChIKey in df_mol_dict:
82 |             mol = df_mol_dict[InChIKey]
   |

utils\tanimoto_similarity_utils.py:89:9: N806 Variable `InChIKey` in function should be lowercase
   |
87 |             df_mol_dict[InChIKey]=mol
88 |         mol_list_suggested.append(mol)
89 |     for InChIKey in results["InchiKey_acquired"][:num_initialisation]:
   |         ^^^^^^^^ N806
90 |         if InChIKey in df_mol_dict:
91 |             mol = df_mol_dict[InChIKey]
   |

utils\tanimoto_similarity_utils.py:102:5: D103 Missing docstring in public function
    |
102 | def get_tanimoto_similarity(mol_list):
    |     ^^^^^^^^^^^^^^^^^^^^^^^ D103
103 |     morgan_fingerprints = generate_morgan_fingerprints(mol_list)
    |

utils\tanimoto_similarity_utils.py:119:58: ARG001 Unused function argument: `group_size`
    |
118 | def plot_similarity_results_elem_suggested(
119 |     search_results, max_iteration=100, min_iteration=50, group_size=10
    |                                                          ^^^^^^^^^^ ARG001
120 | ):
121 |     """Plot the similarity of the molecules found in the search space
    |

utils\tanimoto_similarity_utils.py:121:5: D205 1 blank line required between summary line and description
    |
119 |       search_results, max_iteration=100, min_iteration=50, group_size=10
120 |   ):
121 |       """Plot the similarity of the molecules found in the search space
    |  _____^
122 | |     search_results: list of dictionaries with the search results
123 | |     num_mol: number of molecules to plot
124 | |     num_mol_init: number of molecules in the initialisation
125 | |     group_size: number of iterations to group together
126 | |     return: array of the similarity of the molecules found.
127 | | 
128 | |     """
    | |_______^ D205
129 |       mol_list = []
130 |       for dict_org in search_results:
    |
    = help: Insert single blank line

utils\tanimoto_similarity_utils.py:131:9: A001 Variable `dict` is shadowing a Python builtin
    |
129 |     mol_list = []
130 |     for dict_org in search_results:
131 |         dict = dict_org.copy()
    |         ^^^^ A001
132 | 
133 |         dict.pop("searched_space_df")
    |

utils\tanimoto_similarity_utils.py:134:9: PD901 Avoid using the generic variable name `df` for DataFrames
    |
133 |         dict.pop("searched_space_df")
134 |         df = pd.DataFrame.from_records(dict)
    |         ^^ PD901
135 |         df["InChIKey"] = df["InchiKey_acquired"]
136 |         df = df[df["ids_acquired"] < max_iteration]
    |

utils\tanimoto_similarity_utils.py:136:9: PD901 Avoid using the generic variable name `df` for DataFrames
    |
134 |         df = pd.DataFrame.from_records(dict)
135 |         df["InChIKey"] = df["InchiKey_acquired"]
136 |         df = df[df["ids_acquired"] < max_iteration]
    |         ^^ PD901
137 |         df = df[df["ids_acquired"] > min_iteration]
138 |         [mol_list.append(x) for x in get_mol_from_df(df, df.shape[0])]
    |

utils\tanimoto_similarity_utils.py:137:9: PD901 Avoid using the generic variable name `df` for DataFrames
    |
135 |         df["InChIKey"] = df["InchiKey_acquired"]
136 |         df = df[df["ids_acquired"] < max_iteration]
137 |         df = df[df["ids_acquired"] > min_iteration]
    |         ^^ PD901
138 |         [mol_list.append(x) for x in get_mol_from_df(df, df.shape[0])]
139 |         # Generate Morgan fingerprints for the dataset
    |

utils\tanimoto_similarity_utils.py:154:5: D103 Missing docstring in public function
    |
154 | def get_mean_similarity(mol_list_suggested, mol_list_init):
    |     ^^^^^^^^^^^^^^^^^^^ D103
155 |     morgan_fingerprints_suggested = generate_morgan_fingerprints(
156 |         mol_list_suggested
    |

utils\tanimoto_similarity_utils.py:167:5: D103 Missing docstring in public function
    |
165 |     return tanimoto_sim
166 | 
167 | def moving_average(x, w):
    |     ^^^^^^^^^^^^^^ D103
168 |     return np.convolve(x, np.ones(w), "same") / w
    |

utils\tanimoto_similarity_utils.py:170:5: PLR0913 Too many arguments in function definition (7 > 5)
    |
168 |     return np.convolve(x, np.ones(w), "same") / w
169 | 
170 | def plot_similarity_results_elem_suggested_to_initial(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
171 |     search_results,
172 |     nb_iterations=300,
    |

utils\tanimoto_similarity_utils.py:170:5: D103 Missing docstring in public function
    |
168 |     return np.convolve(x, np.ones(w), "same") / w
169 | 
170 | def plot_similarity_results_elem_suggested_to_initial(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
171 |     search_results,
172 |     nb_iterations=300,
    |

utils\tanimoto_similarity_utils.py:191:13: ERA001 Found commented-out code
    |
189 |             similarity[res_num, i] = np.max(tanimoto_sim[i, :])
190 |         similarity[res_num, 5:-5] = moving_average(similarity[res_num, 5:-5], 5)
191 |             # std_similarity.append(np.std(tanimoto_sim[:i,]))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
192 |     mean_similarity = np.mean(similarity, axis=0)
193 |     std_similarity = np.std(similarity, axis=0)
    |
    = help: Remove commented-out code

utils\tanimoto_similarity_utils.py:210:5: PLR0913 Too many arguments in function definition (7 > 5)
    |
210 | def plot_similarity_results_elem_suggested_df(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLR0913
211 |     search_results,
212 |     nb_iterations=300,
    |

utils\tanimoto_similarity_utils.py:210:5: D103 Missing docstring in public function
    |
210 | def plot_similarity_results_elem_suggested_df(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103
211 |     search_results,
212 |     nb_iterations=300,
    |

utils\update_datasets.py:1:1: INP001 File `utils\update_datasets.py` is part of an implicit namespace package. Add an `__init__.py`.
utils\update_datasets.py:1:1: D100 Missing docstring in public module
utils\update_datasets.py:13:5: D417 Missing argument descriptions in the docstring for `get_dataset_from_df`: `config`, `df`
   |
13 | def get_dataset_from_df(dataset_all, df, config):
   |     ^^^^^^^^^^^^^^^^^^^ D417
14 |     """Check the input dataset for the oligomer embeddiing model and add missing molecules to the dataset.
   |

utils\update_datasets.py:31:9: N806 Variable `Inchikey` in function should be lowercase
   |
29 |     dataset = []
30 |     missing_inchikey = []
31 |     for Inchikey in df["InChIKey"]:
   |         ^^^^^^^^ N806
32 |         if Inchikey in dataset_all_dict:
33 |             dataset.append(dataset_all_dict[Inchikey])
   |

utils\update_datasets.py:58:5: D417 Missing argument descriptions in the docstring for `get_dataset_frag_from_df`: `config`, `df`
   |
57 | # save the dataset for the transformer model if already calculated dataset all exists
58 | def get_dataset_frag_from_df(dataset_all_frag, df, config):
   |     ^^^^^^^^^^^^^^^^^^^^^^^^ D417
59 |     """Check the input dataset for the oligomer encoding model and add missing molecules to the dataset.
   |

utils\update_datasets.py:79:5: ERA001 Found commented-out code
   |
77 |             data[0]["InChIKey"]: data for data in dataset_all_frag
78 |         }
79 |     # dataset = [dataset_all_dict[Inchikey] for Inchikey in df['InChIKey']]
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ERA001
80 |     dataset = []
81 |     missing_inchikey = []
   |
   = help: Remove commented-out code

utils\update_datasets.py:82:9: N806 Variable `Inchikey` in function should be lowercase
   |
80 |     dataset = []
81 |     missing_inchikey = []
82 |     for Inchikey in df["InChIKey"]:
   |         ^^^^^^^^ N806
83 |         if Inchikey in dataset_all_dict:
84 |             dataset.append(dataset_all_dict[Inchikey])
   |

utils\update_datasets.py:97:5: D417 Missing argument descriptions in the docstring for `update_dataset_learned_embedding`: `config`, `dataset_all_frag`, `extension`
   |
97 | def update_dataset_learned_embedding(
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D417
98 |     df, dataset_all_frag, config, extension="all"
99 | ):
   |

utils\update_datasets.py:121:9: N806 Variable `Inchikey` in function should be lowercase
    |
119 |     dataset_learned_embedding_update = []
120 |     missing_inchikey = []
121 |     for Inchikey in df["InChIKey"]:
    |         ^^^^^^^^ N806
122 |         if Inchikey in dataset_all_dict:
123 |             dataset_learned_embedding_update.append(dataset_all_dict[Inchikey])
    |

utils\update_datasets.py:132:9: N806 Variable `Inchikey` in function should be lowercase
    |
130 |     }
131 |     dataset_frag_missing = []
132 |     for Inchikey in missing_inchikey:
    |         ^^^^^^^^ N806
133 |         if Inchikey in dataset_frag_dict:
134 |             dataset_frag_missing.append(dataset_frag_dict[Inchikey])
    |

utils\update_datasets.py:134:13: PERF401 Use a list comprehension to create a transformed list
    |
132 |     for Inchikey in missing_inchikey:
133 |         if Inchikey in dataset_frag_dict:
134 |             dataset_frag_missing.append(dataset_frag_dict[Inchikey])
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PERF401
135 |     ephemeral_dir = (
136 |         config["ephemeral_path"] + f"/{config['name'].replace('_','/')}/"
    |

utils\update_datasets.py:151:5: D103 Missing docstring in public function
    |
151 | def update_dataset_oligomer(dataset_path, df_total, config):
    |     ^^^^^^^^^^^^^^^^^^^^^^^ D103
152 |     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    |

utils\update_datasets.py:160:5: D103 Missing docstring in public function
    |
160 | def update_dataset_frag(dataset_path, df_total, config):
    |     ^^^^^^^^^^^^^^^^^^^ D103
161 |     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
162 |     dataset = torch.load(dataset_path, map_location=device)
    |

utils\update_datasets.py:169:5: D103 Missing docstring in public function
    |
168 | # save the dataset for the embedding model if already calculated dataset all exists
169 | def save_datasets(config, dataset_train, dataset_val, dataset_test):
    |     ^^^^^^^^^^^^^ D103
170 |     name = config["name"]
171 |     config_dir = config["running_dir"]
    |

utils\update_datasets.py:185:5: D103 Missing docstring in public function
    |
185 | def save_datasets_frag(config, dataset_train, dataset_val, dataset_test):
    |     ^^^^^^^^^^^^^^^^^^ D103
186 |     name = config["name"]
187 |     config_dir = config["running_dir"]
    |

utils\update_datasets.py:210:5: PD901 Avoid using the generic variable name `df` for DataFrames
    |
208 | def update_target_on_dataset(dataset, df, target_name):
209 |     """Update the dataset to have the y as the target property."""
210 |     df = df.copy()
    |     ^^ PD901
211 |     df.index = df["InChIKey"]
212 |     if target_name not in df.columns:
    |

utils\update_datasets.py:236:8: PTH113 `os.path.isfile()` should be replaced by `Path.is_file()`
    |
234 |     df_val = pd.read_csv(config_dir + "df_val.csv", low_memory=False)
235 |     df_test = pd.read_csv(config_dir + "df_test.csv")
236 |     if os.path.isfile(config["dataset_all_path"]):
    |        ^^^^^^^^^^^^^^ PTH113
237 |         dataset_all = torch.load(
238 |             config["dataset_all_path"], map_location=config["device"]
    |

utils\update_datasets.py:248:8: PTH113 `os.path.isfile()` should be replaced by `Path.is_file()`
    |
246 |     save_datasets(config, dataset_train, dataset_val, dataset_test)
247 | 
248 |     if os.path.isfile(config["dataset_all_frag_path"]):
    |        ^^^^^^^^^^^^^^ PTH113
249 |         dataset_all_frag = torch.load(
250 |             config["dataset_all_frag_path"], map_location=config["device"]
    |

Found 5336 errors.
