{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('c:\\\\Users\\\\ma11115\\\\OneDrive - Imperial College London\\\\github_folder\\\\STK_SEARCH\\\\')\n",
    "\n",
    "\n",
    "from stk_search import Searched_space\n",
    "import importlib\n",
    "importlib.reload(Searched_space)\n",
    "import pickle\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stk_search import Database_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\STK_search\\src\\stk_search\\Database_utils.py:68: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_total = pd.read_csv(df_path)\n"
     ]
    }
   ],
   "source": [
    "#%% \n",
    "# Load the searched space\n",
    "df_path = 'data/output/Full_datatset/df_total_new2023_08_20.csv'\n",
    "df_precursors_path = 'Data/output/Prescursor_data/calculation_data_precursor_310823_clean.pkl'\n",
    "df_total, df_precursors = Database_utils.load_data_from_file(df_path, df_precursors_path)\n",
    "#df_total = Database_utils.load_data_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Random Seeds and Reproducibility\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id_x</th>\n",
       "      <th>InChIKey</th>\n",
       "      <th>BB</th>\n",
       "      <th>aI</th>\n",
       "      <th>bI</th>\n",
       "      <th>nBB</th>\n",
       "      <th>_id_y</th>\n",
       "      <th>Excited state energy (eV)</th>\n",
       "      <th>Excited state oscillator strength</th>\n",
       "      <th>Host IP_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LUMO (eV)_5</th>\n",
       "      <th>HOMO_LUMO_GAP (eV)_5</th>\n",
       "      <th>IP (eV)_5</th>\n",
       "      <th>EA (eV)_5</th>\n",
       "      <th>1 Excited state Energy (eV)_5</th>\n",
       "      <th>1 Excited state Osc_5</th>\n",
       "      <th>2 Excited state Energy (eV)_5</th>\n",
       "      <th>2 Excited state Osc_5</th>\n",
       "      <th>3 Excited state Energy (eV)_5</th>\n",
       "      <th>3 Excited state Osc_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64d1217354f281add0a7057d</td>\n",
       "      <td>CLUOOVKTWZALSH-UHFFFAOYSA-N</td>\n",
       "      <td>[{'InChIKey': 'PNLCAIFEPYYUCC-UHFFFAOYSA-N'}, ...</td>\n",
       "      <td>[[0, 0, 0], [5, 5, 1], [1, 1, 0], [5, 5, 0], [...</td>\n",
       "      <td>[[0, 0], [5, 5], [1, 1], [5, 5], [2, 2], [4, 4...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>64d3e80354f281add0b79e76</td>\n",
       "      <td>[3.994, 4.042, 4.08, 4.086, 4.117, 4.135, 4.53...</td>\n",
       "      <td>[0.1243, 0.153, 1.1697, 0.0908, 0.0574, 0.225,...</td>\n",
       "      <td>129.31.64.208</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.9660</td>\n",
       "      <td>2.506486</td>\n",
       "      <td>6.2332</td>\n",
       "      <td>2.3708</td>\n",
       "      <td>3.963</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>4.387</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>4.622</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64d20d2654f281add0ab2f3e</td>\n",
       "      <td>FIAQXLPLTBETIQ-UHFFFAOYSA-N</td>\n",
       "      <td>[{'InChIKey': 'PNLCAIFEPYYUCC-UHFFFAOYSA-N'}, ...</td>\n",
       "      <td>[[0, 0, 0], [1, 1, 0], [2, 2, 0], [3, 3, 0], [...</td>\n",
       "      <td>[[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [0, 0...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>64d2671c54f281add0ab9f94</td>\n",
       "      <td>[3.97, 3.993, 4.033, 4.048, 4.1, 4.468, 4.493,...</td>\n",
       "      <td>[0.1121, 0.7001, 0.151, 0.2114, 0.4041, 0.0137...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.0334</td>\n",
       "      <td>3.799284</td>\n",
       "      <td>6.8301</td>\n",
       "      <td>1.1176</td>\n",
       "      <td>4.976</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>5.181</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>5.464</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64d2150f54f281add0ab3f67</td>\n",
       "      <td>BPPOMYWNHKZIDY-UHFFFAOYSA-N</td>\n",
       "      <td>[{'InChIKey': 'PNLCAIFEPYYUCC-UHFFFAOYSA-N'}, ...</td>\n",
       "      <td>[[5, 5, 0], [5, 5, 1], [0, 0, 0], [1, 1, 0], [...</td>\n",
       "      <td>[[5, 5], [5, 5], [0, 0], [1, 1], [2, 2], [3, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>64d3d13154f281add0b6e336</td>\n",
       "      <td>[3.309, 3.524, 3.539, 3.801, 3.968, 4.022, 4.0...</td>\n",
       "      <td>[0.0925, 0.0002, 0.0114, 0.0521, 0.0396, 0.962...</td>\n",
       "      <td>129.31.64.208</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.2095</td>\n",
       "      <td>2.106172</td>\n",
       "      <td>7.2112</td>\n",
       "      <td>3.5160</td>\n",
       "      <td>3.552</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.559</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4.109</td>\n",
       "      <td>0.0251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64d2202a54f281add0ab4d61</td>\n",
       "      <td>HEARLZDLHXVYEJ-UHFFFAOYSA-N</td>\n",
       "      <td>[{'InChIKey': 'PNLCAIFEPYYUCC-UHFFFAOYSA-N'}, ...</td>\n",
       "      <td>[[0, 0, 0], [5, 5, 0], [5, 5, 1], [1, 1, 0], [...</td>\n",
       "      <td>[[0, 0], [5, 5], [5, 5], [1, 1], [4, 4], [2, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>64d2661554f281add0ab9dae</td>\n",
       "      <td>[3.967, 3.995, 4.052, 4.068, 4.08, 4.475, 4.5,...</td>\n",
       "      <td>[0.1829, 0.5274, 0.5539, 0.151, 0.1505, 0.0058...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.4250</td>\n",
       "      <td>3.394780</td>\n",
       "      <td>6.6286</td>\n",
       "      <td>1.7879</td>\n",
       "      <td>4.907</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>4.965</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>5.214</td>\n",
       "      <td>0.2465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64d2826454f281add0abad9b</td>\n",
       "      <td>BBWANVAHXIOZBW-UHFFFAOYSA-N</td>\n",
       "      <td>[{'InChIKey': 'PNLCAIFEPYYUCC-UHFFFAOYSA-N'}, ...</td>\n",
       "      <td>[[0, 0, 0], [3, 3, 0], [5, 5, 0], [3, 3, 1], [...</td>\n",
       "      <td>[[0, 0], [3, 3], [5, 5], [3, 3], [5, 5], [1, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>64d2827854f281add0abadb7</td>\n",
       "      <td>[3.865, 3.897, 3.913, 3.949, 4.37, 4.397, 4.40...</td>\n",
       "      <td>[0.0999, 0.0303, 0.1944, 0.7833, 0.0004, 0.116...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.4250</td>\n",
       "      <td>3.394780</td>\n",
       "      <td>6.6286</td>\n",
       "      <td>1.7879</td>\n",
       "      <td>4.907</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>4.965</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>5.214</td>\n",
       "      <td>0.2465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      _id_x                     InChIKey  \\\n",
       "0  64d1217354f281add0a7057d  CLUOOVKTWZALSH-UHFFFAOYSA-N   \n",
       "1  64d20d2654f281add0ab2f3e  FIAQXLPLTBETIQ-UHFFFAOYSA-N   \n",
       "2  64d2150f54f281add0ab3f67  BPPOMYWNHKZIDY-UHFFFAOYSA-N   \n",
       "3  64d2202a54f281add0ab4d61  HEARLZDLHXVYEJ-UHFFFAOYSA-N   \n",
       "4  64d2826454f281add0abad9b  BBWANVAHXIOZBW-UHFFFAOYSA-N   \n",
       "\n",
       "                                                  BB  \\\n",
       "0  [{'InChIKey': 'PNLCAIFEPYYUCC-UHFFFAOYSA-N'}, ...   \n",
       "1  [{'InChIKey': 'PNLCAIFEPYYUCC-UHFFFAOYSA-N'}, ...   \n",
       "2  [{'InChIKey': 'PNLCAIFEPYYUCC-UHFFFAOYSA-N'}, ...   \n",
       "3  [{'InChIKey': 'PNLCAIFEPYYUCC-UHFFFAOYSA-N'}, ...   \n",
       "4  [{'InChIKey': 'PNLCAIFEPYYUCC-UHFFFAOYSA-N'}, ...   \n",
       "\n",
       "                                                  aI  \\\n",
       "0  [[0, 0, 0], [5, 5, 1], [1, 1, 0], [5, 5, 0], [...   \n",
       "1  [[0, 0, 0], [1, 1, 0], [2, 2, 0], [3, 3, 0], [...   \n",
       "2  [[5, 5, 0], [5, 5, 1], [0, 0, 0], [1, 1, 0], [...   \n",
       "3  [[0, 0, 0], [5, 5, 0], [5, 5, 1], [1, 1, 0], [...   \n",
       "4  [[0, 0, 0], [3, 3, 0], [5, 5, 0], [3, 3, 1], [...   \n",
       "\n",
       "                                                  bI                 nBB  \\\n",
       "0  [[0, 0], [5, 5], [1, 1], [5, 5], [2, 2], [4, 4...  [1, 1, 1, 1, 1, 1]   \n",
       "1  [[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [0, 0...  [1, 1, 1, 1, 1, 1]   \n",
       "2  [[5, 5], [5, 5], [0, 0], [1, 1], [2, 2], [3, 3...  [1, 1, 1, 1, 1, 1]   \n",
       "3  [[0, 0], [5, 5], [5, 5], [1, 1], [4, 4], [2, 2...  [1, 1, 1, 1, 1, 1]   \n",
       "4  [[0, 0], [3, 3], [5, 5], [3, 3], [5, 5], [1, 1...  [1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                      _id_y  \\\n",
       "0  64d3e80354f281add0b79e76   \n",
       "1  64d2671c54f281add0ab9f94   \n",
       "2  64d3d13154f281add0b6e336   \n",
       "3  64d2661554f281add0ab9dae   \n",
       "4  64d2827854f281add0abadb7   \n",
       "\n",
       "                           Excited state energy (eV)  \\\n",
       "0  [3.994, 4.042, 4.08, 4.086, 4.117, 4.135, 4.53...   \n",
       "1  [3.97, 3.993, 4.033, 4.048, 4.1, 4.468, 4.493,...   \n",
       "2  [3.309, 3.524, 3.539, 3.801, 3.968, 4.022, 4.0...   \n",
       "3  [3.967, 3.995, 4.052, 4.068, 4.08, 4.475, 4.5,...   \n",
       "4  [3.865, 3.897, 3.913, 3.949, 4.37, 4.397, 4.40...   \n",
       "\n",
       "                   Excited state oscillator strength      Host IP_x  ...  \\\n",
       "0  [0.1243, 0.153, 1.1697, 0.0908, 0.0574, 0.225,...  129.31.64.208  ...   \n",
       "1  [0.1121, 0.7001, 0.151, 0.2114, 0.4041, 0.0137...            NaN  ...   \n",
       "2  [0.0925, 0.0002, 0.0114, 0.0521, 0.0396, 0.962...  129.31.64.208  ...   \n",
       "3  [0.1829, 0.5274, 0.5539, 0.151, 0.1505, 0.0058...            NaN  ...   \n",
       "4  [0.0999, 0.0303, 0.1944, 0.7833, 0.0004, 0.116...            NaN  ...   \n",
       "\n",
       "  LUMO (eV)_5 HOMO_LUMO_GAP (eV)_5 IP (eV)_5  EA (eV)_5  \\\n",
       "0     -7.9660             2.506486    6.2332     2.3708   \n",
       "1     -7.0334             3.799284    6.8301     1.1176   \n",
       "2     -9.2095             2.106172    7.2112     3.5160   \n",
       "3     -7.4250             3.394780    6.6286     1.7879   \n",
       "4     -7.4250             3.394780    6.6286     1.7879   \n",
       "\n",
       "   1 Excited state Energy (eV)_5  1 Excited state Osc_5  \\\n",
       "0                          3.963                 0.2318   \n",
       "1                          4.976                 0.0019   \n",
       "2                          3.552                 0.0000   \n",
       "3                          4.907                 0.0069   \n",
       "4                          4.907                 0.0069   \n",
       "\n",
       "   2 Excited state Energy (eV)_5 2 Excited state Osc_5  \\\n",
       "0                          4.387                0.1730   \n",
       "1                          5.181                0.0083   \n",
       "2                          3.559                0.0001   \n",
       "3                          4.965                0.0014   \n",
       "4                          4.965                0.0014   \n",
       "\n",
       "  3 Excited state Energy (eV)_5  3 Excited state Osc_5  \n",
       "0                         4.622                 0.0000  \n",
       "1                         5.464                 0.0025  \n",
       "2                         4.109                 0.0251  \n",
       "3                         5.214                 0.2465  \n",
       "4                         5.214                 0.2465  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-10.4725, -7.966, 2.506486327599, 6.2332, 2.3708],\n",
       " [-10.4725, -7.966, 2.506486327599, 6.2332, 2.3708],\n",
       " [-10.4725, -7.966, 2.506486327599, 6.2332, 2.3708],\n",
       " [-10.4725, -7.966, 2.506486327599, 6.2332, 2.3708],\n",
       " [-10.4725, -7.966, 2.506486327599, 6.2332, 2.3708],\n",
       " [-10.4725, -7.966, 2.506486327599, 6.2332, 2.3708]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_precursors.columns[2:7]\n",
    "Frag_features ={col:df_precursors[col].values for col in df_precursors.columns[2:7]}\n",
    "def get_frag_features(frag_InChIKey, Frag_features=Frag_features):\n",
    "    frag_id = df_precursors[df_precursors['InChIKey']==frag_InChIKey]\n",
    "    if len(frag_id) == 0:\n",
    "        print('No fragment found')\n",
    "        return None\n",
    "    frag_id = frag_id.index[0]\n",
    "    Features = [\n",
    "        Frag_features[col][frag_id] for col in Frag_features.keys()\n",
    "    ]\n",
    "    return Features\n",
    "nodes = [get_frag_features(frag_InChIKey=df_total[f'InChIKey_{x}'][0]) for x in range(6)]\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 1, 1, 2, 2, 3, 3, 4], [1, 0, 2, 1, 3, 2, 4, 3]], [[0], [0], [0], [0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# edge features\n",
    "def get_edge_features(id):\n",
    "    edge_index0, edge_index1 = [], []\n",
    "    bond_fvs = []\n",
    "\n",
    "    for i in range(4):\n",
    "        j=i+1\n",
    "        t=i+2\n",
    "        edge_index0 += [i, j]\n",
    "        edge_index1 += [j, i]\n",
    "        bond_fvs += [[0,]]\n",
    "        #edge_index0 += [i, t]\n",
    "        #edge_index1 += [t, i]\n",
    "        #frag_id = df_precursors[df_precursors['InChIKey']== df_total[f'InChIKey_{j}'][0]].index[0]\n",
    "        #bond_fvs += [[df_precursors['Atom_num'][frag_id]]]\n",
    "\n",
    "    edge_index = [edge_index0, edge_index1]\n",
    "    return edge_index, bond_fvs\n",
    "edge_index, bond_fvs = get_edge_features(0)\n",
    "edge_index, bond_fvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[6, 5], edge_index=[2, 8], edge_attr=[4, 1], y=[1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# convert our data to tensors, which are used for model training\n",
    "mol_id = 0\n",
    "nodes = [get_frag_features(frag_InChIKey=df_total[f'InChIKey_{x}'][mol_id]) for x in range(6)]\n",
    "edge_index, bond_fvs = get_edge_features(mol_id)\n",
    "\n",
    "x = torch.tensor(nodes, dtype=torch.float)\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "edge_attr = torch.tensor(bond_fvs, dtype=torch.float)\n",
    "y = torch.tensor([df_total[f'target'][mol_id]], dtype=torch.float)\n",
    "\n",
    "dmf_data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "dmf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmf_data.validate(raise_on_error=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset,\n",
    "    download_url,\n",
    ")\n",
    "from ogb.utils import smiles2graph\n",
    "\n",
    "\n",
    "class ESOLGraphData(InMemoryDataset):\n",
    "    \"\"\"The ESOL graph dataset using PyG\n",
    "    \"\"\"\n",
    "    # ESOL dataset download link\n",
    "    #raw_url = 'https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/delaney-processed.csv'\n",
    "\n",
    "    def __init__(self, root, transform=None):\n",
    "        super().__init__(root, transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['delaney-processed.csv']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        print('Downloading ESOL dataset...')\n",
    "        #file_path = download_url(self.raw_url, self.raw_dir)\n",
    "\n",
    "    def process(self):\n",
    "        # load raw data from a csv file\n",
    "        df = df_total\n",
    "        InChIKey = df['InChIKey'].values.tolist()\n",
    "        target = df['target'].values.tolist()\n",
    "\n",
    "        # Convert SMILES into graph data\n",
    "        print('Converting SMILES strings into graphs...')\n",
    "        data_list = []\n",
    "        \n",
    "        for mol_id, smi in enumerate(tqdm(InChIKey)):\n",
    "\n",
    "            nodes = [get_frag_features(frag_InChIKey=df_total[f'InChIKey_{x}'][mol_id]) for x in range(6)]\n",
    "            edge_index, bond_fvs = get_edge_features(mol_id)\n",
    "\n",
    "            x = torch.tensor(nodes, dtype=torch.float)\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "            edge_attr = torch.tensor(bond_fvs, dtype=torch.float)\n",
    "            y = torch.tensor([df_total[f'target'][mol_id]], dtype=torch.float)\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "            data_list.append(data)\n",
    "\n",
    "        # save data\n",
    "        torch.save(self.collate(data_list), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ESOL dataset...\n",
      "Converting SMILES strings into graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40975 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40975/40975 [02:15<00:00, 301.84it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = ESOLGraphData(root='data/ESOL', transform=None)\n",
    "dataset = dataset[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "c:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([201])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from deepchem.splits import RandomSplitter\n",
    "\n",
    "# Normalize target to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean()\n",
    "std = dataset.data.y.std()\n",
    "mean, std = mean.item(), std.item()\n",
    "\n",
    "# split data\n",
    "splitter = RandomSplitter()\n",
    "train_idx, valid_idx, test_idx = splitter.split(dataset, frac_train=0.7, frac_valid=0.1, frac_test=0.2)\n",
    "train_dataset = dataset[list(train_idx)].copy()\n",
    "valid_dataset = dataset[list(valid_idx)].copy()\n",
    "test_dataset = dataset[list(test_idx)].copy()\n",
    "train_dataset.data.y = (train_dataset.data.y - mean) / std\n",
    "valid_dataset.data.y = (valid_dataset.data.y - mean) / std\n",
    "test_dataset.data.y = (test_dataset.data.y - mean) / std\n",
    "print(test_dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 6)\n",
    "        self.out = nn.Linear(6, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x=x.squeeze(0)\n",
    "        x = F.relu(x)\n",
    "        #return F.log_softmax(x, dim=1)\n",
    "        return self.out(x).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(5, 16)\n",
      "  (conv2): GCNConv(16, 6)\n",
      "  (out): Linear(in_features=6, out_features=1, bias=True)\n",
      ")\n",
      "tensor([[-10.4725,  -7.9660,   2.5065,   6.2332,   2.3708],\n",
      "        [-10.4725,  -7.9660,   2.5065,   6.2332,   2.3708],\n",
      "        [-10.4725,  -7.9660,   2.5065,   6.2332,   2.3708],\n",
      "        [-10.4725,  -7.9660,   2.5065,   6.2332,   2.3708],\n",
      "        [-10.4725,  -7.9660,   2.5065,   6.2332,   2.3708],\n",
      "        [-10.4725,  -7.9660,   2.5065,   6.2332,   2.3708]])\n",
      "tensor(-1.1190, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "model = GCN()\n",
    "print(model)\n",
    "\n",
    "def visualize_embedding(h, color, epoch=None, loss=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    h = h.detach().cpu().numpy()\n",
    "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
    "    if epoch is not None and loss is not None:\n",
    "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
    "    plt.show()\n",
    "h = model.forward(dataset[0])\n",
    "print(dataset[0].x.float())\n",
    "\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import GRU\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import NNConv, MLP, global_add_pool\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torcheval.metrics.functional import r2_score\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class MPNN(pl.LightningModule):\n",
    "    def __init__(self, hidden_dim, out_dim,\n",
    "                 train_data, valid_data, test_data,\n",
    "                 std, batch_size=32, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.std = std  # std of data's target\n",
    "        self.train_data = train_data\n",
    "        self.valid_data = valid_data\n",
    "        self.test_data = test_data\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        # Initial layers\n",
    "        #self.atom_emb = AtomEncoder(emb_dim=hidden_dim)\n",
    "        #self.bond_emb = BondEncoder(emb_dim=hidden_dim)\n",
    "        # Message passing layers\n",
    "        nn = MLP([hidden_dim, hidden_dim*2, hidden_dim*hidden_dim])\n",
    "        self.conv = GCN(hidden_dim)#NNConv(dataset.num_edge_features,dataset.num_node_features, nn, aggr='mean')#\n",
    "        self.gru = GRU(hidden_dim, hidden_dim)\n",
    "        # Readout layers\n",
    "        self.mlp = MLP([hidden_dim, int(hidden_dim/2), out_dim])\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "\n",
    "        # Initialization\n",
    "        x = data.x\n",
    "        h = x.unsqueeze(0)\n",
    "        edge_attr = data.edge_attr\n",
    "        edge_index = data.edge_index\n",
    "        # Message passing\n",
    "        for i in range(3):\n",
    "\n",
    "\n",
    "            m = F.relu(self.conv(x,edge_index))  # send message and aggregation\n",
    "            #m = F.relu(self.conv(x, data.edge_index, edge_attr))  # send message and aggregation\n",
    "            x, h = self.gru(m.unsqueeze(0), h)  # node update\n",
    "            x = x.squeeze(0)\n",
    "\n",
    "        # Readout\n",
    "        x = global_add_pool(x, data.batch)\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        return x.view(-1)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Here we define the train loop.\n",
    "        \n",
    "        out = self.forward(batch, mode=\"train\")\n",
    "        loss = F.mse_loss(out, batch.y)\n",
    "        self.log(\"Train loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Define validation step. At the end of every epoch, this will be executed\n",
    "        out = self.forward(batch, mode=\"valid\")\n",
    "        loss = F.mse_loss(out * self.std, batch.y * self.std)  # report MSE\n",
    "        #fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        #ax.scatter(batch.y * self.std, out * self.std, s=10)\n",
    "        #ax.set_xlabel(\"Target\")\n",
    "        #ax.set_ylabel(\"Predicted\")\n",
    "       # ax.set_title(\"Validation set\")\n",
    "        #self.logger.experiment.log({\"Validation\": wandb.Image(fig)})\n",
    "        #fig.clf()\n",
    "        #plt.close()\n",
    "        self.log(\"Valid MSE\", loss)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # What to do in test\n",
    "        out = self.forward(batch, mode=\"test\")\n",
    "        loss = F.mse_loss(out * self.std, batch.y * self.std)  # report MSE\n",
    "        R2 = r2_score(out * self.std, batch.y * self.std)\n",
    "        #print(f\"R2 score on train set = {r2_score(train_dataset.y, torch.stack(predicted_data).squeeze(1)):.4f}.\\n\")\n",
    "        self.log(\"Test MSE\", loss)\n",
    "        self.log(\"Test R2\", R2)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Here we configure the optimization algorithm.\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=self.lr\n",
    "        )\n",
    "        return optimizer\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid_data, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:jsz1s3ua) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test MSE</td><td>▁</td></tr><tr><td>Test R2</td><td>▁</td></tr><tr><td>Train loss</td><td>█▆▅▅▄▄▃▃▃▃▂▂▂▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Valid MSE</td><td>█▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test MSE</td><td>0.0985</td></tr><tr><td>Test R2</td><td>-0.06448</td></tr><tr><td>Train loss</td><td>0.07622</td></tr><tr><td>Valid MSE</td><td>0.13349</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>trainer/global_step</td><td>2000</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test1</strong> at: <a href='https://wandb.ai/azzouzi_lab/gnn-test_new/runs/jsz1s3ua' target=\"_blank\">https://wandb.ai/azzouzi_lab/gnn-test_new/runs/jsz1s3ua</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230914_155215-jsz1s3ua\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:jsz1s3ua). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a40b9bd1a44d128dc8ea042bf22035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011277777777932999, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\STK_SEARCH\\wandb\\run-20230914_160215-e3sk4vj2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/azzouzi_lab/gnn-test_new/runs/e3sk4vj2' target=\"_blank\">test1</a></strong> to <a href='https://wandb.ai/azzouzi_lab/gnn-test_new' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/azzouzi_lab/gnn-test_new' target=\"_blank\">https://wandb.ai/azzouzi_lab/gnn-test_new</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/azzouzi_lab/gnn-test_new/runs/e3sk4vj2' target=\"_blank\">https://wandb.ai/azzouzi_lab/gnn-test_new/runs/e3sk4vj2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:398: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | conv | GCN  | 115   \n",
      "1 | gru  | GRU  | 72    \n",
      "2 | mlp  | MLP  | 8     \n",
      "------------------------------\n",
      "195       Trainable params\n",
      "0         Non-trainable params\n",
      "195       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3c387784bd4d20863a9ba7956c080a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "c:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcf22283e1144b18d33d0d2ce413a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\STK_search\\notebooks\\GNN_tests.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     max_epochs \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mmax_epochs\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     logger \u001b[39m=\u001b[39m wandb_logger,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     log_every_n_steps \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Finally! Training a model :)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     model\u001b[39m=\u001b[39;49mgnn_model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Now run test\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mtest(ckpt_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbest\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[1;32m--> 532\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    533\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    534\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[0;32m    562\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[0;32m    563\u001b[0m )\n\u001b[0;32m    565\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    567\u001b[0m     ckpt_path,\n\u001b[0;32m    568\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    569\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    570\u001b[0m )\n\u001b[1;32m--> 571\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1021\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1022\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1023\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1024\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected state \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 202\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance()\n\u001b[0;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:355\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(combined_loader)\n\u001b[0;32m    354\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[0;32m    132\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(data_fetcher)\n\u001b[0;32m    134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:219\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    217\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    218\u001b[0m         \u001b[39m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautomatic_optimization\u001b[39m.\u001b[39;49mrun(trainer\u001b[39m.\u001b[39;49moptimizers[\u001b[39m0\u001b[39;49m], kwargs)\n\u001b[0;32m    220\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_optimization\u001b[39m.\u001b[39mrun(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:188\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m         closure()\n\u001b[0;32m    183\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 188\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[0;32m    190\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[0;32m    191\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:266\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[0;32m    265\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m call\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[0;32m    267\u001b[0m     trainer,\n\u001b[0;32m    268\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    269\u001b[0m     trainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[0;32m    270\u001b[0m     batch_idx,\n\u001b[0;32m    271\u001b[0m     optimizer,\n\u001b[0;32m    272\u001b[0m     train_step_and_backward_closure,\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[0;32m    276\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:146\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 146\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    148\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    149\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\core\\module.py:1270\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[0;32m   1233\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1234\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1239\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer`\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \u001b[39m    calls the optimizer.\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[39m                    pg[\"lr\"] = lr_scale * self.learning_rate\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1270\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:161\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    160\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy\u001b[39m.\u001b[39moptimizer_step(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer, closure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[0;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:231\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[1;32m--> 231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39moptimizer_step(optimizer, model\u001b[39m=\u001b[39mmodel, closure\u001b[39m=\u001b[39mclosure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:116\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 116\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39mstep(closure\u001b[39m=\u001b[39mclosure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch\\optim\\adam.py:121\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[1;32m--> 121\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[0;32m    124\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:103\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[0;32m     92\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     93\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m     optimizer: Optimizer,\n\u001b[0;32m     95\u001b[0m     closure: Callable[[], Any],\n\u001b[0;32m     96\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     97\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer)\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:142\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclosure(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:128\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39menable_grad()\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[1;32m--> 128\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_fn()\n\u001b[0;32m    130\u001b[0m     \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:315\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m trainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\n\u001b[0;32m    314\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m training_step_output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, \u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[0;32m    316\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()\n\u001b[0;32m    318\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_result_cls\u001b[39m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[39m.\u001b[39maccumulate_grad_batches)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:294\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 294\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    297\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:380\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[0;32m    379\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TrainingStep)\n\u001b[1;32m--> 380\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtraining_step(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\STK_search\\notebooks\\GNN_tests.ipynb Cell 19\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     \u001b[39m# Here we define the train loop.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(batch, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(out, batch\u001b[39m.\u001b[39my)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39mTrain loss\u001b[39m\u001b[39m\"\u001b[39m, loss)\n",
      "\u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\STK_search\\notebooks\\GNN_tests.ipynb Cell 19\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# Readout\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m x \u001b[39m=\u001b[39m global_add_pool(x, data\u001b[39m.\u001b[39mbatch)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X23sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch_geometric\\nn\\models\\mlp.py:204\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x, return_emb)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact_first:\n\u001b[0;32m    203\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(x)\n\u001b[1;32m--> 204\u001b[0m x \u001b[39m=\u001b[39m norm(x)\n\u001b[0;32m    205\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact_first:\n\u001b[0;32m    206\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(x)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch_geometric\\nn\\norm\\batch_norm.py:87\u001b[0m, in \u001b[0;36mBatchNorm.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallow_single_element \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mbatch_norm(\n\u001b[0;32m     78\u001b[0m         x,\n\u001b[0;32m     79\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mrunning_mean,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39meps,\n\u001b[0;32m     86\u001b[0m     )\n\u001b[1;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule(x)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[0;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[0;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[0;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m    180\u001b[0m     bn_training,\n\u001b[0;32m    181\u001b[0m     exponential_average_factor,\n\u001b[0;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[0;32m    183\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch\\nn\\functional.py:2448\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2435\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2436\u001b[0m         batch_norm,\n\u001b[0;32m   2437\u001b[0m         (\u001b[39minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2445\u001b[0m         eps\u001b[39m=\u001b[39meps,\n\u001b[0;32m   2446\u001b[0m     )\n\u001b[0;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m-> 2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msize())\n\u001b[0;32m   2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mbatch_norm(\n\u001b[0;32m   2451\u001b[0m     \u001b[39minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39mbackends\u001b[39m.\u001b[39mcudnn\u001b[39m.\u001b[39menabled\n\u001b[0;32m   2452\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch\\nn\\functional.py:2416\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2414\u001b[0m     size_prods \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m size[i \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m]\n\u001b[0;32m   2415\u001b[0m \u001b[39mif\u001b[39;00m size_prods \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 2416\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(size))\n",
      "\u001b[1;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 1])"
     ]
    }
   ],
   "source": [
    "# Here we create an instance of our GNN.\n",
    "# Play around with the hyperparameters!\n",
    "# This will ask you to login to your wandb account\n",
    "import wandb\n",
    "\n",
    "wandb.init(project=\"gnn-test_new\",\n",
    "           config={\n",
    "               \"batch_size\": 100,\n",
    "               \"learning_rate\": 0.001,\n",
    "               \"hidden_size\": 3,\n",
    "               \"max_epochs\": 100,\n",
    "           },\n",
    "           name=\"test1\");\n",
    "gnn_model = MPNN(\n",
    "    hidden_dim=wandb.config[\"hidden_size\"],\n",
    "    out_dim=1,\n",
    "    std=std,\n",
    "    train_data=train_dataset,\n",
    "    valid_data=valid_dataset,\n",
    "    test_data=test_dataset,\n",
    "    lr=wandb.config[\"learning_rate\"],\n",
    "    batch_size=wandb.config[\"batch_size\"]\n",
    ")\n",
    "\n",
    "# Define trainer: How we want to tain the model\n",
    "wandb_logger = WandbLogger()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs = wandb.config[\"max_epochs\"],\n",
    "    logger = wandb_logger,\n",
    "    log_every_n_steps = 50,\n",
    "\n",
    ")\n",
    "\n",
    "# Finally! Training a model :)\n",
    "trainer.fit(\n",
    "    model=gnn_model,\n",
    ")\n",
    "\n",
    "# Now run test\n",
    "results = trainer.test(ckpt_path=\"best\")\n",
    "\n",
    "\n",
    "# Test RMSE\n",
    "test_mse = results[0][\"Test MSE\"]\n",
    "test_rmse = test_mse ** 0.5\n",
    "print(f\"\\nMPNN model performance: RMSE on test set = {test_rmse:.4f}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96a8a3732d44b378e1967290e92a652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on train set = -227.9352.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'test set performance')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise the model performance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torcheval.metrics.functional import r2_score\n",
    "test =train_dataset\n",
    "predicted_data = trainer.predict(trainer.model,test)\n",
    "\n",
    "print(f\"R2 score on train set = {r2_score(test.y, torch.stack(predicted_data).squeeze(1)):.4f}.\\n\")\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(test.y  ,\n",
    "    torch.stack(predicted_data),\n",
    "    alpha=0.3\n",
    ")\n",
    "ax.set_xlabel(\"True values\")\n",
    "ax.set_ylabel(\"Predicted values\")\n",
    "ax.set_title(\"test set performance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GCN.forward() missing 1 required positional argument: 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\STK_search\\notebooks\\GNN_tests.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m h \u001b[39m=\u001b[39m [trainer\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconv(x)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m dataset]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(h[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mcat(h, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\STK_search\\notebooks\\GNN_tests.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m h \u001b[39m=\u001b[39m [trainer\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mconv(x)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m dataset]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(h[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mcat(h, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\BO_polymers\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: GCN.forward() missing 1 required positional argument: 'edge_index'"
     ]
    }
   ],
   "source": [
    "h = [trainer.model.conv(x).reshape(-1,1) for x in dataset]\n",
    "print(h[0].squeeze(1).shape)\n",
    "print(torch.cat(h, dim=1).shape)\n",
    "print(test.y.shape)\n",
    "h=torch.cat(h, dim=1)\n",
    "# run a pca to visualize the embedding\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "h_pca = pca.fit_transform(h.transpose(0,1).detach().cpu().numpy())\n",
    "print(h_pca.shape)\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.scatter(h_pca[:, 0], h_pca[:, 1], s=50,c=dataset.y, cmap=\"Set2\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "print(h_pca.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESOLGraphData(700)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.stack(predicted_data).squeeze(1)-test.y\n",
    "tt=tt.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0280)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.mean()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =train_dataset[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ma11115\\OneDrive - Imperial College London\\github_folder\\STK_search\\notebooks\\GNN_tests.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_features, train_labels \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(data))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ma11115/OneDrive%20-%20Imperial%20College%20London/github_folder/STK_search/notebooks/GNN_tests.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_features\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "data = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "train_features, train_labels = next(iter(data))\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.BatchSampler at 0x2000d1ce680>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
